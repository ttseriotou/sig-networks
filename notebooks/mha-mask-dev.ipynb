{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "2a2ab372-fcac-4506-add6-2cfc51d61ab8",
   "metadata": {},
   "outputs": [],
   "source": [
    "seed = 2023\n",
    "from nlpsig_networks.scripts.swnu_network_functions import obtain_SWNUNetwork_input\n",
    "from nlpsig_networks.utils import obtain_paths_mask, obtain_signatures_mask"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "4a3f950d",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "\n",
    "os.chdir(\"Rumours/\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4e0ad91f-9f08-419e-8119-c93715159d28",
   "metadata": {},
   "source": [
    "## Rumours"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "dff20ec3-c34b-4058-8ec5-ddf94d63e348",
   "metadata": {},
   "outputs": [],
   "source": [
    "%run load_sbert-embeddings.py"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "24fadcec-ab8d-4a2b-b7f5-e746c4ee1f8c",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>id</th>\n",
       "      <th>label</th>\n",
       "      <th>datetime</th>\n",
       "      <th>text</th>\n",
       "      <th>timeline_id</th>\n",
       "      <th>set</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>5.249902e+17</td>\n",
       "      <td>0</td>\n",
       "      <td>2014-10-22 18:26:23</td>\n",
       "      <td>Police have clarified that there were two shoo...</td>\n",
       "      <td>0</td>\n",
       "      <td>train</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>5.249906e+17</td>\n",
       "      <td>0</td>\n",
       "      <td>2014-10-22 18:27:58</td>\n",
       "      <td>@CTVNews you guys \"confirmed\" there were 3 sho...</td>\n",
       "      <td>0</td>\n",
       "      <td>train</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>5.249908e+17</td>\n",
       "      <td>1</td>\n",
       "      <td>2014-10-22 18:28:46</td>\n",
       "      <td>@CTVNews get it right. http://t.co/GHYxMuzPG9</td>\n",
       "      <td>0</td>\n",
       "      <td>train</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>5.249927e+17</td>\n",
       "      <td>1</td>\n",
       "      <td>2014-10-22 18:36:29</td>\n",
       "      <td>RT @CTVNews Police have clarified that there w...</td>\n",
       "      <td>0</td>\n",
       "      <td>train</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>5.250038e+17</td>\n",
       "      <td>1</td>\n",
       "      <td>2014-10-22 19:20:41</td>\n",
       "      <td>@CTVNews @ctvsaskatoon so what happened at Rid...</td>\n",
       "      <td>0</td>\n",
       "      <td>train</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "             id label            datetime  \\\n",
       "0  5.249902e+17     0 2014-10-22 18:26:23   \n",
       "1  5.249906e+17     0 2014-10-22 18:27:58   \n",
       "2  5.249908e+17     1 2014-10-22 18:28:46   \n",
       "3  5.249927e+17     1 2014-10-22 18:36:29   \n",
       "4  5.250038e+17     1 2014-10-22 19:20:41   \n",
       "\n",
       "                                                text timeline_id    set  \n",
       "0  Police have clarified that there were two shoo...           0  train  \n",
       "1  @CTVNews you guys \"confirmed\" there were 3 sho...           0  train  \n",
       "2      @CTVNews get it right. http://t.co/GHYxMuzPG9           0  train  \n",
       "3  RT @CTVNews Police have clarified that there w...           0  train  \n",
       "4  @CTVNews @ctvsaskatoon so what happened at Rid...           0  train  "
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_rumours.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "cd2259de",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "5568"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(df_rumours)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "e1908cc0-4b2b-4c1d-8b17-6c237ed1849a",
   "metadata": {
    "scrolled": true,
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[INFO] Concatenating the embeddings to the dataframe...\n",
      "[INFO] - columns beginning with 'e' denote the full embddings.\n",
      "[INFO] - columns beginning with 'd' denote the dimension reduced embeddings.\n",
      "[INFO] Adding time feature columns into dataframe in `.df`.\n",
      "[INFO] Adding 'time_encoding' feature...\n",
      "[INFO] Adding 'time_diff' feature...\n",
      "[INFO] Adding 'timeline_index' feature...\n",
      "[INFO] Padding ids and storing in `.df_padded` and `.array_padded` attributes.\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "797c3af28c9643aab9736b9ae545fe1d",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/5568 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[INFO] The path was created for each item in the dataframe, by looking at its history, so to include embeddings in the FFN input, we concatenate the embeddings for each sentence / text.\n"
     ]
    }
   ],
   "source": [
    "x_data = obtain_SWNUNetwork_input(\n",
    "    method=\"umap\",\n",
    "    dimension=3,\n",
    "    df=df_rumours,\n",
    "    id_column=\"timeline_id\",\n",
    "    label_column=\"label\",\n",
    "    embeddings=sbert_embeddings,\n",
    "    k=10,\n",
    "    features=[\"time_encoding\", \"timeline_index\"],\n",
    "    standardise_method=None,\n",
    "    include_features_in_path=False,\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "63006582",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "dict_keys(['x_data', 'input_channels', 'embedding_dim', 'num_features'])"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "x_data.keys()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "ecadb0dc",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'path': tensor([[[-7.2296,  2.7356,  8.0972],\n",
       "          [ 0.0000,  0.0000,  0.0000],\n",
       "          [ 0.0000,  0.0000,  0.0000],\n",
       "          ...,\n",
       "          [ 0.0000,  0.0000,  0.0000],\n",
       "          [ 0.0000,  0.0000,  0.0000],\n",
       "          [ 0.0000,  0.0000,  0.0000]],\n",
       " \n",
       "         [[-7.2296,  2.7356,  8.0972],\n",
       "          [-7.4468,  3.6928,  9.9551],\n",
       "          [ 0.0000,  0.0000,  0.0000],\n",
       "          ...,\n",
       "          [ 0.0000,  0.0000,  0.0000],\n",
       "          [ 0.0000,  0.0000,  0.0000],\n",
       "          [ 0.0000,  0.0000,  0.0000]],\n",
       " \n",
       "         [[-7.2296,  2.7356,  8.0972],\n",
       "          [-7.4468,  3.6928,  9.9551],\n",
       "          [-9.0931, 12.8440,  9.0442],\n",
       "          ...,\n",
       "          [ 0.0000,  0.0000,  0.0000],\n",
       "          [ 0.0000,  0.0000,  0.0000],\n",
       "          [ 0.0000,  0.0000,  0.0000]],\n",
       " \n",
       "         ...,\n",
       " \n",
       "         [[-7.1256,  2.5965,  9.4014],\n",
       "          [-5.3229,  6.2228,  9.8129],\n",
       "          [-5.5247,  3.6294,  9.8226],\n",
       "          ...,\n",
       "          [-8.2079,  5.4001, 10.4869],\n",
       "          [-7.0656,  5.3290, 10.1910],\n",
       "          [-6.3481,  5.6492,  8.2465]],\n",
       " \n",
       "         [[-5.3229,  6.2228,  9.8129],\n",
       "          [-5.5247,  3.6294,  9.8226],\n",
       "          [-6.8627,  4.1624,  8.3137],\n",
       "          ...,\n",
       "          [-7.0656,  5.3290, 10.1910],\n",
       "          [-6.3481,  5.6492,  8.2465],\n",
       "          [-6.0434,  5.4135, 10.5972]],\n",
       " \n",
       "         [[-5.5247,  3.6294,  9.8226],\n",
       "          [-6.8627,  4.1624,  8.3137],\n",
       "          [-7.0706,  2.7912, 14.4864],\n",
       "          ...,\n",
       "          [-6.3481,  5.6492,  8.2465],\n",
       "          [-6.0434,  5.4135, 10.5972],\n",
       "          [-6.3322,  5.0021, 11.3597]]], dtype=torch.float64),\n",
       " 'features': tensor([[ 6.4823e-02,  9.3748e-03, -3.3364e-02,  ...,  1.8542e-03,\n",
       "           2.0148e+03,  1.0000e+00],\n",
       "         [-2.9260e-02, -5.3905e-02, -3.9863e-02,  ...,  9.3606e-02,\n",
       "           2.0148e+03,  2.0000e+00],\n",
       "         [-3.1863e-02,  5.5065e-02, -2.4028e-02,  ...,  9.3310e-02,\n",
       "           2.0148e+03,  3.0000e+00],\n",
       "         ...,\n",
       "         [-2.2057e-03,  8.0860e-02, -9.9185e-02,  ..., -2.3929e-02,\n",
       "           2.0148e+03,  2.2000e+01],\n",
       "         [-3.1252e-02,  3.5479e-02,  7.2934e-03,  ..., -1.3536e-02,\n",
       "           2.0148e+03,  2.3000e+01],\n",
       "         [ 1.1187e-02,  8.0548e-02, -4.1098e-02,  ...,  8.9290e-02,\n",
       "           2.0148e+03,  2.4000e+01]])}"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "x_data[\"x_data\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "2abd7518",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([5568, 10, 3])"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "x_data[\"x_data\"][\"path\"].shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "cdee30cb",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[ 6.4823e-02,  9.3748e-03, -3.3364e-02,  ...,  1.8542e-03,\n",
       "          2.0148e+03,  1.0000e+00],\n",
       "        [-2.9260e-02, -5.3905e-02, -3.9863e-02,  ...,  9.3606e-02,\n",
       "          2.0148e+03,  2.0000e+00],\n",
       "        [-3.1863e-02,  5.5065e-02, -2.4028e-02,  ...,  9.3310e-02,\n",
       "          2.0148e+03,  3.0000e+00],\n",
       "        ...,\n",
       "        [-2.2057e-03,  8.0860e-02, -9.9185e-02,  ..., -2.3929e-02,\n",
       "          2.0148e+03,  2.2000e+01],\n",
       "        [-3.1252e-02,  3.5479e-02,  7.2934e-03,  ..., -1.3536e-02,\n",
       "          2.0148e+03,  2.3000e+01],\n",
       "        [ 1.1187e-02,  8.0548e-02, -4.1098e-02,  ...,  8.9290e-02,\n",
       "          2.0148e+03,  2.4000e+01]])"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "x_data[\"x_data\"][\"features\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "65c266e5",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "3"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "x_data[\"input_channels\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "20ebaf67",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "384"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "x_data[\"embedding_dim\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "297955c3",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "2"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "x_data[\"num_features\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "f0b55c30-40af-42b9-9325-a0fcd3547ec0",
   "metadata": {},
   "outputs": [],
   "source": [
    "path = x_data[\"x_data\"][\"path\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "155810f6-0e44-4d7d-a379-fd75d373b5ea",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([5568, 10, 3])"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "path.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "bd0279d2",
   "metadata": {},
   "outputs": [],
   "source": [
    "import signatory"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "5d93c687",
   "metadata": {},
   "outputs": [],
   "source": [
    "signatures = signatory.logsignature(path, 2, stream=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "24dfcc8a",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([5568, 9, 6])"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "signatures.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "b83def21",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[-7.2296,  2.7356,  8.0972],\n",
       "        [ 0.0000,  0.0000,  0.0000],\n",
       "        [ 0.0000,  0.0000,  0.0000],\n",
       "        [ 0.0000,  0.0000,  0.0000],\n",
       "        [ 0.0000,  0.0000,  0.0000],\n",
       "        [ 0.0000,  0.0000,  0.0000],\n",
       "        [ 0.0000,  0.0000,  0.0000],\n",
       "        [ 0.0000,  0.0000,  0.0000],\n",
       "        [ 0.0000,  0.0000,  0.0000],\n",
       "        [ 0.0000,  0.0000,  0.0000]], dtype=torch.float64)"
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "path[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "c6292716",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[ 7.2296, -2.7356, -8.0972,  0.0000,  0.0000,  0.0000],\n",
       "        [ 7.2296, -2.7356, -8.0972,  0.0000,  0.0000,  0.0000],\n",
       "        [ 7.2296, -2.7356, -8.0972,  0.0000,  0.0000,  0.0000],\n",
       "        [ 7.2296, -2.7356, -8.0972,  0.0000,  0.0000,  0.0000],\n",
       "        [ 7.2296, -2.7356, -8.0972,  0.0000,  0.0000,  0.0000],\n",
       "        [ 7.2296, -2.7356, -8.0972,  0.0000,  0.0000,  0.0000],\n",
       "        [ 7.2296, -2.7356, -8.0972,  0.0000,  0.0000,  0.0000],\n",
       "        [ 7.2296, -2.7356, -8.0972,  0.0000,  0.0000,  0.0000],\n",
       "        [ 7.2296, -2.7356, -8.0972,  0.0000,  0.0000,  0.0000]],\n",
       "       dtype=torch.float64)"
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "signatures[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "b39081ce",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[-7.2296,  2.7356,  8.0972],\n",
       "        [-7.4468,  3.6928,  9.9551],\n",
       "        [-9.0931, 12.8440,  9.0442],\n",
       "        [ 0.0000,  0.0000,  0.0000],\n",
       "        [ 0.0000,  0.0000,  0.0000],\n",
       "        [ 0.0000,  0.0000,  0.0000],\n",
       "        [ 0.0000,  0.0000,  0.0000],\n",
       "        [ 0.0000,  0.0000,  0.0000],\n",
       "        [ 0.0000,  0.0000,  0.0000],\n",
       "        [ 0.0000,  0.0000,  0.0000]], dtype=torch.float64)"
      ]
     },
     "execution_count": 22,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "path[2]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "929d040d",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[ -0.2172,   0.9573,   1.8579,   0.0000,   0.0000,   0.0000],\n",
       "        [ -1.8635,  10.1084,   0.9469,  -0.2056,   1.6283,  -8.9369],\n",
       "        [  7.2296,  -2.7356,  -8.0972, -34.1965,   5.7501, -48.5668],\n",
       "        [  7.2296,  -2.7356,  -8.0972, -34.1965,   5.7501, -48.5668],\n",
       "        [  7.2296,  -2.7356,  -8.0972, -34.1965,   5.7501, -48.5668],\n",
       "        [  7.2296,  -2.7356,  -8.0972, -34.1965,   5.7501, -48.5668],\n",
       "        [  7.2296,  -2.7356,  -8.0972, -34.1965,   5.7501, -48.5668],\n",
       "        [  7.2296,  -2.7356,  -8.0972, -34.1965,   5.7501, -48.5668],\n",
       "        [  7.2296,  -2.7356,  -8.0972, -34.1965,   5.7501, -48.5668]],\n",
       "       dtype=torch.float64)"
      ]
     },
     "execution_count": 23,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "signatures[2]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "e04fdd59",
   "metadata": {},
   "outputs": [],
   "source": [
    "stream_dim = signatures.shape[1]\n",
    "lstm_u = torch.sum(signatures, 2)\n",
    "lstm_u_shift = torch.roll(lstm_u, shifts=1, dims=1)\n",
    "lstm_u_shift[:, 0] = -100\n",
    "seq_lengths = torch.sum(torch.eq(lstm_u, lstm_u_shift) == False, 1)\n",
    "\n",
    "seq_lengths, perm_idx = seq_lengths.sort(0, descending=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "c8830153",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "9"
      ]
     },
     "execution_count": 25,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "stream_dim"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "7967693c",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[ -3.6032,  -3.6032,  -3.6032,  ...,  -3.6032,  -3.6032,  -3.6032],\n",
       "        [  2.5980, -13.9378, -13.9378,  ..., -13.9378, -13.9378, -13.9378],\n",
       "        [  2.5980,   1.6776, -80.6164,  ..., -80.6164, -80.6164, -80.6164],\n",
       "        ...,\n",
       "        [  5.8405,   1.6847,  -1.3289,  ...,  10.0744,   8.4509,   3.4485],\n",
       "        [ -2.7856,  -4.7754, -11.6355,  ...,  -1.3128,   0.1892,   0.9920],\n",
       "        [ -2.3138,  -0.4232,  -1.0668,  ...,   2.0493,   5.7191,   6.8993]],\n",
       "       dtype=torch.float64)"
      ]
     },
     "execution_count": 26,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "lstm_u"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "f7840a7d",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[-100.0000,   -3.6032,   -3.6032,  ...,   -3.6032,   -3.6032,\n",
       "           -3.6032],\n",
       "        [-100.0000,    2.5980,  -13.9378,  ...,  -13.9378,  -13.9378,\n",
       "          -13.9378],\n",
       "        [-100.0000,    2.5980,    1.6776,  ...,  -80.6164,  -80.6164,\n",
       "          -80.6164],\n",
       "        ...,\n",
       "        [-100.0000,    5.8405,    1.6847,  ...,    7.0180,   10.0744,\n",
       "            8.4509],\n",
       "        [-100.0000,   -2.7856,   -4.7754,  ...,   -2.8480,   -1.3128,\n",
       "            0.1892],\n",
       "        [-100.0000,   -2.3138,   -0.4232,  ...,    4.1581,    2.0493,\n",
       "            5.7191]], dtype=torch.float64)"
      ]
     },
     "execution_count": 27,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "lstm_u_shift"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "9fca2477",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([1, 2, 3,  ..., 9, 9, 9])"
      ]
     },
     "execution_count": 28,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "torch.sum(torch.eq(lstm_u, lstm_u_shift) == False, 1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "id": "e7e24869",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([1, 2, 3,  ..., 9, 9, 9])"
      ]
     },
     "execution_count": 29,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "torch.sum(obtain_signatures_mask(signatures) == False, 1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "id": "c7cb081d",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 30,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "torch.equal(torch.eq(lstm_u, lstm_u_shift), obtain_signatures_mask(signatures))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "id": "535cd9bd",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 31,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "torch.equal(\n",
    "    torch.sum(torch.eq(lstm_u, lstm_u_shift) == False, 1),\n",
    "    torch.sum(obtain_signatures_mask(signatures) == False, 1),\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9760fab0-d2c8-4651-b95e-fdfaf755fedb",
   "metadata": {},
   "source": [
    "`True` values in the mask are the ones that indicate to MultiheadAttention to ignore in attention calculation."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "id": "6d2aefe3",
   "metadata": {},
   "outputs": [],
   "source": [
    "path_mask = obtain_paths_mask(path)\n",
    "signatures_mask = obtain_signatures_mask(signatures)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "id": "9801f163",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([5568, 10])"
      ]
     },
     "execution_count": 33,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "path_mask.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "id": "c92745bc",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([5568, 9])"
      ]
     },
     "execution_count": 34,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "signatures_mask.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "id": "0b0b3a75",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([False,  True,  True,  True,  True,  True,  True,  True,  True,  True])"
      ]
     },
     "execution_count": 35,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "path_mask[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "id": "1f45ae97",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([False,  True,  True,  True,  True,  True,  True,  True,  True])"
      ]
     },
     "execution_count": 36,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "signatures_mask[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "id": "393a8e83",
   "metadata": {},
   "outputs": [],
   "source": [
    "path_mask_ = torch.sum(path, 2) == 0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "id": "b553656a",
   "metadata": {},
   "outputs": [],
   "source": [
    "signatures_mask_ = path_mask[:, :-1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "id": "f0814d1e",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([False,  True,  True,  True,  True,  True,  True,  True,  True,  True])"
      ]
     },
     "execution_count": 39,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "path_mask_[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "id": "7da36c54",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 40,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "torch.equal(path_mask, path_mask_)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "id": "a586cf62",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 41,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "torch.equal(signatures_mask, signatures_mask_)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "id": "cbbe03bf",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.bool"
      ]
     },
     "execution_count": 42,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "path_mask.dtype"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "id": "c5bdbf15-52da-4cb6-822e-a58dd52ec239",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[-7.2296,  2.7356,  8.0972],\n",
       "        [ 0.0000,  0.0000,  0.0000],\n",
       "        [ 0.0000,  0.0000,  0.0000],\n",
       "        [ 0.0000,  0.0000,  0.0000],\n",
       "        [ 0.0000,  0.0000,  0.0000],\n",
       "        [ 0.0000,  0.0000,  0.0000],\n",
       "        [ 0.0000,  0.0000,  0.0000],\n",
       "        [ 0.0000,  0.0000,  0.0000],\n",
       "        [ 0.0000,  0.0000,  0.0000],\n",
       "        [ 0.0000,  0.0000,  0.0000]], dtype=torch.float64)"
      ]
     },
     "execution_count": 43,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "path[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "id": "fe949afd",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[ 7.2296, -2.7356, -8.0972,  0.0000,  0.0000,  0.0000],\n",
       "        [ 7.2296, -2.7356, -8.0972,  0.0000,  0.0000,  0.0000],\n",
       "        [ 7.2296, -2.7356, -8.0972,  0.0000,  0.0000,  0.0000],\n",
       "        [ 7.2296, -2.7356, -8.0972,  0.0000,  0.0000,  0.0000],\n",
       "        [ 7.2296, -2.7356, -8.0972,  0.0000,  0.0000,  0.0000],\n",
       "        [ 7.2296, -2.7356, -8.0972,  0.0000,  0.0000,  0.0000],\n",
       "        [ 7.2296, -2.7356, -8.0972,  0.0000,  0.0000,  0.0000],\n",
       "        [ 7.2296, -2.7356, -8.0972,  0.0000,  0.0000,  0.0000],\n",
       "        [ 7.2296, -2.7356, -8.0972,  0.0000,  0.0000,  0.0000]],\n",
       "       dtype=torch.float64)"
      ]
     },
     "execution_count": 44,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "signatures[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "id": "c69488a9-dec3-46ca-ade8-11c64324186e",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([False,  True,  True,  True,  True,  True,  True,  True,  True,  True])"
      ]
     },
     "execution_count": 45,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "path_mask[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "id": "2e441b09-6a16-49d4-920b-d01f7acc33d1",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([False,  True,  True,  True,  True,  True,  True,  True,  True])"
      ]
     },
     "execution_count": 46,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "signatures_mask[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "id": "1a3c253c-4385-4dcc-b67f-8d4ed77de2fb",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[-7.2296,  2.7356,  8.0972],\n",
       "        [-7.4468,  3.6928,  9.9551],\n",
       "        [ 0.0000,  0.0000,  0.0000],\n",
       "        [ 0.0000,  0.0000,  0.0000],\n",
       "        [ 0.0000,  0.0000,  0.0000],\n",
       "        [ 0.0000,  0.0000,  0.0000],\n",
       "        [ 0.0000,  0.0000,  0.0000],\n",
       "        [ 0.0000,  0.0000,  0.0000],\n",
       "        [ 0.0000,  0.0000,  0.0000],\n",
       "        [ 0.0000,  0.0000,  0.0000]], dtype=torch.float64)"
      ]
     },
     "execution_count": 47,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "path[1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "id": "b01e9058",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[-0.2172,  0.9573,  1.8579,  0.0000,  0.0000,  0.0000],\n",
       "        [ 7.2296, -2.7356, -8.0972, -3.1634, -5.8367, -1.3345],\n",
       "        [ 7.2296, -2.7356, -8.0972, -3.1634, -5.8367, -1.3345],\n",
       "        [ 7.2296, -2.7356, -8.0972, -3.1634, -5.8367, -1.3345],\n",
       "        [ 7.2296, -2.7356, -8.0972, -3.1634, -5.8367, -1.3345],\n",
       "        [ 7.2296, -2.7356, -8.0972, -3.1634, -5.8367, -1.3345],\n",
       "        [ 7.2296, -2.7356, -8.0972, -3.1634, -5.8367, -1.3345],\n",
       "        [ 7.2296, -2.7356, -8.0972, -3.1634, -5.8367, -1.3345],\n",
       "        [ 7.2296, -2.7356, -8.0972, -3.1634, -5.8367, -1.3345]],\n",
       "       dtype=torch.float64)"
      ]
     },
     "execution_count": 48,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "signatures[1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "id": "fff7e21c-6344-4948-b1b7-0fb234e3fee9",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([False, False,  True,  True,  True,  True,  True,  True,  True,  True])"
      ]
     },
     "execution_count": 49,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "path_mask[1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "id": "4ef1a39d-a37d-4d94-a796-146cab881392",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([False, False,  True,  True,  True,  True,  True,  True,  True])"
      ]
     },
     "execution_count": 50,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "signatures_mask[1]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5c3996f6",
   "metadata": {},
   "source": [
    "## Path mask"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "id": "6f3d090f",
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch.nn as nn\n",
    "\n",
    "mha = nn.MultiheadAttention(\n",
    "    embed_dim=path.shape[2],\n",
    "    num_heads=1,\n",
    "    batch_first=True,\n",
    ").double()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "id": "11f2d8a1",
   "metadata": {},
   "outputs": [],
   "source": [
    "attn_output, attn_output_weights = mha(\n",
    "    path.double(), path.double(), path.double(), key_padding_mask=path_mask\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "id": "5744ef37",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([[-7.2296,  2.7356,  8.0972],\n",
      "        [ 0.0000,  0.0000,  0.0000],\n",
      "        [ 0.0000,  0.0000,  0.0000],\n",
      "        [ 0.0000,  0.0000,  0.0000],\n",
      "        [ 0.0000,  0.0000,  0.0000],\n",
      "        [ 0.0000,  0.0000,  0.0000],\n",
      "        [ 0.0000,  0.0000,  0.0000],\n",
      "        [ 0.0000,  0.0000,  0.0000],\n",
      "        [ 0.0000,  0.0000,  0.0000],\n",
      "        [ 0.0000,  0.0000,  0.0000]], dtype=torch.float64)\n",
      "tensor([False,  True,  True,  True,  True,  True,  True,  True,  True,  True])\n",
      "tensor([[-2.3385, -3.8639,  2.1563],\n",
      "        [-2.3385, -3.8639,  2.1563],\n",
      "        [-2.3385, -3.8639,  2.1563],\n",
      "        [-2.3385, -3.8639,  2.1563],\n",
      "        [-2.3385, -3.8639,  2.1563],\n",
      "        [-2.3385, -3.8639,  2.1563],\n",
      "        [-2.3385, -3.8639,  2.1563],\n",
      "        [-2.3385, -3.8639,  2.1563],\n",
      "        [-2.3385, -3.8639,  2.1563],\n",
      "        [-2.3385, -3.8639,  2.1563]], dtype=torch.float64,\n",
      "       grad_fn=<SelectBackward>)\n"
     ]
    }
   ],
   "source": [
    "i = 0\n",
    "print(path[i])\n",
    "print(path_mask[i])\n",
    "print(attn_output[i])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "id": "f839e9be",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([[-7.2296,  2.7356,  8.0972],\n",
      "        [-7.4468,  3.6928,  9.9551],\n",
      "        [ 0.0000,  0.0000,  0.0000],\n",
      "        [ 0.0000,  0.0000,  0.0000],\n",
      "        [ 0.0000,  0.0000,  0.0000],\n",
      "        [ 0.0000,  0.0000,  0.0000],\n",
      "        [ 0.0000,  0.0000,  0.0000],\n",
      "        [ 0.0000,  0.0000,  0.0000],\n",
      "        [ 0.0000,  0.0000,  0.0000],\n",
      "        [ 0.0000,  0.0000,  0.0000]], dtype=torch.float64)\n",
      "tensor([False, False,  True,  True,  True,  True,  True,  True,  True,  True])\n",
      "tensor([[-2.4279, -4.3203,  2.3048],\n",
      "        [-2.4240, -4.3003,  2.2983],\n",
      "        [-2.4226, -4.2931,  2.2959],\n",
      "        [-2.4226, -4.2931,  2.2959],\n",
      "        [-2.4226, -4.2931,  2.2959],\n",
      "        [-2.4226, -4.2931,  2.2959],\n",
      "        [-2.4226, -4.2931,  2.2959],\n",
      "        [-2.4226, -4.2931,  2.2959],\n",
      "        [-2.4226, -4.2931,  2.2959],\n",
      "        [-2.4226, -4.2931,  2.2959]], dtype=torch.float64,\n",
      "       grad_fn=<SelectBackward>)\n"
     ]
    }
   ],
   "source": [
    "i = 1\n",
    "print(path[i])\n",
    "print(path_mask[i])\n",
    "print(attn_output[i])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "id": "4e68f3fb",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([[-7.2296,  2.7356,  8.0972],\n",
      "        [-7.4468,  3.6928,  9.9551],\n",
      "        [-9.0931, 12.8440,  9.0442],\n",
      "        [ 0.0000,  0.0000,  0.0000],\n",
      "        [ 0.0000,  0.0000,  0.0000],\n",
      "        [ 0.0000,  0.0000,  0.0000],\n",
      "        [ 0.0000,  0.0000,  0.0000],\n",
      "        [ 0.0000,  0.0000,  0.0000],\n",
      "        [ 0.0000,  0.0000,  0.0000],\n",
      "        [ 0.0000,  0.0000,  0.0000]], dtype=torch.float64)\n",
      "tensor([False, False, False,  True,  True,  True,  True,  True,  True,  True])\n",
      "tensor([[-2.4278, -4.3206,  2.3049],\n",
      "        [-2.4239, -4.3006,  2.2984],\n",
      "        [-2.4803, -4.5878,  2.3918],\n",
      "        [-2.2238, -5.6108,  2.7196],\n",
      "        [-2.2238, -5.6108,  2.7196],\n",
      "        [-2.2238, -5.6108,  2.7196],\n",
      "        [-2.2238, -5.6108,  2.7196],\n",
      "        [-2.2238, -5.6108,  2.7196],\n",
      "        [-2.2238, -5.6108,  2.7196],\n",
      "        [-2.2238, -5.6108,  2.7196]], dtype=torch.float64,\n",
      "       grad_fn=<SelectBackward>)\n"
     ]
    }
   ],
   "source": [
    "i = 2\n",
    "print(path[i])\n",
    "print(path_mask[i])\n",
    "print(attn_output[i])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "id": "76953e2c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([[-7.2296,  2.7356,  8.0972],\n",
      "        [-7.4468,  3.6928,  9.9551],\n",
      "        [-9.0931, 12.8440,  9.0442],\n",
      "        [-6.7662,  2.6486,  8.3875],\n",
      "        [-5.3710,  7.5870, 12.4986],\n",
      "        [ 0.0000,  0.0000,  0.0000],\n",
      "        [ 0.0000,  0.0000,  0.0000],\n",
      "        [ 0.0000,  0.0000,  0.0000],\n",
      "        [ 0.0000,  0.0000,  0.0000],\n",
      "        [ 0.0000,  0.0000,  0.0000]], dtype=torch.float64)\n",
      "tensor([False, False, False, False, False,  True,  True,  True,  True,  True])\n",
      "tensor([[-2.3568, -4.2305,  2.2408],\n",
      "        [-2.3613, -4.1863,  2.2317],\n",
      "        [-2.4182, -4.5371,  2.3472],\n",
      "        [-2.3556, -4.2074,  2.2346],\n",
      "        [-2.3724, -4.1854,  2.2383],\n",
      "        [-2.1726, -5.4662,  2.5835],\n",
      "        [-2.1726, -5.4662,  2.5835],\n",
      "        [-2.1726, -5.4662,  2.5835],\n",
      "        [-2.1726, -5.4662,  2.5835],\n",
      "        [-2.1726, -5.4662,  2.5835]], dtype=torch.float64,\n",
      "       grad_fn=<SelectBackward>)\n"
     ]
    }
   ],
   "source": [
    "i = 4\n",
    "print(path[i])\n",
    "print(path_mask[i])\n",
    "print(attn_output[i])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ae9b5792",
   "metadata": {},
   "source": [
    "## Signatures mask"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "id": "5070d2a8",
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch.nn as nn\n",
    "\n",
    "mha = nn.MultiheadAttention(\n",
    "    embed_dim=signatures.shape[2],\n",
    "    num_heads=1,\n",
    "    batch_first=True,\n",
    ").double()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "id": "799731db",
   "metadata": {},
   "outputs": [],
   "source": [
    "attn_output, attn_output_weights = mha(\n",
    "    signatures.double(),\n",
    "    signatures.double(),\n",
    "    signatures.double(),\n",
    "    key_padding_mask=signatures_mask,\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "id": "fe151a73",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([[-7.2296,  2.7356,  8.0972],\n",
      "        [ 0.0000,  0.0000,  0.0000],\n",
      "        [ 0.0000,  0.0000,  0.0000],\n",
      "        [ 0.0000,  0.0000,  0.0000],\n",
      "        [ 0.0000,  0.0000,  0.0000],\n",
      "        [ 0.0000,  0.0000,  0.0000],\n",
      "        [ 0.0000,  0.0000,  0.0000],\n",
      "        [ 0.0000,  0.0000,  0.0000],\n",
      "        [ 0.0000,  0.0000,  0.0000],\n",
      "        [ 0.0000,  0.0000,  0.0000]], dtype=torch.float64)\n",
      "tensor([[ 7.2296, -2.7356, -8.0972,  0.0000,  0.0000,  0.0000],\n",
      "        [ 7.2296, -2.7356, -8.0972,  0.0000,  0.0000,  0.0000],\n",
      "        [ 7.2296, -2.7356, -8.0972,  0.0000,  0.0000,  0.0000],\n",
      "        [ 7.2296, -2.7356, -8.0972,  0.0000,  0.0000,  0.0000],\n",
      "        [ 7.2296, -2.7356, -8.0972,  0.0000,  0.0000,  0.0000],\n",
      "        [ 7.2296, -2.7356, -8.0972,  0.0000,  0.0000,  0.0000],\n",
      "        [ 7.2296, -2.7356, -8.0972,  0.0000,  0.0000,  0.0000],\n",
      "        [ 7.2296, -2.7356, -8.0972,  0.0000,  0.0000,  0.0000],\n",
      "        [ 7.2296, -2.7356, -8.0972,  0.0000,  0.0000,  0.0000]],\n",
      "       dtype=torch.float64)\n",
      "tensor([False,  True,  True,  True,  True,  True,  True,  True,  True])\n",
      "tensor([[ 0.9844,  0.0093, -1.5946, -2.5041,  0.5410, -2.3918],\n",
      "        [ 0.9844,  0.0093, -1.5946, -2.5041,  0.5410, -2.3918],\n",
      "        [ 0.9844,  0.0093, -1.5946, -2.5041,  0.5410, -2.3918],\n",
      "        [ 0.9844,  0.0093, -1.5946, -2.5041,  0.5410, -2.3918],\n",
      "        [ 0.9844,  0.0093, -1.5946, -2.5041,  0.5410, -2.3918],\n",
      "        [ 0.9844,  0.0093, -1.5946, -2.5041,  0.5410, -2.3918],\n",
      "        [ 0.9844,  0.0093, -1.5946, -2.5041,  0.5410, -2.3918],\n",
      "        [ 0.9844,  0.0093, -1.5946, -2.5041,  0.5410, -2.3918],\n",
      "        [ 0.9844,  0.0093, -1.5946, -2.5041,  0.5410, -2.3918]],\n",
      "       dtype=torch.float64, grad_fn=<SelectBackward>)\n"
     ]
    }
   ],
   "source": [
    "i = 0\n",
    "print(path[i])\n",
    "print(signatures[i])\n",
    "print(signatures_mask[i])\n",
    "print(attn_output[i])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "id": "b31204be",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([[-7.2296,  2.7356,  8.0972],\n",
      "        [-7.4468,  3.6928,  9.9551],\n",
      "        [ 0.0000,  0.0000,  0.0000],\n",
      "        [ 0.0000,  0.0000,  0.0000],\n",
      "        [ 0.0000,  0.0000,  0.0000],\n",
      "        [ 0.0000,  0.0000,  0.0000],\n",
      "        [ 0.0000,  0.0000,  0.0000],\n",
      "        [ 0.0000,  0.0000,  0.0000],\n",
      "        [ 0.0000,  0.0000,  0.0000],\n",
      "        [ 0.0000,  0.0000,  0.0000]], dtype=torch.float64)\n",
      "tensor([[-0.2172,  0.9573,  1.8579,  0.0000,  0.0000,  0.0000],\n",
      "        [ 7.2296, -2.7356, -8.0972, -3.1634, -5.8367, -1.3345],\n",
      "        [ 7.2296, -2.7356, -8.0972, -3.1634, -5.8367, -1.3345],\n",
      "        [ 7.2296, -2.7356, -8.0972, -3.1634, -5.8367, -1.3345],\n",
      "        [ 7.2296, -2.7356, -8.0972, -3.1634, -5.8367, -1.3345],\n",
      "        [ 7.2296, -2.7356, -8.0972, -3.1634, -5.8367, -1.3345],\n",
      "        [ 7.2296, -2.7356, -8.0972, -3.1634, -5.8367, -1.3345],\n",
      "        [ 7.2296, -2.7356, -8.0972, -3.1634, -5.8367, -1.3345],\n",
      "        [ 7.2296, -2.7356, -8.0972, -3.1634, -5.8367, -1.3345]],\n",
      "       dtype=torch.float64)\n",
      "tensor([False, False,  True,  True,  True,  True,  True,  True,  True])\n",
      "tensor([[ 2.2384, -0.0223, -1.9074, -1.4464,  2.2830, -1.3908],\n",
      "        [-0.3596,  0.2597,  0.3828,  0.4210, -0.0110,  0.3492],\n",
      "        [-0.3596,  0.2597,  0.3828,  0.4210, -0.0110,  0.3492],\n",
      "        [-0.3596,  0.2597,  0.3828,  0.4210, -0.0110,  0.3492],\n",
      "        [-0.3596,  0.2597,  0.3828,  0.4210, -0.0110,  0.3492],\n",
      "        [-0.3596,  0.2597,  0.3828,  0.4210, -0.0110,  0.3492],\n",
      "        [-0.3596,  0.2597,  0.3828,  0.4210, -0.0110,  0.3492],\n",
      "        [-0.3596,  0.2597,  0.3828,  0.4210, -0.0110,  0.3492],\n",
      "        [-0.3596,  0.2597,  0.3828,  0.4210, -0.0110,  0.3492]],\n",
      "       dtype=torch.float64, grad_fn=<SelectBackward>)\n"
     ]
    }
   ],
   "source": [
    "i = 1\n",
    "print(path[i])\n",
    "print(signatures[i])\n",
    "print(signatures_mask[i])\n",
    "print(attn_output[i])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "id": "975ac9aa",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([[-7.2296,  2.7356,  8.0972],\n",
      "        [-7.4468,  3.6928,  9.9551],\n",
      "        [-9.0931, 12.8440,  9.0442],\n",
      "        [ 0.0000,  0.0000,  0.0000],\n",
      "        [ 0.0000,  0.0000,  0.0000],\n",
      "        [ 0.0000,  0.0000,  0.0000],\n",
      "        [ 0.0000,  0.0000,  0.0000],\n",
      "        [ 0.0000,  0.0000,  0.0000],\n",
      "        [ 0.0000,  0.0000,  0.0000],\n",
      "        [ 0.0000,  0.0000,  0.0000]], dtype=torch.float64)\n",
      "tensor([[ -0.2172,   0.9573,   1.8579,   0.0000,   0.0000,   0.0000],\n",
      "        [ -1.8635,  10.1084,   0.9469,  -0.2056,   1.6283,  -8.9369],\n",
      "        [  7.2296,  -2.7356,  -8.0972, -34.1965,   5.7501, -48.5668],\n",
      "        [  7.2296,  -2.7356,  -8.0972, -34.1965,   5.7501, -48.5668],\n",
      "        [  7.2296,  -2.7356,  -8.0972, -34.1965,   5.7501, -48.5668],\n",
      "        [  7.2296,  -2.7356,  -8.0972, -34.1965,   5.7501, -48.5668],\n",
      "        [  7.2296,  -2.7356,  -8.0972, -34.1965,   5.7501, -48.5668],\n",
      "        [  7.2296,  -2.7356,  -8.0972, -34.1965,   5.7501, -48.5668],\n",
      "        [  7.2296,  -2.7356,  -8.0972, -34.1965,   5.7501, -48.5668]],\n",
      "       dtype=torch.float64)\n",
      "tensor([False, False, False,  True,  True,  True,  True,  True,  True])\n",
      "tensor([[ -9.9860,  11.7804, -10.0563,  -7.6272,  -6.7590,   2.9708],\n",
      "        [ -9.9860,  11.7804, -10.0563,  -7.6272,  -6.7590,   2.9708],\n",
      "        [ -9.9860,  11.7804, -10.0563,  -7.6272,  -6.7590,   2.9708],\n",
      "        [ -9.9860,  11.7804, -10.0563,  -7.6272,  -6.7590,   2.9708],\n",
      "        [ -9.9860,  11.7804, -10.0563,  -7.6272,  -6.7590,   2.9708],\n",
      "        [ -9.9860,  11.7804, -10.0563,  -7.6272,  -6.7590,   2.9708],\n",
      "        [ -9.9860,  11.7804, -10.0563,  -7.6272,  -6.7590,   2.9708],\n",
      "        [ -9.9860,  11.7804, -10.0563,  -7.6272,  -6.7590,   2.9708],\n",
      "        [ -9.9860,  11.7804, -10.0563,  -7.6272,  -6.7590,   2.9708]],\n",
      "       dtype=torch.float64, grad_fn=<SelectBackward>)\n"
     ]
    }
   ],
   "source": [
    "i = 2\n",
    "print(path[i])\n",
    "print(signatures[i])\n",
    "print(signatures_mask[i])\n",
    "print(attn_output[i])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "id": "66ed096a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([[-7.2296,  2.7356,  8.0972],\n",
      "        [-7.4468,  3.6928,  9.9551],\n",
      "        [-9.0931, 12.8440,  9.0442],\n",
      "        [-6.7662,  2.6486,  8.3875],\n",
      "        [-5.3710,  7.5870, 12.4986],\n",
      "        [ 0.0000,  0.0000,  0.0000],\n",
      "        [ 0.0000,  0.0000,  0.0000],\n",
      "        [ 0.0000,  0.0000,  0.0000],\n",
      "        [ 0.0000,  0.0000,  0.0000],\n",
      "        [ 0.0000,  0.0000,  0.0000]], dtype=torch.float64)\n",
      "tensor([[ -0.2172,   0.9573,   1.8579,   0.0000,   0.0000,   0.0000],\n",
      "        [ -1.8635,  10.1084,   0.9469,  -0.2056,   1.6283,  -8.9369],\n",
      "        [  0.4634,  -0.0869,   0.2903,  -2.4666,   1.1384,  -7.4285],\n",
      "        [  1.8586,   4.8514,   4.4014,  -1.2618,   1.8884,  -8.3240],\n",
      "        [  7.2296,  -2.7356,  -8.0972, -21.3409, -21.5464, -21.9455],\n",
      "        [  7.2296,  -2.7356,  -8.0972, -21.3409, -21.5464, -21.9455],\n",
      "        [  7.2296,  -2.7356,  -8.0972, -21.3409, -21.5464, -21.9455],\n",
      "        [  7.2296,  -2.7356,  -8.0972, -21.3409, -21.5464, -21.9455],\n",
      "        [  7.2296,  -2.7356,  -8.0972, -21.3409, -21.5464, -21.9455]],\n",
      "       dtype=torch.float64)\n",
      "tensor([False, False, False, False, False,  True,  True,  True,  True])\n",
      "tensor([[ 3.2356,  3.9230, -5.5195, -0.1767,  5.2371,  3.7944],\n",
      "        [ 3.2356,  3.9230, -5.5195, -0.1767,  5.2371,  3.7944],\n",
      "        [ 3.2356,  3.9230, -5.5195, -0.1767,  5.2371,  3.7944],\n",
      "        [ 3.2356,  3.9230, -5.5195, -0.1767,  5.2371,  3.7944],\n",
      "        [ 3.2356,  3.9230, -5.5195, -0.1767,  5.2371,  3.7944],\n",
      "        [ 3.2356,  3.9230, -5.5195, -0.1767,  5.2371,  3.7944],\n",
      "        [ 3.2356,  3.9230, -5.5195, -0.1767,  5.2371,  3.7944],\n",
      "        [ 3.2356,  3.9230, -5.5195, -0.1767,  5.2371,  3.7944],\n",
      "        [ 3.2356,  3.9230, -5.5195, -0.1767,  5.2371,  3.7944]],\n",
      "       dtype=torch.float64, grad_fn=<SelectBackward>)\n"
     ]
    }
   ],
   "source": [
    "i = 4\n",
    "print(path[i])\n",
    "print(signatures[i])\n",
    "print(signatures_mask[i])\n",
    "print(attn_output[i])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 67,
   "id": "4d1d9d7f",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[ -0.2172,   0.9573,   1.8579,   0.0000,   0.0000,   0.0000],\n",
       "        [ -1.8635,  10.1084,   0.9469,  -0.2056,   1.6283,  -8.9369],\n",
       "        [  0.4634,  -0.0869,   0.2903,  -2.4666,   1.1384,  -7.4285],\n",
       "        [  1.8586,   4.8514,   4.4014,  -1.2618,   1.8884,  -8.3240],\n",
       "        [  7.2296,  -2.7356,  -8.0972, -21.3409, -21.5464, -21.9455],\n",
       "        [  0.0000,  -0.0000,  -0.0000,  -0.0000,  -0.0000,  -0.0000],\n",
       "        [  0.0000,  -0.0000,  -0.0000,  -0.0000,  -0.0000,  -0.0000],\n",
       "        [  0.0000,  -0.0000,  -0.0000,  -0.0000,  -0.0000,  -0.0000],\n",
       "        [  0.0000,  -0.0000,  -0.0000,  -0.0000,  -0.0000,  -0.0000]],\n",
       "       dtype=torch.float64)"
      ]
     },
     "execution_count": 67,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "(signatures * ~signatures_mask.unsqueeze(-1))[i]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 71,
   "id": "8603c260",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([5568, 6])"
      ]
     },
     "execution_count": 71,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "torch.sum(signatures * ~signatures_mask.unsqueeze(-1), dim=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 70,
   "id": "f9f05f95",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([5568, 1])"
      ]
     },
     "execution_count": 70,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "torch.sum(~signatures_mask, -1, keepdim=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 77,
   "id": "1d38bf55",
   "metadata": {},
   "outputs": [],
   "source": [
    "out = torch.sum(signatures * ~signatures_mask.unsqueeze(-1), dim=1) / torch.sum(\n",
    "    ~signatures_mask, -1, keepdim=True\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 81,
   "id": "55fddcb2",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([ 1.4942,  2.6189, -0.1201, -5.0550, -3.3783, -9.3270],\n",
       "       dtype=torch.float64)"
      ]
     },
     "execution_count": 81,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "out[4]"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "nlpsig-networks",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.16"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
