{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "2a2ab372-fcac-4506-add6-2cfc51d61ab8",
   "metadata": {},
   "outputs": [],
   "source": [
    "seed = 2023\n",
    "from nlpsig_networks.scripts.swnu_network_functions import (\n",
    "    obtain_SWNUNetwork_input\n",
    ")\n",
    "from nlpsig_networks.utils import obtain_paths_mask, obtain_signatures_mask"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "4a3f950d",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "os.chdir(\"nlpsig-networks/notebooks/Rumours/\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4e0ad91f-9f08-419e-8119-c93715159d28",
   "metadata": {},
   "source": [
    "## Rumours"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "dff20ec3-c34b-4058-8ec5-ddf94d63e348",
   "metadata": {},
   "outputs": [],
   "source": [
    "%run load_sbert-embeddings.py"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "24fadcec-ab8d-4a2b-b7f5-e746c4ee1f8c",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>id</th>\n",
       "      <th>label</th>\n",
       "      <th>datetime</th>\n",
       "      <th>text</th>\n",
       "      <th>timeline_id</th>\n",
       "      <th>set</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>5.249902e+17</td>\n",
       "      <td>0</td>\n",
       "      <td>2014-10-22 18:26:23</td>\n",
       "      <td>Police have clarified that there were two shoo...</td>\n",
       "      <td>0</td>\n",
       "      <td>train</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>5.249906e+17</td>\n",
       "      <td>0</td>\n",
       "      <td>2014-10-22 18:27:58</td>\n",
       "      <td>@CTVNews you guys \"confirmed\" there were 3 sho...</td>\n",
       "      <td>0</td>\n",
       "      <td>train</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>5.249908e+17</td>\n",
       "      <td>1</td>\n",
       "      <td>2014-10-22 18:28:46</td>\n",
       "      <td>@CTVNews get it right. http://t.co/GHYxMuzPG9</td>\n",
       "      <td>0</td>\n",
       "      <td>train</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>5.249927e+17</td>\n",
       "      <td>1</td>\n",
       "      <td>2014-10-22 18:36:29</td>\n",
       "      <td>RT @CTVNews Police have clarified that there w...</td>\n",
       "      <td>0</td>\n",
       "      <td>train</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>5.250038e+17</td>\n",
       "      <td>1</td>\n",
       "      <td>2014-10-22 19:20:41</td>\n",
       "      <td>@CTVNews @ctvsaskatoon so what happened at Rid...</td>\n",
       "      <td>0</td>\n",
       "      <td>train</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "             id label            datetime  \\\n",
       "0  5.249902e+17     0 2014-10-22 18:26:23   \n",
       "1  5.249906e+17     0 2014-10-22 18:27:58   \n",
       "2  5.249908e+17     1 2014-10-22 18:28:46   \n",
       "3  5.249927e+17     1 2014-10-22 18:36:29   \n",
       "4  5.250038e+17     1 2014-10-22 19:20:41   \n",
       "\n",
       "                                                text timeline_id    set  \n",
       "0  Police have clarified that there were two shoo...           0  train  \n",
       "1  @CTVNews you guys \"confirmed\" there were 3 sho...           0  train  \n",
       "2      @CTVNews get it right. http://t.co/GHYxMuzPG9           0  train  \n",
       "3  RT @CTVNews Police have clarified that there w...           0  train  \n",
       "4  @CTVNews @ctvsaskatoon so what happened at Rid...           0  train  "
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_rumours.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "cd2259de",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "5568"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(df_rumours)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "e1908cc0-4b2b-4c1d-8b17-6c237ed1849a",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[INFO] Concatenating the embeddings to the dataframe...\n",
      "[INFO] - columns beginning with 'e' denote the full embddings.\n",
      "[INFO] - columns beginning with 'd' denote the dimension reduced embeddings.\n",
      "[INFO] Adding time feature columns into dataframe in `.df`.\n",
      "[INFO] Adding 'time_encoding' feature...\n",
      "[INFO] Adding 'time_diff' feature...\n",
      "[INFO] Adding 'timeline_index' feature...\n",
      "[INFO] Padding ids and storing in `.df_padded` and `.array_padded` attributes.\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "fcb5804ab974448d95385f8062c8ca49",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/5568 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[INFO] The path was created for each item in the dataframe, by looking at its history, so to include embeddings in the FFN input, we concatenate the embeddings for each sentence / text.\n"
     ]
    }
   ],
   "source": [
    "x_data = obtain_SWNUNetwork_input(\n",
    "    method=\"umap\",\n",
    "    dimension=3,\n",
    "    df=df_rumours,\n",
    "    id_column='timeline_id',\n",
    "    label_column='label',\n",
    "    embeddings=sbert_embeddings,\n",
    "    k=10,\n",
    "    features=['time_encoding', 'timeline_index'],\n",
    "    standardise_method=None,\n",
    "    include_features_in_path=False,\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "63006582",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "dict_keys(['x_data', 'input_channels', 'embedding_dim', 'num_features'])"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "x_data.keys()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "ecadb0dc",
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'path': tensor([[[-7.2296,  2.7356,  8.0972],\n",
       "          [ 0.0000,  0.0000,  0.0000],\n",
       "          [ 0.0000,  0.0000,  0.0000],\n",
       "          ...,\n",
       "          [ 0.0000,  0.0000,  0.0000],\n",
       "          [ 0.0000,  0.0000,  0.0000],\n",
       "          [ 0.0000,  0.0000,  0.0000]],\n",
       " \n",
       "         [[-7.2296,  2.7356,  8.0972],\n",
       "          [-7.4468,  3.6928,  9.9551],\n",
       "          [ 0.0000,  0.0000,  0.0000],\n",
       "          ...,\n",
       "          [ 0.0000,  0.0000,  0.0000],\n",
       "          [ 0.0000,  0.0000,  0.0000],\n",
       "          [ 0.0000,  0.0000,  0.0000]],\n",
       " \n",
       "         [[-7.2296,  2.7356,  8.0972],\n",
       "          [-7.4468,  3.6928,  9.9551],\n",
       "          [-9.0931, 12.8440,  9.0442],\n",
       "          ...,\n",
       "          [ 0.0000,  0.0000,  0.0000],\n",
       "          [ 0.0000,  0.0000,  0.0000],\n",
       "          [ 0.0000,  0.0000,  0.0000]],\n",
       " \n",
       "         ...,\n",
       " \n",
       "         [[-7.1256,  2.5965,  9.4014],\n",
       "          [-5.3229,  6.2228,  9.8129],\n",
       "          [-5.5247,  3.6294,  9.8226],\n",
       "          ...,\n",
       "          [-8.2079,  5.4001, 10.4869],\n",
       "          [-7.0656,  5.3290, 10.1910],\n",
       "          [-6.3481,  5.6492,  8.2465]],\n",
       " \n",
       "         [[-5.3229,  6.2228,  9.8129],\n",
       "          [-5.5247,  3.6294,  9.8226],\n",
       "          [-6.8627,  4.1624,  8.3137],\n",
       "          ...,\n",
       "          [-7.0656,  5.3290, 10.1910],\n",
       "          [-6.3481,  5.6492,  8.2465],\n",
       "          [-6.0434,  5.4135, 10.5972]],\n",
       " \n",
       "         [[-5.5247,  3.6294,  9.8226],\n",
       "          [-6.8627,  4.1624,  8.3137],\n",
       "          [-7.0706,  2.7912, 14.4864],\n",
       "          ...,\n",
       "          [-6.3481,  5.6492,  8.2465],\n",
       "          [-6.0434,  5.4135, 10.5972],\n",
       "          [-6.3322,  5.0021, 11.3597]]], dtype=torch.float64),\n",
       " 'features': tensor([[ 6.4823e-02,  9.3748e-03, -3.3364e-02,  ...,  1.8542e-03,\n",
       "           2.0148e+03,  1.0000e+00],\n",
       "         [-2.9260e-02, -5.3905e-02, -3.9863e-02,  ...,  9.3606e-02,\n",
       "           2.0148e+03,  2.0000e+00],\n",
       "         [-3.1863e-02,  5.5065e-02, -2.4028e-02,  ...,  9.3310e-02,\n",
       "           2.0148e+03,  3.0000e+00],\n",
       "         ...,\n",
       "         [-2.2057e-03,  8.0860e-02, -9.9185e-02,  ..., -2.3929e-02,\n",
       "           2.0148e+03,  2.2000e+01],\n",
       "         [-3.1252e-02,  3.5479e-02,  7.2934e-03,  ..., -1.3536e-02,\n",
       "           2.0148e+03,  2.3000e+01],\n",
       "         [ 1.1187e-02,  8.0548e-02, -4.1098e-02,  ...,  8.9290e-02,\n",
       "           2.0148e+03,  2.4000e+01]])}"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "x_data[\"x_data\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "2abd7518",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([5568, 10, 3])"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "x_data[\"x_data\"][\"path\"].shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "cdee30cb",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[ 6.4823e-02,  9.3748e-03, -3.3364e-02,  ...,  1.8542e-03,\n",
       "          2.0148e+03,  1.0000e+00],\n",
       "        [-2.9260e-02, -5.3905e-02, -3.9863e-02,  ...,  9.3606e-02,\n",
       "          2.0148e+03,  2.0000e+00],\n",
       "        [-3.1863e-02,  5.5065e-02, -2.4028e-02,  ...,  9.3310e-02,\n",
       "          2.0148e+03,  3.0000e+00],\n",
       "        ...,\n",
       "        [-2.2057e-03,  8.0860e-02, -9.9185e-02,  ..., -2.3929e-02,\n",
       "          2.0148e+03,  2.2000e+01],\n",
       "        [-3.1252e-02,  3.5479e-02,  7.2934e-03,  ..., -1.3536e-02,\n",
       "          2.0148e+03,  2.3000e+01],\n",
       "        [ 1.1187e-02,  8.0548e-02, -4.1098e-02,  ...,  8.9290e-02,\n",
       "          2.0148e+03,  2.4000e+01]])"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "x_data[\"x_data\"][\"features\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "65c266e5",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "3"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "x_data[\"input_channels\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "20ebaf67",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "384"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "x_data[\"embedding_dim\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "297955c3",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "2"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "x_data[\"num_features\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "f0b55c30-40af-42b9-9325-a0fcd3547ec0",
   "metadata": {},
   "outputs": [],
   "source": [
    "path = x_data[\"x_data\"][\"path\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "155810f6-0e44-4d7d-a379-fd75d373b5ea",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([5568, 10, 3])"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "path.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "bd0279d2",
   "metadata": {},
   "outputs": [],
   "source": [
    "import signatory"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "5d93c687",
   "metadata": {},
   "outputs": [],
   "source": [
    "signatures = signatory.logsignature(path, 2, stream=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "24dfcc8a",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([5568, 9, 6])"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "signatures.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "b83def21",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[-7.2296,  2.7356,  8.0972],\n",
       "        [ 0.0000,  0.0000,  0.0000],\n",
       "        [ 0.0000,  0.0000,  0.0000],\n",
       "        [ 0.0000,  0.0000,  0.0000],\n",
       "        [ 0.0000,  0.0000,  0.0000],\n",
       "        [ 0.0000,  0.0000,  0.0000],\n",
       "        [ 0.0000,  0.0000,  0.0000],\n",
       "        [ 0.0000,  0.0000,  0.0000],\n",
       "        [ 0.0000,  0.0000,  0.0000],\n",
       "        [ 0.0000,  0.0000,  0.0000]], dtype=torch.float64)"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "path[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "c6292716",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[ 7.2296, -2.7356, -8.0972,  0.0000,  0.0000,  0.0000],\n",
       "        [ 7.2296, -2.7356, -8.0972,  0.0000,  0.0000,  0.0000],\n",
       "        [ 7.2296, -2.7356, -8.0972,  0.0000,  0.0000,  0.0000],\n",
       "        [ 7.2296, -2.7356, -8.0972,  0.0000,  0.0000,  0.0000],\n",
       "        [ 7.2296, -2.7356, -8.0972,  0.0000,  0.0000,  0.0000],\n",
       "        [ 7.2296, -2.7356, -8.0972,  0.0000,  0.0000,  0.0000],\n",
       "        [ 7.2296, -2.7356, -8.0972,  0.0000,  0.0000,  0.0000],\n",
       "        [ 7.2296, -2.7356, -8.0972,  0.0000,  0.0000,  0.0000],\n",
       "        [ 7.2296, -2.7356, -8.0972,  0.0000,  0.0000,  0.0000]],\n",
       "       dtype=torch.float64)"
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "signatures[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "b39081ce",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[-7.2296,  2.7356,  8.0972],\n",
       "        [-7.4468,  3.6928,  9.9551],\n",
       "        [-9.0931, 12.8440,  9.0442],\n",
       "        [ 0.0000,  0.0000,  0.0000],\n",
       "        [ 0.0000,  0.0000,  0.0000],\n",
       "        [ 0.0000,  0.0000,  0.0000],\n",
       "        [ 0.0000,  0.0000,  0.0000],\n",
       "        [ 0.0000,  0.0000,  0.0000],\n",
       "        [ 0.0000,  0.0000,  0.0000],\n",
       "        [ 0.0000,  0.0000,  0.0000]], dtype=torch.float64)"
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "path[2]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "929d040d",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[ -0.2172,   0.9573,   1.8579,   0.0000,   0.0000,   0.0000],\n",
       "        [ -1.8635,  10.1084,   0.9469,  -0.2056,   1.6283,  -8.9369],\n",
       "        [  7.2296,  -2.7356,  -8.0972, -34.1965,   5.7501, -48.5668],\n",
       "        [  7.2296,  -2.7356,  -8.0972, -34.1965,   5.7501, -48.5668],\n",
       "        [  7.2296,  -2.7356,  -8.0972, -34.1965,   5.7501, -48.5668],\n",
       "        [  7.2296,  -2.7356,  -8.0972, -34.1965,   5.7501, -48.5668],\n",
       "        [  7.2296,  -2.7356,  -8.0972, -34.1965,   5.7501, -48.5668],\n",
       "        [  7.2296,  -2.7356,  -8.0972, -34.1965,   5.7501, -48.5668],\n",
       "        [  7.2296,  -2.7356,  -8.0972, -34.1965,   5.7501, -48.5668]],\n",
       "       dtype=torch.float64)"
      ]
     },
     "execution_count": 22,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "signatures[2]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9760fab0-d2c8-4651-b95e-fdfaf755fedb",
   "metadata": {},
   "source": [
    "`True` values in the mask are the ones that indicate to MultiheadAttention to ignore in attention calculation."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "6d2aefe3",
   "metadata": {},
   "outputs": [],
   "source": [
    "path_mask = obtain_paths_mask(path)\n",
    "signatures_mask = obtain_signatures_mask(signatures)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "id": "9801f163",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([5568, 10])"
      ]
     },
     "execution_count": 36,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "path_mask.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "id": "c92745bc",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([5568, 9])"
      ]
     },
     "execution_count": 37,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "signatures_mask.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "0b0b3a75",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([False,  True,  True,  True,  True,  True,  True,  True,  True,  True])"
      ]
     },
     "execution_count": 28,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "path_mask[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "id": "1f45ae97",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([False,  True,  True,  True,  True,  True,  True,  True,  True])"
      ]
     },
     "execution_count": 29,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "signatures_mask[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "id": "393a8e83",
   "metadata": {},
   "outputs": [],
   "source": [
    "path_mask_ = (torch.sum(path, 2) == 0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "id": "b553656a",
   "metadata": {},
   "outputs": [],
   "source": [
    "signatures_mask_ = path_mask[:,:-1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 300,
   "id": "f0814d1e",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([False,  True,  True,  True,  True,  True,  True,  True,  True])"
      ]
     },
     "execution_count": 300,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "path_mask_[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "id": "7da36c54",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 32,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "torch.equal(path_mask, path_mask_)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "id": "a586cf62",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 33,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "torch.equal(signatures_mask, signatures_mask_)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "id": "cbbe03bf",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.bool"
      ]
     },
     "execution_count": 34,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "path_mask.dtype"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 149,
   "id": "c5bdbf15-52da-4cb6-822e-a58dd52ec239",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[ 2.0148e+03,  1.0000e+00, -7.2296e+00,  2.7356e+00,  8.0972e+00],\n",
       "        [ 0.0000e+00,  0.0000e+00,  0.0000e+00,  0.0000e+00,  0.0000e+00],\n",
       "        [ 0.0000e+00,  0.0000e+00,  0.0000e+00,  0.0000e+00,  0.0000e+00],\n",
       "        [ 0.0000e+00,  0.0000e+00,  0.0000e+00,  0.0000e+00,  0.0000e+00],\n",
       "        [ 0.0000e+00,  0.0000e+00,  0.0000e+00,  0.0000e+00,  0.0000e+00],\n",
       "        [ 0.0000e+00,  0.0000e+00,  0.0000e+00,  0.0000e+00,  0.0000e+00],\n",
       "        [ 0.0000e+00,  0.0000e+00,  0.0000e+00,  0.0000e+00,  0.0000e+00],\n",
       "        [ 0.0000e+00,  0.0000e+00,  0.0000e+00,  0.0000e+00,  0.0000e+00],\n",
       "        [ 0.0000e+00,  0.0000e+00,  0.0000e+00,  0.0000e+00,  0.0000e+00],\n",
       "        [ 0.0000e+00,  0.0000e+00,  0.0000e+00,  0.0000e+00,  0.0000e+00]],\n",
       "       dtype=torch.float64)"
      ]
     },
     "execution_count": 149,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "path[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 150,
   "id": "fe949afd",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[-2.0148e+03, -1.0000e+00,  7.2296e+00, -2.7356e+00, -8.0972e+00,\n",
       "          0.0000e+00,  0.0000e+00,  0.0000e+00,  0.0000e+00,  0.0000e+00,\n",
       "          0.0000e+00,  0.0000e+00,  0.0000e+00,  0.0000e+00,  0.0000e+00],\n",
       "        [-2.0148e+03, -1.0000e+00,  7.2296e+00, -2.7356e+00, -8.0972e+00,\n",
       "          0.0000e+00,  0.0000e+00,  0.0000e+00,  0.0000e+00,  0.0000e+00,\n",
       "          0.0000e+00,  0.0000e+00,  0.0000e+00,  0.0000e+00,  0.0000e+00],\n",
       "        [-2.0148e+03, -1.0000e+00,  7.2296e+00, -2.7356e+00, -8.0972e+00,\n",
       "          0.0000e+00,  0.0000e+00,  0.0000e+00,  0.0000e+00,  0.0000e+00,\n",
       "          0.0000e+00,  0.0000e+00,  0.0000e+00,  0.0000e+00,  0.0000e+00],\n",
       "        [-2.0148e+03, -1.0000e+00,  7.2296e+00, -2.7356e+00, -8.0972e+00,\n",
       "          0.0000e+00,  0.0000e+00,  0.0000e+00,  0.0000e+00,  0.0000e+00,\n",
       "          0.0000e+00,  0.0000e+00,  0.0000e+00,  0.0000e+00,  0.0000e+00],\n",
       "        [-2.0148e+03, -1.0000e+00,  7.2296e+00, -2.7356e+00, -8.0972e+00,\n",
       "          0.0000e+00,  0.0000e+00,  0.0000e+00,  0.0000e+00,  0.0000e+00,\n",
       "          0.0000e+00,  0.0000e+00,  0.0000e+00,  0.0000e+00,  0.0000e+00],\n",
       "        [-2.0148e+03, -1.0000e+00,  7.2296e+00, -2.7356e+00, -8.0972e+00,\n",
       "          0.0000e+00,  0.0000e+00,  0.0000e+00,  0.0000e+00,  0.0000e+00,\n",
       "          0.0000e+00,  0.0000e+00,  0.0000e+00,  0.0000e+00,  0.0000e+00],\n",
       "        [-2.0148e+03, -1.0000e+00,  7.2296e+00, -2.7356e+00, -8.0972e+00,\n",
       "          0.0000e+00,  0.0000e+00,  0.0000e+00,  0.0000e+00,  0.0000e+00,\n",
       "          0.0000e+00,  0.0000e+00,  0.0000e+00,  0.0000e+00,  0.0000e+00],\n",
       "        [-2.0148e+03, -1.0000e+00,  7.2296e+00, -2.7356e+00, -8.0972e+00,\n",
       "          0.0000e+00,  0.0000e+00,  0.0000e+00,  0.0000e+00,  0.0000e+00,\n",
       "          0.0000e+00,  0.0000e+00,  0.0000e+00,  0.0000e+00,  0.0000e+00],\n",
       "        [-2.0148e+03, -1.0000e+00,  7.2296e+00, -2.7356e+00, -8.0972e+00,\n",
       "          0.0000e+00,  0.0000e+00,  0.0000e+00,  0.0000e+00,  0.0000e+00,\n",
       "          0.0000e+00,  0.0000e+00,  0.0000e+00,  0.0000e+00,  0.0000e+00]],\n",
       "       dtype=torch.float64)"
      ]
     },
     "execution_count": 150,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "signatures[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 151,
   "id": "c69488a9-dec3-46ca-ade8-11c64324186e",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([False,  True,  True,  True,  True,  True,  True,  True,  True])"
      ]
     },
     "execution_count": 151,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "mask[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 108,
   "id": "1a3c253c-4385-4dcc-b67f-8d4ed77de2fb",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[ 2.0148e+03,  1.0000e+00, -7.2296e+00,  2.7356e+00,  8.0972e+00],\n",
       "        [ 2.0148e+03,  2.0000e+00, -7.4468e+00,  3.6928e+00,  9.9551e+00],\n",
       "        [ 0.0000e+00,  0.0000e+00,  0.0000e+00,  0.0000e+00,  0.0000e+00],\n",
       "        [ 0.0000e+00,  0.0000e+00,  0.0000e+00,  0.0000e+00,  0.0000e+00],\n",
       "        [ 0.0000e+00,  0.0000e+00,  0.0000e+00,  0.0000e+00,  0.0000e+00],\n",
       "        [ 0.0000e+00,  0.0000e+00,  0.0000e+00,  0.0000e+00,  0.0000e+00],\n",
       "        [ 0.0000e+00,  0.0000e+00,  0.0000e+00,  0.0000e+00,  0.0000e+00],\n",
       "        [ 0.0000e+00,  0.0000e+00,  0.0000e+00,  0.0000e+00,  0.0000e+00],\n",
       "        [ 0.0000e+00,  0.0000e+00,  0.0000e+00,  0.0000e+00,  0.0000e+00],\n",
       "        [ 0.0000e+00,  0.0000e+00,  0.0000e+00,  0.0000e+00,  0.0000e+00]],\n",
       "       dtype=torch.float64)"
      ]
     },
     "execution_count": 108,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "path[1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 152,
   "id": "b01e9058",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[ 3.0124e-06,  1.0000e+00, -2.1716e-01,  9.5729e-01,  1.8579e+00,\n",
       "          0.0000e+00,  0.0000e+00,  0.0000e+00,  0.0000e+00,  0.0000e+00,\n",
       "          0.0000e+00,  0.0000e+00,  0.0000e+00,  0.0000e+00,  0.0000e+00],\n",
       "        [-2.0148e+03, -1.0000e+00,  7.2296e+00, -2.7356e+00, -8.0972e+00,\n",
       "          1.0074e+03, -2.1876e+02,  9.6438e+02,  1.8716e+03,  3.5062e+00,\n",
       "         -8.8913e-01, -3.1197e+00, -3.1634e+00, -5.8367e+00, -1.3345e+00],\n",
       "        [-2.0148e+03, -1.0000e+00,  7.2296e+00, -2.7356e+00, -8.0972e+00,\n",
       "          1.0074e+03, -2.1876e+02,  9.6438e+02,  1.8716e+03,  3.5062e+00,\n",
       "         -8.8913e-01, -3.1197e+00, -3.1634e+00, -5.8367e+00, -1.3345e+00],\n",
       "        [-2.0148e+03, -1.0000e+00,  7.2296e+00, -2.7356e+00, -8.0972e+00,\n",
       "          1.0074e+03, -2.1876e+02,  9.6438e+02,  1.8716e+03,  3.5062e+00,\n",
       "         -8.8913e-01, -3.1197e+00, -3.1634e+00, -5.8367e+00, -1.3345e+00],\n",
       "        [-2.0148e+03, -1.0000e+00,  7.2296e+00, -2.7356e+00, -8.0972e+00,\n",
       "          1.0074e+03, -2.1876e+02,  9.6438e+02,  1.8716e+03,  3.5062e+00,\n",
       "         -8.8913e-01, -3.1197e+00, -3.1634e+00, -5.8367e+00, -1.3345e+00],\n",
       "        [-2.0148e+03, -1.0000e+00,  7.2296e+00, -2.7356e+00, -8.0972e+00,\n",
       "          1.0074e+03, -2.1876e+02,  9.6438e+02,  1.8716e+03,  3.5062e+00,\n",
       "         -8.8913e-01, -3.1197e+00, -3.1634e+00, -5.8367e+00, -1.3345e+00],\n",
       "        [-2.0148e+03, -1.0000e+00,  7.2296e+00, -2.7356e+00, -8.0972e+00,\n",
       "          1.0074e+03, -2.1876e+02,  9.6438e+02,  1.8716e+03,  3.5062e+00,\n",
       "         -8.8913e-01, -3.1197e+00, -3.1634e+00, -5.8367e+00, -1.3345e+00],\n",
       "        [-2.0148e+03, -1.0000e+00,  7.2296e+00, -2.7356e+00, -8.0972e+00,\n",
       "          1.0074e+03, -2.1876e+02,  9.6438e+02,  1.8716e+03,  3.5062e+00,\n",
       "         -8.8913e-01, -3.1197e+00, -3.1634e+00, -5.8367e+00, -1.3345e+00],\n",
       "        [-2.0148e+03, -1.0000e+00,  7.2296e+00, -2.7356e+00, -8.0972e+00,\n",
       "          1.0074e+03, -2.1876e+02,  9.6438e+02,  1.8716e+03,  3.5062e+00,\n",
       "         -8.8913e-01, -3.1197e+00, -3.1634e+00, -5.8367e+00, -1.3345e+00]],\n",
       "       dtype=torch.float64)"
      ]
     },
     "execution_count": 152,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "signatures[1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 153,
   "id": "fff7e21c-6344-4948-b1b7-0fb234e3fee9",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([False, False,  True,  True,  True,  True,  True,  True,  True])"
      ]
     },
     "execution_count": 153,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "mask[1]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5c3996f6",
   "metadata": {},
   "source": [
    "## Path mask"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "id": "6f3d090f",
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch.nn as nn\n",
    "mha = nn.MultiheadAttention(\n",
    "    embed_dim=path.shape[2],\n",
    "    num_heads=1,\n",
    "    batch_first=True,\n",
    ").double()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "id": "11f2d8a1",
   "metadata": {},
   "outputs": [],
   "source": [
    "attn_output, attn_output_weights = mha(path.double(),\n",
    "                                       path.double(),\n",
    "                                       path.double(),\n",
    "                                       key_padding_mask=path_mask)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "id": "5744ef37",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([[-7.2296,  2.7356,  8.0972],\n",
      "        [ 0.0000,  0.0000,  0.0000],\n",
      "        [ 0.0000,  0.0000,  0.0000],\n",
      "        [ 0.0000,  0.0000,  0.0000],\n",
      "        [ 0.0000,  0.0000,  0.0000],\n",
      "        [ 0.0000,  0.0000,  0.0000],\n",
      "        [ 0.0000,  0.0000,  0.0000],\n",
      "        [ 0.0000,  0.0000,  0.0000],\n",
      "        [ 0.0000,  0.0000,  0.0000],\n",
      "        [ 0.0000,  0.0000,  0.0000]], dtype=torch.float64)\n",
      "tensor([False,  True,  True,  True,  True,  True,  True,  True,  True,  True])\n",
      "tensor([[ 4.3150, -2.1866,  4.7752],\n",
      "        [ 4.3150, -2.1866,  4.7752],\n",
      "        [ 4.3150, -2.1866,  4.7752],\n",
      "        [ 4.3150, -2.1866,  4.7752],\n",
      "        [ 4.3150, -2.1866,  4.7752],\n",
      "        [ 4.3150, -2.1866,  4.7752],\n",
      "        [ 4.3150, -2.1866,  4.7752],\n",
      "        [ 4.3150, -2.1866,  4.7752],\n",
      "        [ 4.3150, -2.1866,  4.7752],\n",
      "        [ 4.3150, -2.1866,  4.7752]], dtype=torch.float64,\n",
      "       grad_fn=<SelectBackward>)\n"
     ]
    }
   ],
   "source": [
    "i=0\n",
    "print(path[i])\n",
    "print(path_mask[i])\n",
    "print(attn_output[i])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "id": "f839e9be",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([[-7.2296,  2.7356,  8.0972],\n",
      "        [-7.4468,  3.6928,  9.9551],\n",
      "        [ 0.0000,  0.0000,  0.0000],\n",
      "        [ 0.0000,  0.0000,  0.0000],\n",
      "        [ 0.0000,  0.0000,  0.0000],\n",
      "        [ 0.0000,  0.0000,  0.0000],\n",
      "        [ 0.0000,  0.0000,  0.0000],\n",
      "        [ 0.0000,  0.0000,  0.0000],\n",
      "        [ 0.0000,  0.0000,  0.0000],\n",
      "        [ 0.0000,  0.0000,  0.0000]], dtype=torch.float64)\n",
      "tensor([False, False,  True,  True,  True,  True,  True,  True,  True,  True])\n",
      "tensor([[ 4.4488, -2.4560,  5.1267],\n",
      "        [ 4.4500, -2.4584,  5.1299],\n",
      "        [ 4.4136, -2.3851,  5.0342],\n",
      "        [ 4.4136, -2.3851,  5.0342],\n",
      "        [ 4.4136, -2.3851,  5.0342],\n",
      "        [ 4.4136, -2.3851,  5.0342],\n",
      "        [ 4.4136, -2.3851,  5.0342],\n",
      "        [ 4.4136, -2.3851,  5.0342],\n",
      "        [ 4.4136, -2.3851,  5.0342],\n",
      "        [ 4.4136, -2.3851,  5.0342]], dtype=torch.float64,\n",
      "       grad_fn=<SelectBackward>)\n"
     ]
    }
   ],
   "source": [
    "i=1\n",
    "print(path[i])\n",
    "print(path_mask[i])\n",
    "print(attn_output[i])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "id": "4e68f3fb",
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([[-7.2296,  2.7356,  8.0972],\n",
      "        [-7.4468,  3.6928,  9.9551],\n",
      "        [-9.0931, 12.8440,  9.0442],\n",
      "        [ 0.0000,  0.0000,  0.0000],\n",
      "        [ 0.0000,  0.0000,  0.0000],\n",
      "        [ 0.0000,  0.0000,  0.0000],\n",
      "        [ 0.0000,  0.0000,  0.0000],\n",
      "        [ 0.0000,  0.0000,  0.0000],\n",
      "        [ 0.0000,  0.0000,  0.0000],\n",
      "        [ 0.0000,  0.0000,  0.0000]], dtype=torch.float64)\n",
      "tensor([False, False, False,  True,  True,  True,  True,  True,  True,  True])\n",
      "tensor([[ 4.4488, -2.4560,  5.1267],\n",
      "        [ 4.4500, -2.4584,  5.1299],\n",
      "        [ 4.3267, -2.2101,  4.8059],\n",
      "        [ 4.8140, -1.7748,  5.8232],\n",
      "        [ 4.8140, -1.7748,  5.8232],\n",
      "        [ 4.8140, -1.7748,  5.8232],\n",
      "        [ 4.8140, -1.7748,  5.8232],\n",
      "        [ 4.8140, -1.7748,  5.8232],\n",
      "        [ 4.8140, -1.7748,  5.8232],\n",
      "        [ 4.8140, -1.7748,  5.8232]], dtype=torch.float64,\n",
      "       grad_fn=<SelectBackward>)\n"
     ]
    }
   ],
   "source": [
    "i=2\n",
    "print(path[i])\n",
    "print(path_mask[i])\n",
    "print(attn_output[i])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "id": "76953e2c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([[-7.2296,  2.7356,  8.0972],\n",
      "        [-7.4468,  3.6928,  9.9551],\n",
      "        [-9.0931, 12.8440,  9.0442],\n",
      "        [-6.7662,  2.6486,  8.3875],\n",
      "        [-5.3710,  7.5870, 12.4986],\n",
      "        [ 0.0000,  0.0000,  0.0000],\n",
      "        [ 0.0000,  0.0000,  0.0000],\n",
      "        [ 0.0000,  0.0000,  0.0000],\n",
      "        [ 0.0000,  0.0000,  0.0000],\n",
      "        [ 0.0000,  0.0000,  0.0000]], dtype=torch.float64)\n",
      "tensor([False, False, False, False, False,  True,  True,  True,  True,  True])\n",
      "tensor([[ 4.3171, -2.4032,  4.9670],\n",
      "        [ 4.3217, -2.4011,  4.9583],\n",
      "        [ 4.1344, -2.2620,  4.6543],\n",
      "        [ 4.3273, -2.4105,  4.9804],\n",
      "        [ 4.2305, -2.3234,  4.8004],\n",
      "        [ 4.4062, -2.0321,  5.4916],\n",
      "        [ 4.4062, -2.0321,  5.4916],\n",
      "        [ 4.4062, -2.0321,  5.4916],\n",
      "        [ 4.4062, -2.0321,  5.4916],\n",
      "        [ 4.4062, -2.0321,  5.4916]], dtype=torch.float64,\n",
      "       grad_fn=<SelectBackward>)\n"
     ]
    }
   ],
   "source": [
    "i=4\n",
    "print(path[i])\n",
    "print(path_mask[i])\n",
    "print(attn_output[i])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ae9b5792",
   "metadata": {},
   "source": [
    "## Signatures mask"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "id": "5070d2a8",
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch.nn as nn\n",
    "mha = nn.MultiheadAttention(\n",
    "    embed_dim=signatures.shape[2],\n",
    "    num_heads=1,\n",
    "    batch_first=True,\n",
    ").double()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "id": "799731db",
   "metadata": {},
   "outputs": [],
   "source": [
    "attn_output, attn_output_weights = mha(signatures.double(),\n",
    "                                       signatures.double(),\n",
    "                                       signatures.double(),\n",
    "                                       key_padding_mask=signatures_mask)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "id": "fe151a73",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([[-7.2296,  2.7356,  8.0972],\n",
      "        [ 0.0000,  0.0000,  0.0000],\n",
      "        [ 0.0000,  0.0000,  0.0000],\n",
      "        [ 0.0000,  0.0000,  0.0000],\n",
      "        [ 0.0000,  0.0000,  0.0000],\n",
      "        [ 0.0000,  0.0000,  0.0000],\n",
      "        [ 0.0000,  0.0000,  0.0000],\n",
      "        [ 0.0000,  0.0000,  0.0000],\n",
      "        [ 0.0000,  0.0000,  0.0000],\n",
      "        [ 0.0000,  0.0000,  0.0000]], dtype=torch.float64)\n",
      "tensor([[ 7.2296, -2.7356, -8.0972,  0.0000,  0.0000,  0.0000],\n",
      "        [ 7.2296, -2.7356, -8.0972,  0.0000,  0.0000,  0.0000],\n",
      "        [ 7.2296, -2.7356, -8.0972,  0.0000,  0.0000,  0.0000],\n",
      "        [ 7.2296, -2.7356, -8.0972,  0.0000,  0.0000,  0.0000],\n",
      "        [ 7.2296, -2.7356, -8.0972,  0.0000,  0.0000,  0.0000],\n",
      "        [ 7.2296, -2.7356, -8.0972,  0.0000,  0.0000,  0.0000],\n",
      "        [ 7.2296, -2.7356, -8.0972,  0.0000,  0.0000,  0.0000],\n",
      "        [ 7.2296, -2.7356, -8.0972,  0.0000,  0.0000,  0.0000],\n",
      "        [ 7.2296, -2.7356, -8.0972,  0.0000,  0.0000,  0.0000]],\n",
      "       dtype=torch.float64)\n",
      "tensor([False,  True,  True,  True,  True,  True,  True,  True,  True])\n",
      "tensor([[-2.0814,  3.2314, -1.5500,  4.1111,  2.7368, -1.6808],\n",
      "        [-2.0814,  3.2314, -1.5500,  4.1111,  2.7368, -1.6808],\n",
      "        [-2.0814,  3.2314, -1.5500,  4.1111,  2.7368, -1.6808],\n",
      "        [-2.0814,  3.2314, -1.5500,  4.1111,  2.7368, -1.6808],\n",
      "        [-2.0814,  3.2314, -1.5500,  4.1111,  2.7368, -1.6808],\n",
      "        [-2.0814,  3.2314, -1.5500,  4.1111,  2.7368, -1.6808],\n",
      "        [-2.0814,  3.2314, -1.5500,  4.1111,  2.7368, -1.6808],\n",
      "        [-2.0814,  3.2314, -1.5500,  4.1111,  2.7368, -1.6808],\n",
      "        [-2.0814,  3.2314, -1.5500,  4.1111,  2.7368, -1.6808]],\n",
      "       dtype=torch.float64, grad_fn=<SelectBackward>)\n"
     ]
    }
   ],
   "source": [
    "i=0\n",
    "print(path[i])\n",
    "print(signatures[i])\n",
    "print(signatures_mask[i])\n",
    "print(attn_output[i])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "id": "b31204be",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([[-7.2296,  2.7356,  8.0972],\n",
      "        [-7.4468,  3.6928,  9.9551],\n",
      "        [ 0.0000,  0.0000,  0.0000],\n",
      "        [ 0.0000,  0.0000,  0.0000],\n",
      "        [ 0.0000,  0.0000,  0.0000],\n",
      "        [ 0.0000,  0.0000,  0.0000],\n",
      "        [ 0.0000,  0.0000,  0.0000],\n",
      "        [ 0.0000,  0.0000,  0.0000],\n",
      "        [ 0.0000,  0.0000,  0.0000],\n",
      "        [ 0.0000,  0.0000,  0.0000]], dtype=torch.float64)\n",
      "tensor([[-0.2172,  0.9573,  1.8579,  0.0000,  0.0000,  0.0000],\n",
      "        [ 7.2296, -2.7356, -8.0972, -3.1634, -5.8367, -1.3345],\n",
      "        [ 7.2296, -2.7356, -8.0972, -3.1634, -5.8367, -1.3345],\n",
      "        [ 7.2296, -2.7356, -8.0972, -3.1634, -5.8367, -1.3345],\n",
      "        [ 7.2296, -2.7356, -8.0972, -3.1634, -5.8367, -1.3345],\n",
      "        [ 7.2296, -2.7356, -8.0972, -3.1634, -5.8367, -1.3345],\n",
      "        [ 7.2296, -2.7356, -8.0972, -3.1634, -5.8367, -1.3345],\n",
      "        [ 7.2296, -2.7356, -8.0972, -3.1634, -5.8367, -1.3345],\n",
      "        [ 7.2296, -2.7356, -8.0972, -3.1634, -5.8367, -1.3345]],\n",
      "       dtype=torch.float64)\n",
      "tensor([False, False,  True,  True,  True,  True,  True,  True,  True])\n",
      "tensor([[-2.0739,  3.3507, -0.8124,  4.0361,  2.6648, -1.4468],\n",
      "        [ 0.5209, -0.7456,  0.2919, -0.5671, -0.5292,  0.0367],\n",
      "        [ 0.5209, -0.7456,  0.2919, -0.5671, -0.5292,  0.0367],\n",
      "        [ 0.5209, -0.7456,  0.2919, -0.5671, -0.5292,  0.0367],\n",
      "        [ 0.5209, -0.7456,  0.2919, -0.5671, -0.5292,  0.0367],\n",
      "        [ 0.5209, -0.7456,  0.2919, -0.5671, -0.5292,  0.0367],\n",
      "        [ 0.5209, -0.7456,  0.2919, -0.5671, -0.5292,  0.0367],\n",
      "        [ 0.5209, -0.7456,  0.2919, -0.5671, -0.5292,  0.0367],\n",
      "        [ 0.5209, -0.7456,  0.2919, -0.5671, -0.5292,  0.0367]],\n",
      "       dtype=torch.float64, grad_fn=<SelectBackward>)\n"
     ]
    }
   ],
   "source": [
    "i=1\n",
    "print(path[i])\n",
    "print(signatures[i])\n",
    "print(signatures_mask[i])\n",
    "print(attn_output[i])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "id": "975ac9aa",
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([[-7.2296,  2.7356,  8.0972],\n",
      "        [-7.4468,  3.6928,  9.9551],\n",
      "        [-9.0931, 12.8440,  9.0442],\n",
      "        [ 0.0000,  0.0000,  0.0000],\n",
      "        [ 0.0000,  0.0000,  0.0000],\n",
      "        [ 0.0000,  0.0000,  0.0000],\n",
      "        [ 0.0000,  0.0000,  0.0000],\n",
      "        [ 0.0000,  0.0000,  0.0000],\n",
      "        [ 0.0000,  0.0000,  0.0000],\n",
      "        [ 0.0000,  0.0000,  0.0000]], dtype=torch.float64)\n",
      "tensor([[ -0.2172,   0.9573,   1.8579,   0.0000,   0.0000,   0.0000],\n",
      "        [ -1.8635,  10.1084,   0.9469,  -0.2056,   1.6283,  -8.9369],\n",
      "        [  7.2296,  -2.7356,  -8.0972, -34.1965,   5.7501, -48.5668],\n",
      "        [  7.2296,  -2.7356,  -8.0972, -34.1965,   5.7501, -48.5668],\n",
      "        [  7.2296,  -2.7356,  -8.0972, -34.1965,   5.7501, -48.5668],\n",
      "        [  7.2296,  -2.7356,  -8.0972, -34.1965,   5.7501, -48.5668],\n",
      "        [  7.2296,  -2.7356,  -8.0972, -34.1965,   5.7501, -48.5668],\n",
      "        [  7.2296,  -2.7356,  -8.0972, -34.1965,   5.7501, -48.5668],\n",
      "        [  7.2296,  -2.7356,  -8.0972, -34.1965,   5.7501, -48.5668]],\n",
      "       dtype=torch.float64)\n",
      "tensor([False, False, False,  True,  True,  True,  True,  True,  True])\n",
      "tensor([[  0.8077,  -1.4836,   0.7517,  -1.1093,  -1.2562,   0.0862],\n",
      "        [  0.5643,  -0.8141,   0.3103,  -0.6441,  -0.5826,   0.0615],\n",
      "        [-13.6403,  19.9122,  16.1484,   1.4020,   8.2629,   7.1200],\n",
      "        [-13.6403,  19.9122,  16.1484,   1.4020,   8.2629,   7.1200],\n",
      "        [-13.6403,  19.9122,  16.1484,   1.4020,   8.2629,   7.1200],\n",
      "        [-13.6403,  19.9122,  16.1484,   1.4020,   8.2629,   7.1200],\n",
      "        [-13.6403,  19.9122,  16.1484,   1.4020,   8.2629,   7.1200],\n",
      "        [-13.6403,  19.9122,  16.1484,   1.4020,   8.2629,   7.1200],\n",
      "        [-13.6403,  19.9122,  16.1484,   1.4020,   8.2629,   7.1200]],\n",
      "       dtype=torch.float64, grad_fn=<SelectBackward>)\n"
     ]
    }
   ],
   "source": [
    "i=2\n",
    "print(path[i])\n",
    "print(signatures[i])\n",
    "print(signatures_mask[i])\n",
    "print(attn_output[i])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "id": "66ed096a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([[-7.2296,  2.7356,  8.0972],\n",
      "        [-7.4468,  3.6928,  9.9551],\n",
      "        [-9.0931, 12.8440,  9.0442],\n",
      "        [-6.7662,  2.6486,  8.3875],\n",
      "        [-5.3710,  7.5870, 12.4986],\n",
      "        [ 0.0000,  0.0000,  0.0000],\n",
      "        [ 0.0000,  0.0000,  0.0000],\n",
      "        [ 0.0000,  0.0000,  0.0000],\n",
      "        [ 0.0000,  0.0000,  0.0000],\n",
      "        [ 0.0000,  0.0000,  0.0000]], dtype=torch.float64)\n",
      "tensor([[ -0.2172,   0.9573,   1.8579,   0.0000,   0.0000,   0.0000],\n",
      "        [ -1.8635,  10.1084,   0.9469,  -0.2056,   1.6283,  -8.9369],\n",
      "        [  0.4634,  -0.0869,   0.2903,  -2.4666,   1.1384,  -7.4285],\n",
      "        [  1.8586,   4.8514,   4.4014,  -1.2618,   1.8884,  -8.3240],\n",
      "        [  7.2296,  -2.7356,  -8.0972, -21.3409, -21.5464, -21.9455],\n",
      "        [  7.2296,  -2.7356,  -8.0972, -21.3409, -21.5464, -21.9455],\n",
      "        [  7.2296,  -2.7356,  -8.0972, -21.3409, -21.5464, -21.9455],\n",
      "        [  7.2296,  -2.7356,  -8.0972, -21.3409, -21.5464, -21.9455],\n",
      "        [  7.2296,  -2.7356,  -8.0972, -21.3409, -21.5464, -21.9455]],\n",
      "       dtype=torch.float64)\n",
      "tensor([False, False, False, False, False,  True,  True,  True,  True])\n",
      "tensor([[-2.3748,  3.6588,  4.0337,  1.1972,  1.4506,  0.8043],\n",
      "        [ 0.5611, -0.8095,  0.3148, -0.6431, -0.5807,  0.0628],\n",
      "        [-5.6438,  8.9313,  7.3147,  3.6797,  4.2341,  1.4925],\n",
      "        [ 0.3325, -0.4528,  0.5786, -0.4908, -0.4070,  0.1182],\n",
      "        [-5.6642,  8.9634,  7.3370,  3.6946,  4.2502,  1.4969],\n",
      "        [-5.6642,  8.9634,  7.3370,  3.6946,  4.2502,  1.4969],\n",
      "        [-5.6642,  8.9634,  7.3370,  3.6946,  4.2502,  1.4969],\n",
      "        [-5.6642,  8.9634,  7.3370,  3.6946,  4.2502,  1.4969],\n",
      "        [-5.6642,  8.9634,  7.3370,  3.6946,  4.2502,  1.4969]],\n",
      "       dtype=torch.float64, grad_fn=<SelectBackward>)\n"
     ]
    }
   ],
   "source": [
    "i=4\n",
    "print(path[i])\n",
    "print(signatures[i])\n",
    "print(signatures_mask[i])\n",
    "print(attn_output[i])"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "nlpsig-networks",
   "language": "python",
   "name": "nlpsig-networks"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.16"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
