{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pickle\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import re\n",
    "\n",
    "seed = 2023"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "device(type='cuda')"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import torch\n",
    "\n",
    "# set device\n",
    "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "device"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "from nlpsig_networks.scripts.ffn_baseline_functions import (\n",
    "    ffn_hyperparameter_search,\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "output_dir = \"talklife_moc_output\"\n",
    "if not os.path.isdir(output_dir):\n",
    "    os.makedirs(output_dir)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Talklife MoC"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "%run load_talklifemoc.py"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "%run load_sbert-embeddings.py"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([18604, 384])"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "sbert_embeddings.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Baseline: FFN"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "num_epochs = 100\n",
    "hidden_dim_sizes = [[64,64],[128,128],[256,256],[512, 512]]\n",
    "dropout_rates = [0.1, 0.2]\n",
    "learning_rates = [1e-3, 1e-4, 5e-4]\n",
    "seeds = [1, 12, 123]\n",
    "loss = \"focal\"\n",
    "gamma = 2\n",
    "validation_metric = \"f1\"\n",
    "patience = 5"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "#create indices for kfold\n",
    "fold_col_names = [c for c in df.columns if 'fold' in c ]\n",
    "fold_list = []\n",
    "for foldc in fold_col_names:\n",
    "    fold_list.append((df[df[foldc]=='train'].index, df[df[foldc]=='dev'].index, df[df[foldc]=='test'].index))\n",
    "fold_list = tuple(fold_list)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "35de71c568f54b3d80b27797c2095c84",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/3 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "888f0f7512604d6892f70c074a480e6c",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/2 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "3dbaa9303bc24c148dcfc9c2052a22e1",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/3 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[10], line 1\u001b[0m\n\u001b[0;32m----> 1\u001b[0m ffn_current, best_ffn_current, _, __ \u001b[38;5;241m=\u001b[39m \u001b[43mffn_hyperparameter_search\u001b[49m\u001b[43m(\u001b[49m\u001b[43m \u001b[49m\n\u001b[1;32m      2\u001b[0m \u001b[43m    \u001b[49m\u001b[43mnum_epochs\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mnum_epochs\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m      3\u001b[0m \u001b[43m    \u001b[49m\u001b[43mx_data\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43msbert_embeddings\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m      4\u001b[0m \u001b[43m    \u001b[49m\u001b[43my_data\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43my_data\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m      5\u001b[0m \u001b[43m    \u001b[49m\u001b[43mhidden_dim_sizes\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mhidden_dim_sizes\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m      6\u001b[0m \u001b[43m    \u001b[49m\u001b[43moutput_dim\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43moutput_dim\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m      7\u001b[0m \u001b[43m    \u001b[49m\u001b[43mdropout_rates\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mdropout_rates\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m      8\u001b[0m \u001b[43m    \u001b[49m\u001b[43mlearning_rates\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mlearning_rates\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m      9\u001b[0m \u001b[43m    \u001b[49m\u001b[43mseeds\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mseeds\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m     10\u001b[0m \u001b[43m    \u001b[49m\u001b[43mloss\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mloss\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m     11\u001b[0m \u001b[43m    \u001b[49m\u001b[43mgamma\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mgamma\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m     12\u001b[0m \u001b[43m    \u001b[49m\u001b[43mdevice\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mdevice\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m     13\u001b[0m \u001b[43m    \u001b[49m\u001b[43msplit_ids\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43;01mNone\u001b[39;49;00m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\n\u001b[1;32m     14\u001b[0m \u001b[43m    \u001b[49m\u001b[43msplit_indices\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mfold_list\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m     15\u001b[0m \u001b[43m    \u001b[49m\u001b[43mk_fold\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43;01mTrue\u001b[39;49;00m\u001b[43m,\u001b[49m\n\u001b[1;32m     16\u001b[0m \u001b[43m    \u001b[49m\u001b[43mpatience\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mpatience\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m     17\u001b[0m \u001b[43m    \u001b[49m\u001b[43mvalidation_metric\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mvalidation_metric\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m     18\u001b[0m \u001b[43m    \u001b[49m\u001b[43mresults_output\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43m \u001b[49m\u001b[38;5;124;43mf\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;132;43;01m{\u001b[39;49;00m\u001b[43moutput_dir\u001b[49m\u001b[38;5;132;43;01m}\u001b[39;49;00m\u001b[38;5;124;43m/ffn_current_focal_\u001b[39;49m\u001b[38;5;132;43;01m{\u001b[39;49;00m\u001b[43mgamma\u001b[49m\u001b[38;5;132;43;01m}\u001b[39;49;00m\u001b[38;5;124;43m.csv\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m,\u001b[49m\n\u001b[1;32m     19\u001b[0m \u001b[43m    \u001b[49m\u001b[43mverbose\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43;01mFalse\u001b[39;49;00m\n\u001b[1;32m     20\u001b[0m \u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m~/nlpsig-networks/nlpsig_networks/scripts/ffn_baseline_functions.py:260\u001b[0m, in \u001b[0;36mffn_hyperparameter_search\u001b[0;34m(num_epochs, x_data, y_data, output_dim, hidden_dim_sizes, dropout_rates, learning_rates, seeds, loss, gamma, device, batch_size, data_split_seed, split_ids, split_indices, k_fold, n_splits, patience, validation_metric, results_output, verbose)\u001b[0m\n\u001b[1;32m    <a href='file:///homes/tt003/nlpsig-networks/nlpsig_networks/scripts/ffn_baseline_functions.py?line=257'>258</a>\u001b[0m verbose_model \u001b[39m=\u001b[39m verbose\n\u001b[1;32m    <a href='file:///homes/tt003/nlpsig-networks/nlpsig_networks/scripts/ffn_baseline_functions.py?line=258'>259</a>\u001b[0m \u001b[39mfor\u001b[39;00m seed \u001b[39min\u001b[39;00m seeds:\n\u001b[0;32m--> <a href='file:///homes/tt003/nlpsig-networks/nlpsig_networks/scripts/ffn_baseline_functions.py?line=259'>260</a>\u001b[0m     _, results \u001b[39m=\u001b[39m implement_ffn(\n\u001b[1;32m    <a href='file:///homes/tt003/nlpsig-networks/nlpsig_networks/scripts/ffn_baseline_functions.py?line=260'>261</a>\u001b[0m         num_epochs\u001b[39m=\u001b[39;49mnum_epochs,\n\u001b[1;32m    <a href='file:///homes/tt003/nlpsig-networks/nlpsig_networks/scripts/ffn_baseline_functions.py?line=261'>262</a>\u001b[0m         x_data\u001b[39m=\u001b[39;49mx_data,\n\u001b[1;32m    <a href='file:///homes/tt003/nlpsig-networks/nlpsig_networks/scripts/ffn_baseline_functions.py?line=262'>263</a>\u001b[0m         y_data\u001b[39m=\u001b[39;49my_data,\n\u001b[1;32m    <a href='file:///homes/tt003/nlpsig-networks/nlpsig_networks/scripts/ffn_baseline_functions.py?line=263'>264</a>\u001b[0m         hidden_dim\u001b[39m=\u001b[39;49mhidden_dim,\n\u001b[1;32m    <a href='file:///homes/tt003/nlpsig-networks/nlpsig_networks/scripts/ffn_baseline_functions.py?line=264'>265</a>\u001b[0m         output_dim\u001b[39m=\u001b[39;49moutput_dim,\n\u001b[1;32m    <a href='file:///homes/tt003/nlpsig-networks/nlpsig_networks/scripts/ffn_baseline_functions.py?line=265'>266</a>\u001b[0m         dropout_rate\u001b[39m=\u001b[39;49mdropout,\n\u001b[1;32m    <a href='file:///homes/tt003/nlpsig-networks/nlpsig_networks/scripts/ffn_baseline_functions.py?line=266'>267</a>\u001b[0m         learning_rate\u001b[39m=\u001b[39;49mlr,\n\u001b[1;32m    <a href='file:///homes/tt003/nlpsig-networks/nlpsig_networks/scripts/ffn_baseline_functions.py?line=267'>268</a>\u001b[0m         seed\u001b[39m=\u001b[39;49mseed,\n\u001b[1;32m    <a href='file:///homes/tt003/nlpsig-networks/nlpsig_networks/scripts/ffn_baseline_functions.py?line=268'>269</a>\u001b[0m         loss\u001b[39m=\u001b[39;49mloss,\n\u001b[1;32m    <a href='file:///homes/tt003/nlpsig-networks/nlpsig_networks/scripts/ffn_baseline_functions.py?line=269'>270</a>\u001b[0m         gamma\u001b[39m=\u001b[39;49mgamma,\n\u001b[1;32m    <a href='file:///homes/tt003/nlpsig-networks/nlpsig_networks/scripts/ffn_baseline_functions.py?line=270'>271</a>\u001b[0m         device\u001b[39m=\u001b[39;49mdevice,\n\u001b[1;32m    <a href='file:///homes/tt003/nlpsig-networks/nlpsig_networks/scripts/ffn_baseline_functions.py?line=271'>272</a>\u001b[0m         batch_size\u001b[39m=\u001b[39;49mbatch_size,\n\u001b[1;32m    <a href='file:///homes/tt003/nlpsig-networks/nlpsig_networks/scripts/ffn_baseline_functions.py?line=272'>273</a>\u001b[0m         data_split_seed\u001b[39m=\u001b[39;49mdata_split_seed,\n\u001b[1;32m    <a href='file:///homes/tt003/nlpsig-networks/nlpsig_networks/scripts/ffn_baseline_functions.py?line=273'>274</a>\u001b[0m         split_ids\u001b[39m=\u001b[39;49msplit_ids,\n\u001b[1;32m    <a href='file:///homes/tt003/nlpsig-networks/nlpsig_networks/scripts/ffn_baseline_functions.py?line=274'>275</a>\u001b[0m         split_indices\u001b[39m=\u001b[39;49msplit_indices,\n\u001b[1;32m    <a href='file:///homes/tt003/nlpsig-networks/nlpsig_networks/scripts/ffn_baseline_functions.py?line=275'>276</a>\u001b[0m         k_fold\u001b[39m=\u001b[39;49mk_fold,\n\u001b[1;32m    <a href='file:///homes/tt003/nlpsig-networks/nlpsig_networks/scripts/ffn_baseline_functions.py?line=276'>277</a>\u001b[0m         n_splits\u001b[39m=\u001b[39;49mn_splits,\n\u001b[1;32m    <a href='file:///homes/tt003/nlpsig-networks/nlpsig_networks/scripts/ffn_baseline_functions.py?line=277'>278</a>\u001b[0m         patience\u001b[39m=\u001b[39;49mpatience,\n\u001b[1;32m    <a href='file:///homes/tt003/nlpsig-networks/nlpsig_networks/scripts/ffn_baseline_functions.py?line=278'>279</a>\u001b[0m         verbose_training\u001b[39m=\u001b[39;49m\u001b[39mFalse\u001b[39;49;00m,\n\u001b[1;32m    <a href='file:///homes/tt003/nlpsig-networks/nlpsig_networks/scripts/ffn_baseline_functions.py?line=279'>280</a>\u001b[0m         verbose_results\u001b[39m=\u001b[39;49mverbose,\n\u001b[1;32m    <a href='file:///homes/tt003/nlpsig-networks/nlpsig_networks/scripts/ffn_baseline_functions.py?line=280'>281</a>\u001b[0m         verbose_model\u001b[39m=\u001b[39;49mverbose_model,\n\u001b[1;32m    <a href='file:///homes/tt003/nlpsig-networks/nlpsig_networks/scripts/ffn_baseline_functions.py?line=281'>282</a>\u001b[0m     )\n\u001b[1;32m    <a href='file:///homes/tt003/nlpsig-networks/nlpsig_networks/scripts/ffn_baseline_functions.py?line=283'>284</a>\u001b[0m     \u001b[39m# save metric that we want to validate on\u001b[39;00m\n\u001b[1;32m    <a href='file:///homes/tt003/nlpsig-networks/nlpsig_networks/scripts/ffn_baseline_functions.py?line=284'>285</a>\u001b[0m     \u001b[39m# take mean of performance on the folds\u001b[39;00m\n\u001b[1;32m    <a href='file:///homes/tt003/nlpsig-networks/nlpsig_networks/scripts/ffn_baseline_functions.py?line=285'>286</a>\u001b[0m     \u001b[39m# if k_fold=False, return performance for seed\u001b[39;00m\n\u001b[1;32m    <a href='file:///homes/tt003/nlpsig-networks/nlpsig_networks/scripts/ffn_baseline_functions.py?line=286'>287</a>\u001b[0m     scores\u001b[39m.\u001b[39mappend(results[\u001b[39mf\u001b[39m\u001b[39m\"\u001b[39m\u001b[39mvalid_\u001b[39m\u001b[39m{\u001b[39;00mvalidation_metric\u001b[39m}\u001b[39;00m\u001b[39m\"\u001b[39m]\u001b[39m.\u001b[39mmean())\n",
      "File \u001b[0;32m~/nlpsig-networks/nlpsig_networks/scripts/ffn_baseline_functions.py:132\u001b[0m, in \u001b[0;36mimplement_ffn\u001b[0;34m(num_epochs, x_data, y_data, hidden_dim, output_dim, dropout_rate, learning_rate, seed, loss, gamma, device, batch_size, data_split_seed, split_ids, split_indices, k_fold, n_splits, patience, verbose_training, verbose_results, verbose_model)\u001b[0m\n\u001b[1;32m    <a href='file:///homes/tt003/nlpsig-networks/nlpsig_networks/scripts/ffn_baseline_functions.py?line=128'>129</a>\u001b[0m     y_data \u001b[39m=\u001b[39m torch\u001b[39m.\u001b[39mtensor(y_data)\n\u001b[1;32m    <a href='file:///homes/tt003/nlpsig-networks/nlpsig_networks/scripts/ffn_baseline_functions.py?line=129'>130</a>\u001b[0m x_data \u001b[39m=\u001b[39m x_data\u001b[39m.\u001b[39mfloat()\n\u001b[0;32m--> <a href='file:///homes/tt003/nlpsig-networks/nlpsig_networks/scripts/ffn_baseline_functions.py?line=131'>132</a>\u001b[0m \u001b[39mreturn\u001b[39;00m implement_model(\n\u001b[1;32m    <a href='file:///homes/tt003/nlpsig-networks/nlpsig_networks/scripts/ffn_baseline_functions.py?line=132'>133</a>\u001b[0m     model\u001b[39m=\u001b[39;49mffn_model,\n\u001b[1;32m    <a href='file:///homes/tt003/nlpsig-networks/nlpsig_networks/scripts/ffn_baseline_functions.py?line=133'>134</a>\u001b[0m     num_epochs\u001b[39m=\u001b[39;49mnum_epochs,\n\u001b[1;32m    <a href='file:///homes/tt003/nlpsig-networks/nlpsig_networks/scripts/ffn_baseline_functions.py?line=134'>135</a>\u001b[0m     x_data\u001b[39m=\u001b[39;49mx_data,\n\u001b[1;32m    <a href='file:///homes/tt003/nlpsig-networks/nlpsig_networks/scripts/ffn_baseline_functions.py?line=135'>136</a>\u001b[0m     y_data\u001b[39m=\u001b[39;49my_data,\n\u001b[1;32m    <a href='file:///homes/tt003/nlpsig-networks/nlpsig_networks/scripts/ffn_baseline_functions.py?line=136'>137</a>\u001b[0m     learning_rate\u001b[39m=\u001b[39;49mlearning_rate,\n\u001b[1;32m    <a href='file:///homes/tt003/nlpsig-networks/nlpsig_networks/scripts/ffn_baseline_functions.py?line=137'>138</a>\u001b[0m     seed\u001b[39m=\u001b[39;49mseed,\n\u001b[1;32m    <a href='file:///homes/tt003/nlpsig-networks/nlpsig_networks/scripts/ffn_baseline_functions.py?line=138'>139</a>\u001b[0m     loss\u001b[39m=\u001b[39;49mloss,\n\u001b[1;32m    <a href='file:///homes/tt003/nlpsig-networks/nlpsig_networks/scripts/ffn_baseline_functions.py?line=139'>140</a>\u001b[0m     gamma\u001b[39m=\u001b[39;49mgamma,\n\u001b[1;32m    <a href='file:///homes/tt003/nlpsig-networks/nlpsig_networks/scripts/ffn_baseline_functions.py?line=140'>141</a>\u001b[0m     device\u001b[39m=\u001b[39;49mdevice,\n\u001b[1;32m    <a href='file:///homes/tt003/nlpsig-networks/nlpsig_networks/scripts/ffn_baseline_functions.py?line=141'>142</a>\u001b[0m     batch_size\u001b[39m=\u001b[39;49mbatch_size,\n\u001b[1;32m    <a href='file:///homes/tt003/nlpsig-networks/nlpsig_networks/scripts/ffn_baseline_functions.py?line=142'>143</a>\u001b[0m     data_split_seed\u001b[39m=\u001b[39;49mdata_split_seed,\n\u001b[1;32m    <a href='file:///homes/tt003/nlpsig-networks/nlpsig_networks/scripts/ffn_baseline_functions.py?line=143'>144</a>\u001b[0m     split_ids\u001b[39m=\u001b[39;49msplit_ids,\n\u001b[1;32m    <a href='file:///homes/tt003/nlpsig-networks/nlpsig_networks/scripts/ffn_baseline_functions.py?line=144'>145</a>\u001b[0m     split_indices\u001b[39m=\u001b[39;49msplit_indices,\n\u001b[1;32m    <a href='file:///homes/tt003/nlpsig-networks/nlpsig_networks/scripts/ffn_baseline_functions.py?line=145'>146</a>\u001b[0m     k_fold\u001b[39m=\u001b[39;49mk_fold,\n\u001b[1;32m    <a href='file:///homes/tt003/nlpsig-networks/nlpsig_networks/scripts/ffn_baseline_functions.py?line=146'>147</a>\u001b[0m     n_splits\u001b[39m=\u001b[39;49mn_splits,\n\u001b[1;32m    <a href='file:///homes/tt003/nlpsig-networks/nlpsig_networks/scripts/ffn_baseline_functions.py?line=147'>148</a>\u001b[0m     patience\u001b[39m=\u001b[39;49mpatience,\n\u001b[1;32m    <a href='file:///homes/tt003/nlpsig-networks/nlpsig_networks/scripts/ffn_baseline_functions.py?line=148'>149</a>\u001b[0m     verbose_training\u001b[39m=\u001b[39;49mverbose_training,\n\u001b[1;32m    <a href='file:///homes/tt003/nlpsig-networks/nlpsig_networks/scripts/ffn_baseline_functions.py?line=149'>150</a>\u001b[0m     verbose_results\u001b[39m=\u001b[39;49mverbose_results,\n\u001b[1;32m    <a href='file:///homes/tt003/nlpsig-networks/nlpsig_networks/scripts/ffn_baseline_functions.py?line=150'>151</a>\u001b[0m )\n",
      "File \u001b[0;32m~/nlpsig-networks/nlpsig_networks/scripts/implement_model.py:106\u001b[0m, in \u001b[0;36mimplement_model\u001b[0;34m(model, num_epochs, x_data, y_data, learning_rate, seed, loss, gamma, device, batch_size, data_split_seed, split_ids, split_indices, k_fold, n_splits, patience, verbose_training, verbose_results)\u001b[0m\n\u001b[1;32m     <a href='file:///homes/tt003/nlpsig-networks/nlpsig_networks/scripts/implement_model.py?line=98'>99</a>\u001b[0m     optimizer \u001b[39m=\u001b[39m torch\u001b[39m.\u001b[39moptim\u001b[39m.\u001b[39mAdam(\n\u001b[1;32m    <a href='file:///homes/tt003/nlpsig-networks/nlpsig_networks/scripts/implement_model.py?line=99'>100</a>\u001b[0m         model\u001b[39m.\u001b[39mparameters(), lr\u001b[39m=\u001b[39mlearning_rate, weight_decay\u001b[39m=\u001b[39mweight_decay_adam\n\u001b[1;32m    <a href='file:///homes/tt003/nlpsig-networks/nlpsig_networks/scripts/implement_model.py?line=100'>101</a>\u001b[0m     )\n\u001b[1;32m    <a href='file:///homes/tt003/nlpsig-networks/nlpsig_networks/scripts/implement_model.py?line=102'>103</a>\u001b[0m     \u001b[39m# perform k-fold evaluation which returns a dataframe with columns for the\u001b[39;00m\n\u001b[1;32m    <a href='file:///homes/tt003/nlpsig-networks/nlpsig_networks/scripts/implement_model.py?line=103'>104</a>\u001b[0m     \u001b[39m# loss, accuracy, f1 (macro) and individual f1-scores for each fold\u001b[39;00m\n\u001b[1;32m    <a href='file:///homes/tt003/nlpsig-networks/nlpsig_networks/scripts/implement_model.py?line=104'>105</a>\u001b[0m     \u001b[39m# (for both validation and test set)\u001b[39;00m\n\u001b[0;32m--> <a href='file:///homes/tt003/nlpsig-networks/nlpsig_networks/scripts/implement_model.py?line=105'>106</a>\u001b[0m     results \u001b[39m=\u001b[39m KFold_pytorch(\n\u001b[1;32m    <a href='file:///homes/tt003/nlpsig-networks/nlpsig_networks/scripts/implement_model.py?line=106'>107</a>\u001b[0m         folds\u001b[39m=\u001b[39;49mfolds,\n\u001b[1;32m    <a href='file:///homes/tt003/nlpsig-networks/nlpsig_networks/scripts/implement_model.py?line=107'>108</a>\u001b[0m         model\u001b[39m=\u001b[39;49mmodel,\n\u001b[1;32m    <a href='file:///homes/tt003/nlpsig-networks/nlpsig_networks/scripts/implement_model.py?line=108'>109</a>\u001b[0m         criterion\u001b[39m=\u001b[39;49mcriterion,\n\u001b[1;32m    <a href='file:///homes/tt003/nlpsig-networks/nlpsig_networks/scripts/implement_model.py?line=109'>110</a>\u001b[0m         optimizer\u001b[39m=\u001b[39;49moptimizer,\n\u001b[1;32m    <a href='file:///homes/tt003/nlpsig-networks/nlpsig_networks/scripts/implement_model.py?line=110'>111</a>\u001b[0m         num_epochs\u001b[39m=\u001b[39;49mnum_epochs,\n\u001b[1;32m    <a href='file:///homes/tt003/nlpsig-networks/nlpsig_networks/scripts/implement_model.py?line=111'>112</a>\u001b[0m         batch_size\u001b[39m=\u001b[39;49mbatch_size,\n\u001b[1;32m    <a href='file:///homes/tt003/nlpsig-networks/nlpsig_networks/scripts/implement_model.py?line=112'>113</a>\u001b[0m         seed\u001b[39m=\u001b[39;49mseed,\n\u001b[1;32m    <a href='file:///homes/tt003/nlpsig-networks/nlpsig_networks/scripts/implement_model.py?line=113'>114</a>\u001b[0m         return_best\u001b[39m=\u001b[39;49mreturn_best,\n\u001b[1;32m    <a href='file:///homes/tt003/nlpsig-networks/nlpsig_networks/scripts/implement_model.py?line=114'>115</a>\u001b[0m         early_stopping\u001b[39m=\u001b[39;49mearly_stopping,\n\u001b[1;32m    <a href='file:///homes/tt003/nlpsig-networks/nlpsig_networks/scripts/implement_model.py?line=115'>116</a>\u001b[0m         patience\u001b[39m=\u001b[39;49mpatience,\n\u001b[1;32m    <a href='file:///homes/tt003/nlpsig-networks/nlpsig_networks/scripts/implement_model.py?line=116'>117</a>\u001b[0m         device\u001b[39m=\u001b[39;49mdevice,\n\u001b[1;32m    <a href='file:///homes/tt003/nlpsig-networks/nlpsig_networks/scripts/implement_model.py?line=117'>118</a>\u001b[0m         verbose\u001b[39m=\u001b[39;49mverbose_training,\n\u001b[1;32m    <a href='file:///homes/tt003/nlpsig-networks/nlpsig_networks/scripts/implement_model.py?line=118'>119</a>\u001b[0m     )\n\u001b[1;32m    <a href='file:///homes/tt003/nlpsig-networks/nlpsig_networks/scripts/implement_model.py?line=119'>120</a>\u001b[0m \u001b[39melse\u001b[39;00m:\n\u001b[1;32m    <a href='file:///homes/tt003/nlpsig-networks/nlpsig_networks/scripts/implement_model.py?line=120'>121</a>\u001b[0m     \u001b[39m# split dataset\u001b[39;00m\n\u001b[1;32m    <a href='file:///homes/tt003/nlpsig-networks/nlpsig_networks/scripts/implement_model.py?line=121'>122</a>\u001b[0m     data_loader_args \u001b[39m=\u001b[39m {\u001b[39m\"\u001b[39m\u001b[39mbatch_size\u001b[39m\u001b[39m\"\u001b[39m: batch_size, \u001b[39m\"\u001b[39m\u001b[39mshuffle\u001b[39m\u001b[39m\"\u001b[39m: \u001b[39mTrue\u001b[39;00m}\n",
      "File \u001b[0;32m~/nlpsig-networks/nlpsig_networks/pytorch_utils.py:770\u001b[0m, in \u001b[0;36mKFold_pytorch\u001b[0;34m(folds, model, criterion, optimizer, num_epochs, batch_size, return_metric_for_each_fold, seed, return_best, early_stopping, patience, device, verbose, verbose_epoch)\u001b[0m\n\u001b[1;32m    <a href='file:///homes/tt003/nlpsig-networks/nlpsig_networks/pytorch_utils.py?line=764'>765</a>\u001b[0m train, valid, test \u001b[39m=\u001b[39m folds\u001b[39m.\u001b[39mget_splits(\n\u001b[1;32m    <a href='file:///homes/tt003/nlpsig-networks/nlpsig_networks/pytorch_utils.py?line=765'>766</a>\u001b[0m     fold_index\u001b[39m=\u001b[39mfold, as_DataLoader\u001b[39m=\u001b[39m\u001b[39mTrue\u001b[39;00m, data_loader_args\u001b[39m=\u001b[39mdata_loader_args\n\u001b[1;32m    <a href='file:///homes/tt003/nlpsig-networks/nlpsig_networks/pytorch_utils.py?line=766'>767</a>\u001b[0m )\n\u001b[1;32m    <a href='file:///homes/tt003/nlpsig-networks/nlpsig_networks/pytorch_utils.py?line=768'>769</a>\u001b[0m \u001b[39m# train pytorch model\u001b[39;00m\n\u001b[0;32m--> <a href='file:///homes/tt003/nlpsig-networks/nlpsig_networks/pytorch_utils.py?line=769'>770</a>\u001b[0m model \u001b[39m=\u001b[39m training_pytorch(\n\u001b[1;32m    <a href='file:///homes/tt003/nlpsig-networks/nlpsig_networks/pytorch_utils.py?line=770'>771</a>\u001b[0m     model\u001b[39m=\u001b[39;49mmodel,\n\u001b[1;32m    <a href='file:///homes/tt003/nlpsig-networks/nlpsig_networks/pytorch_utils.py?line=771'>772</a>\u001b[0m     train_loader\u001b[39m=\u001b[39;49mtrain,\n\u001b[1;32m    <a href='file:///homes/tt003/nlpsig-networks/nlpsig_networks/pytorch_utils.py?line=772'>773</a>\u001b[0m     valid_loader\u001b[39m=\u001b[39;49mvalid,\n\u001b[1;32m    <a href='file:///homes/tt003/nlpsig-networks/nlpsig_networks/pytorch_utils.py?line=773'>774</a>\u001b[0m     criterion\u001b[39m=\u001b[39;49mcriterion,\n\u001b[1;32m    <a href='file:///homes/tt003/nlpsig-networks/nlpsig_networks/pytorch_utils.py?line=774'>775</a>\u001b[0m     optimizer\u001b[39m=\u001b[39;49moptimizer,\n\u001b[1;32m    <a href='file:///homes/tt003/nlpsig-networks/nlpsig_networks/pytorch_utils.py?line=775'>776</a>\u001b[0m     num_epochs\u001b[39m=\u001b[39;49mnum_epochs,\n\u001b[1;32m    <a href='file:///homes/tt003/nlpsig-networks/nlpsig_networks/pytorch_utils.py?line=776'>777</a>\u001b[0m     seed\u001b[39m=\u001b[39;49mseed,\n\u001b[1;32m    <a href='file:///homes/tt003/nlpsig-networks/nlpsig_networks/pytorch_utils.py?line=777'>778</a>\u001b[0m     return_best\u001b[39m=\u001b[39;49mreturn_best,\n\u001b[1;32m    <a href='file:///homes/tt003/nlpsig-networks/nlpsig_networks/pytorch_utils.py?line=778'>779</a>\u001b[0m     save_best\u001b[39m=\u001b[39;49m\u001b[39mFalse\u001b[39;49;00m,\n\u001b[1;32m    <a href='file:///homes/tt003/nlpsig-networks/nlpsig_networks/pytorch_utils.py?line=779'>780</a>\u001b[0m     early_stopping\u001b[39m=\u001b[39;49mearly_stopping,\n\u001b[1;32m    <a href='file:///homes/tt003/nlpsig-networks/nlpsig_networks/pytorch_utils.py?line=780'>781</a>\u001b[0m     patience\u001b[39m=\u001b[39;49mpatience,\n\u001b[1;32m    <a href='file:///homes/tt003/nlpsig-networks/nlpsig_networks/pytorch_utils.py?line=781'>782</a>\u001b[0m     device\u001b[39m=\u001b[39;49mdevice,\n\u001b[1;32m    <a href='file:///homes/tt003/nlpsig-networks/nlpsig_networks/pytorch_utils.py?line=782'>783</a>\u001b[0m     verbose\u001b[39m=\u001b[39;49mverbose,\n\u001b[1;32m    <a href='file:///homes/tt003/nlpsig-networks/nlpsig_networks/pytorch_utils.py?line=783'>784</a>\u001b[0m     verbose_epoch\u001b[39m=\u001b[39;49mverbose_epoch,\n\u001b[1;32m    <a href='file:///homes/tt003/nlpsig-networks/nlpsig_networks/pytorch_utils.py?line=784'>785</a>\u001b[0m )\n\u001b[1;32m    <a href='file:///homes/tt003/nlpsig-networks/nlpsig_networks/pytorch_utils.py?line=786'>787</a>\u001b[0m \u001b[39m# test model\u001b[39;00m\n\u001b[1;32m    <a href='file:///homes/tt003/nlpsig-networks/nlpsig_networks/pytorch_utils.py?line=787'>788</a>\u001b[0m test_results \u001b[39m=\u001b[39m testing_pytorch(\n\u001b[1;32m    <a href='file:///homes/tt003/nlpsig-networks/nlpsig_networks/pytorch_utils.py?line=788'>789</a>\u001b[0m     model\u001b[39m=\u001b[39mmodel,\n\u001b[1;32m    <a href='file:///homes/tt003/nlpsig-networks/nlpsig_networks/pytorch_utils.py?line=789'>790</a>\u001b[0m     test_loader\u001b[39m=\u001b[39mtest,\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m    <a href='file:///homes/tt003/nlpsig-networks/nlpsig_networks/pytorch_utils.py?line=792'>793</a>\u001b[0m     verbose\u001b[39m=\u001b[39mverbose,\n\u001b[1;32m    <a href='file:///homes/tt003/nlpsig-networks/nlpsig_networks/pytorch_utils.py?line=793'>794</a>\u001b[0m )\n",
      "File \u001b[0;32m~/nlpsig-networks/nlpsig_networks/pytorch_utils.py:457\u001b[0m, in \u001b[0;36mtraining_pytorch\u001b[0;34m(model, train_loader, criterion, optimizer, num_epochs, scheduler, valid_loader, seed, return_best, save_best, output, early_stopping, validation_metric, patience, device, verbose, verbose_epoch)\u001b[0m\n\u001b[1;32m    <a href='file:///homes/tt003/nlpsig-networks/nlpsig_networks/pytorch_utils.py?line=454'>455</a>\u001b[0m \u001b[39m# perform training by performing forward and backward passes\u001b[39;00m\n\u001b[1;32m    <a href='file:///homes/tt003/nlpsig-networks/nlpsig_networks/pytorch_utils.py?line=455'>456</a>\u001b[0m optimizer\u001b[39m.\u001b[39mzero_grad()\n\u001b[0;32m--> <a href='file:///homes/tt003/nlpsig-networks/nlpsig_networks/pytorch_utils.py?line=456'>457</a>\u001b[0m model_output \u001b[39m=\u001b[39m model(\u001b[39m*\u001b[39;49mbatch_inputs)\n\u001b[1;32m    <a href='file:///homes/tt003/nlpsig-networks/nlpsig_networks/pytorch_utils.py?line=457'>458</a>\u001b[0m loss \u001b[39m=\u001b[39m criterion(model_output, batch_labels)\n\u001b[1;32m    <a href='file:///homes/tt003/nlpsig-networks/nlpsig_networks/pytorch_utils.py?line=458'>459</a>\u001b[0m loss\u001b[39m.\u001b[39mbackward()\n",
      "File \u001b[0;32m/import/nlp/tt003/envs/nlpsig-networks/lib/python3.8/site-packages/torch/nn/modules/module.py:1051\u001b[0m, in \u001b[0;36mModule._call_impl\u001b[0;34m(self, *input, **kwargs)\u001b[0m\n\u001b[1;32m   <a href='file:///import/nlp/tt003/envs/nlpsig-networks/lib/python3.8/site-packages/torch/nn/modules/module.py?line=1046'>1047</a>\u001b[0m \u001b[39m# If we don't have any hooks, we want to skip the rest of the logic in\u001b[39;00m\n\u001b[1;32m   <a href='file:///import/nlp/tt003/envs/nlpsig-networks/lib/python3.8/site-packages/torch/nn/modules/module.py?line=1047'>1048</a>\u001b[0m \u001b[39m# this function, and just call forward.\u001b[39;00m\n\u001b[1;32m   <a href='file:///import/nlp/tt003/envs/nlpsig-networks/lib/python3.8/site-packages/torch/nn/modules/module.py?line=1048'>1049</a>\u001b[0m \u001b[39mif\u001b[39;00m \u001b[39mnot\u001b[39;00m (\u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_backward_hooks \u001b[39mor\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_forward_hooks \u001b[39mor\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_forward_pre_hooks \u001b[39mor\u001b[39;00m _global_backward_hooks\n\u001b[1;32m   <a href='file:///import/nlp/tt003/envs/nlpsig-networks/lib/python3.8/site-packages/torch/nn/modules/module.py?line=1049'>1050</a>\u001b[0m         \u001b[39mor\u001b[39;00m _global_forward_hooks \u001b[39mor\u001b[39;00m _global_forward_pre_hooks):\n\u001b[0;32m-> <a href='file:///import/nlp/tt003/envs/nlpsig-networks/lib/python3.8/site-packages/torch/nn/modules/module.py?line=1050'>1051</a>\u001b[0m     \u001b[39mreturn\u001b[39;00m forward_call(\u001b[39m*\u001b[39;49m\u001b[39minput\u001b[39;49m, \u001b[39m*\u001b[39;49m\u001b[39m*\u001b[39;49mkwargs)\n\u001b[1;32m   <a href='file:///import/nlp/tt003/envs/nlpsig-networks/lib/python3.8/site-packages/torch/nn/modules/module.py?line=1051'>1052</a>\u001b[0m \u001b[39m# Do not call functions when jit is used\u001b[39;00m\n\u001b[1;32m   <a href='file:///import/nlp/tt003/envs/nlpsig-networks/lib/python3.8/site-packages/torch/nn/modules/module.py?line=1052'>1053</a>\u001b[0m full_backward_hooks, non_full_backward_hooks \u001b[39m=\u001b[39m [], []\n",
      "File \u001b[0;32m~/nlpsig-networks/nlpsig_networks/ffn_baseline.py:73\u001b[0m, in \u001b[0;36mFeedforwardNeuralNetModel.forward\u001b[0;34m(self, x)\u001b[0m\n\u001b[1;32m     <a href='file:///homes/tt003/nlpsig-networks/nlpsig_networks/ffn_baseline.py?line=70'>71</a>\u001b[0m \u001b[39mfor\u001b[39;00m layer \u001b[39min\u001b[39;00m \u001b[39mrange\u001b[39m(\u001b[39mlen\u001b[39m(\u001b[39mself\u001b[39m\u001b[39m.\u001b[39mlinear_layers)):\n\u001b[1;32m     <a href='file:///homes/tt003/nlpsig-networks/nlpsig_networks/ffn_baseline.py?line=71'>72</a>\u001b[0m     out \u001b[39m=\u001b[39m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mlinear_layers[layer](out)\n\u001b[0;32m---> <a href='file:///homes/tt003/nlpsig-networks/nlpsig_networks/ffn_baseline.py?line=72'>73</a>\u001b[0m     out \u001b[39m=\u001b[39m \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49mnon_linear_layers[layer](out)\n\u001b[1;32m     <a href='file:///homes/tt003/nlpsig-networks/nlpsig_networks/ffn_baseline.py?line=73'>74</a>\u001b[0m     out \u001b[39m=\u001b[39m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mdropout_layers[layer](out)\n\u001b[1;32m     <a href='file:///homes/tt003/nlpsig-networks/nlpsig_networks/ffn_baseline.py?line=75'>76</a>\u001b[0m \u001b[39m# FFN: readout\u001b[39;00m\n",
      "File \u001b[0;32m/import/nlp/tt003/envs/nlpsig-networks/lib/python3.8/site-packages/torch/nn/modules/module.py:1051\u001b[0m, in \u001b[0;36mModule._call_impl\u001b[0;34m(self, *input, **kwargs)\u001b[0m\n\u001b[1;32m   <a href='file:///import/nlp/tt003/envs/nlpsig-networks/lib/python3.8/site-packages/torch/nn/modules/module.py?line=1046'>1047</a>\u001b[0m \u001b[39m# If we don't have any hooks, we want to skip the rest of the logic in\u001b[39;00m\n\u001b[1;32m   <a href='file:///import/nlp/tt003/envs/nlpsig-networks/lib/python3.8/site-packages/torch/nn/modules/module.py?line=1047'>1048</a>\u001b[0m \u001b[39m# this function, and just call forward.\u001b[39;00m\n\u001b[1;32m   <a href='file:///import/nlp/tt003/envs/nlpsig-networks/lib/python3.8/site-packages/torch/nn/modules/module.py?line=1048'>1049</a>\u001b[0m \u001b[39mif\u001b[39;00m \u001b[39mnot\u001b[39;00m (\u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_backward_hooks \u001b[39mor\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_forward_hooks \u001b[39mor\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_forward_pre_hooks \u001b[39mor\u001b[39;00m _global_backward_hooks\n\u001b[1;32m   <a href='file:///import/nlp/tt003/envs/nlpsig-networks/lib/python3.8/site-packages/torch/nn/modules/module.py?line=1049'>1050</a>\u001b[0m         \u001b[39mor\u001b[39;00m _global_forward_hooks \u001b[39mor\u001b[39;00m _global_forward_pre_hooks):\n\u001b[0;32m-> <a href='file:///import/nlp/tt003/envs/nlpsig-networks/lib/python3.8/site-packages/torch/nn/modules/module.py?line=1050'>1051</a>\u001b[0m     \u001b[39mreturn\u001b[39;00m forward_call(\u001b[39m*\u001b[39;49m\u001b[39minput\u001b[39;49m, \u001b[39m*\u001b[39;49m\u001b[39m*\u001b[39;49mkwargs)\n\u001b[1;32m   <a href='file:///import/nlp/tt003/envs/nlpsig-networks/lib/python3.8/site-packages/torch/nn/modules/module.py?line=1051'>1052</a>\u001b[0m \u001b[39m# Do not call functions when jit is used\u001b[39;00m\n\u001b[1;32m   <a href='file:///import/nlp/tt003/envs/nlpsig-networks/lib/python3.8/site-packages/torch/nn/modules/module.py?line=1052'>1053</a>\u001b[0m full_backward_hooks, non_full_backward_hooks \u001b[39m=\u001b[39m [], []\n",
      "File \u001b[0;32m/import/nlp/tt003/envs/nlpsig-networks/lib/python3.8/site-packages/torch/nn/modules/activation.py:102\u001b[0m, in \u001b[0;36mReLU.forward\u001b[0;34m(self, input)\u001b[0m\n\u001b[1;32m    <a href='file:///import/nlp/tt003/envs/nlpsig-networks/lib/python3.8/site-packages/torch/nn/modules/activation.py?line=100'>101</a>\u001b[0m \u001b[39mdef\u001b[39;00m \u001b[39mforward\u001b[39m(\u001b[39mself\u001b[39m, \u001b[39minput\u001b[39m: Tensor) \u001b[39m-\u001b[39m\u001b[39m>\u001b[39m Tensor:\n\u001b[0;32m--> <a href='file:///import/nlp/tt003/envs/nlpsig-networks/lib/python3.8/site-packages/torch/nn/modules/activation.py?line=101'>102</a>\u001b[0m     \u001b[39mreturn\u001b[39;00m F\u001b[39m.\u001b[39;49mrelu(\u001b[39minput\u001b[39;49m, inplace\u001b[39m=\u001b[39;49m\u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49minplace)\n",
      "File \u001b[0;32m/import/nlp/tt003/envs/nlpsig-networks/lib/python3.8/site-packages/torch/nn/functional.py:1298\u001b[0m, in \u001b[0;36mrelu\u001b[0;34m(input, inplace)\u001b[0m\n\u001b[1;32m   <a href='file:///import/nlp/tt003/envs/nlpsig-networks/lib/python3.8/site-packages/torch/nn/functional.py?line=1295'>1296</a>\u001b[0m     result \u001b[39m=\u001b[39m torch\u001b[39m.\u001b[39mrelu_(\u001b[39minput\u001b[39m)\n\u001b[1;32m   <a href='file:///import/nlp/tt003/envs/nlpsig-networks/lib/python3.8/site-packages/torch/nn/functional.py?line=1296'>1297</a>\u001b[0m \u001b[39melse\u001b[39;00m:\n\u001b[0;32m-> <a href='file:///import/nlp/tt003/envs/nlpsig-networks/lib/python3.8/site-packages/torch/nn/functional.py?line=1297'>1298</a>\u001b[0m     result \u001b[39m=\u001b[39m torch\u001b[39m.\u001b[39;49mrelu(\u001b[39minput\u001b[39;49m)\n\u001b[1;32m   <a href='file:///import/nlp/tt003/envs/nlpsig-networks/lib/python3.8/site-packages/torch/nn/functional.py?line=1298'>1299</a>\u001b[0m \u001b[39mreturn\u001b[39;00m result\n",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
     ]
    },
    {
     "ename": "",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31mThe Kernel crashed while executing code in the the current cell or a previous cell. Please review the code in the cell(s) to identify a possible cause of the failure. Click <a href='https://aka.ms/vscodeJupyterKernelCrash'>here</a> for more info. View Jupyter <a href='command:jupyter.viewOutput'>log</a> for further details."
     ]
    }
   ],
   "source": [
    "ffn_current, best_ffn_current, _, __ = ffn_hyperparameter_search( \n",
    "    num_epochs=num_epochs,\n",
    "    x_data=sbert_embeddings,\n",
    "    y_data=y_data,\n",
    "    hidden_dim_sizes=hidden_dim_sizes,\n",
    "    output_dim=output_dim,\n",
    "    dropout_rates=dropout_rates,\n",
    "    learning_rates=learning_rates,\n",
    "    seeds=seeds,\n",
    "    loss=loss,\n",
    "    gamma=gamma,\n",
    "    device=device,\n",
    "    split_ids=None, \n",
    "    split_indices=fold_list,\n",
    "    k_fold=True,\n",
    "    patience=patience,\n",
    "    validation_metric=validation_metric,\n",
    "    results_output= f\"{output_dir}/ffn_current_focal_{gamma}.csv\",\n",
    "    verbose=False\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>loss</th>\n",
       "      <th>accuracy</th>\n",
       "      <th>f1</th>\n",
       "      <th>f1_scores</th>\n",
       "      <th>precision</th>\n",
       "      <th>precision_scores</th>\n",
       "      <th>recall</th>\n",
       "      <th>recall_scores</th>\n",
       "      <th>valid_loss</th>\n",
       "      <th>valid_accuracy</th>\n",
       "      <th>...</th>\n",
       "      <th>valid_recall_scores</th>\n",
       "      <th>hidden_dim</th>\n",
       "      <th>dropout_rate</th>\n",
       "      <th>learning_rate</th>\n",
       "      <th>seed</th>\n",
       "      <th>loss_function</th>\n",
       "      <th>gamma</th>\n",
       "      <th>k_fold</th>\n",
       "      <th>n_splits</th>\n",
       "      <th>batch_size</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>None</td>\n",
       "      <td>0.806923</td>\n",
       "      <td>0.532520</td>\n",
       "      <td>[0.8877564102564103, 0.4314827828531272, 0.278...</td>\n",
       "      <td>0.528515</td>\n",
       "      <td>[0.8937145069695406, 0.40878828229027964, 0.28...</td>\n",
       "      <td>0.537493</td>\n",
       "      <td>[0.8818772287315334, 0.4568452380952381, 0.273...</td>\n",
       "      <td>None</td>\n",
       "      <td>0.798716</td>\n",
       "      <td>...</td>\n",
       "      <td>[0.8726038932091733, 0.47889485801995396, 0.24...</td>\n",
       "      <td>(64, 64)</td>\n",
       "      <td>0.5</td>\n",
       "      <td>0.0001</td>\n",
       "      <td>1</td>\n",
       "      <td>focal</td>\n",
       "      <td>2</td>\n",
       "      <td>True</td>\n",
       "      <td>5</td>\n",
       "      <td>64</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>None</td>\n",
       "      <td>0.804451</td>\n",
       "      <td>0.530992</td>\n",
       "      <td>[0.8861360718870347, 0.4303015910710045, 0.276...</td>\n",
       "      <td>0.524176</td>\n",
       "      <td>[0.8932453416149069, 0.41275626423690204, 0.26...</td>\n",
       "      <td>0.538625</td>\n",
       "      <td>[0.8791390728476821, 0.4494047619047619, 0.287...</td>\n",
       "      <td>None</td>\n",
       "      <td>0.799508</td>\n",
       "      <td>...</td>\n",
       "      <td>[0.8732973401357175, 0.4716039907904835, 0.268...</td>\n",
       "      <td>(64, 64)</td>\n",
       "      <td>0.5</td>\n",
       "      <td>0.0001</td>\n",
       "      <td>12</td>\n",
       "      <td>focal</td>\n",
       "      <td>2</td>\n",
       "      <td>True</td>\n",
       "      <td>5</td>\n",
       "      <td>64</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>None</td>\n",
       "      <td>0.812943</td>\n",
       "      <td>0.531022</td>\n",
       "      <td>[0.8918798523609521, 0.4297560975609756, 0.271...</td>\n",
       "      <td>0.533497</td>\n",
       "      <td>[0.8913126430933604, 0.4227447216890595, 0.286...</td>\n",
       "      <td>0.529123</td>\n",
       "      <td>[0.8924477840040754, 0.43700396825396826, 0.25...</td>\n",
       "      <td>None</td>\n",
       "      <td>0.806511</td>\n",
       "      <td>...</td>\n",
       "      <td>[0.885828916736837, 0.4508825786646201, 0.2424...</td>\n",
       "      <td>(64, 64)</td>\n",
       "      <td>0.5</td>\n",
       "      <td>0.0001</td>\n",
       "      <td>123</td>\n",
       "      <td>focal</td>\n",
       "      <td>2</td>\n",
       "      <td>True</td>\n",
       "      <td>5</td>\n",
       "      <td>64</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>3 rows × 25 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "   loss  accuracy        f1  \\\n",
       "0  None  0.806923  0.532520   \n",
       "0  None  0.804451  0.530992   \n",
       "0  None  0.812943  0.531022   \n",
       "\n",
       "                                           f1_scores  precision  \\\n",
       "0  [0.8877564102564103, 0.4314827828531272, 0.278...   0.528515   \n",
       "0  [0.8861360718870347, 0.4303015910710045, 0.276...   0.524176   \n",
       "0  [0.8918798523609521, 0.4297560975609756, 0.271...   0.533497   \n",
       "\n",
       "                                    precision_scores    recall  \\\n",
       "0  [0.8937145069695406, 0.40878828229027964, 0.28...  0.537493   \n",
       "0  [0.8932453416149069, 0.41275626423690204, 0.26...  0.538625   \n",
       "0  [0.8913126430933604, 0.4227447216890595, 0.286...  0.529123   \n",
       "\n",
       "                                       recall_scores valid_loss  \\\n",
       "0  [0.8818772287315334, 0.4568452380952381, 0.273...       None   \n",
       "0  [0.8791390728476821, 0.4494047619047619, 0.287...       None   \n",
       "0  [0.8924477840040754, 0.43700396825396826, 0.25...       None   \n",
       "\n",
       "   valid_accuracy  ...                                valid_recall_scores  \\\n",
       "0        0.798716  ...  [0.8726038932091733, 0.47889485801995396, 0.24...   \n",
       "0        0.799508  ...  [0.8732973401357175, 0.4716039907904835, 0.268...   \n",
       "0        0.806511  ...  [0.885828916736837, 0.4508825786646201, 0.2424...   \n",
       "\n",
       "  hidden_dim  dropout_rate learning_rate  seed loss_function gamma  k_fold  \\\n",
       "0   (64, 64)           0.5        0.0001     1         focal     2    True   \n",
       "0   (64, 64)           0.5        0.0001    12         focal     2    True   \n",
       "0   (64, 64)           0.5        0.0001   123         focal     2    True   \n",
       "\n",
       "   n_splits  batch_size  \n",
       "0         5          64  \n",
       "0         5          64  \n",
       "0         5          64  \n",
       "\n",
       "[3 rows x 25 columns]"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "best_ffn_current"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.531511120545299"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "best_ffn_current[\"f1\"].mean()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.5287290682197932"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "best_ffn_current[\"precision\"].mean()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.5350802865249041"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "best_ffn_current[\"recall\"].mean()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([0.88859078, 0.43051349, 0.27542909])"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "np.stack(best_ffn_current[\"f1_scores\"]).mean(axis=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([0.8927575 , 0.41476309, 0.27866662])"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "np.stack(best_ffn_current[\"precision_scores\"]).mean(axis=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([0.88448803, 0.44775132, 0.27300151])"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "np.stack(best_ffn_current[\"recall_scores\"]).mean(axis=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "interpreter": {
   "hash": "b2013b70f5165546ff531eadcfc35b64307c3717f205ea3ff61fa34bab89c803"
  },
  "kernelspec": {
   "display_name": "Python 3.8.17 ('nlpsig-networks')",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.17"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
