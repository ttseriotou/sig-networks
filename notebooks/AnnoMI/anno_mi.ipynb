{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "a983a5e8",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import torch\n",
    "import transformers\n",
    "import pickle\n",
    "import os\n",
    "\n",
    "import nlpsig\n",
    "import nlpsig_networks\n",
    "\n",
    "from torch.optim.lr_scheduler import ReduceLROnPlateau, StepLR\n",
    "from nlpsig.classification_utils import split_dataset\n",
    "from nlpsig_networks.pytorch_utils import training_pytorch, testing_pytorch, set_seed\n",
    "from nlpsig_networks.ffn import FeedforwardNeuralNetModel\n",
    "from nlpsig_networks.deepsignet import StackedDeepSigNet\n",
    "from nlpsig_networks.focal_loss import FocalLoss, ClassBalanced_FocalLoss\n",
    "from sklearn import metrics\n",
    "\n",
    "from tqdm.notebook import tqdm\n",
    "\n",
    "seed = 2023"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "193d632e",
   "metadata": {},
   "outputs": [],
   "source": [
    "import signatory"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f7409a03",
   "metadata": {},
   "source": [
    "## AnnoMI"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "f00bb922",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>mi_quality</th>\n",
       "      <th>transcript_id</th>\n",
       "      <th>topic</th>\n",
       "      <th>utterance_id</th>\n",
       "      <th>interlocutor</th>\n",
       "      <th>timestamp</th>\n",
       "      <th>utterance_text</th>\n",
       "      <th>annotator_id</th>\n",
       "      <th>therapist_input_exists</th>\n",
       "      <th>therapist_input_subtype</th>\n",
       "      <th>reflection_exists</th>\n",
       "      <th>reflection_subtype</th>\n",
       "      <th>question_exists</th>\n",
       "      <th>question_subtype</th>\n",
       "      <th>main_therapist_behaviour</th>\n",
       "      <th>client_talk_type</th>\n",
       "      <th>datetime</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>high</td>\n",
       "      <td>0</td>\n",
       "      <td>reducing alcohol consumption</td>\n",
       "      <td>0</td>\n",
       "      <td>therapist</td>\n",
       "      <td>00:00:13</td>\n",
       "      <td>Thanks for filling it out. We give this form t...</td>\n",
       "      <td>3</td>\n",
       "      <td>False</td>\n",
       "      <td>NaN</td>\n",
       "      <td>False</td>\n",
       "      <td>NaN</td>\n",
       "      <td>True</td>\n",
       "      <td>open</td>\n",
       "      <td>question</td>\n",
       "      <td>NaN</td>\n",
       "      <td>2023-05-10 00:00:13</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>high</td>\n",
       "      <td>0</td>\n",
       "      <td>reducing alcohol consumption</td>\n",
       "      <td>1</td>\n",
       "      <td>client</td>\n",
       "      <td>00:00:24</td>\n",
       "      <td>Sure.</td>\n",
       "      <td>3</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>neutral</td>\n",
       "      <td>2023-05-10 00:00:24</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>high</td>\n",
       "      <td>0</td>\n",
       "      <td>reducing alcohol consumption</td>\n",
       "      <td>2</td>\n",
       "      <td>therapist</td>\n",
       "      <td>00:00:25</td>\n",
       "      <td>So, let's see. It looks that you put-- You dri...</td>\n",
       "      <td>3</td>\n",
       "      <td>True</td>\n",
       "      <td>information</td>\n",
       "      <td>False</td>\n",
       "      <td>NaN</td>\n",
       "      <td>False</td>\n",
       "      <td>NaN</td>\n",
       "      <td>therapist_input</td>\n",
       "      <td>NaN</td>\n",
       "      <td>2023-05-10 00:00:25</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>high</td>\n",
       "      <td>0</td>\n",
       "      <td>reducing alcohol consumption</td>\n",
       "      <td>3</td>\n",
       "      <td>client</td>\n",
       "      <td>00:00:34</td>\n",
       "      <td>Mm-hmm.</td>\n",
       "      <td>3</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>neutral</td>\n",
       "      <td>2023-05-10 00:00:34</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>high</td>\n",
       "      <td>0</td>\n",
       "      <td>reducing alcohol consumption</td>\n",
       "      <td>4</td>\n",
       "      <td>therapist</td>\n",
       "      <td>00:00:34</td>\n",
       "      <td>-and you usually have three to four drinks whe...</td>\n",
       "      <td>3</td>\n",
       "      <td>True</td>\n",
       "      <td>information</td>\n",
       "      <td>False</td>\n",
       "      <td>NaN</td>\n",
       "      <td>False</td>\n",
       "      <td>NaN</td>\n",
       "      <td>therapist_input</td>\n",
       "      <td>NaN</td>\n",
       "      <td>2023-05-10 00:00:34</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "  mi_quality  transcript_id                         topic  utterance_id  \\\n",
       "0       high              0  reducing alcohol consumption             0   \n",
       "1       high              0  reducing alcohol consumption             1   \n",
       "2       high              0  reducing alcohol consumption             2   \n",
       "3       high              0  reducing alcohol consumption             3   \n",
       "4       high              0  reducing alcohol consumption             4   \n",
       "\n",
       "  interlocutor timestamp                                     utterance_text  \\\n",
       "0    therapist  00:00:13  Thanks for filling it out. We give this form t...   \n",
       "1       client  00:00:24                                              Sure.   \n",
       "2    therapist  00:00:25  So, let's see. It looks that you put-- You dri...   \n",
       "3       client  00:00:34                                            Mm-hmm.   \n",
       "4    therapist  00:00:34  -and you usually have three to four drinks whe...   \n",
       "\n",
       "   annotator_id therapist_input_exists therapist_input_subtype  \\\n",
       "0             3                  False                     NaN   \n",
       "1             3                    NaN                     NaN   \n",
       "2             3                   True             information   \n",
       "3             3                    NaN                     NaN   \n",
       "4             3                   True             information   \n",
       "\n",
       "  reflection_exists reflection_subtype question_exists question_subtype  \\\n",
       "0             False                NaN            True             open   \n",
       "1               NaN                NaN             NaN              NaN   \n",
       "2             False                NaN           False              NaN   \n",
       "3               NaN                NaN             NaN              NaN   \n",
       "4             False                NaN           False              NaN   \n",
       "\n",
       "  main_therapist_behaviour client_talk_type            datetime  \n",
       "0                 question              NaN 2023-05-10 00:00:13  \n",
       "1                      NaN          neutral 2023-05-10 00:00:24  \n",
       "2          therapist_input              NaN 2023-05-10 00:00:25  \n",
       "3                      NaN          neutral 2023-05-10 00:00:34  \n",
       "4          therapist_input              NaN 2023-05-10 00:00:34  "
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "anno_mi = pd.read_csv(\"AnnoMI-full.csv\")\n",
    "anno_mi[\"datetime\"] = pd.to_datetime(anno_mi[\"timestamp\"])\n",
    "anno_mi = anno_mi.drop(columns=[\"video_title\", \"video_url\"])\n",
    "anno_mi.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "cea8099b",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "13551"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(anno_mi)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "44217a68",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "neutral    0.627063\n",
       "change     0.248030\n",
       "sustain    0.124907\n",
       "Name: client_talk_type, dtype: float64"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "anno_mi[\"client_talk_type\"].value_counts() / anno_mi[\"interlocutor\"].value_counts()[\"client\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "367137a3",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "therapist    6826\n",
       "client       6725\n",
       "Name: interlocutor, dtype: int64"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "anno_mi[\"interlocutor\"].value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "9a5a319f",
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "reducing alcohol consumption                                                          2326\n",
       "more exercise / increasing activity                                                   2034\n",
       "reducing recidivism                                                                   1303\n",
       "reducing drug use                                                                     1104\n",
       "diabetes management                                                                    948\n",
       "smoking cessation                                                                      923\n",
       "smoking cessation                                                                      541\n",
       "taking medicine / following medical procedure                                          448\n",
       "asthma management                                                                      431\n",
       "avoiding DOI                                                                           394\n",
       "changing approach to disease                                                           315\n",
       "reducing gambling                                                                      297\n",
       "weight loss                                                                            294\n",
       "unidentifiable                                                                         287\n",
       "smoking cessation; reducing alcohol consumption                                        254\n",
       "overcoming issues at school                                                            167\n",
       "compliance with rules                                                                  146\n",
       "supporting client to live in more alignment with her values                            133\n",
       "increasing activity; taking medicine / following medical procedure                     126\n",
       "better oral health                                                                      97\n",
       "managing life                                                                           86\n",
       "anxiety management                                                                      79\n",
       "more exercise / increasing activity; weight loss                                        66\n",
       "Being assertive with flatmate about moving out                                          62\n",
       "reducing drug use; following medical procedure                                          59\n",
       "taking steps towards getting help with day-care                                         57\n",
       "reducing alcohol consumption; safe sex                                                  55\n",
       "reducing self-harm                                                                      54\n",
       "reducing coffee consumption                                                             51\n",
       "increasing self-confidence                                                              50\n",
       "completion of community service                                                         46\n",
       "reducing violence                                                                       41\n",
       "diet; reducing alcohol consumption; diabetes management                                 40\n",
       "weight loss; diet                                                                       36\n",
       "birth control                                                                           36\n",
       "reducing alcohol consumption; compliance with rules                                     31\n",
       "charging battery                                                                        29\n",
       "diagnosis                                                                               21\n",
       "providing information on medicines                                                      19\n",
       "engaging in community activities                                                        17\n",
       "problem recognition                                                                     16\n",
       "opening up                                                                              15\n",
       "recognising success                                                                     11\n",
       "not getting into a car with someone who is under the influence of drugs or alcohol       6\n",
       "Name: topic, dtype: int64"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "anno_mi[\"topic\"].value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "507f8a50",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "133"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(anno_mi[\"transcript_id\"].unique())"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d31003be",
   "metadata": {},
   "source": [
    "## Only considering client for now..."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "a5a752a9",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "6725"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "client_index = [isinstance(x, str) for x in anno_mi[\"client_talk_type\"]]\n",
    "sum(client_index)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "1a84179e",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(6725,)"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y_data = anno_mi[\"client_talk_type\"][client_index]\n",
    "y_data.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "7272095b",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "1     neutral\n",
       "3     neutral\n",
       "5     neutral\n",
       "7     neutral\n",
       "9     neutral\n",
       "11    neutral\n",
       "13    neutral\n",
       "15    neutral\n",
       "17    neutral\n",
       "19    neutral\n",
       "21    neutral\n",
       "23    neutral\n",
       "25    neutral\n",
       "27    neutral\n",
       "29    neutral\n",
       "31    neutral\n",
       "33    neutral\n",
       "35     change\n",
       "37     change\n",
       "39     change\n",
       "Name: client_talk_type, dtype: object"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y_data[0:20]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "7b8bd903",
   "metadata": {},
   "outputs": [],
   "source": [
    "label_to_id = {y_data.unique()[i]: i for i in range(len(y_data.unique()))}\n",
    "id_to_label = {v: k for k, v in label_to_id.items()}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "e478c216",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'neutral': 0, 'change': 1, 'sustain': 2}"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "label_to_id"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "4f716f8e",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{0: 'neutral', 1: 'change', 2: 'sustain'}"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "id_to_label"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "e46018b4",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 1, 1]"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y_data = [label_to_id[x] for x in y_data]\n",
    "y_data[0:20]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "07a35e43",
   "metadata": {},
   "source": [
    "## Obtaining SBERT Embeddings\n",
    "\n",
    "We can use the `SentenceEncoder` class within `nlpsig` to obtain sentence embeddings from a model. This class uses the [`sentence-transformer`](https://www.sbert.net/docs/package_reference/SentenceTransformer.html) package and here, we have use the pre-trained `all-mpnet-base-v2` model by passing this name as a string to the class - alternative models can be found [here](https://www.sbert.net/docs/pretrained_models.html).\n",
    "\n",
    "We can pass these into the constructor of the class to initialise our text encoder as follows:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "1a63cff5",
   "metadata": {},
   "outputs": [],
   "source": [
    "# sbert_768_embeddings = np.load(\"anno_mi_sentence_embeddings_768.npy\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "07fe57d4",
   "metadata": {},
   "outputs": [],
   "source": [
    "# initialise the Text Encoder\n",
    "sbert_model_768 = \"all-mpnet-base-v2\"\n",
    "text_encoder_sbert_768 = nlpsig.SentenceEncoder(df=anno_mi,\n",
    "                                                feature_name=\"utterance_text\",\n",
    "                                                model_name=sbert_model_768)\n",
    "text_encoder_sbert_768.load_pretrained_model()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "798b0890",
   "metadata": {},
   "source": [
    "The class has a `.encode_sentence_transformer()` method which first loads in the model (using the `model_name` and `model_args` attributes) and then obtains an embedding for each sentence. These sentence embeddings are then stored in the `embeddings_sentence` attribute of the object."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "1b984327",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[INFO] number of sentences to encode: 13551\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "c4a3a67e3c8e4ba29e300e29d5b8c509",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Batches:   0%|          | 0/212 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "text_encoder_sbert_768.obtain_embeddings()\n",
    "sbert_768_embeddings = text_encoder_sbert_768.sentence_embeddings"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "33f5aa66",
   "metadata": {},
   "outputs": [],
   "source": [
    "np.save(\"anno_mi_sentence_embeddings_768\", sbert_768_embeddings)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "70fc53d9",
   "metadata": {},
   "source": [
    "## SBERT with 384 dimension vectors"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "fcb7c3de",
   "metadata": {},
   "outputs": [],
   "source": [
    "# sbert_384_embeddings = np.load(\"anno_mi_sentence_embeddings_384.npy\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "87e3568e",
   "metadata": {},
   "outputs": [],
   "source": [
    "# initialise the Text Encoder\n",
    "sbert_model_384 = \"all-MiniLM-L12-v2\"\n",
    "text_encoder_sbert_384 = nlpsig.SentenceEncoder(df=anno_mi,\n",
    "                                                feature_name=\"utterance_text\",\n",
    "                                                model_name=sbert_model_384)\n",
    "text_encoder_sbert_384.load_pretrained_model()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "7e03af88",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[INFO] number of sentences to encode: 13551\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "dda6f6b4ccb14589ad271ae010fc6d13",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Batches:   0%|          | 0/212 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "text_encoder_sbert_384.obtain_embeddings()\n",
    "sbert_384_embeddings = text_encoder_sbert_384.sentence_embeddings"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "84b34862",
   "metadata": {},
   "outputs": [],
   "source": [
    "np.save(\"anno_mi_sentence_embeddings_384\", sbert_384_embeddings)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "70697bd9",
   "metadata": {},
   "source": [
    "## Pretrained BERT and pooling"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "92d15d7c",
   "metadata": {},
   "outputs": [],
   "source": [
    "# pooled_mean_pretrained = np.load(\"anno_mi_pretrained_BERT_mean.npy\")\n",
    "# pooled_max_pretrained = np.load(\"anno_mi_pretrained_BERT_max.npy\")\n",
    "# pooled_sum_pretrained = np.load(\"anno_mi_pretrained_BERT_sum.npy\")\n",
    "# pooled_cls_pretrained = np.load(\"anno_mi_pretrained_BERT_cls.npy\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "fa911480",
   "metadata": {},
   "outputs": [],
   "source": [
    "bert_model = \"bert-base-uncased\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "40a317e2",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of the model checkpoint at bert-base-uncased were not used when initializing BertModel: ['cls.predictions.bias', 'cls.seq_relationship.bias', 'cls.predictions.decoder.weight', 'cls.predictions.transform.dense.bias', 'cls.seq_relationship.weight', 'cls.predictions.transform.dense.weight', 'cls.predictions.transform.LayerNorm.bias', 'cls.predictions.transform.LayerNorm.weight']\n",
      "- This IS expected if you are initializing BertModel from the checkpoint of a model trained on another task or with another architecture (e.g. initializing a BertForSequenceClassification model from a BertForPreTraining model).\n",
      "- This IS NOT expected if you are initializing BertModel from the checkpoint of a model that you expect to be exactly identical (initializing a BertForSequenceClassification model from a BertForSequenceClassification model).\n"
     ]
    }
   ],
   "source": [
    "text_encoder_pretrained_BERT = nlpsig.TextEncoder(df=anno_mi,\n",
    "                                                  feature_name=\"utterance_text\",\n",
    "                                                  model_name=bert_model)\n",
    "text_encoder_pretrained_BERT.load_pretrained_model()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "232b6964",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[INFO] Setting return_special_tokens_mask=True\n",
      "[INFO] Tokenizing the dataset...\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Map:   0%|          | 0/13551 [00:00<?, ? examples/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[INFO] Saving the tokenized text for each sentence into `.df['tokens']`...\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Map:   0%|          | 0/13551 [00:00<?, ? examples/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[INFO] Creating tokenized dataframe and setting in `.tokenized_df` attribute...\n",
      "[INFO] Note: 'text_id' is the column name for denoting the corresponding text id\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "Dataset({\n",
       "    features: ['mi_quality', 'transcript_id', 'topic', 'utterance_id', 'interlocutor', 'timestamp', 'utterance_text', 'annotator_id', 'therapist_input_exists', 'therapist_input_subtype', 'reflection_exists', 'reflection_subtype', 'question_exists', 'question_subtype', 'main_therapist_behaviour', 'client_talk_type', 'datetime', 'input_ids', 'token_type_ids', 'attention_mask', 'special_tokens_mask', 'tokens'],\n",
       "    num_rows: 13551\n",
       "})"
      ]
     },
     "execution_count": 26,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "text_encoder_pretrained_BERT.tokenize_text(skip_special_tokens=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "542e45d8",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "27e0296f8c2244c0bd37a79b2ed773f0",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/136 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "You're using a BertTokenizerFast tokenizer. Please note that with a fast tokenizer, using the `__call__` method is faster than using a method to encode the text followed by a call to the `pad` method to get a padded encoding.\n"
     ]
    }
   ],
   "source": [
    "token_embeddings_pretrained = text_encoder_pretrained_BERT.obtain_embeddings(method=\"hidden_layer\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "8eb94e1f",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "af56fde9d7974848b3ee2f426e5312d9",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/13551 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "7a5e2741f2cd4db3a1428eabfde89e6b",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/13551 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "020c2619b18f4c348df9add3d7e62a4c",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/13551 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "2abc947b4dde41aeb72d417dc46e4681",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/13551 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "pooled_mean_pretrained = text_encoder_pretrained_BERT.pool_token_embeddings()\n",
    "pooled_max_pretrained = text_encoder_pretrained_BERT.pool_token_embeddings(method=\"max\")\n",
    "pooled_sum_pretrained = text_encoder_pretrained_BERT.pool_token_embeddings(method=\"sum\") \n",
    "pooled_cls_pretrained = text_encoder_pretrained_BERT.pool_token_embeddings(method=\"cls\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "id": "9a0d0cb8",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(13551, 768)"
      ]
     },
     "execution_count": 29,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pooled_mean_pretrained.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "id": "e3dbbf88",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(13551, 768)"
      ]
     },
     "execution_count": 30,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pooled_max_pretrained.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "id": "4d80f7b3",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(13551, 768)"
      ]
     },
     "execution_count": 31,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pooled_sum_pretrained.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "id": "8a600d81",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(13551, 768)"
      ]
     },
     "execution_count": 32,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pooled_cls_pretrained.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "id": "e349143f",
   "metadata": {},
   "outputs": [],
   "source": [
    "np.save(\"anno_mi_pretrained_BERT_mean\", pooled_mean_pretrained)\n",
    "np.save(\"anno_mi_pretrained_BERT_max\", pooled_max_pretrained)\n",
    "np.save(\"anno_mi_pretrained_BERT_sum\", pooled_sum_pretrained)\n",
    "np.save(\"anno_mi_pretrained_BERT_cls\", pooled_cls_pretrained)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "78f49f72",
   "metadata": {},
   "source": [
    "## Fine-tuning BERT and pooling\n",
    "\n",
    "### (Ignoring this part for now while, but will run this on GPU cluster soon...)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "8aa279f8",
   "metadata": {},
   "outputs": [],
   "source": [
    "# pooled_mean = np.load(\"anno_mi_BERT_mean.npy\")\n",
    "# pooled_max = np.load(\"anno_mi_BERT_max.npy\")\n",
    "# pooled_sum = np.load(\"anno_mi_BERT_sum.npy\")\n",
    "# pooled_cls = np.load(\"anno_mi_BERT_cls.npy\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "id": "71edcab0",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of the model checkpoint at bert-base-uncased were not used when initializing BertForMaskedLM: ['cls.seq_relationship.weight', 'cls.seq_relationship.bias']\n",
      "- This IS expected if you are initializing BertForMaskedLM from the checkpoint of a model trained on another task or with another architecture (e.g. initializing a BertForSequenceClassification model from a BertForPreTraining model).\n",
      "- This IS NOT expected if you are initializing BertForMaskedLM from the checkpoint of a model that you expect to be exactly identical (initializing a BertForSequenceClassification model from a BertForSequenceClassification model).\n"
     ]
    }
   ],
   "source": [
    "from transformers import (\n",
    "    AutoModelForMaskedLM,\n",
    "    AutoTokenizer,\n",
    "    DataCollatorWithPadding,\n",
    "    DataCollatorForLanguageModeling,\n",
    "    Trainer,\n",
    "    TrainingArguments,\n",
    "    pipeline,\n",
    ")\n",
    "\n",
    "model = AutoModelForMaskedLM.from_pretrained(bert_model)\n",
    "tokenizer = AutoTokenizer.from_pretrained(bert_model)\n",
    "data_collator = DataCollatorWithPadding(tokenizer=tokenizer)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "id": "8981b91b",
   "metadata": {},
   "outputs": [],
   "source": [
    "text_encoder_BERT = nlpsig.TextEncoder(df=anno_mi,\n",
    "                                       feature_name=\"utterance_text\",\n",
    "                                       model=model,\n",
    "                                       tokenizer=tokenizer,\n",
    "                                       data_collator=data_collator)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "id": "e67b5e7a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[INFO] Setting return_special_tokens_mask=True\n",
      "[INFO] Tokenizing the dataset...\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Map:   0%|          | 0/13551 [00:00<?, ? examples/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[INFO] Saving the tokenized text for each sentence into `.df['tokens']`...\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Map:   0%|          | 0/13551 [00:00<?, ? examples/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[INFO] Creating tokenized dataframe and setting in `.tokenized_df` attribute...\n",
      "[INFO] Note: 'text_id' is the column name for denoting the corresponding text id\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "Dataset({\n",
       "    features: ['mi_quality', 'transcript_id', 'topic', 'utterance_id', 'interlocutor', 'timestamp', 'utterance_text', 'annotator_id', 'therapist_input_exists', 'therapist_input_subtype', 'reflection_exists', 'reflection_subtype', 'question_exists', 'question_subtype', 'main_therapist_behaviour', 'client_talk_type', 'datetime', 'tokens', 'input_ids', 'token_type_ids', 'attention_mask', 'special_tokens_mask'],\n",
       "    num_rows: 13551\n",
       "})"
      ]
     },
     "execution_count": 37,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "text_encoder_BERT.tokenize_text(skip_special_tokens=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "dcfe836f",
   "metadata": {},
   "source": [
    "### Training the model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "id": "db27164e",
   "metadata": {},
   "outputs": [],
   "source": [
    "# set up data_collator for language modelling (has dynamic padding)\n",
    "data_collator_for_LM = DataCollatorForLanguageModeling(tokenizer=tokenizer,\n",
    "                                                       mlm=True,\n",
    "                                                       mlm_probability=0.15)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "id": "c0a951eb",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[INFO] Splitting up dataset into train / validation / test sets, and saving to `.dataset_split`.\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "DatasetDict({\n",
       "    train: Dataset({\n",
       "        features: ['mi_quality', 'transcript_id', 'topic', 'utterance_id', 'interlocutor', 'timestamp', 'utterance_text', 'annotator_id', 'therapist_input_exists', 'therapist_input_subtype', 'reflection_exists', 'reflection_subtype', 'question_exists', 'question_subtype', 'main_therapist_behaviour', 'client_talk_type', 'datetime', 'tokens', 'input_ids', 'token_type_ids', 'attention_mask', 'special_tokens_mask'],\n",
       "        num_rows: 10840\n",
       "    })\n",
       "    test: Dataset({\n",
       "        features: ['mi_quality', 'transcript_id', 'topic', 'utterance_id', 'interlocutor', 'timestamp', 'utterance_text', 'annotator_id', 'therapist_input_exists', 'therapist_input_subtype', 'reflection_exists', 'reflection_subtype', 'question_exists', 'question_subtype', 'main_therapist_behaviour', 'client_talk_type', 'datetime', 'tokens', 'input_ids', 'token_type_ids', 'attention_mask', 'special_tokens_mask'],\n",
       "        num_rows: 1356\n",
       "    })\n",
       "    validation: Dataset({\n",
       "        features: ['mi_quality', 'transcript_id', 'topic', 'utterance_id', 'interlocutor', 'timestamp', 'utterance_text', 'annotator_id', 'therapist_input_exists', 'therapist_input_subtype', 'reflection_exists', 'reflection_subtype', 'question_exists', 'question_subtype', 'main_therapist_behaviour', 'client_talk_type', 'datetime', 'tokens', 'input_ids', 'token_type_ids', 'attention_mask', 'special_tokens_mask'],\n",
       "        num_rows: 1355\n",
       "    })\n",
       "})"
      ]
     },
     "execution_count": 39,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "text_encoder_BERT.split_dataset(seed=seed)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "id": "f1b63447",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "datasets.dataset_dict.DatasetDict"
      ]
     },
     "execution_count": 40,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "type(text_encoder_BERT.dataset_split)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "id": "4fbcae37",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[INFO] Setting up TrainingArguments object and saving to `.training_args`.\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "TrainingArguments(\n",
       "_n_gpu=0,\n",
       "adafactor=False,\n",
       "adam_beta1=0.9,\n",
       "adam_beta2=0.999,\n",
       "adam_epsilon=1e-08,\n",
       "auto_find_batch_size=False,\n",
       "bf16=False,\n",
       "bf16_full_eval=False,\n",
       "data_seed=None,\n",
       "dataloader_drop_last=False,\n",
       "dataloader_num_workers=0,\n",
       "dataloader_pin_memory=True,\n",
       "ddp_bucket_cap_mb=None,\n",
       "ddp_find_unused_parameters=None,\n",
       "ddp_timeout=1800,\n",
       "debug=[],\n",
       "deepspeed=None,\n",
       "disable_tqdm=False,\n",
       "do_eval=True,\n",
       "do_predict=False,\n",
       "do_train=False,\n",
       "eval_accumulation_steps=None,\n",
       "eval_delay=0,\n",
       "eval_steps=None,\n",
       "evaluation_strategy=epoch,\n",
       "fp16=False,\n",
       "fp16_backend=auto,\n",
       "fp16_full_eval=False,\n",
       "fp16_opt_level=O1,\n",
       "fsdp=[],\n",
       "fsdp_config={'fsdp_min_num_params': 0, 'xla': False, 'xla_fsdp_grad_ckpt': False},\n",
       "fsdp_min_num_params=0,\n",
       "fsdp_transformer_layer_cls_to_wrap=None,\n",
       "full_determinism=False,\n",
       "gradient_accumulation_steps=1,\n",
       "gradient_checkpointing=False,\n",
       "greater_is_better=None,\n",
       "group_by_length=False,\n",
       "half_precision_backend=auto,\n",
       "hub_model_id=None,\n",
       "hub_private_repo=False,\n",
       "hub_strategy=every_save,\n",
       "hub_token=<HUB_TOKEN>,\n",
       "ignore_data_skip=False,\n",
       "include_inputs_for_metrics=False,\n",
       "jit_mode_eval=False,\n",
       "label_names=None,\n",
       "label_smoothing_factor=0.0,\n",
       "learning_rate=5e-05,\n",
       "length_column_name=length,\n",
       "load_best_model_at_end=False,\n",
       "local_rank=-1,\n",
       "log_level=passive,\n",
       "log_level_replica=warning,\n",
       "log_on_each_node=True,\n",
       "logging_dir=bert-base-uncased-anno-mi/runs/May05_13-23-13_MAC-ATI1167,\n",
       "logging_first_step=False,\n",
       "logging_nan_inf_filter=True,\n",
       "logging_steps=500,\n",
       "logging_strategy=steps,\n",
       "lr_scheduler_type=linear,\n",
       "max_grad_norm=1.0,\n",
       "max_steps=-1,\n",
       "metric_for_best_model=None,\n",
       "mp_parameters=,\n",
       "no_cuda=False,\n",
       "num_train_epochs=600,\n",
       "optim=adamw_hf,\n",
       "optim_args=None,\n",
       "output_dir=bert-base-uncased-anno-mi,\n",
       "overwrite_output_dir=False,\n",
       "past_index=-1,\n",
       "per_device_eval_batch_size=8,\n",
       "per_device_train_batch_size=128,\n",
       "prediction_loss_only=False,\n",
       "push_to_hub=False,\n",
       "push_to_hub_model_id=None,\n",
       "push_to_hub_organization=None,\n",
       "push_to_hub_token=<PUSH_TO_HUB_TOKEN>,\n",
       "ray_scope=last,\n",
       "remove_unused_columns=True,\n",
       "report_to=[],\n",
       "resume_from_checkpoint=None,\n",
       "run_name=bert-base-uncased-anno-mi,\n",
       "save_on_each_node=False,\n",
       "save_steps=10000,\n",
       "save_strategy=steps,\n",
       "save_total_limit=None,\n",
       "seed=2023,\n",
       "sharded_ddp=[],\n",
       "skip_memory_metrics=True,\n",
       "tf32=None,\n",
       "torch_compile=False,\n",
       "torch_compile_backend=None,\n",
       "torch_compile_mode=None,\n",
       "torchdynamo=None,\n",
       "tpu_metrics_debug=False,\n",
       "tpu_num_cores=None,\n",
       "use_ipex=False,\n",
       "use_legacy_prediction_loop=False,\n",
       "use_mps_device=False,\n",
       "warmup_ratio=0.0,\n",
       "warmup_steps=0,\n",
       "weight_decay=0.0,\n",
       "xpu_backend=None,\n",
       ")"
      ]
     },
     "execution_count": 41,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model_name = \"bert-base-uncased-anno-mi\"\n",
    "text_encoder_BERT.set_up_training_args(output_dir=model_name,\n",
    "                                  num_train_epochs=600,\n",
    "                                  per_device_train_batch_size=128,\n",
    "                                  disable_tqdm=False,\n",
    "                                  save_strategy=\"steps\",\n",
    "                                  save_steps=10000,\n",
    "                                  seed=seed)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "id": "40e25170",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "transformers.training_args.TrainingArguments"
      ]
     },
     "execution_count": 42,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "type(text_encoder_BERT.training_args)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "id": "b2553a11",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[INFO] Setting up Trainer object, and saving to `.trainer`.\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<transformers.trainer.Trainer at 0x2b04c1e80>"
      ]
     },
     "execution_count": 43,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "text_encoder_BERT.set_up_trainer(data_collator=data_collator_for_LM)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "id": "5f98dbd2",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "transformers.trainer.Trainer"
      ]
     },
     "execution_count": 44,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "type(text_encoder_BERT.trainer)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "id": "63d67e88",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "False"
      ]
     },
     "execution_count": 45,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "torch.cuda.is_available()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "id": "8de2f7b5",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0"
      ]
     },
     "execution_count": 46,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "torch.cuda.device_count()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "id": "f94d187d",
   "metadata": {},
   "outputs": [],
   "source": [
    "# set to only report errors to avoid excessing logging\n",
    "transformers.utils.logging.set_verbosity(40)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7117e8a9",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[INFO] Training model with 109514298 parameters...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/rchan/opt/miniconda3/envs/nlpsig-networks/lib/python3.8/site-packages/transformers/optimization.py:391: FutureWarning: This implementation of AdamW is deprecated and will be removed in a future version. Use the PyTorch implementation torch.optim.AdamW instead, or set `no_deprecation_warning=True` to disable this warning\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "\n",
       "    <div>\n",
       "      \n",
       "      <progress value='6' max='51000' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
       "      [    6/51000 01:31 < 323:48:12, 0.04 it/s, Epoch 0.06/600]\n",
       "    </div>\n",
       "    <table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       " <tr style=\"text-align: left;\">\n",
       "      <th>Epoch</th>\n",
       "      <th>Training Loss</th>\n",
       "      <th>Validation Loss</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "  </tbody>\n",
       "</table><p>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "text_encoder_BERT.fit_transformer_with_trainer_api()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bdd4a201",
   "metadata": {},
   "outputs": [],
   "source": [
    "text_encoder_BERT.trainer.save_model(model_name)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "045c97b5",
   "metadata": {},
   "source": [
    "### Evaluating model on masked language modelling task"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "276316d8",
   "metadata": {},
   "outputs": [],
   "source": [
    "text_encoder_BERT.tokenizer.special_tokens_map"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6b67034b",
   "metadata": {},
   "outputs": [],
   "source": [
    "def compute_masked_character_accuracy(fill_mask, words):\n",
    "    was_correct = []\n",
    "    print(f\"Evaluating with {len(words)} words\")\n",
    "    for word in tqdm(words):\n",
    "        masked_strings = [word[:i] + '<mask>' + word[i+1:] for i in range(len(word))]\n",
    "        predictions = [fill_mask(word)[0]['sequence'] for word in masked_strings]\n",
    "        was_correct += [pred == word for pred in predictions]\n",
    "    \n",
    "    acc = np.sum(was_correct) / len(was_correct)\n",
    "    print(f\"Accuracy: {acc}\")\n",
    "    return acc"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4ef730f7",
   "metadata": {},
   "outputs": [],
   "source": [
    "fill_mask = pipeline(\"fill-mask\",\n",
    "                     model=model_name,\n",
    "                     tokenizer=model_name)\n",
    "\n",
    "compute_masked_character_accuracy(fill_mask, text_encoder_BERT.dataset_split[\"test\"][\"word\"])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "47d84e48",
   "metadata": {},
   "source": [
    "### Obtain embeddings from model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cda951d1",
   "metadata": {},
   "outputs": [],
   "source": [
    "# setting the model to CPU (might not be always necessary to run this)\n",
    "text_encoder_BERT.model.to('cpu')\n",
    "token_embeddings = text_encoder_BERT.obtain_embeddings(method=\"hidden_layer\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fb33ebea",
   "metadata": {},
   "outputs": [],
   "source": [
    "token_embeddings.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a9b2c773",
   "metadata": {},
   "outputs": [],
   "source": [
    "pooled_mean = text_encoder_BERT.pool_token_embeddings()\n",
    "pooled_max = text_encoder_BERT.pool_token_embeddings(method=\"max\")\n",
    "pooled_sum = text_encoder_BERT.pool_token_embeddings(method=\"sum\")\n",
    "pooled_cls = text_encoder_BERT.pool_token_embeddings(method=\"cls\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7049984f",
   "metadata": {},
   "outputs": [],
   "source": [
    "pooled_mean.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "df55c029",
   "metadata": {},
   "outputs": [],
   "source": [
    "pooled_max.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9437d362",
   "metadata": {},
   "outputs": [],
   "source": [
    "pooled_sum.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1ce2099f",
   "metadata": {},
   "outputs": [],
   "source": [
    "pooled_cls.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ca113e99",
   "metadata": {},
   "outputs": [],
   "source": [
    "np.save(\"anno_mi_BERT_mean\", pooled_mean)\n",
    "np.save(\"anno_mi_BERT_max\", pooled_max)\n",
    "np.save(\"anno_mi_BERT_sum\", pooled_sum)\n",
    "np.save(\"anno_mi_BERT_cls\", pooled_cls)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "21be231a",
   "metadata": {},
   "source": [
    "# Baseline 1: FFN baseline\n",
    "\n",
    "Using the embeddings for the sentences directly in a FFN.\n",
    "\n",
    "Below is a function that takes in some inputs x_data, y_data and fits a FFN. Will do early stopping if the F1 score continually gets worse."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 81,
   "id": "fa4edbbc",
   "metadata": {},
   "outputs": [],
   "source": [
    "def implement_ffn(x_data,\n",
    "                  y_data,\n",
    "                  hidden_dim,\n",
    "                  learning_rate,\n",
    "                  loss,\n",
    "                  gamma=0):\n",
    "    # set seed\n",
    "    set_seed(seed)\n",
    "    \n",
    "    # initialise FFN\n",
    "    ffn_model = FeedforwardNeuralNetModel(input_dim=x_data.shape[1],\n",
    "                                          hidden_dim=hidden_dim,\n",
    "                                          output_dim=len(label_to_id),\n",
    "                                          dropout_rate=0.1)\n",
    "    # print(ffn_model)\n",
    "    \n",
    "    # split dataset\n",
    "    train, valid, test = split_dataset(x_data=torch.tensor(x_data).float(),\n",
    "                                       y_data=torch.tensor(y_data),\n",
    "                                       train_size=0.8,\n",
    "                                       valid_size=0.5,\n",
    "                                       shuffle=True,\n",
    "                                       as_DataLoader=True,\n",
    "                                       seed=seed)\n",
    "\n",
    "    # define loss\n",
    "    if loss == \"focal\":\n",
    "        criterion = FocalLoss(gamma = gamma)\n",
    "    elif loss == \"cross_entropy\":\n",
    "        criterion = torch.nn.CrossEntropyLoss()\n",
    "\n",
    "    # define optimizer\n",
    "    optimizer = torch.optim.Adam(ffn_model.parameters(), lr=learning_rate)\n",
    "    # define scheduler for adjusting the learning rate\n",
    "    scheduler = ReduceLROnPlateau(optimizer, 'min')\n",
    "    # scheduler = StepLR(optimizer, step_size = 4, gamma = 0.5)\n",
    "    # scheduler = None\n",
    "    \n",
    "    ffn_model = training_pytorch(model=ffn_model,\n",
    "                                 train_loader=train,\n",
    "                                 criterion=criterion,\n",
    "                                 optimizer=optimizer,\n",
    "                                 num_epochs=10000,\n",
    "                                 scheduler=scheduler,\n",
    "                                 valid_loader=valid,\n",
    "                                 seed=seed,\n",
    "                                 early_stopping=True,\n",
    "                                 early_stopping_metric=\"f1\",\n",
    "                                 patience=10,\n",
    "                                 verbose=True,\n",
    "                                 verbose_epoch=100)\n",
    "\n",
    "    pred, label = testing_pytorch(ffn_model, test, criterion)\n",
    "    print(f\"proportion of labels in prediction: {[sum(pred==i)/len(pred) for i in label_to_id.values()]}\")\n",
    "    print(f\"proportion of labels in data: {[sum(label==i)/len(label) for i in label_to_id.values()]}\")\n",
    "    \n",
    "    f1_scores = metrics.f1_score(label, pred, average=None)\n",
    "    print(f\"- f1: {f1_scores}\")\n",
    "    print(f\"- f1 (average): {sum(f1_scores)/len(f1_scores)}\")\n",
    "    print(f\"- accuracy: {sum(pred==label)/len(pred)}\")\n",
    "    \n",
    "    return ffn_model"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0697e221",
   "metadata": {},
   "source": [
    "Going to try out some variations (1 hidden layer, 2 hidden layers and 3 hidden layers - all of size 100)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 82,
   "id": "78c5cd22",
   "metadata": {},
   "outputs": [],
   "source": [
    "hidden_dim_trials = [[100]*i for i in range(1, 6)]\n",
    "learning_rate = 1e-4\n",
    "loss = \"cross_entropy\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 83,
   "id": "8917b3bc",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[[100],\n",
       " [100, 100],\n",
       " [100, 100, 100],\n",
       " [100, 100, 100, 100],\n",
       " [100, 100, 100, 100, 100]]"
      ]
     },
     "execution_count": 83,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "hidden_dim_trials"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "111e8e8f",
   "metadata": {},
   "source": [
    "## SBERT 768"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 84,
   "id": "7c127f1d",
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "********** hidden_dim: [100]\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "818e8a75f89b499084b69374bd1a99fa",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/10000 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 1/10000 || Item: 0/85 || Loss: 1.0885392427444458\n",
      "--------------------------------------------------\n",
      "##### Epoch: 1/10000 || Loss: 1.023568868637085\n",
      "--------------------------------------------------\n",
      "Validation || Epoch: 1 || Loss: 1.016163945198059 || Accuracy: 0.6225854158401489 || F1-score: 0.25579975579975583\n",
      "Early stopping at epoch 40!\n",
      "Accuracy on dataset of size 672: 71.2797622680664 %.\n",
      "Average loss: 0.6995780386707999\n",
      "proportion of labels in prediction: [tensor(0.7173), tensor(0.1845), tensor(0.0982)]\n",
      "proportion of labels in data: [tensor(0.6235), tensor(0.2232), tensor(0.1533)]\n",
      "- f1: [0.81243063 0.53284672 0.47337278]\n",
      "- f1 (average): 0.6062167096746555\n",
      "- accuracy: 0.7127976417541504\n",
      "\n",
      "********** hidden_dim: [100, 100]\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "f32b1b3abc3a4057a950931edeb9402f",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/10000 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 1/10000 || Item: 0/85 || Loss: 1.116580843925476\n",
      "--------------------------------------------------\n",
      "##### Epoch: 1/10000 || Loss: 1.0521271228790283\n",
      "--------------------------------------------------\n",
      "Validation || Epoch: 1 || Loss: 1.026239974932237 || Accuracy: 0.6225854158401489 || F1-score: 0.25579975579975583\n",
      "Early stopping at epoch 45!\n",
      "Accuracy on dataset of size 672: 70.08928680419922 %.\n",
      "Average loss: 0.7389487461610273\n",
      "proportion of labels in prediction: [tensor(0.6875), tensor(0.2024), tensor(0.1101)]\n",
      "proportion of labels in data: [tensor(0.6235), tensor(0.2232), tensor(0.1533)]\n",
      "- f1: [0.80817253 0.51748252 0.46327684]\n",
      "- f1 (average): 0.5963106282850795\n",
      "- accuracy: 0.7008928656578064\n",
      "\n",
      "********** hidden_dim: [100, 100, 100]\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "0fb4803d4be244efbf7659308677c3d4",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/10000 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 1/10000 || Item: 0/85 || Loss: 1.0993850231170654\n",
      "--------------------------------------------------\n",
      "##### Epoch: 1/10000 || Loss: 1.0102291107177734\n",
      "--------------------------------------------------\n",
      "Validation || Epoch: 1 || Loss: 0.994836606762626 || Accuracy: 0.6225854158401489 || F1-score: 0.25579975579975583\n",
      "Early stopping at epoch 42!\n",
      "Accuracy on dataset of size 672: 70.23809814453125 %.\n",
      "Average loss: 0.7553030956875194\n",
      "proportion of labels in prediction: [tensor(0.6801), tensor(0.2098), tensor(0.1101)]\n",
      "proportion of labels in data: [tensor(0.6235), tensor(0.2232), tensor(0.1533)]\n",
      "- f1: [0.80821918 0.52920962 0.46327684]\n",
      "- f1 (average): 0.600235212077837\n",
      "- accuracy: 0.7023809552192688\n",
      "\n",
      "********** hidden_dim: [100, 100, 100, 100]\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "3bc31cf5a42447fdb810ea87df98981a",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/10000 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 1/10000 || Item: 0/85 || Loss: 1.072503924369812\n",
      "--------------------------------------------------\n",
      "##### Epoch: 1/10000 || Loss: 0.993831992149353\n",
      "--------------------------------------------------\n",
      "Validation || Epoch: 1 || Loss: 0.9791417772119696 || Accuracy: 0.6225854158401489 || F1-score: 0.25579975579975583\n",
      "Early stopping at epoch 47!\n",
      "Accuracy on dataset of size 672: 69.04762268066406 %.\n",
      "Average loss: 0.8187992193482139\n",
      "proportion of labels in prediction: [tensor(0.6801), tensor(0.1890), tensor(0.1310)]\n",
      "proportion of labels in data: [tensor(0.6235), tensor(0.2232), tensor(0.1533)]\n",
      "- f1: [0.79908676 0.50541516 0.46073298]\n",
      "- f1 (average): 0.5884116349129783\n",
      "- accuracy: 0.6904761791229248\n",
      "\n",
      "********** hidden_dim: [100, 100, 100, 100, 100]\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "5b82ac0c25ed4c5f8f6b07ff12573fe2",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/10000 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 1/10000 || Item: 0/85 || Loss: 1.1058584451675415\n",
      "--------------------------------------------------\n",
      "##### Epoch: 1/10000 || Loss: 1.0399665832519531\n",
      "--------------------------------------------------\n",
      "Validation || Epoch: 1 || Loss: 1.0396888039328835 || Accuracy: 0.6225854158401489 || F1-score: 0.25579975579975583\n",
      "Early stopping at epoch 50!\n",
      "Accuracy on dataset of size 672: 69.19642639160156 %.\n",
      "Average loss: 0.8239231001247059\n",
      "proportion of labels in prediction: [tensor(0.7113), tensor(0.1815), tensor(0.1071)]\n",
      "proportion of labels in data: [tensor(0.6235), tensor(0.2232), tensor(0.1533)]\n",
      "- f1: [0.79821628 0.51470588 0.42285714]\n",
      "- f1 (average): 0.57859310056241\n",
      "- accuracy: 0.6919642686843872\n"
     ]
    }
   ],
   "source": [
    "for hidden_dim in hidden_dim_trials:\n",
    "    print(f\"\\n********** hidden_dim: {hidden_dim}\")\n",
    "    implement_ffn(x_data=sbert_768_embeddings[client_index],\n",
    "                  y_data=y_data,\n",
    "                  hidden_dim=hidden_dim,\n",
    "                  learning_rate=learning_rate,\n",
    "                  loss=loss)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "07d3fa20",
   "metadata": {},
   "source": [
    "## SBERT 384"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 85,
   "id": "171c2dab",
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "********** hidden_dim: [100]\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "9fd64fa3ff5b46c7b17003a200c057f0",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/10000 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 1/10000 || Item: 0/85 || Loss: 1.0692368745803833\n",
      "--------------------------------------------------\n",
      "##### Epoch: 1/10000 || Loss: 1.0163383483886719\n",
      "--------------------------------------------------\n",
      "Validation || Epoch: 1 || Loss: 1.0099996599284085 || Accuracy: 0.6225854158401489 || F1-score: 0.25579975579975583\n",
      "Early stopping at epoch 52!\n",
      "Accuracy on dataset of size 672: 71.875 %.\n",
      "Average loss: 0.7035864103924144\n",
      "proportion of labels in prediction: [tensor(0.7232), tensor(0.1696), tensor(0.1071)]\n",
      "proportion of labels in data: [tensor(0.6235), tensor(0.2232), tensor(0.1533)]\n",
      "- f1: [0.81767956 0.51515152 0.51428571]\n",
      "- f1 (average): 0.6157055958160931\n",
      "- accuracy: 0.71875\n",
      "\n",
      "********** hidden_dim: [100, 100]\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "e56c90c16cf146c0bfe8d03d23c9f4ca",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/10000 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 1/10000 || Item: 0/85 || Loss: 1.1142284870147705\n",
      "--------------------------------------------------\n",
      "##### Epoch: 1/10000 || Loss: 1.0404751300811768\n",
      "--------------------------------------------------\n",
      "Validation || Epoch: 1 || Loss: 1.043692480434071 || Accuracy: 0.6225854158401489 || F1-score: 0.25579975579975583\n",
      "Early stopping at epoch 45!\n",
      "Accuracy on dataset of size 672: 70.53571319580078 %.\n",
      "Average loss: 0.7237868959253485\n",
      "proportion of labels in prediction: [tensor(0.7247), tensor(0.1741), tensor(0.1012)]\n",
      "proportion of labels in data: [tensor(0.6235), tensor(0.2232), tensor(0.1533)]\n",
      "- f1: [0.80573951 0.51685393 0.46783626]\n",
      "- f1 (average): 0.5968099014143323\n",
      "- accuracy: 0.7053571343421936\n",
      "\n",
      "********** hidden_dim: [100, 100, 100]\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "6ad6268f02a84439ac02fb076f1e3fe4",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/10000 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 1/10000 || Item: 0/85 || Loss: 1.0598180294036865\n",
      "--------------------------------------------------\n",
      "##### Epoch: 1/10000 || Loss: 0.9991912245750427\n",
      "--------------------------------------------------\n",
      "Validation || Epoch: 1 || Loss: 1.004194275899367 || Accuracy: 0.6225854158401489 || F1-score: 0.25579975579975583\n",
      "Early stopping at epoch 67!\n",
      "Accuracy on dataset of size 672: 70.68452453613281 %.\n",
      "Average loss: 0.7685691226612438\n",
      "proportion of labels in prediction: [tensor(0.6979), tensor(0.1830), tensor(0.1190)]\n",
      "proportion of labels in data: [tensor(0.6235), tensor(0.2232), tensor(0.1533)]\n",
      "- f1: [0.8018018  0.54212454 0.49180328]\n",
      "- f1 (average): 0.6119098742049561\n",
      "- accuracy: 0.706845223903656\n",
      "\n",
      "********** hidden_dim: [100, 100, 100, 100]\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "e608003236c74290b2930e1dd694b274",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/10000 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 1/10000 || Item: 0/85 || Loss: 1.075019359588623\n",
      "--------------------------------------------------\n",
      "##### Epoch: 1/10000 || Loss: 0.9795213937759399\n",
      "--------------------------------------------------\n",
      "Validation || Epoch: 1 || Loss: 1.0088304281234741 || Accuracy: 0.6225854158401489 || F1-score: 0.25579975579975583\n",
      "Early stopping at epoch 31!\n",
      "Accuracy on dataset of size 672: 65.92262268066406 %.\n",
      "Average loss: 0.8153174790469083\n",
      "proportion of labels in prediction: [tensor(0.7188), tensor(0.2812), tensor(0.)]\n",
      "proportion of labels in data: [tensor(0.6235), tensor(0.2232), tensor(0.1533)]\n",
      "- f1: [0.81374723 0.44837758 0.        ]\n",
      "- f1 (average): 0.42070826983410625\n",
      "- accuracy: 0.6592261791229248\n",
      "\n",
      "********** hidden_dim: [100, 100, 100, 100, 100]\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "8b05b48342974e369c6946ca769d2474",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/10000 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 1/10000 || Item: 0/85 || Loss: 1.1322060823440552\n",
      "--------------------------------------------------\n",
      "##### Epoch: 1/10000 || Loss: 1.0921815633773804\n",
      "--------------------------------------------------\n",
      "Validation || Epoch: 1 || Loss: 1.0522005774758079 || Accuracy: 0.6225854158401489 || F1-score: 0.25579975579975583\n",
      "Early stopping at epoch 49!\n",
      "Accuracy on dataset of size 672: 66.81547546386719 %.\n",
      "Average loss: 0.814079609784213\n",
      "proportion of labels in prediction: [tensor(0.7009), tensor(0.2321), tensor(0.0670)]\n",
      "proportion of labels in data: [tensor(0.6235), tensor(0.2232), tensor(0.1533)]\n",
      "- f1: [0.80449438 0.43137255 0.33783784]\n",
      "- f1 (average): 0.524568256293306\n",
      "- accuracy: 0.668154776096344\n"
     ]
    }
   ],
   "source": [
    "for hidden_dim in hidden_dim_trials:\n",
    "    print(f\"\\n********** hidden_dim: {hidden_dim}\")\n",
    "    implement_ffn(x_data=sbert_384_embeddings[client_index],\n",
    "                  y_data=y_data,\n",
    "                  hidden_dim=hidden_dim,\n",
    "                  learning_rate=learning_rate,\n",
    "                  loss=loss)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8b733d5c",
   "metadata": {},
   "source": [
    "## Pretrained BERT"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "65a1a153",
   "metadata": {},
   "source": [
    "### Mean pooled"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 86,
   "id": "ec223628",
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "********** hidden_dim: [100]\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "4cc243a02bc74d45925d01b228697c02",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/10000 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 1/10000 || Item: 0/85 || Loss: 1.0839786529541016\n",
      "--------------------------------------------------\n",
      "##### Epoch: 1/10000 || Loss: 0.7457855343818665\n",
      "--------------------------------------------------\n",
      "Validation || Epoch: 1 || Loss: 0.8354992433027788 || Accuracy: 0.6225854158401489 || F1-score: 0.25579975579975583\n",
      "Early stopping at epoch 43!\n",
      "Accuracy on dataset of size 672: 69.79166412353516 %.\n",
      "Average loss: 0.7122157866304571\n",
      "proportion of labels in prediction: [tensor(0.7039), tensor(0.2083), tensor(0.0878)]\n",
      "proportion of labels in data: [tensor(0.6235), tensor(0.2232), tensor(0.1533)]\n",
      "- f1: [0.80269058 0.51724138 0.44444444]\n",
      "- f1 (average): 0.5881254689048102\n",
      "- accuracy: 0.6979166865348816\n",
      "\n",
      "********** hidden_dim: [100, 100]\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "f4d89dc209fd48b9913f083fb2543fff",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/10000 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 1/10000 || Item: 0/85 || Loss: 1.1131868362426758\n",
      "--------------------------------------------------\n",
      "##### Epoch: 1/10000 || Loss: 0.8533899784088135\n",
      "--------------------------------------------------\n",
      "Validation || Epoch: 1 || Loss: 0.8532686233520508 || Accuracy: 0.6225854158401489 || F1-score: 0.25579975579975583\n",
      "Early stopping at epoch 35!\n",
      "Accuracy on dataset of size 672: 70.98213958740234 %.\n",
      "Average loss: 0.701988697052002\n",
      "proportion of labels in prediction: [tensor(0.6949), tensor(0.2128), tensor(0.0923)]\n",
      "proportion of labels in data: [tensor(0.6235), tensor(0.2232), tensor(0.1533)]\n",
      "- f1: [0.81038375 0.53924915 0.47272727]\n",
      "- f1 (average): 0.6074533888877603\n",
      "- accuracy: 0.7098214030265808\n",
      "\n",
      "********** hidden_dim: [100, 100, 100]\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "c0bde0b9336140c09371d1191f99c3dc",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/10000 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 1/10000 || Item: 0/85 || Loss: 1.098788857460022\n",
      "--------------------------------------------------\n",
      "##### Epoch: 1/10000 || Loss: 0.8470583558082581\n",
      "--------------------------------------------------\n",
      "Validation || Epoch: 1 || Loss: 0.8576378388838335 || Accuracy: 0.6225854158401489 || F1-score: 0.25579975579975583\n",
      "Early stopping at epoch 36!\n",
      "Accuracy on dataset of size 672: 70.83333587646484 %.\n",
      "Average loss: 0.7304971489039335\n",
      "proportion of labels in prediction: [tensor(0.6830), tensor(0.2188), tensor(0.0982)]\n",
      "proportion of labels in data: [tensor(0.6235), tensor(0.2232), tensor(0.1533)]\n",
      "- f1: [0.80637813 0.55892256 0.46153846]\n",
      "- f1 (average): 0.6089463841931573\n",
      "- accuracy: 0.7083333134651184\n",
      "\n",
      "********** hidden_dim: [100, 100, 100, 100]\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "0fc03731998848909a2a2ccdc3a0a198",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/10000 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 1/10000 || Item: 0/85 || Loss: 1.0730299949645996\n",
      "--------------------------------------------------\n",
      "##### Epoch: 1/10000 || Loss: 0.835125207901001\n",
      "--------------------------------------------------\n",
      "Validation || Epoch: 1 || Loss: 0.8732638359069824 || Accuracy: 0.6225854158401489 || F1-score: 0.25579975579975583\n",
      "Early stopping at epoch 45!\n",
      "Accuracy on dataset of size 672: 70.68452453613281 %.\n",
      "Average loss: 0.7486193478107452\n",
      "proportion of labels in prediction: [tensor(0.7068), tensor(0.1994), tensor(0.0938)]\n",
      "proportion of labels in data: [tensor(0.6235), tensor(0.2232), tensor(0.1533)]\n",
      "- f1: [0.81208054 0.52112676 0.45783133]\n",
      "- f1 (average): 0.5970128742591122\n",
      "- accuracy: 0.706845223903656\n",
      "\n",
      "********** hidden_dim: [100, 100, 100, 100, 100]\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "8ba9a436d3ab44e18e5f0fc31dcec0c9",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/10000 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 1/10000 || Item: 0/85 || Loss: 1.1056439876556396\n",
      "--------------------------------------------------\n",
      "##### Epoch: 1/10000 || Loss: 0.9540625214576721\n",
      "--------------------------------------------------\n",
      "Validation || Epoch: 1 || Loss: 0.882446364922957 || Accuracy: 0.6225854158401489 || F1-score: 0.25579975579975583\n",
      "Early stopping at epoch 51!\n",
      "Accuracy on dataset of size 672: 72.76786041259766 %.\n",
      "Average loss: 0.7767329216003418\n",
      "proportion of labels in prediction: [tensor(0.6905), tensor(0.1979), tensor(0.1116)]\n",
      "proportion of labels in data: [tensor(0.6235), tensor(0.2232), tensor(0.1533)]\n",
      "- f1: [0.81993205 0.55123675 0.5505618 ]\n",
      "- f1 (average): 0.6405768655665137\n",
      "- accuracy: 0.7276785969734192\n"
     ]
    }
   ],
   "source": [
    "for hidden_dim in hidden_dim_trials:\n",
    "    print(f\"\\n********** hidden_dim: {hidden_dim}\")\n",
    "    implement_ffn(x_data=pooled_mean_pretrained[client_index],\n",
    "                  y_data=y_data,\n",
    "                  hidden_dim=hidden_dim,\n",
    "                  learning_rate=learning_rate,\n",
    "                  loss=loss)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d5ccba75",
   "metadata": {},
   "source": [
    "### Max pooled"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 87,
   "id": "b29316bf",
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "********** hidden_dim: [100]\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "b8c5bc6f5e4e42e0b41d03328e524828",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/10000 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 1/10000 || Item: 0/85 || Loss: 1.0957067012786865\n",
      "--------------------------------------------------\n",
      "##### Epoch: 1/10000 || Loss: 0.7537550926208496\n",
      "--------------------------------------------------\n",
      "Validation || Epoch: 1 || Loss: 0.8680760372768749 || Accuracy: 0.6225854158401489 || F1-score: 0.25579975579975583\n",
      "Early stopping at epoch 52!\n",
      "Accuracy on dataset of size 672: 69.79166412353516 %.\n",
      "Average loss: 0.7068305503238331\n",
      "proportion of labels in prediction: [tensor(0.7173), tensor(0.2054), tensor(0.0774)]\n",
      "proportion of labels in data: [tensor(0.6235), tensor(0.2232), tensor(0.1533)]\n",
      "- f1: [0.80133185 0.52777778 0.41290323]\n",
      "- f1 (average): 0.580670952360115\n",
      "- accuracy: 0.6979166865348816\n",
      "\n",
      "********** hidden_dim: [100, 100]\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "77a168ac0f8e47e788b2845ea34e9487",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/10000 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 1/10000 || Item: 0/85 || Loss: 1.1076050996780396\n",
      "--------------------------------------------------\n",
      "##### Epoch: 1/10000 || Loss: 0.9455707669258118\n",
      "--------------------------------------------------\n",
      "Validation || Epoch: 1 || Loss: 0.9177429025823419 || Accuracy: 0.6225854158401489 || F1-score: 0.25579975579975583\n",
      "Early stopping at epoch 53!\n",
      "Accuracy on dataset of size 672: 71.42857360839844 %.\n",
      "Average loss: 0.7085082368417219\n",
      "proportion of labels in prediction: [tensor(0.7202), tensor(0.2024), tensor(0.0774)]\n",
      "proportion of labels in data: [tensor(0.6235), tensor(0.2232), tensor(0.1533)]\n",
      "- f1: [0.80841639 0.53846154 0.49032258]\n",
      "- f1 (average): 0.6124001696394794\n",
      "- accuracy: 0.7142857313156128\n",
      "\n",
      "********** hidden_dim: [100, 100, 100]\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "f2fc7daa66544bd1acac762cdd97d92a",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/10000 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 1/10000 || Item: 0/85 || Loss: 1.0997354984283447\n",
      "--------------------------------------------------\n",
      "##### Epoch: 1/10000 || Loss: 0.929989755153656\n",
      "--------------------------------------------------\n",
      "Validation || Epoch: 1 || Loss: 0.9196747053753246 || Accuracy: 0.6225854158401489 || F1-score: 0.25579975579975583\n",
      "Early stopping at epoch 53!\n",
      "Accuracy on dataset of size 672: 70.08928680419922 %.\n",
      "Average loss: 0.7250180461189963\n",
      "proportion of labels in prediction: [tensor(0.7024), tensor(0.2143), tensor(0.0833)]\n",
      "proportion of labels in data: [tensor(0.6235), tensor(0.2232), tensor(0.1533)]\n",
      "- f1: [0.8013468  0.53741497 0.44025157]\n",
      "- f1 (average): 0.5930044465534133\n",
      "- accuracy: 0.7008928656578064\n",
      "\n",
      "********** hidden_dim: [100, 100, 100, 100]\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "6815235e5060498dba04d6d09310f06d",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/10000 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 1/10000 || Item: 0/85 || Loss: 1.0746076107025146\n",
      "--------------------------------------------------\n",
      "##### Epoch: 1/10000 || Loss: 0.9190363883972168\n",
      "--------------------------------------------------\n",
      "Validation || Epoch: 1 || Loss: 0.9312605370174755 || Accuracy: 0.6225854158401489 || F1-score: 0.25579975579975583\n",
      "Early stopping at epoch 53!\n",
      "Accuracy on dataset of size 672: 69.64286041259766 %.\n",
      "Average loss: 0.7155440043319355\n",
      "proportion of labels in prediction: [tensor(0.7083), tensor(0.2054), tensor(0.0863)]\n",
      "proportion of labels in data: [tensor(0.6235), tensor(0.2232), tensor(0.1533)]\n",
      "- f1: [0.79553073 0.52083333 0.45962733]\n",
      "- f1 (average): 0.5919971295942877\n",
      "- accuracy: 0.6964285969734192\n",
      "\n",
      "********** hidden_dim: [100, 100, 100, 100, 100]\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "bb2d81bee4f44e72a7c64c7c3cfaa446",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/10000 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 1/10000 || Item: 0/85 || Loss: 1.1055570840835571\n",
      "--------------------------------------------------\n",
      "##### Epoch: 1/10000 || Loss: 1.035354733467102\n",
      "--------------------------------------------------\n",
      "Validation || Epoch: 1 || Loss: 0.9438045024871826 || Accuracy: 0.6225854158401489 || F1-score: 0.25579975579975583\n",
      "Early stopping at epoch 58!\n",
      "Accuracy on dataset of size 672: 70.23809814453125 %.\n",
      "Average loss: 0.7381011681123213\n",
      "proportion of labels in prediction: [tensor(0.7024), tensor(0.2068), tensor(0.0908)]\n",
      "proportion of labels in data: [tensor(0.6235), tensor(0.2232), tensor(0.1533)]\n",
      "- f1: [0.80359147 0.52595156 0.46341463]\n",
      "- f1 (average): 0.5976525538326346\n",
      "- accuracy: 0.7023809552192688\n"
     ]
    }
   ],
   "source": [
    "for hidden_dim in hidden_dim_trials:\n",
    "    print(f\"\\n********** hidden_dim: {hidden_dim}\")\n",
    "    implement_ffn(x_data=pooled_max_pretrained[client_index],\n",
    "                  y_data=y_data,\n",
    "                  hidden_dim=hidden_dim,\n",
    "                  learning_rate=learning_rate,\n",
    "                  loss=loss)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2bc6d9ad",
   "metadata": {},
   "source": [
    "### Sum pooled"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 88,
   "id": "dc652cf2",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "********** hidden_dim: [100]\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "5d30807b61e94c3791eb5de2ec0de99e",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/10000 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 1/10000 || Item: 0/85 || Loss: 2.0271031856536865\n",
      "--------------------------------------------------\n",
      "##### Epoch: 1/10000 || Loss: 0.8685790300369263\n",
      "--------------------------------------------------\n",
      "Validation || Epoch: 1 || Loss: 0.8226919986984946 || Accuracy: 0.6463595628738403 || F1-score: 0.4247232595366326\n",
      "Early stopping at epoch 31!\n",
      "Accuracy on dataset of size 672: 70.98213958740234 %.\n",
      "Average loss: 0.774150935086337\n",
      "proportion of labels in prediction: [tensor(0.7173), tensor(0.2039), tensor(0.0789)]\n",
      "proportion of labels in data: [tensor(0.6235), tensor(0.2232), tensor(0.1533)]\n",
      "- f1: [0.81021088 0.55052265 0.42307692]\n",
      "- f1 (average): 0.5946034826546994\n",
      "- accuracy: 0.7098214030265808\n",
      "\n",
      "********** hidden_dim: [100, 100]\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "887360b473bf49aa8a0a7fb95cd8c7d5",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/10000 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 1/10000 || Item: 0/85 || Loss: 1.114878535270691\n",
      "--------------------------------------------------\n",
      "##### Epoch: 1/10000 || Loss: 0.7568445205688477\n",
      "--------------------------------------------------\n",
      "Validation || Epoch: 1 || Loss: 0.8589342778379266 || Accuracy: 0.6508172154426575 || F1-score: 0.46548398969451604\n",
      "Early stopping at epoch 35!\n",
      "Accuracy on dataset of size 672: 70.83333587646484 %.\n",
      "Average loss: 0.7620173096656799\n",
      "proportion of labels in prediction: [tensor(0.7039), tensor(0.2113), tensor(0.0848)]\n",
      "proportion of labels in data: [tensor(0.6235), tensor(0.2232), tensor(0.1533)]\n",
      "- f1: [0.80493274 0.56849315 0.425     ]\n",
      "- f1 (average): 0.5994752953703134\n",
      "- accuracy: 0.7083333134651184\n",
      "\n",
      "********** hidden_dim: [100, 100, 100]\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "bb8d898dcbd74a9e8aad6e29f1ede595",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/10000 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 1/10000 || Item: 0/85 || Loss: 1.111946940422058\n",
      "--------------------------------------------------\n",
      "##### Epoch: 1/10000 || Loss: 0.8133658766746521\n",
      "--------------------------------------------------\n",
      "Validation || Epoch: 1 || Loss: 0.8259054476564581 || Accuracy: 0.637444257736206 || F1-score: 0.4151506273197447\n",
      "Early stopping at epoch 29!\n",
      "Accuracy on dataset of size 672: 70.38690185546875 %.\n",
      "Average loss: 0.8185790181159973\n",
      "proportion of labels in prediction: [tensor(0.6815), tensor(0.2277), tensor(0.0908)]\n",
      "proportion of labels in data: [tensor(0.6235), tensor(0.2232), tensor(0.1533)]\n",
      "- f1: [0.8027366  0.55445545 0.45121951]\n",
      "- f1 (average): 0.6028038532640426\n",
      "- accuracy: 0.7038690447807312\n",
      "\n",
      "********** hidden_dim: [100, 100, 100, 100]\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "44cf8d5e6c5a42c7bf22197b6d13c34e",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/10000 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 1/10000 || Item: 0/85 || Loss: 1.0758711099624634\n",
      "--------------------------------------------------\n",
      "##### Epoch: 1/10000 || Loss: 0.8967788219451904\n",
      "--------------------------------------------------\n",
      "Validation || Epoch: 1 || Loss: 0.9189632643352855 || Accuracy: 0.6315007209777832 || F1-score: 0.30164060280829436\n",
      "Early stopping at epoch 37!\n",
      "Accuracy on dataset of size 672: 72.32142639160156 %.\n",
      "Average loss: 0.8004374504089355\n",
      "proportion of labels in prediction: [tensor(0.7024), tensor(0.1935), tensor(0.1042)]\n",
      "proportion of labels in data: [tensor(0.6235), tensor(0.2232), tensor(0.1533)]\n",
      "- f1: [0.81481481 0.56428571 0.50867052]\n",
      "- f1 (average): 0.6292570164439142\n",
      "- accuracy: 0.7232142686843872\n",
      "\n",
      "********** hidden_dim: [100, 100, 100, 100, 100]\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "b1c0d80ebf624573b6ab48a42c1e7304",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/10000 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 1/10000 || Item: 0/85 || Loss: 1.1112335920333862\n",
      "--------------------------------------------------\n",
      "##### Epoch: 1/10000 || Loss: 0.9961893558502197\n",
      "--------------------------------------------------\n",
      "Validation || Epoch: 1 || Loss: 0.975874434817921 || Accuracy: 0.6225854158401489 || F1-score: 0.25579975579975583\n",
      "Early stopping at epoch 41!\n",
      "Accuracy on dataset of size 672: 70.08928680419922 %.\n",
      "Average loss: 0.9458087682723999\n",
      "proportion of labels in prediction: [tensor(0.6830), tensor(0.2158), tensor(0.1012)]\n",
      "proportion of labels in data: [tensor(0.6235), tensor(0.2232), tensor(0.1533)]\n",
      "- f1: [0.79954442 0.53559322 0.47953216]\n",
      "- f1 (average): 0.6048899344053565\n",
      "- accuracy: 0.7008928656578064\n"
     ]
    }
   ],
   "source": [
    "for hidden_dim in hidden_dim_trials:\n",
    "    print(f\"\\n********** hidden_dim: {hidden_dim}\")\n",
    "    implement_ffn(x_data=pooled_sum_pretrained[client_index],\n",
    "                  y_data=y_data,\n",
    "                  hidden_dim=hidden_dim,\n",
    "                  learning_rate=learning_rate,\n",
    "                  loss=loss)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d48ba477",
   "metadata": {},
   "source": [
    "### CLS"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 89,
   "id": "66881445",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "********** hidden_dim: [100]\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "92467b7cfb594cb1836f34e26b603671",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/10000 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 1/10000 || Item: 0/85 || Loss: 1.072586178779602\n",
      "--------------------------------------------------\n",
      "##### Epoch: 1/10000 || Loss: 0.7834479808807373\n",
      "--------------------------------------------------\n",
      "Validation || Epoch: 1 || Loss: 0.8409460566260598 || Accuracy: 0.6225854158401489 || F1-score: 0.25579975579975583\n",
      "Early stopping at epoch 43!\n",
      "Accuracy on dataset of size 672: 71.875 %.\n",
      "Average loss: 0.6774346611716531\n",
      "proportion of labels in prediction: [tensor(0.7366), tensor(0.1786), tensor(0.0848)]\n",
      "proportion of labels in data: [tensor(0.6235), tensor(0.2232), tensor(0.1533)]\n",
      "- f1: [0.81619256 0.53333333 0.475     ]\n",
      "- f1 (average): 0.6081752978361293\n",
      "- accuracy: 0.71875\n",
      "\n",
      "********** hidden_dim: [100, 100]\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "971770230441481ca223ce6e4ad422b6",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/10000 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 1/10000 || Item: 0/85 || Loss: 1.1158097982406616\n",
      "--------------------------------------------------\n",
      "##### Epoch: 1/10000 || Loss: 0.9066270589828491\n",
      "--------------------------------------------------\n",
      "Validation || Epoch: 1 || Loss: 0.8640799901702187 || Accuracy: 0.6225854158401489 || F1-score: 0.25579975579975583\n",
      "Early stopping at epoch 38!\n",
      "Accuracy on dataset of size 672: 72.02381134033203 %.\n",
      "Average loss: 0.673450849272988\n",
      "proportion of labels in prediction: [tensor(0.7351), tensor(0.1741), tensor(0.0908)]\n",
      "proportion of labels in data: [tensor(0.6235), tensor(0.2232), tensor(0.1533)]\n",
      "- f1: [0.81489595 0.52434457 0.51219512]\n",
      "- f1 (average): 0.617145212888559\n",
      "- accuracy: 0.7202380895614624\n",
      "\n",
      "********** hidden_dim: [100, 100, 100]\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "9206f44232d143bca47e50b29b436dbd",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/10000 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 1/10000 || Item: 0/85 || Loss: 1.099726676940918\n",
      "--------------------------------------------------\n",
      "##### Epoch: 1/10000 || Loss: 0.9140689969062805\n",
      "--------------------------------------------------\n",
      "Validation || Epoch: 1 || Loss: 0.8757737441496416 || Accuracy: 0.6225854158401489 || F1-score: 0.25579975579975583\n",
      "Early stopping at epoch 44!\n",
      "Accuracy on dataset of size 672: 71.57737731933594 %.\n",
      "Average loss: 0.6988080143928528\n",
      "proportion of labels in prediction: [tensor(0.7068), tensor(0.1964), tensor(0.0967)]\n",
      "proportion of labels in data: [tensor(0.6235), tensor(0.2232), tensor(0.1533)]\n",
      "- f1: [0.81208054 0.5248227  0.52380952]\n",
      "- f1 (average): 0.6202375852525788\n",
      "- accuracy: 0.7157738208770752\n",
      "\n",
      "********** hidden_dim: [100, 100, 100, 100]\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "50ce91de422843e28ac7caca38c6804e",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/10000 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 1/10000 || Item: 0/85 || Loss: 1.0739099979400635\n",
      "--------------------------------------------------\n",
      "##### Epoch: 1/10000 || Loss: 0.8497714996337891\n",
      "--------------------------------------------------\n",
      "Validation || Epoch: 1 || Loss: 0.8862914334643971 || Accuracy: 0.6225854158401489 || F1-score: 0.25579975579975583\n",
      "Early stopping at epoch 36!\n",
      "Accuracy on dataset of size 672: 70.08928680419922 %.\n",
      "Average loss: 0.7242212187160145\n",
      "proportion of labels in prediction: [tensor(0.6786), tensor(0.2381), tensor(0.0833)]\n",
      "proportion of labels in data: [tensor(0.6235), tensor(0.2232), tensor(0.1533)]\n",
      "- f1: [0.79771429 0.5483871  0.46540881]\n",
      "- f1 (average): 0.6038367291733087\n",
      "- accuracy: 0.7008928656578064\n",
      "\n",
      "********** hidden_dim: [100, 100, 100, 100, 100]\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "5336895762ff41abaf43f039c8871f8e",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/10000 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 1/10000 || Item: 0/85 || Loss: 1.1050199270248413\n",
      "--------------------------------------------------\n",
      "##### Epoch: 1/10000 || Loss: 1.0113009214401245\n",
      "--------------------------------------------------\n",
      "Validation || Epoch: 1 || Loss: 0.8908429525115273 || Accuracy: 0.6225854158401489 || F1-score: 0.25579975579975583\n",
      "Early stopping at epoch 60!\n",
      "Accuracy on dataset of size 672: 70.38690185546875 %.\n",
      "Average loss: 0.7129268104379828\n",
      "proportion of labels in prediction: [tensor(0.7217), tensor(0.1771), tensor(0.1012)]\n",
      "proportion of labels in data: [tensor(0.6235), tensor(0.2232), tensor(0.1533)]\n",
      "- f1: [0.80530973 0.49814126 0.49122807]\n",
      "- f1 (average): 0.5982263562097445\n",
      "- accuracy: 0.7038690447807312\n"
     ]
    }
   ],
   "source": [
    "for hidden_dim in hidden_dim_trials:\n",
    "    print(f\"\\n********** hidden_dim: {hidden_dim}\")\n",
    "    implement_ffn(x_data=pooled_cls_pretrained[client_index],\n",
    "                  y_data=y_data,\n",
    "                  hidden_dim=hidden_dim,\n",
    "                  learning_rate=learning_rate,\n",
    "                  loss=loss)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5b56f20c",
   "metadata": {},
   "source": [
    "## Fine-tuned BERT"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "322b9c48",
   "metadata": {},
   "source": [
    "### Mean pooled"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "49c5917f",
   "metadata": {},
   "outputs": [],
   "source": [
    "for hidden_dim in hidden_dim_trials:\n",
    "    print(f\"\\n********** hidden_dim: {hidden_dim}\")\n",
    "    implement_ffn(x_data=pooled_mean_pretrained[client_index],\n",
    "                  y_data=y_data,\n",
    "                  hidden_dim=hidden_dim,\n",
    "                  learning_rate=1e-5,\n",
    "                  loss=\"cross_entropy\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2d8539bc",
   "metadata": {},
   "source": [
    "### Max pooled"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ed9ea306",
   "metadata": {},
   "outputs": [],
   "source": [
    "for hidden_dim in hidden_dim_trials:\n",
    "    print(f\"\\n********** hidden_dim: {hidden_dim}\")\n",
    "    implement_ffn(x_data=pooled_max_pretrained[client_index],\n",
    "                  y_data=y_data,\n",
    "                  hidden_dim=hidden_dim,\n",
    "                  learning_rate=learning_rate,\n",
    "                  loss=loss)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "010c3752",
   "metadata": {},
   "source": [
    "### Sum pooled"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1c343d0c",
   "metadata": {},
   "outputs": [],
   "source": [
    "for hidden_dim in hidden_dim_trials:\n",
    "    print(f\"\\n********** hidden_dim: {hidden_dim}\")\n",
    "    implement_ffn(x_data=pooled_sum_pretrained[client_index],\n",
    "                  y_data=y_data,\n",
    "                  hidden_dim=hidden_dim,\n",
    "                  learning_rate=learning_rate,\n",
    "                  loss=loss)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "df7bbdf7",
   "metadata": {},
   "source": [
    "### CLS"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f6ada025",
   "metadata": {},
   "outputs": [],
   "source": [
    "for hidden_dim in hidden_dim_trials:\n",
    "    print(f\"\\n********** hidden_dim: {hidden_dim}\")\n",
    "    implement_ffn(x_data=pooled_sum_pretrained[client_index],\n",
    "                  y_data=y_data,\n",
    "                  hidden_dim=hidden_dim,\n",
    "                  learning_rate=learning_rate,\n",
    "                  loss=loss)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8ad7a7e7",
   "metadata": {},
   "source": [
    "# Baseline 2: Averaging history and use FFN\n",
    "\n",
    "Here, we will use `nlpsig` to construct some paths of embeddings which we will average and use those in a FFN.\n",
    "\n",
    "First, we define the arguments for how we want to construct our path. As we're going to just do a simple average of embeddings, I'll set zero padding as false, and construct the path by looking at the last `k` posts.\n",
    "\n",
    "We will consider one where we average their histories and that is the only inputs to the FFN. Alternatively, we can concatenate the full post embedding as well."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 181,
   "id": "5740fcf7",
   "metadata": {},
   "outputs": [],
   "source": [
    "path_specifics = {\"pad_by\": \"history\",\n",
    "                  \"zero_padding\": False,\n",
    "                  \"method\": \"k_last\",\n",
    "                  \"k\": 10,\n",
    "                  \"time_feature\": None,\n",
    "                  \"embeddings\": \"full\",\n",
    "                  \"include_current_embedding\": True}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 182,
   "id": "801fe1af",
   "metadata": {},
   "outputs": [],
   "source": [
    "def obtain_mean_history(embeddings, path_specifics, concatenate_current = True):\n",
    "    paths = nlpsig.PrepareData(anno_mi,\n",
    "                               id_column=\"transcript_id\",\n",
    "                               label_column=\"client_talk_type\",\n",
    "                               embeddings=embeddings)\n",
    "    path = paths.pad(**path_specifics)\n",
    "    # remove last two columns (which contains the id and the label)\n",
    "    path = path[client_index][:,:,:-2]\n",
    "    # average in the first dimension\n",
    "    path = path.mean(1).astype(\"float\")\n",
    "    # concatenate with current embedding\n",
    "    if concatenate_current:\n",
    "        path = np.concatenate([path, embeddings[client_index]], axis=1)\n",
    "    return path"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fe58b289",
   "metadata": {},
   "source": [
    "## SBERT 768"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 183,
   "id": "ea61eb5c",
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[INFO] Concatenating the embeddings to the dataframe...\n",
      "[INFO] - columns beginning with 'e' denote the full embddings.\n",
      "[INFO] Adding time feature columns into dataframe in `.df`.\n",
      "[INFO] Adding 'time_encoding' and feature...\n",
      "[INFO] Adding 'time_diff' and feature...\n",
      "[INFO] Adding 'timeline_index' feature...\n",
      "[INFO] Padding ids and storing in `.df_padded` and `.array_padded` attributes.\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "9b2b62f0879941fe812d642dcdc4bce6",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/13551 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "********** hidden_dim: [100]\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "a33ffac4fa874228a69852d55e5153ce",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/10000 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 1/10000 || Item: 0/85 || Loss: 1.0951521396636963\n",
      "--------------------------------------------------\n",
      "##### Epoch: 1/10000 || Loss: 0.989008367061615\n",
      "--------------------------------------------------\n",
      "Validation || Epoch: 1 || Loss: 0.9893851226026361 || Accuracy: 0.6225854158401489 || F1-score: 0.25579975579975583\n",
      "Early stopping at epoch 50!\n",
      "Accuracy on dataset of size 672: 72.02381134033203 %.\n",
      "Average loss: 0.6766794919967651\n",
      "proportion of labels in prediction: [tensor(0.6949), tensor(0.2054), tensor(0.0997)]\n",
      "proportion of labels in data: [tensor(0.6235), tensor(0.2232), tensor(0.1533)]\n",
      "- f1: [0.81489842 0.57638889 0.47058824]\n",
      "- f1 (average): 0.6206251813491889\n",
      "- accuracy: 0.7202380895614624\n",
      "\n",
      "********** hidden_dim: [100, 100]\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "7e2115f0524b4a879c6444423c14aa85",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/10000 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 1/10000 || Item: 0/85 || Loss: 1.0840717554092407\n",
      "--------------------------------------------------\n",
      "##### Epoch: 1/10000 || Loss: 0.9826463460922241\n",
      "--------------------------------------------------\n",
      "Validation || Epoch: 1 || Loss: 0.9629483819007874 || Accuracy: 0.6225854158401489 || F1-score: 0.25579975579975583\n",
      "Early stopping at epoch 41!\n",
      "Accuracy on dataset of size 672: 71.72618865966797 %.\n",
      "Average loss: 0.6966309574517336\n",
      "proportion of labels in prediction: [tensor(0.6741), tensor(0.2217), tensor(0.1042)]\n",
      "proportion of labels in data: [tensor(0.6235), tensor(0.2232), tensor(0.1533)]\n",
      "- f1: [0.80963303 0.58862876 0.47398844]\n",
      "- f1 (average): 0.6240834097903668\n",
      "- accuracy: 0.7172619104385376\n",
      "\n",
      "********** hidden_dim: [100, 100, 100]\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "8232a020c46b4d168651ea472d81e387",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/10000 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 1/10000 || Item: 0/85 || Loss: 1.0726923942565918\n",
      "--------------------------------------------------\n",
      "##### Epoch: 1/10000 || Loss: 1.004392385482788\n",
      "--------------------------------------------------\n",
      "Validation || Epoch: 1 || Loss: 0.9865520596504211 || Accuracy: 0.6225854158401489 || F1-score: 0.25579975579975583\n",
      "Early stopping at epoch 42!\n",
      "Accuracy on dataset of size 672: 71.13095092773438 %.\n",
      "Average loss: 0.7030555768446489\n",
      "proportion of labels in prediction: [tensor(0.6637), tensor(0.2173), tensor(0.1190)]\n",
      "proportion of labels in data: [tensor(0.6235), tensor(0.2232), tensor(0.1533)]\n",
      "- f1: [0.80231214 0.58783784 0.48087432]\n",
      "- f1 (average): 0.6236747645020175\n",
      "- accuracy: 0.711309552192688\n",
      "\n",
      "********** hidden_dim: [100, 100, 100, 100]\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "cc4804e90fa143469b25608f5fdb07b7",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/10000 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 1/10000 || Item: 0/85 || Loss: 1.094164490699768\n",
      "--------------------------------------------------\n",
      "##### Epoch: 1/10000 || Loss: 1.024963617324829\n",
      "--------------------------------------------------\n",
      "Validation || Epoch: 1 || Loss: 0.981616123156114 || Accuracy: 0.6225854158401489 || F1-score: 0.25579975579975583\n",
      "Early stopping at epoch 43!\n",
      "Accuracy on dataset of size 672: 72.76786041259766 %.\n",
      "Average loss: 0.7731133970347318\n",
      "proportion of labels in prediction: [tensor(0.6756), tensor(0.2113), tensor(0.1131)]\n",
      "proportion of labels in data: [tensor(0.6235), tensor(0.2232), tensor(0.1533)]\n",
      "- f1: [0.81786942 0.61643836 0.46927374]\n",
      "- f1 (average): 0.6345271716629012\n",
      "- accuracy: 0.7276785969734192\n",
      "\n",
      "********** hidden_dim: [100, 100, 100, 100, 100]\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "a9e889a684f44b38a0d3c32a576ebb4a",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/10000 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 1/10000 || Item: 0/85 || Loss: 1.0790125131607056\n",
      "--------------------------------------------------\n",
      "##### Epoch: 1/10000 || Loss: 1.0606188774108887\n",
      "--------------------------------------------------\n",
      "Validation || Epoch: 1 || Loss: 1.0005513754757969 || Accuracy: 0.6225854158401489 || F1-score: 0.25579975579975583\n",
      "Early stopping at epoch 42!\n",
      "Accuracy on dataset of size 672: 68.1547622680664 %.\n",
      "Average loss: 0.7737902836366133\n",
      "proportion of labels in prediction: [tensor(0.7113), tensor(0.2887), tensor(0.)]\n",
      "proportion of labels in data: [tensor(0.6235), tensor(0.2232), tensor(0.1533)]\n",
      "- f1: [0.82274247 0.51744186 0.        ]\n",
      "- f1 (average): 0.4467281117938347\n",
      "- accuracy: 0.6815476417541504\n"
     ]
    }
   ],
   "source": [
    "path_history = obtain_mean_history(sbert_768_embeddings, path_specifics)\n",
    "for hidden_dim in hidden_dim_trials:\n",
    "    print(f\"\\n********** hidden_dim: {hidden_dim}\")\n",
    "    implement_ffn(x_data=path_history,\n",
    "                  y_data=y_data,\n",
    "                  hidden_dim=hidden_dim,\n",
    "                  learning_rate=learning_rate,\n",
    "                  loss=loss)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 184,
   "id": "dc029e46",
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[INFO] Concatenating the embeddings to the dataframe...\n",
      "[INFO] - columns beginning with 'e' denote the full embddings.\n",
      "[INFO] Adding time feature columns into dataframe in `.df`.\n",
      "[INFO] Adding 'time_encoding' and feature...\n",
      "[INFO] Adding 'time_diff' and feature...\n",
      "[INFO] Adding 'timeline_index' feature...\n",
      "[INFO] Padding ids and storing in `.df_padded` and `.array_padded` attributes.\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "d35729b7a343410989e18e08c02aec0c",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/13551 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "********** hidden_dim: [100]\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "01443fea51e741b799fcea024f99a803",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/10000 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 1/10000 || Item: 0/85 || Loss: 1.0880542993545532\n",
      "--------------------------------------------------\n",
      "##### Epoch: 1/10000 || Loss: 1.0509945154190063\n",
      "--------------------------------------------------\n",
      "Validation || Epoch: 1 || Loss: 1.0244701613079419 || Accuracy: 0.6225854158401489 || F1-score: 0.25579975579975583\n",
      "Epoch: 101/10000 || Item: 0/85 || Loss: 0.5583634972572327\n",
      "--------------------------------------------------\n",
      "##### Epoch: 101/10000 || Loss: 0.585810661315918\n",
      "--------------------------------------------------\n",
      "Validation || Epoch: 101 || Loss: 0.839062815362757 || Accuracy: 0.6433877944946289 || F1-score: 0.41885211195699923\n",
      "Epoch: 201/10000 || Item: 0/85 || Loss: 0.7235603928565979\n",
      "--------------------------------------------------\n",
      "##### Epoch: 201/10000 || Loss: 0.9222613573074341\n",
      "--------------------------------------------------\n",
      "Validation || Epoch: 201 || Loss: 0.8442041603001681 || Accuracy: 0.6433877944946289 || F1-score: 0.41885211195699923\n",
      "Epoch: 301/10000 || Item: 0/85 || Loss: 0.5920047163963318\n",
      "--------------------------------------------------\n",
      "##### Epoch: 301/10000 || Loss: 0.9662424325942993\n",
      "--------------------------------------------------\n",
      "Validation || Epoch: 301 || Loss: 0.8294442241842096 || Accuracy: 0.6433877944946289 || F1-score: 0.41885211195699923\n",
      "Epoch: 401/10000 || Item: 0/85 || Loss: 0.6790724992752075\n",
      "--------------------------------------------------\n",
      "##### Epoch: 401/10000 || Loss: 0.909406304359436\n",
      "--------------------------------------------------\n",
      "Validation || Epoch: 401 || Loss: 0.8412123430858959 || Accuracy: 0.6433877944946289 || F1-score: 0.41885211195699923\n",
      "Epoch: 501/10000 || Item: 0/85 || Loss: 0.6981169581413269\n",
      "--------------------------------------------------\n",
      "##### Epoch: 501/10000 || Loss: 0.22343561053276062\n",
      "--------------------------------------------------\n",
      "Validation || Epoch: 501 || Loss: 0.8392861051992937 || Accuracy: 0.6433877944946289 || F1-score: 0.41885211195699923\n",
      "Epoch: 601/10000 || Item: 0/85 || Loss: 0.5387876033782959\n",
      "--------------------------------------------------\n",
      "##### Epoch: 601/10000 || Loss: 0.3916431665420532\n",
      "--------------------------------------------------\n",
      "Validation || Epoch: 601 || Loss: 0.8348061713305387 || Accuracy: 0.6433877944946289 || F1-score: 0.41885211195699923\n",
      "Epoch: 701/10000 || Item: 0/85 || Loss: 0.6003940105438232\n",
      "--------------------------------------------------\n",
      "##### Epoch: 701/10000 || Loss: 0.5813522934913635\n",
      "--------------------------------------------------\n",
      "Validation || Epoch: 701 || Loss: 0.8283192786303434 || Accuracy: 0.6433877944946289 || F1-score: 0.41885211195699923\n",
      "Epoch: 801/10000 || Item: 0/85 || Loss: 0.7248688340187073\n",
      "--------------------------------------------------\n",
      "##### Epoch: 801/10000 || Loss: 0.7408626675605774\n",
      "--------------------------------------------------\n",
      "Validation || Epoch: 801 || Loss: 0.8505943363363092 || Accuracy: 0.6433877944946289 || F1-score: 0.41885211195699923\n",
      "Epoch: 901/10000 || Item: 0/85 || Loss: 0.4980325698852539\n",
      "--------------------------------------------------\n",
      "##### Epoch: 901/10000 || Loss: 0.47099679708480835\n",
      "--------------------------------------------------\n",
      "Validation || Epoch: 901 || Loss: 0.8347967700524763 || Accuracy: 0.6433877944946289 || F1-score: 0.41885211195699923\n",
      "Epoch: 1001/10000 || Item: 0/85 || Loss: 0.6409279108047485\n",
      "--------------------------------------------------\n",
      "##### Epoch: 1001/10000 || Loss: 0.7367464900016785\n",
      "--------------------------------------------------\n",
      "Validation || Epoch: 1001 || Loss: 0.8454318263313987 || Accuracy: 0.6433877944946289 || F1-score: 0.41885211195699923\n",
      "Epoch: 1101/10000 || Item: 0/85 || Loss: 0.7663983702659607\n",
      "--------------------------------------------------\n",
      "##### Epoch: 1101/10000 || Loss: 1.17780339717865\n",
      "--------------------------------------------------\n",
      "Validation || Epoch: 1101 || Loss: 0.8307847543196245 || Accuracy: 0.6433877944946289 || F1-score: 0.41885211195699923\n",
      "Epoch: 1201/10000 || Item: 0/85 || Loss: 0.7067415118217468\n",
      "--------------------------------------------------\n",
      "##### Epoch: 1201/10000 || Loss: 0.6274296045303345\n",
      "--------------------------------------------------\n",
      "Validation || Epoch: 1201 || Loss: 0.8330220580101013 || Accuracy: 0.6433877944946289 || F1-score: 0.41885211195699923\n",
      "Epoch: 1301/10000 || Item: 0/85 || Loss: 0.8050370216369629\n",
      "--------------------------------------------------\n",
      "##### Epoch: 1301/10000 || Loss: 1.092362403869629\n",
      "--------------------------------------------------\n",
      "Validation || Epoch: 1301 || Loss: 0.8308925628662109 || Accuracy: 0.6433877944946289 || F1-score: 0.41885211195699923\n",
      "Epoch: 1401/10000 || Item: 0/85 || Loss: 0.654321551322937\n",
      "--------------------------------------------------\n",
      "##### Epoch: 1401/10000 || Loss: 1.48299241065979\n",
      "--------------------------------------------------\n",
      "Validation || Epoch: 1401 || Loss: 0.8417337265881625 || Accuracy: 0.6433877944946289 || F1-score: 0.41885211195699923\n",
      "Epoch: 1501/10000 || Item: 0/85 || Loss: 0.6778185367584229\n",
      "--------------------------------------------------\n",
      "##### Epoch: 1501/10000 || Loss: 0.5808417201042175\n",
      "--------------------------------------------------\n",
      "Validation || Epoch: 1501 || Loss: 0.8355596715753729 || Accuracy: 0.6433877944946289 || F1-score: 0.41885211195699923\n",
      "Epoch: 1601/10000 || Item: 0/85 || Loss: 0.5881289839744568\n",
      "--------------------------------------------------\n",
      "##### Epoch: 1601/10000 || Loss: 1.3359768390655518\n",
      "--------------------------------------------------\n",
      "Validation || Epoch: 1601 || Loss: 0.8325426090847362 || Accuracy: 0.6433877944946289 || F1-score: 0.41885211195699923\n",
      "Epoch: 1701/10000 || Item: 0/85 || Loss: 0.5771466493606567\n",
      "--------------------------------------------------\n",
      "##### Epoch: 1701/10000 || Loss: 0.6622010469436646\n",
      "--------------------------------------------------\n",
      "Validation || Epoch: 1701 || Loss: 0.8351128209720958 || Accuracy: 0.6433877944946289 || F1-score: 0.41885211195699923\n",
      "Epoch: 1801/10000 || Item: 0/85 || Loss: 0.7719352841377258\n",
      "--------------------------------------------------\n",
      "##### Epoch: 1801/10000 || Loss: 0.9985703229904175\n",
      "--------------------------------------------------\n",
      "Validation || Epoch: 1801 || Loss: 0.8401816866614602 || Accuracy: 0.6433877944946289 || F1-score: 0.41885211195699923\n",
      "Epoch: 1901/10000 || Item: 0/85 || Loss: 0.6479575037956238\n",
      "--------------------------------------------------\n",
      "##### Epoch: 1901/10000 || Loss: 0.6989930272102356\n",
      "--------------------------------------------------\n",
      "Validation || Epoch: 1901 || Loss: 0.8413030450994318 || Accuracy: 0.6433877944946289 || F1-score: 0.41885211195699923\n",
      "Epoch: 2001/10000 || Item: 0/85 || Loss: 0.6123430728912354\n",
      "--------------------------------------------------\n",
      "##### Epoch: 2001/10000 || Loss: 0.7402787208557129\n",
      "--------------------------------------------------\n",
      "Validation || Epoch: 2001 || Loss: 0.8320758613673124 || Accuracy: 0.6433877944946289 || F1-score: 0.41885211195699923\n",
      "Epoch: 2101/10000 || Item: 0/85 || Loss: 0.6103181838989258\n",
      "--------------------------------------------------\n",
      "##### Epoch: 2101/10000 || Loss: 0.7306152582168579\n",
      "--------------------------------------------------\n",
      "Validation || Epoch: 2101 || Loss: 0.8299578590826555 || Accuracy: 0.6433877944946289 || F1-score: 0.41885211195699923\n",
      "Epoch: 2201/10000 || Item: 0/85 || Loss: 0.6670680046081543\n",
      "--------------------------------------------------\n",
      "##### Epoch: 2201/10000 || Loss: 0.8617569208145142\n",
      "--------------------------------------------------\n",
      "Validation || Epoch: 2201 || Loss: 0.8415545333515514 || Accuracy: 0.6433877944946289 || F1-score: 0.41885211195699923\n",
      "Epoch: 2301/10000 || Item: 0/85 || Loss: 0.6461907029151917\n",
      "--------------------------------------------------\n",
      "##### Epoch: 2301/10000 || Loss: 0.831814169883728\n",
      "--------------------------------------------------\n",
      "Validation || Epoch: 2301 || Loss: 0.8469563776796515 || Accuracy: 0.6433877944946289 || F1-score: 0.41885211195699923\n",
      "Epoch: 2401/10000 || Item: 0/85 || Loss: 0.7875521779060364\n",
      "--------------------------------------------------\n",
      "##### Epoch: 2401/10000 || Loss: 0.7263110876083374\n",
      "--------------------------------------------------\n",
      "Validation || Epoch: 2401 || Loss: 0.8268339525569569 || Accuracy: 0.6433877944946289 || F1-score: 0.41885211195699923\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 2501/10000 || Item: 0/85 || Loss: 0.7536625862121582\n",
      "--------------------------------------------------\n",
      "##### Epoch: 2501/10000 || Loss: 0.5907317996025085\n",
      "--------------------------------------------------\n",
      "Validation || Epoch: 2501 || Loss: 0.8393472324718129 || Accuracy: 0.6433877944946289 || F1-score: 0.41885211195699923\n",
      "Epoch: 2601/10000 || Item: 0/85 || Loss: 0.7094292640686035\n",
      "--------------------------------------------------\n",
      "##### Epoch: 2601/10000 || Loss: 1.0559871196746826\n",
      "--------------------------------------------------\n",
      "Validation || Epoch: 2601 || Loss: 0.8366749557581815 || Accuracy: 0.6433877944946289 || F1-score: 0.41885211195699923\n",
      "Epoch: 2701/10000 || Item: 0/85 || Loss: 0.6577372550964355\n",
      "--------------------------------------------------\n",
      "##### Epoch: 2701/10000 || Loss: 0.7832667231559753\n",
      "--------------------------------------------------\n",
      "Validation || Epoch: 2701 || Loss: 0.839256075295535 || Accuracy: 0.6433877944946289 || F1-score: 0.41885211195699923\n",
      "Epoch: 2801/10000 || Item: 0/85 || Loss: 0.7763367295265198\n",
      "--------------------------------------------------\n",
      "##### Epoch: 2801/10000 || Loss: 0.9442986249923706\n",
      "--------------------------------------------------\n",
      "Validation || Epoch: 2801 || Loss: 0.8357163125818426 || Accuracy: 0.6433877944946289 || F1-score: 0.41885211195699923\n",
      "Epoch: 2901/10000 || Item: 0/85 || Loss: 0.8108526468276978\n",
      "--------------------------------------------------\n",
      "##### Epoch: 2901/10000 || Loss: 0.2617725133895874\n",
      "--------------------------------------------------\n",
      "Validation || Epoch: 2901 || Loss: 0.8387367833744396 || Accuracy: 0.6433877944946289 || F1-score: 0.41885211195699923\n",
      "Epoch: 3001/10000 || Item: 0/85 || Loss: 0.6745149493217468\n",
      "--------------------------------------------------\n",
      "##### Epoch: 3001/10000 || Loss: 0.48446834087371826\n",
      "--------------------------------------------------\n",
      "Validation || Epoch: 3001 || Loss: 0.8301600488749418 || Accuracy: 0.6433877944946289 || F1-score: 0.41885211195699923\n",
      "Epoch: 3101/10000 || Item: 0/85 || Loss: 0.6560128927230835\n",
      "--------------------------------------------------\n",
      "##### Epoch: 3101/10000 || Loss: 0.43805819749832153\n",
      "--------------------------------------------------\n",
      "Validation || Epoch: 3101 || Loss: 0.8388563231988386 || Accuracy: 0.6433877944946289 || F1-score: 0.41885211195699923\n",
      "Epoch: 3201/10000 || Item: 0/85 || Loss: 0.5811225771903992\n",
      "--------------------------------------------------\n",
      "##### Epoch: 3201/10000 || Loss: 1.3039661645889282\n",
      "--------------------------------------------------\n",
      "Validation || Epoch: 3201 || Loss: 0.8566086238080804 || Accuracy: 0.6433877944946289 || F1-score: 0.41885211195699923\n",
      "Epoch: 3301/10000 || Item: 0/85 || Loss: 0.6076288819313049\n",
      "--------------------------------------------------\n",
      "##### Epoch: 3301/10000 || Loss: 0.7175047397613525\n",
      "--------------------------------------------------\n",
      "Validation || Epoch: 3301 || Loss: 0.8299989429387179 || Accuracy: 0.6433877944946289 || F1-score: 0.41885211195699923\n",
      "Epoch: 3401/10000 || Item: 0/85 || Loss: 0.6464788317680359\n",
      "--------------------------------------------------\n",
      "##### Epoch: 3401/10000 || Loss: 0.5881425142288208\n",
      "--------------------------------------------------\n",
      "Validation || Epoch: 3401 || Loss: 0.8433066660707648 || Accuracy: 0.6433877944946289 || F1-score: 0.41885211195699923\n",
      "Epoch: 3501/10000 || Item: 0/85 || Loss: 0.5249145030975342\n",
      "--------------------------------------------------\n",
      "##### Epoch: 3501/10000 || Loss: 1.672715187072754\n",
      "--------------------------------------------------\n",
      "Validation || Epoch: 3501 || Loss: 0.8368574976921082 || Accuracy: 0.6433877944946289 || F1-score: 0.41885211195699923\n",
      "Epoch: 3601/10000 || Item: 0/85 || Loss: 0.5822636485099792\n",
      "--------------------------------------------------\n",
      "##### Epoch: 3601/10000 || Loss: 0.7591995000839233\n",
      "--------------------------------------------------\n",
      "Validation || Epoch: 3601 || Loss: 0.8355889320373535 || Accuracy: 0.6433877944946289 || F1-score: 0.41885211195699923\n",
      "Epoch: 3701/10000 || Item: 0/85 || Loss: 0.7156544923782349\n",
      "--------------------------------------------------\n",
      "##### Epoch: 3701/10000 || Loss: 0.7092358469963074\n",
      "--------------------------------------------------\n",
      "Validation || Epoch: 3701 || Loss: 0.8383785106919028 || Accuracy: 0.6433877944946289 || F1-score: 0.41885211195699923\n",
      "Epoch: 3801/10000 || Item: 0/85 || Loss: 0.6031133532524109\n",
      "--------------------------------------------------\n",
      "##### Epoch: 3801/10000 || Loss: 0.7545669674873352\n",
      "--------------------------------------------------\n",
      "Validation || Epoch: 3801 || Loss: 0.8337540138851512 || Accuracy: 0.6433877944946289 || F1-score: 0.41885211195699923\n",
      "Epoch: 3901/10000 || Item: 0/85 || Loss: 0.809363067150116\n",
      "--------------------------------------------------\n",
      "##### Epoch: 3901/10000 || Loss: 0.3240409791469574\n",
      "--------------------------------------------------\n",
      "Validation || Epoch: 3901 || Loss: 0.8274373520504344 || Accuracy: 0.6433877944946289 || F1-score: 0.41885211195699923\n",
      "Epoch: 4001/10000 || Item: 0/85 || Loss: 0.6262032985687256\n",
      "--------------------------------------------------\n",
      "##### Epoch: 4001/10000 || Loss: 0.45346730947494507\n",
      "--------------------------------------------------\n",
      "Validation || Epoch: 4001 || Loss: 0.8310890739614313 || Accuracy: 0.6433877944946289 || F1-score: 0.41885211195699923\n",
      "Epoch: 4101/10000 || Item: 0/85 || Loss: 0.6833329796791077\n",
      "--------------------------------------------------\n",
      "##### Epoch: 4101/10000 || Loss: 0.4698188602924347\n",
      "--------------------------------------------------\n",
      "Validation || Epoch: 4101 || Loss: 0.8338149135762994 || Accuracy: 0.6433877944946289 || F1-score: 0.41885211195699923\n",
      "Epoch: 4201/10000 || Item: 0/85 || Loss: 0.6445040106773376\n",
      "--------------------------------------------------\n",
      "##### Epoch: 4201/10000 || Loss: 2.154695510864258\n",
      "--------------------------------------------------\n",
      "Validation || Epoch: 4201 || Loss: 0.845837267962369 || Accuracy: 0.6433877944946289 || F1-score: 0.41885211195699923\n",
      "Epoch: 4301/10000 || Item: 0/85 || Loss: 0.5957415699958801\n",
      "--------------------------------------------------\n",
      "##### Epoch: 4301/10000 || Loss: 0.39260929822921753\n",
      "--------------------------------------------------\n",
      "Validation || Epoch: 4301 || Loss: 0.8285954973914407 || Accuracy: 0.6433877944946289 || F1-score: 0.41885211195699923\n",
      "Epoch: 4401/10000 || Item: 0/85 || Loss: 0.5284245014190674\n",
      "--------------------------------------------------\n",
      "##### Epoch: 4401/10000 || Loss: 1.2115614414215088\n",
      "--------------------------------------------------\n",
      "Validation || Epoch: 4401 || Loss: 0.837232611396096 || Accuracy: 0.6433877944946289 || F1-score: 0.41885211195699923\n",
      "Epoch: 4501/10000 || Item: 0/85 || Loss: 0.6412433385848999\n",
      "--------------------------------------------------\n",
      "##### Epoch: 4501/10000 || Loss: 0.8719560503959656\n",
      "--------------------------------------------------\n",
      "Validation || Epoch: 4501 || Loss: 0.8309637904167175 || Accuracy: 0.6433877944946289 || F1-score: 0.41885211195699923\n",
      "Epoch: 4601/10000 || Item: 0/85 || Loss: 0.6786374449729919\n",
      "--------------------------------------------------\n",
      "##### Epoch: 4601/10000 || Loss: 0.8633456230163574\n",
      "--------------------------------------------------\n",
      "Validation || Epoch: 4601 || Loss: 0.8374713876030662 || Accuracy: 0.6433877944946289 || F1-score: 0.41885211195699923\n",
      "Epoch: 4701/10000 || Item: 0/85 || Loss: 0.6775655150413513\n",
      "--------------------------------------------------\n",
      "##### Epoch: 4701/10000 || Loss: 0.6429789662361145\n",
      "--------------------------------------------------\n",
      "Validation || Epoch: 4701 || Loss: 0.8256296732208945 || Accuracy: 0.6433877944946289 || F1-score: 0.41885211195699923\n",
      "Epoch: 4801/10000 || Item: 0/85 || Loss: 0.6200969219207764\n",
      "--------------------------------------------------\n",
      "##### Epoch: 4801/10000 || Loss: 0.3899986445903778\n",
      "--------------------------------------------------\n",
      "Validation || Epoch: 4801 || Loss: 0.839328484101729 || Accuracy: 0.6433877944946289 || F1-score: 0.41885211195699923\n",
      "Epoch: 4901/10000 || Item: 0/85 || Loss: 0.6513777375221252\n",
      "--------------------------------------------------\n",
      "##### Epoch: 4901/10000 || Loss: 1.1588263511657715\n",
      "--------------------------------------------------\n",
      "Validation || Epoch: 4901 || Loss: 0.8363258784467523 || Accuracy: 0.6433877944946289 || F1-score: 0.41885211195699923\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 5001/10000 || Item: 0/85 || Loss: 0.6542056798934937\n",
      "--------------------------------------------------\n",
      "##### Epoch: 5001/10000 || Loss: 0.5106123685836792\n",
      "--------------------------------------------------\n",
      "Validation || Epoch: 5001 || Loss: 0.8313697413964705 || Accuracy: 0.6433877944946289 || F1-score: 0.41885211195699923\n",
      "Epoch: 5101/10000 || Item: 0/85 || Loss: 0.6271029710769653\n",
      "--------------------------------------------------\n",
      "##### Epoch: 5101/10000 || Loss: 0.7818343639373779\n",
      "--------------------------------------------------\n",
      "Validation || Epoch: 5101 || Loss: 0.8302126526832581 || Accuracy: 0.6433877944946289 || F1-score: 0.41885211195699923\n",
      "Epoch: 5201/10000 || Item: 0/85 || Loss: 0.5383269786834717\n",
      "--------------------------------------------------\n",
      "##### Epoch: 5201/10000 || Loss: 1.1728729009628296\n",
      "--------------------------------------------------\n",
      "Validation || Epoch: 5201 || Loss: 0.851501004262404 || Accuracy: 0.6433877944946289 || F1-score: 0.41885211195699923\n",
      "Epoch: 5301/10000 || Item: 0/85 || Loss: 0.6857506036758423\n",
      "--------------------------------------------------\n",
      "##### Epoch: 5301/10000 || Loss: 0.9355784058570862\n",
      "--------------------------------------------------\n",
      "Validation || Epoch: 5301 || Loss: 0.8351134061813354 || Accuracy: 0.6433877944946289 || F1-score: 0.41885211195699923\n",
      "Epoch: 5401/10000 || Item: 0/85 || Loss: 0.774519681930542\n",
      "--------------------------------------------------\n",
      "##### Epoch: 5401/10000 || Loss: 0.9383746981620789\n",
      "--------------------------------------------------\n",
      "Validation || Epoch: 5401 || Loss: 0.8242814053188671 || Accuracy: 0.6433877944946289 || F1-score: 0.41885211195699923\n",
      "Epoch: 5501/10000 || Item: 0/85 || Loss: 0.6545531749725342\n",
      "--------------------------------------------------\n",
      "##### Epoch: 5501/10000 || Loss: 0.6853520274162292\n",
      "--------------------------------------------------\n",
      "Validation || Epoch: 5501 || Loss: 0.8383721275763079 || Accuracy: 0.6433877944946289 || F1-score: 0.41885211195699923\n",
      "Epoch: 5601/10000 || Item: 0/85 || Loss: 0.8280114531517029\n",
      "--------------------------------------------------\n",
      "##### Epoch: 5601/10000 || Loss: 0.4365917146205902\n",
      "--------------------------------------------------\n",
      "Validation || Epoch: 5601 || Loss: 0.8298046101223339 || Accuracy: 0.6433877944946289 || F1-score: 0.41885211195699923\n",
      "Epoch: 5701/10000 || Item: 0/85 || Loss: 0.6388463973999023\n",
      "--------------------------------------------------\n",
      "##### Epoch: 5701/10000 || Loss: 1.0407794713974\n",
      "--------------------------------------------------\n",
      "Validation || Epoch: 5701 || Loss: 0.8221634409644387 || Accuracy: 0.6433877944946289 || F1-score: 0.41885211195699923\n",
      "Epoch: 5801/10000 || Item: 0/85 || Loss: 0.7526723146438599\n",
      "--------------------------------------------------\n",
      "##### Epoch: 5801/10000 || Loss: 0.7101107835769653\n",
      "--------------------------------------------------\n",
      "Validation || Epoch: 5801 || Loss: 0.8374602957205339 || Accuracy: 0.6433877944946289 || F1-score: 0.41885211195699923\n",
      "Epoch: 5901/10000 || Item: 0/85 || Loss: 0.6889966130256653\n",
      "--------------------------------------------------\n",
      "##### Epoch: 5901/10000 || Loss: 0.6742041110992432\n",
      "--------------------------------------------------\n",
      "Validation || Epoch: 5901 || Loss: 0.8343919894912026 || Accuracy: 0.6433877944946289 || F1-score: 0.41885211195699923\n",
      "Epoch: 6001/10000 || Item: 0/85 || Loss: 0.7497429847717285\n",
      "--------------------------------------------------\n",
      "##### Epoch: 6001/10000 || Loss: 1.2664989233016968\n",
      "--------------------------------------------------\n",
      "Validation || Epoch: 6001 || Loss: 0.8453151746229692 || Accuracy: 0.6433877944946289 || F1-score: 0.41885211195699923\n",
      "Epoch: 6101/10000 || Item: 0/85 || Loss: 0.6087910532951355\n",
      "--------------------------------------------------\n",
      "##### Epoch: 6101/10000 || Loss: 0.322079062461853\n",
      "--------------------------------------------------\n",
      "Validation || Epoch: 6101 || Loss: 0.8358615149151195 || Accuracy: 0.6433877944946289 || F1-score: 0.41885211195699923\n",
      "Epoch: 6201/10000 || Item: 0/85 || Loss: 0.662328839302063\n",
      "--------------------------------------------------\n",
      "##### Epoch: 6201/10000 || Loss: 0.560808539390564\n",
      "--------------------------------------------------\n",
      "Validation || Epoch: 6201 || Loss: 0.8389306664466858 || Accuracy: 0.6433877944946289 || F1-score: 0.41885211195699923\n",
      "Epoch: 6301/10000 || Item: 0/85 || Loss: 0.7040153741836548\n",
      "--------------------------------------------------\n",
      "##### Epoch: 6301/10000 || Loss: 0.631828248500824\n",
      "--------------------------------------------------\n",
      "Validation || Epoch: 6301 || Loss: 0.8311180038885637 || Accuracy: 0.6433877944946289 || F1-score: 0.41885211195699923\n",
      "Epoch: 6401/10000 || Item: 0/85 || Loss: 0.542366087436676\n",
      "--------------------------------------------------\n",
      "##### Epoch: 6401/10000 || Loss: 0.47357574105262756\n",
      "--------------------------------------------------\n",
      "Validation || Epoch: 6401 || Loss: 0.8246332623741843 || Accuracy: 0.6433877944946289 || F1-score: 0.41885211195699923\n",
      "Epoch: 6501/10000 || Item: 0/85 || Loss: 0.6304095387458801\n",
      "--------------------------------------------------\n",
      "##### Epoch: 6501/10000 || Loss: 0.33470457792282104\n",
      "--------------------------------------------------\n",
      "Validation || Epoch: 6501 || Loss: 0.8533954078500922 || Accuracy: 0.6433877944946289 || F1-score: 0.41885211195699923\n",
      "Epoch: 6601/10000 || Item: 0/85 || Loss: 0.5857524275779724\n",
      "--------------------------------------------------\n",
      "##### Epoch: 6601/10000 || Loss: 1.165973424911499\n",
      "--------------------------------------------------\n",
      "Validation || Epoch: 6601 || Loss: 0.8396060304208235 || Accuracy: 0.6433877944946289 || F1-score: 0.41885211195699923\n",
      "Epoch: 6701/10000 || Item: 0/85 || Loss: 0.6236975789070129\n",
      "--------------------------------------------------\n",
      "##### Epoch: 6701/10000 || Loss: 0.778764009475708\n",
      "--------------------------------------------------\n",
      "Validation || Epoch: 6701 || Loss: 0.8341161933812228 || Accuracy: 0.6433877944946289 || F1-score: 0.41885211195699923\n",
      "Epoch: 6801/10000 || Item: 0/85 || Loss: 0.6007236242294312\n",
      "--------------------------------------------------\n",
      "##### Epoch: 6801/10000 || Loss: 0.2437247931957245\n",
      "--------------------------------------------------\n",
      "Validation || Epoch: 6801 || Loss: 0.835654312914068 || Accuracy: 0.6433877944946289 || F1-score: 0.41885211195699923\n",
      "Epoch: 6901/10000 || Item: 0/85 || Loss: 0.7893702387809753\n",
      "--------------------------------------------------\n",
      "##### Epoch: 6901/10000 || Loss: 0.5527958273887634\n",
      "--------------------------------------------------\n",
      "Validation || Epoch: 6901 || Loss: 0.8460337086157366 || Accuracy: 0.6433877944946289 || F1-score: 0.41885211195699923\n",
      "Epoch: 7001/10000 || Item: 0/85 || Loss: 0.6280937194824219\n",
      "--------------------------------------------------\n",
      "##### Epoch: 7001/10000 || Loss: 0.7257893085479736\n",
      "--------------------------------------------------\n",
      "Validation || Epoch: 7001 || Loss: 0.8342576135288585 || Accuracy: 0.6433877944946289 || F1-score: 0.41885211195699923\n",
      "Epoch: 7101/10000 || Item: 0/85 || Loss: 0.6281341314315796\n",
      "--------------------------------------------------\n",
      "##### Epoch: 7101/10000 || Loss: 0.410443514585495\n",
      "--------------------------------------------------\n",
      "Validation || Epoch: 7101 || Loss: 0.8260588104074652 || Accuracy: 0.6433877944946289 || F1-score: 0.41885211195699923\n",
      "Epoch: 7201/10000 || Item: 0/85 || Loss: 0.5777377486228943\n",
      "--------------------------------------------------\n",
      "##### Epoch: 7201/10000 || Loss: 0.28630331158638\n",
      "--------------------------------------------------\n",
      "Validation || Epoch: 7201 || Loss: 0.8303100195798007 || Accuracy: 0.6433877944946289 || F1-score: 0.41885211195699923\n",
      "Epoch: 7301/10000 || Item: 0/85 || Loss: 0.8271401524543762\n",
      "--------------------------------------------------\n",
      "##### Epoch: 7301/10000 || Loss: 1.1129623651504517\n",
      "--------------------------------------------------\n",
      "Validation || Epoch: 7301 || Loss: 0.8474568616260182 || Accuracy: 0.6433877944946289 || F1-score: 0.41885211195699923\n",
      "Epoch: 7401/10000 || Item: 0/85 || Loss: 0.6516881585121155\n",
      "--------------------------------------------------\n",
      "##### Epoch: 7401/10000 || Loss: 0.962882936000824\n",
      "--------------------------------------------------\n",
      "Validation || Epoch: 7401 || Loss: 0.8330933343280446 || Accuracy: 0.6433877944946289 || F1-score: 0.41885211195699923\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 7501/10000 || Item: 0/85 || Loss: 0.5564772486686707\n",
      "--------------------------------------------------\n",
      "##### Epoch: 7501/10000 || Loss: 0.8176395297050476\n",
      "--------------------------------------------------\n",
      "Validation || Epoch: 7501 || Loss: 0.8336770209399137 || Accuracy: 0.6433877944946289 || F1-score: 0.41885211195699923\n",
      "Epoch: 7601/10000 || Item: 0/85 || Loss: 0.622069239616394\n",
      "--------------------------------------------------\n",
      "##### Epoch: 7601/10000 || Loss: 0.6505205631256104\n",
      "--------------------------------------------------\n",
      "Validation || Epoch: 7601 || Loss: 0.8343544602394104 || Accuracy: 0.6433877944946289 || F1-score: 0.41885211195699923\n",
      "Epoch: 7701/10000 || Item: 0/85 || Loss: 0.5496020317077637\n",
      "--------------------------------------------------\n",
      "##### Epoch: 7701/10000 || Loss: 0.4282279908657074\n",
      "--------------------------------------------------\n",
      "Validation || Epoch: 7701 || Loss: 0.8355135267431085 || Accuracy: 0.6433877944946289 || F1-score: 0.41885211195699923\n",
      "Epoch: 7801/10000 || Item: 0/85 || Loss: 0.6834086775779724\n",
      "--------------------------------------------------\n",
      "##### Epoch: 7801/10000 || Loss: 0.8753664493560791\n",
      "--------------------------------------------------\n",
      "Validation || Epoch: 7801 || Loss: 0.831584556536241 || Accuracy: 0.6433877944946289 || F1-score: 0.41885211195699923\n",
      "Epoch: 7901/10000 || Item: 0/85 || Loss: 0.7160522937774658\n",
      "--------------------------------------------------\n",
      "##### Epoch: 7901/10000 || Loss: 0.48034390807151794\n",
      "--------------------------------------------------\n",
      "Validation || Epoch: 7901 || Loss: 0.833562661301006 || Accuracy: 0.6433877944946289 || F1-score: 0.41885211195699923\n",
      "Epoch: 8001/10000 || Item: 0/85 || Loss: 0.7091420292854309\n",
      "--------------------------------------------------\n",
      "##### Epoch: 8001/10000 || Loss: 0.339097797870636\n",
      "--------------------------------------------------\n",
      "Validation || Epoch: 8001 || Loss: 0.8484975478865884 || Accuracy: 0.6433877944946289 || F1-score: 0.41885211195699923\n",
      "Epoch: 8101/10000 || Item: 0/85 || Loss: 0.761664092540741\n",
      "--------------------------------------------------\n",
      "##### Epoch: 8101/10000 || Loss: 0.1751021444797516\n",
      "--------------------------------------------------\n",
      "Validation || Epoch: 8101 || Loss: 0.8400974327867682 || Accuracy: 0.6433877944946289 || F1-score: 0.41885211195699923\n",
      "Epoch: 8201/10000 || Item: 0/85 || Loss: 0.6097674369812012\n",
      "--------------------------------------------------\n",
      "##### Epoch: 8201/10000 || Loss: 0.5932946801185608\n",
      "--------------------------------------------------\n",
      "Validation || Epoch: 8201 || Loss: 0.8288467526435852 || Accuracy: 0.6433877944946289 || F1-score: 0.41885211195699923\n",
      "Epoch: 8301/10000 || Item: 0/85 || Loss: 0.5618782043457031\n",
      "--------------------------------------------------\n",
      "##### Epoch: 8301/10000 || Loss: 0.3415192663669586\n",
      "--------------------------------------------------\n",
      "Validation || Epoch: 8301 || Loss: 0.8351453055034984 || Accuracy: 0.6433877944946289 || F1-score: 0.41885211195699923\n",
      "Epoch: 8401/10000 || Item: 0/85 || Loss: 0.7248093485832214\n",
      "--------------------------------------------------\n",
      "##### Epoch: 8401/10000 || Loss: 0.563202977180481\n",
      "--------------------------------------------------\n",
      "Validation || Epoch: 8401 || Loss: 0.8293509916825728 || Accuracy: 0.6433877944946289 || F1-score: 0.41885211195699923\n",
      "Epoch: 8501/10000 || Item: 0/85 || Loss: 0.707271933555603\n",
      "--------------------------------------------------\n",
      "##### Epoch: 8501/10000 || Loss: 0.16156701743602753\n",
      "--------------------------------------------------\n",
      "Validation || Epoch: 8501 || Loss: 0.8309505636041815 || Accuracy: 0.6433877944946289 || F1-score: 0.41885211195699923\n",
      "Epoch: 8601/10000 || Item: 0/85 || Loss: 0.7620176672935486\n",
      "--------------------------------------------------\n",
      "##### Epoch: 8601/10000 || Loss: 1.6299859285354614\n",
      "--------------------------------------------------\n",
      "Validation || Epoch: 8601 || Loss: 0.8352464112368497 || Accuracy: 0.6433877944946289 || F1-score: 0.41885211195699923\n",
      "Epoch: 8701/10000 || Item: 0/85 || Loss: 0.6992596983909607\n",
      "--------------------------------------------------\n",
      "##### Epoch: 8701/10000 || Loss: 0.8644610643386841\n",
      "--------------------------------------------------\n",
      "Validation || Epoch: 8701 || Loss: 0.837188184261322 || Accuracy: 0.6433877944946289 || F1-score: 0.41885211195699923\n",
      "Epoch: 8801/10000 || Item: 0/85 || Loss: 0.6928362250328064\n",
      "--------------------------------------------------\n",
      "##### Epoch: 8801/10000 || Loss: 1.277285099029541\n",
      "--------------------------------------------------\n",
      "Validation || Epoch: 8801 || Loss: 0.8281193700703707 || Accuracy: 0.6433877944946289 || F1-score: 0.41885211195699923\n",
      "Epoch: 8901/10000 || Item: 0/85 || Loss: 0.6105521321296692\n",
      "--------------------------------------------------\n",
      "##### Epoch: 8901/10000 || Loss: 0.38985180854797363\n",
      "--------------------------------------------------\n",
      "Validation || Epoch: 8901 || Loss: 0.830585008317774 || Accuracy: 0.6433877944946289 || F1-score: 0.41885211195699923\n",
      "Epoch: 9001/10000 || Item: 0/85 || Loss: 0.558593213558197\n",
      "--------------------------------------------------\n",
      "##### Epoch: 9001/10000 || Loss: 0.42363837361335754\n",
      "--------------------------------------------------\n",
      "Validation || Epoch: 9001 || Loss: 0.8396162715825167 || Accuracy: 0.6433877944946289 || F1-score: 0.41885211195699923\n",
      "Epoch: 9101/10000 || Item: 0/85 || Loss: 0.5685397386550903\n",
      "--------------------------------------------------\n",
      "##### Epoch: 9101/10000 || Loss: 0.5207656025886536\n",
      "--------------------------------------------------\n",
      "Validation || Epoch: 9101 || Loss: 0.8431339209729974 || Accuracy: 0.6433877944946289 || F1-score: 0.41885211195699923\n",
      "Epoch: 9201/10000 || Item: 0/85 || Loss: 0.6382976770401001\n",
      "--------------------------------------------------\n",
      "##### Epoch: 9201/10000 || Loss: 1.3744938373565674\n",
      "--------------------------------------------------\n",
      "Validation || Epoch: 9201 || Loss: 0.8388095064596697 || Accuracy: 0.6433877944946289 || F1-score: 0.41885211195699923\n",
      "Epoch: 9301/10000 || Item: 0/85 || Loss: 0.7178423404693604\n",
      "--------------------------------------------------\n",
      "##### Epoch: 9301/10000 || Loss: 0.4626238942146301\n",
      "--------------------------------------------------\n",
      "Validation || Epoch: 9301 || Loss: 0.8235427466305819 || Accuracy: 0.6433877944946289 || F1-score: 0.41885211195699923\n",
      "Epoch: 9401/10000 || Item: 0/85 || Loss: 0.7623867988586426\n",
      "--------------------------------------------------\n",
      "##### Epoch: 9401/10000 || Loss: 0.3823624849319458\n",
      "--------------------------------------------------\n",
      "Validation || Epoch: 9401 || Loss: 0.827922132882205 || Accuracy: 0.6433877944946289 || F1-score: 0.41885211195699923\n",
      "Epoch: 9501/10000 || Item: 0/85 || Loss: 0.7364686131477356\n",
      "--------------------------------------------------\n",
      "##### Epoch: 9501/10000 || Loss: 0.551897406578064\n",
      "--------------------------------------------------\n",
      "Validation || Epoch: 9501 || Loss: 0.8285398212346163 || Accuracy: 0.6433877944946289 || F1-score: 0.41885211195699923\n",
      "Epoch: 9601/10000 || Item: 0/85 || Loss: 0.572771430015564\n",
      "--------------------------------------------------\n",
      "##### Epoch: 9601/10000 || Loss: 1.0048291683197021\n",
      "--------------------------------------------------\n",
      "Validation || Epoch: 9601 || Loss: 0.8331123644655402 || Accuracy: 0.6433877944946289 || F1-score: 0.41885211195699923\n",
      "Epoch: 9701/10000 || Item: 0/85 || Loss: 0.6643272042274475\n",
      "--------------------------------------------------\n",
      "##### Epoch: 9701/10000 || Loss: 0.8321873545646667\n",
      "--------------------------------------------------\n",
      "Validation || Epoch: 9701 || Loss: 0.8379389968785372 || Accuracy: 0.6433877944946289 || F1-score: 0.41885211195699923\n",
      "Epoch: 9801/10000 || Item: 0/85 || Loss: 0.6855589747428894\n",
      "--------------------------------------------------\n",
      "##### Epoch: 9801/10000 || Loss: 0.27154722809791565\n",
      "--------------------------------------------------\n",
      "Validation || Epoch: 9801 || Loss: 0.8317394635894082 || Accuracy: 0.6433877944946289 || F1-score: 0.41885211195699923\n",
      "Epoch: 9901/10000 || Item: 0/85 || Loss: 0.6830729246139526\n",
      "--------------------------------------------------\n",
      "##### Epoch: 9901/10000 || Loss: 0.6087630987167358\n",
      "--------------------------------------------------\n",
      "Validation || Epoch: 9901 || Loss: 0.8396678241816434 || Accuracy: 0.6433877944946289 || F1-score: 0.41885211195699923\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy on dataset of size 672: 66.36904907226562 %.\n",
      "Average loss: 0.784445892680775\n",
      "proportion of labels in prediction: [tensor(0.8408), tensor(0.1384), tensor(0.0208)]\n",
      "proportion of labels in data: [tensor(0.6235), tensor(0.2232), tensor(0.1533)]\n",
      "- f1: [0.78252033 0.41152263 0.18803419]\n",
      "- f1 (average): 0.460692382327432\n",
      "- accuracy: 0.663690447807312\n",
      "\n",
      "********** hidden_dim: [100, 100]\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "cbb145e9d9bf418483c86685b5d6d4ac",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/10000 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 1/10000 || Item: 0/85 || Loss: 1.1165680885314941\n",
      "--------------------------------------------------\n",
      "##### Epoch: 1/10000 || Loss: 1.0671789646148682\n",
      "--------------------------------------------------\n",
      "Validation || Epoch: 1 || Loss: 1.034122884273529 || Accuracy: 0.6225854158401489 || F1-score: 0.25579975579975583\n",
      "Early stopping at epoch 55!\n",
      "Accuracy on dataset of size 672: 65.47618865966797 %.\n",
      "Average loss: 0.8014345873485912\n",
      "proportion of labels in prediction: [tensor(0.8497), tensor(0.1220), tensor(0.0283)]\n",
      "proportion of labels in data: [tensor(0.6235), tensor(0.2232), tensor(0.1533)]\n",
      "- f1: [0.78383838 0.31896552 0.24590164]\n",
      "- f1 (average): 0.4495685134746752\n",
      "- accuracy: 0.6547619104385376\n",
      "\n",
      "********** hidden_dim: [100, 100, 100]\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "793b15c7d58a40b2bc014d049fa52c49",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/10000 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 1/10000 || Item: 0/85 || Loss: 1.0994811058044434\n",
      "--------------------------------------------------\n",
      "##### Epoch: 1/10000 || Loss: 1.0283174514770508\n",
      "--------------------------------------------------\n",
      "Validation || Epoch: 1 || Loss: 1.0029825622385198 || Accuracy: 0.6225854158401489 || F1-score: 0.25579975579975583\n",
      "Early stopping at epoch 54!\n",
      "Accuracy on dataset of size 672: 62.5 %.\n",
      "Average loss: 0.8602861762046814\n",
      "proportion of labels in prediction: [tensor(0.7798), tensor(0.2202), tensor(0.)]\n",
      "proportion of labels in data: [tensor(0.6235), tensor(0.2232), tensor(0.1533)]\n",
      "- f1: [0.78685048 0.32885906 0.        ]\n",
      "- f1 (average): 0.37190317920103627\n",
      "- accuracy: 0.625\n",
      "\n",
      "********** hidden_dim: [100, 100, 100, 100]\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "7386f87893c74af99bfdffdcd1755fd9",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/10000 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 1/10000 || Item: 0/85 || Loss: 1.0725291967391968\n",
      "--------------------------------------------------\n",
      "##### Epoch: 1/10000 || Loss: 1.0014322996139526\n",
      "--------------------------------------------------\n",
      "Validation || Epoch: 1 || Loss: 0.9836918874220415 || Accuracy: 0.6225854158401489 || F1-score: 0.25579975579975583\n",
      "Early stopping at epoch 62!\n",
      "Accuracy on dataset of size 672: 62.35118865966797 %.\n",
      "Average loss: 0.8477486642924222\n",
      "proportion of labels in prediction: [tensor(0.8690), tensor(0.1101), tensor(0.0208)]\n",
      "proportion of labels in data: [tensor(0.6235), tensor(0.2232), tensor(0.1533)]\n",
      "- f1: [0.77966102 0.16071429 0.17094017]\n",
      "- f1 (average): 0.37043849120120304\n",
      "- accuracy: 0.6235119104385376\n",
      "\n",
      "********** hidden_dim: [100, 100, 100, 100, 100]\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "ec281a55877d4f0686d58b80f433c6fe",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/10000 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 1/10000 || Item: 0/85 || Loss: 1.1058520078659058\n",
      "--------------------------------------------------\n",
      "##### Epoch: 1/10000 || Loss: 1.0424485206604004\n",
      "--------------------------------------------------\n",
      "Validation || Epoch: 1 || Loss: 1.0408807884563098 || Accuracy: 0.6225854158401489 || F1-score: 0.25579975579975583\n",
      "Early stopping at epoch 49!\n",
      "Accuracy on dataset of size 672: 63.83928680419922 %.\n",
      "Average loss: 0.8748811971057545\n",
      "proportion of labels in prediction: [tensor(0.7902), tensor(0.1801), tensor(0.0298)]\n",
      "proportion of labels in data: [tensor(0.6235), tensor(0.2232), tensor(0.1533)]\n",
      "- f1: [0.78526316 0.32472325 0.19512195]\n",
      "- f1 (average): 0.43503611878224047\n",
      "- accuracy: 0.6383928656578064\n"
     ]
    }
   ],
   "source": [
    "path_history = obtain_mean_history(sbert_768_embeddings, path_specifics, concatenate_current=False)\n",
    "for hidden_dim in hidden_dim_trials:\n",
    "    print(f\"\\n********** hidden_dim: {hidden_dim}\")\n",
    "    implement_ffn(x_data=path_history,\n",
    "                  y_data=y_data,\n",
    "                  hidden_dim=hidden_dim,\n",
    "                  learning_rate=learning_rate,\n",
    "                  loss=loss)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ad2d3ce5",
   "metadata": {},
   "source": [
    "## SBERT 384"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 185,
   "id": "ee0012ab",
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[INFO] Concatenating the embeddings to the dataframe...\n",
      "[INFO] - columns beginning with 'e' denote the full embddings.\n",
      "[INFO] Adding time feature columns into dataframe in `.df`.\n",
      "[INFO] Adding 'time_encoding' and feature...\n",
      "[INFO] Adding 'time_diff' and feature...\n",
      "[INFO] Adding 'timeline_index' feature...\n",
      "[INFO] Padding ids and storing in `.df_padded` and `.array_padded` attributes.\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "5deb8f5795144691a1a5f87b3ec77d2d",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/13551 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "********** hidden_dim: [100]\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "456a4e6b610b446988f1e3240ffa3f1d",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/10000 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 1/10000 || Item: 0/85 || Loss: 1.088646411895752\n",
      "--------------------------------------------------\n",
      "##### Epoch: 1/10000 || Loss: 1.0224132537841797\n",
      "--------------------------------------------------\n",
      "Validation || Epoch: 1 || Loss: 1.0024505149234424 || Accuracy: 0.6225854158401489 || F1-score: 0.25579975579975583\n",
      "Early stopping at epoch 49!\n",
      "Accuracy on dataset of size 672: 71.57737731933594 %.\n",
      "Average loss: 0.6831169778650458\n",
      "proportion of labels in prediction: [tensor(0.7128), tensor(0.1801), tensor(0.1071)]\n",
      "proportion of labels in data: [tensor(0.6235), tensor(0.2232), tensor(0.1533)]\n",
      "- f1: [0.81514477 0.52398524 0.50285714]\n",
      "- f1 (average): 0.6139957162855116\n",
      "- accuracy: 0.7157738208770752\n",
      "\n",
      "********** hidden_dim: [100, 100]\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "7f01cc6d98c5438ea60e8e00f3279159",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/10000 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 1/10000 || Item: 0/85 || Loss: 1.1163111925125122\n",
      "--------------------------------------------------\n",
      "##### Epoch: 1/10000 || Loss: 1.0465764999389648\n",
      "--------------------------------------------------\n",
      "Validation || Epoch: 1 || Loss: 1.0169885971329429 || Accuracy: 0.6225854158401489 || F1-score: 0.25579975579975583\n",
      "Early stopping at epoch 47!\n",
      "Accuracy on dataset of size 672: 71.72618865966797 %.\n",
      "Average loss: 0.7060108239000494\n",
      "proportion of labels in prediction: [tensor(0.6875), tensor(0.1890), tensor(0.1235)]\n",
      "proportion of labels in data: [tensor(0.6235), tensor(0.2232), tensor(0.1533)]\n",
      "- f1: [0.81725312 0.52707581 0.52688172]\n",
      "- f1 (average): 0.6237368847191235\n",
      "- accuracy: 0.7172619104385376\n",
      "\n",
      "********** hidden_dim: [100, 100, 100]\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "f36258a5369e47c4bc3cf8b79e95e62b",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/10000 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 1/10000 || Item: 0/85 || Loss: 1.0996454954147339\n",
      "--------------------------------------------------\n",
      "##### Epoch: 1/10000 || Loss: 1.0017808675765991\n",
      "--------------------------------------------------\n",
      "Validation || Epoch: 1 || Loss: 0.982284361665899 || Accuracy: 0.6225854158401489 || F1-score: 0.25579975579975583\n",
      "Early stopping at epoch 57!\n",
      "Accuracy on dataset of size 672: 71.72618865966797 %.\n",
      "Average loss: 0.7493027719584379\n",
      "proportion of labels in prediction: [tensor(0.6860), tensor(0.2098), tensor(0.1042)]\n",
      "proportion of labels in data: [tensor(0.6235), tensor(0.2232), tensor(0.1533)]\n",
      "- f1: [0.81818182 0.56357388 0.46242775]\n",
      "- f1 (average): 0.6147278156693566\n",
      "- accuracy: 0.7172619104385376\n",
      "\n",
      "********** hidden_dim: [100, 100, 100, 100]\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "eae146f5d6404ea0b0faf0d4ebfaf10f",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/10000 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 1/10000 || Item: 0/85 || Loss: 1.072601079940796\n",
      "--------------------------------------------------\n",
      "##### Epoch: 1/10000 || Loss: 0.9884348511695862\n",
      "--------------------------------------------------\n",
      "Validation || Epoch: 1 || Loss: 0.9732580510052767 || Accuracy: 0.6225854158401489 || F1-score: 0.25579975579975583\n",
      "Early stopping at epoch 49!\n",
      "Accuracy on dataset of size 672: 70.53571319580078 %.\n",
      "Average loss: 0.7905030711130663\n",
      "proportion of labels in prediction: [tensor(0.6726), tensor(0.2188), tensor(0.1086)]\n",
      "proportion of labels in data: [tensor(0.6235), tensor(0.2232), tensor(0.1533)]\n",
      "- f1: [0.80367394 0.54545455 0.48863636]\n",
      "- f1 (average): 0.6125882823644018\n",
      "- accuracy: 0.7053571343421936\n",
      "\n",
      "********** hidden_dim: [100, 100, 100, 100, 100]\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "fec580f00a364bf2a0ae8987d0061d24",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/10000 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 1/10000 || Item: 0/85 || Loss: 1.1058897972106934\n",
      "--------------------------------------------------\n",
      "##### Epoch: 1/10000 || Loss: 1.0390312671661377\n",
      "--------------------------------------------------\n",
      "Validation || Epoch: 1 || Loss: 1.0375065803527832 || Accuracy: 0.6225854158401489 || F1-score: 0.25579975579975583\n",
      "Early stopping at epoch 48!\n",
      "Accuracy on dataset of size 672: 67.41071319580078 %.\n",
      "Average loss: 0.822012028910897\n",
      "proportion of labels in prediction: [tensor(0.7202), tensor(0.2798), tensor(0.)]\n",
      "proportion of labels in data: [tensor(0.6235), tensor(0.2232), tensor(0.1533)]\n",
      "- f1: [0.81284607 0.50887574 0.        ]\n",
      "- f1 (average): 0.4405739361016641\n",
      "- accuracy: 0.6741071343421936\n"
     ]
    }
   ],
   "source": [
    "path_history = obtain_mean_history(sbert_384_embeddings, path_specifics)\n",
    "for hidden_dim in hidden_dim_trials:\n",
    "    print(f\"\\n********** hidden_dim: {hidden_dim}\")\n",
    "    implement_ffn(x_data=path_history,\n",
    "                  y_data=y_data,\n",
    "                  hidden_dim=hidden_dim,\n",
    "                  learning_rate=learning_rate,\n",
    "                  loss=loss)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 186,
   "id": "d8501567",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[INFO] Concatenating the embeddings to the dataframe...\n",
      "[INFO] - columns beginning with 'e' denote the full embddings.\n",
      "[INFO] Adding time feature columns into dataframe in `.df`.\n",
      "[INFO] Adding 'time_encoding' and feature...\n",
      "[INFO] Adding 'time_diff' and feature...\n",
      "[INFO] Adding 'timeline_index' feature...\n",
      "[INFO] Padding ids and storing in `.df_padded` and `.array_padded` attributes.\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "111348a4d73b44f689b5f285379c184f",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/13551 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "********** hidden_dim: [100]\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "948fda2bb7764bdfb224ee033dc737c4",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/10000 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 1/10000 || Item: 0/85 || Loss: 1.068945288658142\n",
      "--------------------------------------------------\n",
      "##### Epoch: 1/10000 || Loss: 1.0284571647644043\n",
      "--------------------------------------------------\n",
      "Validation || Epoch: 1 || Loss: 1.0144835060293025 || Accuracy: 0.6225854158401489 || F1-score: 0.25579975579975583\n",
      "Early stopping at epoch 83!\n",
      "Accuracy on dataset of size 672: 63.69047546386719 %.\n",
      "Average loss: 0.826813361861489\n",
      "proportion of labels in prediction: [tensor(0.8304), tensor(0.1488), tensor(0.0208)]\n",
      "proportion of labels in data: [tensor(0.6235), tensor(0.2232), tensor(0.1533)]\n",
      "- f1: [0.76151484 0.352      0.20512821]\n",
      "- f1 (average): 0.43954768215975987\n",
      "- accuracy: 0.636904776096344\n",
      "\n",
      "********** hidden_dim: [100, 100]\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "a7ef17e3ce164e9db08f1635f53388ba",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/10000 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 1/10000 || Item: 0/85 || Loss: 1.114108681678772\n",
      "--------------------------------------------------\n",
      "##### Epoch: 1/10000 || Loss: 1.0454522371292114\n",
      "--------------------------------------------------\n",
      "Validation || Epoch: 1 || Loss: 1.0465515418486162 || Accuracy: 0.6225854158401489 || F1-score: 0.25579975579975583\n",
      "Early stopping at epoch 73!\n",
      "Accuracy on dataset of size 672: 68.1547622680664 %.\n",
      "Average loss: 0.8352445689114657\n",
      "proportion of labels in prediction: [tensor(0.7872), tensor(0.1711), tensor(0.0417)]\n",
      "proportion of labels in data: [tensor(0.6235), tensor(0.2232), tensor(0.1533)]\n",
      "- f1: [0.79746835 0.43773585 0.33587786]\n",
      "- f1 (average): 0.5236940220274677\n",
      "- accuracy: 0.6815476417541504\n",
      "\n",
      "********** hidden_dim: [100, 100, 100]\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "95a74bc1a58b46ec909de7219687512f",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/10000 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 1/10000 || Item: 0/85 || Loss: 1.059796690940857\n",
      "--------------------------------------------------\n",
      "##### Epoch: 1/10000 || Loss: 1.002020239830017\n",
      "--------------------------------------------------\n",
      "Validation || Epoch: 1 || Loss: 1.0058825016021729 || Accuracy: 0.6225854158401489 || F1-score: 0.25579975579975583\n",
      "Early stopping at epoch 56!\n",
      "Accuracy on dataset of size 672: 62.7976188659668 %.\n",
      "Average loss: 0.8746451193636114\n",
      "proportion of labels in prediction: [tensor(0.8274), tensor(0.1696), tensor(0.0030)]\n",
      "proportion of labels in data: [tensor(0.6235), tensor(0.2232), tensor(0.1533)]\n",
      "- f1: [0.78769231 0.28030303 0.01904762]\n",
      "- f1 (average): 0.3623476523476523\n",
      "- accuracy: 0.6279761791229248\n",
      "\n",
      "********** hidden_dim: [100, 100, 100, 100]\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "14a62b8479234262b486a868ed0da286",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/10000 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 1/10000 || Item: 0/85 || Loss: 1.0749471187591553\n",
      "--------------------------------------------------\n",
      "##### Epoch: 1/10000 || Loss: 0.9816824197769165\n",
      "--------------------------------------------------\n",
      "Validation || Epoch: 1 || Loss: 1.0096874778920955 || Accuracy: 0.6225854158401489 || F1-score: 0.25579975579975583\n",
      "Early stopping at epoch 58!\n",
      "Accuracy on dataset of size 672: 62.5 %.\n",
      "Average loss: 0.8662289001724937\n",
      "proportion of labels in prediction: [tensor(0.8661), tensor(0.1339), tensor(0.)]\n",
      "proportion of labels in data: [tensor(0.6235), tensor(0.2232), tensor(0.1533)]\n",
      "- f1: [0.77922078 0.25       0.        ]\n",
      "- f1 (average): 0.34307359307359303\n",
      "- accuracy: 0.625\n",
      "\n",
      "********** hidden_dim: [100, 100, 100, 100, 100]\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "f9c683f872974f28ac0b51f2a420fcd4",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/10000 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 1/10000 || Item: 0/85 || Loss: 1.132214903831482\n",
      "--------------------------------------------------\n",
      "##### Epoch: 1/10000 || Loss: 1.0944277048110962\n",
      "--------------------------------------------------\n",
      "Validation || Epoch: 1 || Loss: 1.0532963817769831 || Accuracy: 0.6225854158401489 || F1-score: 0.25579975579975583\n",
      "Early stopping at epoch 51!\n",
      "Accuracy on dataset of size 672: 65.625 %.\n",
      "Average loss: 0.8680606105110862\n",
      "proportion of labels in prediction: [tensor(0.8661), tensor(0.0565), tensor(0.0774)]\n",
      "proportion of labels in data: [tensor(0.6235), tensor(0.2232), tensor(0.1533)]\n",
      "- f1: [0.78921079 0.18085106 0.37419355]\n",
      "- f1 (average): 0.44808513380922443\n",
      "- accuracy: 0.65625\n"
     ]
    }
   ],
   "source": [
    "path_history = obtain_mean_history(sbert_384_embeddings, path_specifics, concatenate_current=False)\n",
    "for hidden_dim in hidden_dim_trials:\n",
    "    print(f\"\\n********** hidden_dim: {hidden_dim}\")\n",
    "    implement_ffn(x_data=path_history,\n",
    "                  y_data=y_data,\n",
    "                  hidden_dim=hidden_dim,\n",
    "                  learning_rate=learning_rate,\n",
    "                  loss=loss)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7b5c1094",
   "metadata": {},
   "source": [
    "## Pretrained BERT"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "67773974",
   "metadata": {},
   "source": [
    "### Mean pooled"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 187,
   "id": "2eaf36a2",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[INFO] Concatenating the embeddings to the dataframe...\n",
      "[INFO] - columns beginning with 'e' denote the full embddings.\n",
      "[INFO] Adding time feature columns into dataframe in `.df`.\n",
      "[INFO] Adding 'time_encoding' and feature...\n",
      "[INFO] Adding 'time_diff' and feature...\n",
      "[INFO] Adding 'timeline_index' feature...\n",
      "[INFO] Padding ids and storing in `.df_padded` and `.array_padded` attributes.\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "a75f82483e214b7db1cc0fd19eb44b40",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/13551 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "********** hidden_dim: [100]\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "df5d60bd596146d08b2f76c4e2a30049",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/10000 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 1/10000 || Item: 0/85 || Loss: 1.102067232131958\n",
      "--------------------------------------------------\n",
      "##### Epoch: 1/10000 || Loss: 0.8260780572891235\n",
      "--------------------------------------------------\n",
      "Validation || Epoch: 1 || Loss: 0.847004462372173 || Accuracy: 0.6225854158401489 || F1-score: 0.25579975579975583\n",
      "Early stopping at epoch 53!\n",
      "Accuracy on dataset of size 672: 71.13095092773438 %.\n",
      "Average loss: 0.6744792082092979\n",
      "proportion of labels in prediction: [tensor(0.7143), tensor(0.2068), tensor(0.0789)]\n",
      "proportion of labels in data: [tensor(0.6235), tensor(0.2232), tensor(0.1533)]\n",
      "- f1: [0.80978865 0.55363322 0.43589744]\n",
      "- f1 (average): 0.5997731026501941\n",
      "- accuracy: 0.711309552192688\n",
      "\n",
      "********** hidden_dim: [100, 100]\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "0349d360fc1e47ab882c2dc9037b98bc",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/10000 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 1/10000 || Item: 0/85 || Loss: 1.0826632976531982\n",
      "--------------------------------------------------\n",
      "##### Epoch: 1/10000 || Loss: 0.7909537553787231\n",
      "--------------------------------------------------\n",
      "Validation || Epoch: 1 || Loss: 0.8423506671732123 || Accuracy: 0.6225854158401489 || F1-score: 0.25579975579975583\n",
      "Early stopping at epoch 46!\n",
      "Accuracy on dataset of size 672: 72.61904907226562 %.\n",
      "Average loss: 0.732296651059931\n",
      "proportion of labels in prediction: [tensor(0.6949), tensor(0.2217), tensor(0.0833)]\n",
      "proportion of labels in data: [tensor(0.6235), tensor(0.2232), tensor(0.1533)]\n",
      "- f1: [0.82392777 0.57525084 0.46540881]\n",
      "- f1 (average): 0.6215291354629561\n",
      "- accuracy: 0.726190447807312\n",
      "\n",
      "********** hidden_dim: [100, 100, 100]\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "0d11a423595746fab4b2325d53708997",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/10000 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 1/10000 || Item: 0/85 || Loss: 1.0727503299713135\n",
      "--------------------------------------------------\n",
      "##### Epoch: 1/10000 || Loss: 0.8658488988876343\n",
      "--------------------------------------------------\n",
      "Validation || Epoch: 1 || Loss: 0.8703606507994912 || Accuracy: 0.6225854158401489 || F1-score: 0.25579975579975583\n",
      "Epoch: 101/10000 || Item: 0/85 || Loss: 0.44898688793182373\n",
      "--------------------------------------------------\n",
      "##### Epoch: 101/10000 || Loss: 0.0886840745806694\n",
      "--------------------------------------------------\n",
      "Validation || Epoch: 101 || Loss: 0.706783879886974 || Accuracy: 0.720653772354126 || F1-score: 0.623069393795254\n",
      "Early stopping at epoch 118!\n",
      "Accuracy on dataset of size 672: 71.57737731933594 %.\n",
      "Average loss: 0.7238770777528937\n",
      "proportion of labels in prediction: [tensor(0.6949), tensor(0.2128), tensor(0.0923)]\n",
      "proportion of labels in data: [tensor(0.6235), tensor(0.2232), tensor(0.1533)]\n",
      "- f1: [0.81264108 0.5665529  0.46060606]\n",
      "- f1 (average): 0.6132666817171321\n",
      "- accuracy: 0.7157738208770752\n",
      "\n",
      "********** hidden_dim: [100, 100, 100, 100]\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "48bc67000b3c49449b9b66eae905571a",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/10000 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 1/10000 || Item: 0/85 || Loss: 1.0943586826324463\n",
      "--------------------------------------------------\n",
      "##### Epoch: 1/10000 || Loss: 0.9349538683891296\n",
      "--------------------------------------------------\n",
      "Validation || Epoch: 1 || Loss: 0.8743602362546053 || Accuracy: 0.6225854158401489 || F1-score: 0.25579975579975583\n",
      "Early stopping at epoch 54!\n",
      "Accuracy on dataset of size 672: 72.02381134033203 %.\n",
      "Average loss: 0.7312079180370678\n",
      "proportion of labels in prediction: [tensor(0.6905), tensor(0.2217), tensor(0.0878)]\n",
      "proportion of labels in data: [tensor(0.6235), tensor(0.2232), tensor(0.1533)]\n",
      "- f1: [0.81993205 0.55518395 0.48148148]\n",
      "- f1 (average): 0.6188658259333001\n",
      "- accuracy: 0.7202380895614624\n",
      "\n",
      "********** hidden_dim: [100, 100, 100, 100, 100]\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "264db7ef66a84e8d97660b45b9b739e8",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/10000 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 1/10000 || Item: 0/85 || Loss: 1.0790555477142334\n",
      "--------------------------------------------------\n",
      "##### Epoch: 1/10000 || Loss: 1.0316280126571655\n",
      "--------------------------------------------------\n",
      "Validation || Epoch: 1 || Loss: 0.8944603638215498 || Accuracy: 0.6225854158401489 || F1-score: 0.25579975579975583\n",
      "Early stopping at epoch 49!\n",
      "Accuracy on dataset of size 672: 72.02381134033203 %.\n",
      "Average loss: 0.7407215400175615\n",
      "proportion of labels in prediction: [tensor(0.6801), tensor(0.2188), tensor(0.1012)]\n",
      "proportion of labels in data: [tensor(0.6235), tensor(0.2232), tensor(0.1533)]\n",
      "- f1: [0.81050228 0.57239057 0.51461988]\n",
      "- f1 (average): 0.6325042461788436\n",
      "- accuracy: 0.7202380895614624\n"
     ]
    }
   ],
   "source": [
    "path_history = obtain_mean_history(pooled_mean_pretrained, path_specifics)\n",
    "for hidden_dim in hidden_dim_trials:\n",
    "    print(f\"\\n********** hidden_dim: {hidden_dim}\")\n",
    "    implement_ffn(x_data=path_history,\n",
    "                  y_data=y_data,\n",
    "                  hidden_dim=hidden_dim,\n",
    "                  learning_rate=learning_rate,\n",
    "                  loss=loss)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 188,
   "id": "e8947039",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[INFO] Concatenating the embeddings to the dataframe...\n",
      "[INFO] - columns beginning with 'e' denote the full embddings.\n",
      "[INFO] Adding time feature columns into dataframe in `.df`.\n",
      "[INFO] Adding 'time_encoding' and feature...\n",
      "[INFO] Adding 'time_diff' and feature...\n",
      "[INFO] Adding 'timeline_index' feature...\n",
      "[INFO] Padding ids and storing in `.df_padded` and `.array_padded` attributes.\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "46e97928faf949eb833f93baf0a59625",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/13551 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "********** hidden_dim: [100]\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "5b499452a546498696960e92da659804",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/10000 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 1/10000 || Item: 0/85 || Loss: 1.0823326110839844\n",
      "--------------------------------------------------\n",
      "##### Epoch: 1/10000 || Loss: 0.9887112379074097\n",
      "--------------------------------------------------\n",
      "Validation || Epoch: 1 || Loss: 0.9002521959218112 || Accuracy: 0.6225854158401489 || F1-score: 0.25579975579975583\n",
      "Early stopping at epoch 43!\n",
      "Accuracy on dataset of size 672: 64.28571319580078 %.\n",
      "Average loss: 0.841454104943709\n",
      "proportion of labels in prediction: [tensor(0.9182), tensor(0.0670), tensor(0.0149)]\n",
      "proportion of labels in data: [tensor(0.6235), tensor(0.2232), tensor(0.1533)]\n",
      "- f1: [0.77220077 0.24615385 0.14159292]\n",
      "- f1 (average): 0.3866491795695335\n",
      "- accuracy: 0.6428571343421936\n",
      "\n",
      "********** hidden_dim: [100, 100]\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "1fc89faca9e64e9eb9dc2bd398f13435",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/10000 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 1/10000 || Item: 0/85 || Loss: 1.1143786907196045\n",
      "--------------------------------------------------\n",
      "##### Epoch: 1/10000 || Loss: 0.9647703766822815\n",
      "--------------------------------------------------\n",
      "Validation || Epoch: 1 || Loss: 0.8960050561211326 || Accuracy: 0.6225854158401489 || F1-score: 0.25579975579975583\n",
      "Early stopping at epoch 53!\n",
      "Accuracy on dataset of size 672: 65.625 %.\n",
      "Average loss: 0.8285364671186968\n",
      "proportion of labels in prediction: [tensor(0.8438), tensor(0.1310), tensor(0.0253)]\n",
      "proportion of labels in data: [tensor(0.6235), tensor(0.2232), tensor(0.1533)]\n",
      "- f1: [0.77281947 0.40336134 0.2       ]\n",
      "- f1 (average): 0.4587269390514826\n",
      "- accuracy: 0.65625\n",
      "\n",
      "********** hidden_dim: [100, 100, 100]\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "35090ff0296d474fae9168598e556c67",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/10000 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 1/10000 || Item: 0/85 || Loss: 1.099800705909729\n",
      "--------------------------------------------------\n",
      "##### Epoch: 1/10000 || Loss: 0.982613742351532\n",
      "--------------------------------------------------\n",
      "Validation || Epoch: 1 || Loss: 0.9065857475454157 || Accuracy: 0.6225854158401489 || F1-score: 0.25579975579975583\n",
      "Early stopping at epoch 52!\n",
      "Accuracy on dataset of size 672: 64.73213958740234 %.\n",
      "Average loss: 0.8655710599639199\n",
      "proportion of labels in prediction: [tensor(0.8467), tensor(0.1280), tensor(0.0253)]\n",
      "proportion of labels in data: [tensor(0.6235), tensor(0.2232), tensor(0.1533)]\n",
      "- f1: [0.77530364 0.3559322  0.16666667]\n",
      "- f1 (average): 0.4326341712603979\n",
      "- accuracy: 0.6473214030265808\n",
      "\n",
      "********** hidden_dim: [100, 100, 100, 100]\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "e1644555dc4d4096bd2aab0bbbeecfb0",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/10000 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 1/10000 || Item: 0/85 || Loss: 1.072922706604004\n",
      "--------------------------------------------------\n",
      "##### Epoch: 1/10000 || Loss: 0.8768916726112366\n",
      "--------------------------------------------------\n",
      "Validation || Epoch: 1 || Loss: 0.9030661312016574 || Accuracy: 0.6225854158401489 || F1-score: 0.25579975579975583\n",
      "Early stopping at epoch 45!\n",
      "Accuracy on dataset of size 672: 64.58333587646484 %.\n",
      "Average loss: 0.8798430941321633\n",
      "proportion of labels in prediction: [tensor(0.8780), tensor(0.0893), tensor(0.0327)]\n",
      "proportion of labels in data: [tensor(0.6235), tensor(0.2232), tensor(0.1533)]\n",
      "- f1: [0.78097126 0.25714286 0.208     ]\n",
      "- f1 (average): 0.41537137193826984\n",
      "- accuracy: 0.6458333134651184\n",
      "\n",
      "********** hidden_dim: [100, 100, 100, 100, 100]\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "c62965fde2ad4b97933ab50d14b322bf",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/10000 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 1/10000 || Item: 0/85 || Loss: 1.105739951133728\n",
      "--------------------------------------------------\n",
      "##### Epoch: 1/10000 || Loss: 1.0086760520935059\n",
      "--------------------------------------------------\n",
      "Validation || Epoch: 1 || Loss: 0.9046244783834978 || Accuracy: 0.6225854158401489 || F1-score: 0.25579975579975583\n",
      "Early stopping at epoch 51!\n",
      "Accuracy on dataset of size 672: 63.69047546386719 %.\n",
      "Average loss: 0.9047468304634094\n",
      "proportion of labels in prediction: [tensor(0.9167), tensor(0.0625), tensor(0.0208)]\n",
      "proportion of labels in data: [tensor(0.6235), tensor(0.2232), tensor(0.1533)]\n",
      "- f1: [0.77487923 0.1875     0.15384615]\n",
      "- f1 (average): 0.3720751269664313\n",
      "- accuracy: 0.636904776096344\n"
     ]
    }
   ],
   "source": [
    "path_history = obtain_mean_history(pooled_mean_pretrained, path_specifics, concatenate_current=False)\n",
    "for hidden_dim in hidden_dim_trials:\n",
    "    print(f\"\\n********** hidden_dim: {hidden_dim}\")\n",
    "    implement_ffn(x_data=path_history,\n",
    "                  y_data=y_data,\n",
    "                  hidden_dim=hidden_dim,\n",
    "                  learning_rate=learning_rate,\n",
    "                  loss=loss)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "75bac012",
   "metadata": {},
   "source": [
    "### Max pooled"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 189,
   "id": "fd57480e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[INFO] Concatenating the embeddings to the dataframe...\n",
      "[INFO] - columns beginning with 'e' denote the full embddings.\n",
      "[INFO] Adding time feature columns into dataframe in `.df`.\n",
      "[INFO] Adding 'time_encoding' and feature...\n",
      "[INFO] Adding 'time_diff' and feature...\n",
      "[INFO] Adding 'timeline_index' feature...\n",
      "[INFO] Padding ids and storing in `.df_padded` and `.array_padded` attributes.\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "a5fb33f6061d4188956fb9a50bc472c2",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/13551 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "********** hidden_dim: [100]\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "5d195ac97470482699111310d0a9f52d",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/10000 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 1/10000 || Item: 0/85 || Loss: 1.107502818107605\n",
      "--------------------------------------------------\n",
      "##### Epoch: 1/10000 || Loss: 0.7524529695510864\n",
      "--------------------------------------------------\n",
      "Validation || Epoch: 1 || Loss: 0.8631793043830178 || Accuracy: 0.6225854158401489 || F1-score: 0.2565044383226201\n",
      "Early stopping at epoch 65!\n",
      "Accuracy on dataset of size 672: 71.72618865966797 %.\n",
      "Average loss: 0.695426426150582\n",
      "proportion of labels in prediction: [tensor(0.7381), tensor(0.1845), tensor(0.0774)]\n",
      "proportion of labels in data: [tensor(0.6235), tensor(0.2232), tensor(0.1533)]\n",
      "- f1: [0.81530055 0.55474453 0.42580645]\n",
      "- f1 (average): 0.5986171745361454\n",
      "- accuracy: 0.7172619104385376\n",
      "\n",
      "********** hidden_dim: [100, 100]\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "9d0ed793652f44a9b607920a9a5a81ad",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/10000 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 1/10000 || Item: 0/85 || Loss: 1.0758923292160034\n",
      "--------------------------------------------------\n",
      "##### Epoch: 1/10000 || Loss: 0.8602192401885986\n",
      "--------------------------------------------------\n",
      "Validation || Epoch: 1 || Loss: 0.8644225434823469 || Accuracy: 0.6225854158401489 || F1-score: 0.25579975579975583\n",
      "Early stopping at epoch 66!\n",
      "Accuracy on dataset of size 672: 70.38690185546875 %.\n",
      "Average loss: 0.7158872539346869\n",
      "proportion of labels in prediction: [tensor(0.6830), tensor(0.2366), tensor(0.0804)]\n",
      "proportion of labels in data: [tensor(0.6235), tensor(0.2232), tensor(0.1533)]\n",
      "- f1: [0.79954442 0.5631068  0.44585987]\n",
      "- f1 (average): 0.6028370292874553\n",
      "- accuracy: 0.7038690447807312\n",
      "\n",
      "********** hidden_dim: [100, 100, 100]\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "eabb43daeecd4065a84e859d9dc9dc75",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/10000 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 1/10000 || Item: 0/85 || Loss: 1.0745344161987305\n",
      "--------------------------------------------------\n",
      "##### Epoch: 1/10000 || Loss: 0.903744637966156\n",
      "--------------------------------------------------\n",
      "Validation || Epoch: 1 || Loss: 0.8973067511211742 || Accuracy: 0.6225854158401489 || F1-score: 0.25579975579975583\n",
      "Early stopping at epoch 60!\n",
      "Accuracy on dataset of size 672: 71.13095092773438 %.\n",
      "Average loss: 0.707133639942516\n",
      "proportion of labels in prediction: [tensor(0.6964), tensor(0.1979), tensor(0.1057)]\n",
      "proportion of labels in data: [tensor(0.6235), tensor(0.2232), tensor(0.1533)]\n",
      "- f1: [0.80496054 0.55830389 0.48275862]\n",
      "- f1 (average): 0.6153410162551314\n",
      "- accuracy: 0.711309552192688\n",
      "\n",
      "********** hidden_dim: [100, 100, 100, 100]\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "00676280e0a14c8cbb255b0067f8ca5f",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/10000 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 1/10000 || Item: 0/85 || Loss: 1.094313144683838\n",
      "--------------------------------------------------\n",
      "##### Epoch: 1/10000 || Loss: 0.9924508333206177\n",
      "--------------------------------------------------\n",
      "Validation || Epoch: 1 || Loss: 0.9078524871305986 || Accuracy: 0.6225854158401489 || F1-score: 0.25579975579975583\n",
      "Early stopping at epoch 57!\n",
      "Accuracy on dataset of size 672: 69.19642639160156 %.\n",
      "Average loss: 0.7343476577238603\n",
      "proportion of labels in prediction: [tensor(0.8259), tensor(0.0878), tensor(0.0863)]\n",
      "proportion of labels in data: [tensor(0.6235), tensor(0.2232), tensor(0.1533)]\n",
      "- f1: [0.79876797 0.37320574 0.45962733]\n",
      "- f1 (average): 0.5438670126550438\n",
      "- accuracy: 0.6919642686843872\n",
      "\n",
      "********** hidden_dim: [100, 100, 100, 100, 100]\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "17fcdf378eb544968665208d359cea55",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/10000 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 1/10000 || Item: 0/85 || Loss: 1.0789034366607666\n",
      "--------------------------------------------------\n",
      "##### Epoch: 1/10000 || Loss: 1.0043119192123413\n",
      "--------------------------------------------------\n",
      "Validation || Epoch: 1 || Loss: 0.9153049750761553 || Accuracy: 0.6225854158401489 || F1-score: 0.25579975579975583\n",
      "Early stopping at epoch 62!\n",
      "Accuracy on dataset of size 672: 70.53571319580078 %.\n",
      "Average loss: 0.7639460184357383\n",
      "proportion of labels in prediction: [tensor(0.7485), tensor(0.2113), tensor(0.0402)]\n",
      "proportion of labels in data: [tensor(0.6235), tensor(0.2232), tensor(0.1533)]\n",
      "- f1: [0.80694143 0.53424658 0.36923077]\n",
      "- f1 (average): 0.5701395920811724\n",
      "- accuracy: 0.7053571343421936\n"
     ]
    }
   ],
   "source": [
    "path_history = obtain_mean_history(pooled_max_pretrained, path_specifics)\n",
    "for hidden_dim in hidden_dim_trials:\n",
    "    print(f\"\\n********** hidden_dim: {hidden_dim}\")\n",
    "    implement_ffn(x_data=path_history,\n",
    "                  y_data=y_data,\n",
    "                  hidden_dim=hidden_dim,\n",
    "                  learning_rate=learning_rate,\n",
    "                  loss=loss)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 190,
   "id": "2bcba355",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[INFO] Concatenating the embeddings to the dataframe...\n",
      "[INFO] - columns beginning with 'e' denote the full embddings.\n",
      "[INFO] Adding time feature columns into dataframe in `.df`.\n",
      "[INFO] Adding 'time_encoding' and feature...\n",
      "[INFO] Adding 'time_diff' and feature...\n",
      "[INFO] Adding 'timeline_index' feature...\n",
      "[INFO] Padding ids and storing in `.df_padded` and `.array_padded` attributes.\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "5fe725cd2821427ab72586260dc02c6e",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/13551 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "********** hidden_dim: [100]\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "d5d2185d9b9949c09f41186e74532e1d",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/10000 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 1/10000 || Item: 0/85 || Loss: 1.0902756452560425\n",
      "--------------------------------------------------\n",
      "##### Epoch: 1/10000 || Loss: 1.0397809743881226\n",
      "--------------------------------------------------\n",
      "Validation || Epoch: 1 || Loss: 0.9006156542084434 || Accuracy: 0.6225854158401489 || F1-score: 0.25579975579975583\n",
      "Early stopping at epoch 61!\n",
      "Accuracy on dataset of size 672: 62.35118865966797 %.\n",
      "Average loss: 0.876682395284826\n",
      "proportion of labels in prediction: [tensor(0.8988), tensor(0.0967), tensor(0.0045)]\n",
      "proportion of labels in data: [tensor(0.6235), tensor(0.2232), tensor(0.1533)]\n",
      "- f1: [0.75659824 0.26976744 0.05660377]\n",
      "- f1 (average): 0.360989818638193\n",
      "- accuracy: 0.6235119104385376\n",
      "\n",
      "********** hidden_dim: [100, 100]\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "e91594dd6c664593b14f33f071a4079c",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/10000 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 1/10000 || Item: 0/85 || Loss: 1.1092349290847778\n",
      "--------------------------------------------------\n",
      "##### Epoch: 1/10000 || Loss: 0.9899702072143555\n",
      "--------------------------------------------------\n",
      "Validation || Epoch: 1 || Loss: 0.8991328586231578 || Accuracy: 0.6225854158401489 || F1-score: 0.25579975579975583\n",
      "Early stopping at epoch 55!\n",
      "Accuracy on dataset of size 672: 62.5 %.\n",
      "Average loss: 0.8921718272295865\n",
      "proportion of labels in prediction: [tensor(0.9464), tensor(0.0521), tensor(0.0015)]\n",
      "proportion of labels in data: [tensor(0.6235), tensor(0.2232), tensor(0.1533)]\n",
      "- f1: [0.76398104 0.17297297 0.01923077]\n",
      "- f1 (average): 0.3187282616192569\n",
      "- accuracy: 0.625\n",
      "\n",
      "********** hidden_dim: [100, 100, 100]\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "31a07d4646744358914a1579bde0b691",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/10000 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 1/10000 || Item: 0/85 || Loss: 1.0993415117263794\n",
      "--------------------------------------------------\n",
      "##### Epoch: 1/10000 || Loss: 0.9690505862236023\n",
      "--------------------------------------------------\n",
      "Validation || Epoch: 1 || Loss: 0.9076739387078718 || Accuracy: 0.6225854158401489 || F1-score: 0.25579975579975583\n",
      "Early stopping at epoch 69!\n",
      "Accuracy on dataset of size 672: 60.41666793823242 %.\n",
      "Average loss: 0.9077662283724005\n",
      "proportion of labels in prediction: [tensor(0.7738), tensor(0.2113), tensor(0.0149)]\n",
      "proportion of labels in data: [tensor(0.6235), tensor(0.2232), tensor(0.1533)]\n",
      "- f1: [0.73695421 0.3630137  0.12389381]\n",
      "- f1 (average): 0.40795390351421346\n",
      "- accuracy: 0.6041666865348816\n",
      "\n",
      "********** hidden_dim: [100, 100, 100, 100]\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "7d9a237adf7a432eb30cda5ac5f2495e",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/10000 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 1/10000 || Item: 0/85 || Loss: 1.0752605199813843\n",
      "--------------------------------------------------\n",
      "##### Epoch: 1/10000 || Loss: 0.8759329915046692\n",
      "--------------------------------------------------\n",
      "Validation || Epoch: 1 || Loss: 0.9057751568880948 || Accuracy: 0.6225854158401489 || F1-score: 0.25579975579975583\n",
      "Early stopping at epoch 91!\n",
      "Accuracy on dataset of size 672: 63.39285659790039 %.\n",
      "Average loss: 0.8984722766009244\n",
      "proportion of labels in prediction: [tensor(0.8646), tensor(0.1101), tensor(0.0253)]\n",
      "proportion of labels in data: [tensor(0.6235), tensor(0.2232), tensor(0.1533)]\n",
      "- f1: [0.764      0.29464286 0.18333333]\n",
      "- f1 (average): 0.4139920634920635\n",
      "- accuracy: 0.6339285969734192\n",
      "\n",
      "********** hidden_dim: [100, 100, 100, 100, 100]\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "47a6192ed4fd4a9bab724c58cfb5f2fc",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/10000 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 1/10000 || Item: 0/85 || Loss: 1.105695366859436\n",
      "--------------------------------------------------\n",
      "##### Epoch: 1/10000 || Loss: 1.0434092283248901\n",
      "--------------------------------------------------\n",
      "Validation || Epoch: 1 || Loss: 0.9036447134884921 || Accuracy: 0.6225854158401489 || F1-score: 0.25579975579975583\n",
      "Epoch: 101/10000 || Item: 0/85 || Loss: 0.9244691729545593\n",
      "--------------------------------------------------\n",
      "##### Epoch: 101/10000 || Loss: 1.319921851158142\n",
      "--------------------------------------------------\n",
      "Validation || Epoch: 101 || Loss: 0.8929828893054615 || Accuracy: 0.6225854158401489 || F1-score: 0.25579975579975583\n",
      "Epoch: 201/10000 || Item: 0/85 || Loss: 0.7867549061775208\n",
      "--------------------------------------------------\n",
      "##### Epoch: 201/10000 || Loss: 1.2821563482284546\n",
      "--------------------------------------------------\n",
      "Validation || Epoch: 201 || Loss: 0.8963441252708435 || Accuracy: 0.6225854158401489 || F1-score: 0.25579975579975583\n",
      "Epoch: 301/10000 || Item: 0/85 || Loss: 0.8272361159324646\n",
      "--------------------------------------------------\n",
      "##### Epoch: 301/10000 || Loss: 0.8983702063560486\n",
      "--------------------------------------------------\n",
      "Validation || Epoch: 301 || Loss: 0.8985877199606462 || Accuracy: 0.6225854158401489 || F1-score: 0.25579975579975583\n",
      "Epoch: 401/10000 || Item: 0/85 || Loss: 0.8347123861312866\n",
      "--------------------------------------------------\n",
      "##### Epoch: 401/10000 || Loss: 1.289528489112854\n",
      "--------------------------------------------------\n",
      "Validation || Epoch: 401 || Loss: 0.9007689356803894 || Accuracy: 0.6225854158401489 || F1-score: 0.25579975579975583\n",
      "Epoch: 501/10000 || Item: 0/85 || Loss: 0.9990346431732178\n",
      "--------------------------------------------------\n",
      "##### Epoch: 501/10000 || Loss: 1.3655784130096436\n",
      "--------------------------------------------------\n",
      "Validation || Epoch: 501 || Loss: 0.8900107091123407 || Accuracy: 0.6225854158401489 || F1-score: 0.25579975579975583\n",
      "Epoch: 601/10000 || Item: 0/85 || Loss: 0.8276135921478271\n",
      "--------------------------------------------------\n",
      "##### Epoch: 601/10000 || Loss: 0.487362802028656\n",
      "--------------------------------------------------\n",
      "Validation || Epoch: 601 || Loss: 0.8959428071975708 || Accuracy: 0.6225854158401489 || F1-score: 0.25579975579975583\n",
      "Epoch: 701/10000 || Item: 0/85 || Loss: 0.9401465058326721\n",
      "--------------------------------------------------\n",
      "##### Epoch: 701/10000 || Loss: 1.1648640632629395\n",
      "--------------------------------------------------\n",
      "Validation || Epoch: 701 || Loss: 0.8965747139670632 || Accuracy: 0.6225854158401489 || F1-score: 0.25579975579975583\n",
      "Epoch: 801/10000 || Item: 0/85 || Loss: 0.8629510998725891\n",
      "--------------------------------------------------\n",
      "##### Epoch: 801/10000 || Loss: 1.3304022550582886\n",
      "--------------------------------------------------\n",
      "Validation || Epoch: 801 || Loss: 0.8895358172329989 || Accuracy: 0.6225854158401489 || F1-score: 0.25579975579975583\n",
      "Epoch: 901/10000 || Item: 0/85 || Loss: 0.9611719846725464\n",
      "--------------------------------------------------\n",
      "##### Epoch: 901/10000 || Loss: 1.0541119575500488\n",
      "--------------------------------------------------\n",
      "Validation || Epoch: 901 || Loss: 0.9027496738867327 || Accuracy: 0.6225854158401489 || F1-score: 0.25579975579975583\n",
      "Epoch: 1001/10000 || Item: 0/85 || Loss: 0.915845513343811\n",
      "--------------------------------------------------\n",
      "##### Epoch: 1001/10000 || Loss: 0.6464566588401794\n",
      "--------------------------------------------------\n",
      "Validation || Epoch: 1001 || Loss: 0.8971304947679694 || Accuracy: 0.6225854158401489 || F1-score: 0.25579975579975583\n",
      "Epoch: 1101/10000 || Item: 0/85 || Loss: 0.862126886844635\n",
      "--------------------------------------------------\n",
      "##### Epoch: 1101/10000 || Loss: 0.962205708026886\n",
      "--------------------------------------------------\n",
      "Validation || Epoch: 1101 || Loss: 0.9007062045010653 || Accuracy: 0.6225854158401489 || F1-score: 0.25579975579975583\n",
      "Epoch: 1201/10000 || Item: 0/85 || Loss: 0.7836043238639832\n",
      "--------------------------------------------------\n",
      "##### Epoch: 1201/10000 || Loss: 0.9747729301452637\n",
      "--------------------------------------------------\n",
      "Validation || Epoch: 1201 || Loss: 0.8985942493785511 || Accuracy: 0.6225854158401489 || F1-score: 0.25579975579975583\n",
      "Epoch: 1301/10000 || Item: 0/85 || Loss: 0.8837551474571228\n",
      "--------------------------------------------------\n",
      "##### Epoch: 1301/10000 || Loss: 0.4819881319999695\n",
      "--------------------------------------------------\n",
      "Validation || Epoch: 1301 || Loss: 0.9040165543556213 || Accuracy: 0.6225854158401489 || F1-score: 0.25579975579975583\n",
      "Epoch: 1401/10000 || Item: 0/85 || Loss: 0.9317203760147095\n",
      "--------------------------------------------------\n",
      "##### Epoch: 1401/10000 || Loss: 0.8300915360450745\n",
      "--------------------------------------------------\n",
      "Validation || Epoch: 1401 || Loss: 0.891057859767567 || Accuracy: 0.6225854158401489 || F1-score: 0.25579975579975583\n",
      "Epoch: 1501/10000 || Item: 0/85 || Loss: 0.8537811636924744\n",
      "--------------------------------------------------\n",
      "##### Epoch: 1501/10000 || Loss: 1.10481595993042\n",
      "--------------------------------------------------\n",
      "Validation || Epoch: 1501 || Loss: 0.8975726582787253 || Accuracy: 0.6225854158401489 || F1-score: 0.25579975579975583\n",
      "Epoch: 1601/10000 || Item: 0/85 || Loss: 0.8491355180740356\n",
      "--------------------------------------------------\n",
      "##### Epoch: 1601/10000 || Loss: 0.4665268659591675\n",
      "--------------------------------------------------\n",
      "Validation || Epoch: 1601 || Loss: 0.8978754173625599 || Accuracy: 0.6225854158401489 || F1-score: 0.25579975579975583\n",
      "Epoch: 1701/10000 || Item: 0/85 || Loss: 0.9331827163696289\n",
      "--------------------------------------------------\n",
      "##### Epoch: 1701/10000 || Loss: 1.459452748298645\n",
      "--------------------------------------------------\n",
      "Validation || Epoch: 1701 || Loss: 0.8954987905242227 || Accuracy: 0.6225854158401489 || F1-score: 0.25579975579975583\n",
      "Epoch: 1801/10000 || Item: 0/85 || Loss: 0.9590957760810852\n",
      "--------------------------------------------------\n",
      "##### Epoch: 1801/10000 || Loss: 0.7282631397247314\n",
      "--------------------------------------------------\n",
      "Validation || Epoch: 1801 || Loss: 0.8951044082641602 || Accuracy: 0.6225854158401489 || F1-score: 0.25579975579975583\n",
      "Epoch: 1901/10000 || Item: 0/85 || Loss: 0.8027002811431885\n",
      "--------------------------------------------------\n",
      "##### Epoch: 1901/10000 || Loss: 0.6833744049072266\n",
      "--------------------------------------------------\n",
      "Validation || Epoch: 1901 || Loss: 0.8978340950879183 || Accuracy: 0.6225854158401489 || F1-score: 0.25579975579975583\n",
      "Epoch: 2001/10000 || Item: 0/85 || Loss: 0.7339716553688049\n",
      "--------------------------------------------------\n",
      "##### Epoch: 2001/10000 || Loss: 0.5032205581665039\n",
      "--------------------------------------------------\n",
      "Validation || Epoch: 2001 || Loss: 0.9012797203930941 || Accuracy: 0.6225854158401489 || F1-score: 0.25579975579975583\n",
      "Epoch: 2101/10000 || Item: 0/85 || Loss: 0.9856822490692139\n",
      "--------------------------------------------------\n",
      "##### Epoch: 2101/10000 || Loss: 0.3754391670227051\n",
      "--------------------------------------------------\n",
      "Validation || Epoch: 2101 || Loss: 0.8966978083957325 || Accuracy: 0.6225854158401489 || F1-score: 0.25579975579975583\n",
      "Epoch: 2201/10000 || Item: 0/85 || Loss: 0.8614676594734192\n",
      "--------------------------------------------------\n",
      "##### Epoch: 2201/10000 || Loss: 0.7052392363548279\n",
      "--------------------------------------------------\n",
      "Validation || Epoch: 2201 || Loss: 0.901310308413072 || Accuracy: 0.6225854158401489 || F1-score: 0.25579975579975583\n",
      "Epoch: 2301/10000 || Item: 0/85 || Loss: 0.8764938116073608\n",
      "--------------------------------------------------\n",
      "##### Epoch: 2301/10000 || Loss: 1.0511423349380493\n",
      "--------------------------------------------------\n",
      "Validation || Epoch: 2301 || Loss: 0.8940058079632845 || Accuracy: 0.6225854158401489 || F1-score: 0.25579975579975583\n",
      "Epoch: 2401/10000 || Item: 0/85 || Loss: 1.0321335792541504\n",
      "--------------------------------------------------\n",
      "##### Epoch: 2401/10000 || Loss: 0.875445544719696\n",
      "--------------------------------------------------\n",
      "Validation || Epoch: 2401 || Loss: 0.8942651748657227 || Accuracy: 0.6225854158401489 || F1-score: 0.25579975579975583\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 2501/10000 || Item: 0/85 || Loss: 1.0034199953079224\n",
      "--------------------------------------------------\n",
      "##### Epoch: 2501/10000 || Loss: 0.645277202129364\n",
      "--------------------------------------------------\n",
      "Validation || Epoch: 2501 || Loss: 0.8993629975752397 || Accuracy: 0.6225854158401489 || F1-score: 0.25579975579975583\n",
      "Epoch: 2601/10000 || Item: 0/85 || Loss: 0.8773769736289978\n",
      "--------------------------------------------------\n",
      "##### Epoch: 2601/10000 || Loss: 0.6896044611930847\n",
      "--------------------------------------------------\n",
      "Validation || Epoch: 2601 || Loss: 0.8988425243984569 || Accuracy: 0.6225854158401489 || F1-score: 0.25579975579975583\n",
      "Epoch: 2701/10000 || Item: 0/85 || Loss: 0.8763327598571777\n",
      "--------------------------------------------------\n",
      "##### Epoch: 2701/10000 || Loss: 0.7868524193763733\n",
      "--------------------------------------------------\n",
      "Validation || Epoch: 2701 || Loss: 0.9059645371003584 || Accuracy: 0.6225854158401489 || F1-score: 0.25579975579975583\n",
      "Epoch: 2801/10000 || Item: 0/85 || Loss: 0.8375979065895081\n",
      "--------------------------------------------------\n",
      "##### Epoch: 2801/10000 || Loss: 0.8809260725975037\n",
      "--------------------------------------------------\n",
      "Validation || Epoch: 2801 || Loss: 0.8965747464786876 || Accuracy: 0.6225854158401489 || F1-score: 0.25579975579975583\n",
      "Epoch: 2901/10000 || Item: 0/85 || Loss: 0.9410533308982849\n",
      "--------------------------------------------------\n",
      "##### Epoch: 2901/10000 || Loss: 1.0835111141204834\n",
      "--------------------------------------------------\n",
      "Validation || Epoch: 2901 || Loss: 0.8963425051082264 || Accuracy: 0.6225854158401489 || F1-score: 0.25579975579975583\n",
      "Epoch: 3001/10000 || Item: 0/85 || Loss: 0.9735991358757019\n",
      "--------------------------------------------------\n",
      "##### Epoch: 3001/10000 || Loss: 0.9229563474655151\n",
      "--------------------------------------------------\n",
      "Validation || Epoch: 3001 || Loss: 0.9037334431301464 || Accuracy: 0.6225854158401489 || F1-score: 0.25579975579975583\n",
      "Epoch: 3101/10000 || Item: 0/85 || Loss: 0.9306795001029968\n",
      "--------------------------------------------------\n",
      "##### Epoch: 3101/10000 || Loss: 0.45405179262161255\n",
      "--------------------------------------------------\n",
      "Validation || Epoch: 3101 || Loss: 0.8913072943687439 || Accuracy: 0.6225854158401489 || F1-score: 0.25579975579975583\n",
      "Epoch: 3201/10000 || Item: 0/85 || Loss: 0.9043869376182556\n",
      "--------------------------------------------------\n",
      "##### Epoch: 3201/10000 || Loss: 1.2725635766983032\n",
      "--------------------------------------------------\n",
      "Validation || Epoch: 3201 || Loss: 0.8941957354545593 || Accuracy: 0.6225854158401489 || F1-score: 0.25579975579975583\n",
      "Epoch: 3301/10000 || Item: 0/85 || Loss: 0.8518106937408447\n",
      "--------------------------------------------------\n",
      "##### Epoch: 3301/10000 || Loss: 1.0630671977996826\n",
      "--------------------------------------------------\n",
      "Validation || Epoch: 3301 || Loss: 0.8892871520736001 || Accuracy: 0.6225854158401489 || F1-score: 0.25579975579975583\n",
      "Epoch: 3401/10000 || Item: 0/85 || Loss: 0.9151184558868408\n",
      "--------------------------------------------------\n",
      "##### Epoch: 3401/10000 || Loss: 0.8779723048210144\n",
      "--------------------------------------------------\n",
      "Validation || Epoch: 3401 || Loss: 0.8936098597266457 || Accuracy: 0.6225854158401489 || F1-score: 0.25579975579975583\n",
      "Epoch: 3501/10000 || Item: 0/85 || Loss: 1.0090341567993164\n",
      "--------------------------------------------------\n",
      "##### Epoch: 3501/10000 || Loss: 0.8693708181381226\n",
      "--------------------------------------------------\n",
      "Validation || Epoch: 3501 || Loss: 0.9019201072779569 || Accuracy: 0.6225854158401489 || F1-score: 0.25579975579975583\n",
      "Epoch: 3601/10000 || Item: 0/85 || Loss: 0.8822567462921143\n",
      "--------------------------------------------------\n",
      "##### Epoch: 3601/10000 || Loss: 0.4426151514053345\n",
      "--------------------------------------------------\n",
      "Validation || Epoch: 3601 || Loss: 0.8965790163386952 || Accuracy: 0.6225854158401489 || F1-score: 0.25579975579975583\n",
      "Epoch: 3701/10000 || Item: 0/85 || Loss: 0.8151037096977234\n",
      "--------------------------------------------------\n",
      "##### Epoch: 3701/10000 || Loss: 0.9704940319061279\n",
      "--------------------------------------------------\n",
      "Validation || Epoch: 3701 || Loss: 0.8952187462286516 || Accuracy: 0.6225854158401489 || F1-score: 0.25579975579975583\n",
      "Epoch: 3801/10000 || Item: 0/85 || Loss: 0.864924430847168\n",
      "--------------------------------------------------\n",
      "##### Epoch: 3801/10000 || Loss: 0.4710994064807892\n",
      "--------------------------------------------------\n",
      "Validation || Epoch: 3801 || Loss: 0.8997356512329795 || Accuracy: 0.6225854158401489 || F1-score: 0.25579975579975583\n",
      "Epoch: 3901/10000 || Item: 0/85 || Loss: 1.0031867027282715\n",
      "--------------------------------------------------\n",
      "##### Epoch: 3901/10000 || Loss: 0.6387273073196411\n",
      "--------------------------------------------------\n",
      "Validation || Epoch: 3901 || Loss: 0.8952873620119962 || Accuracy: 0.6225854158401489 || F1-score: 0.25579975579975583\n",
      "Epoch: 4001/10000 || Item: 0/85 || Loss: 0.993807852268219\n",
      "--------------------------------------------------\n",
      "##### Epoch: 4001/10000 || Loss: 0.6921679973602295\n",
      "--------------------------------------------------\n",
      "Validation || Epoch: 4001 || Loss: 0.9033344117077914 || Accuracy: 0.6225854158401489 || F1-score: 0.25579975579975583\n",
      "Epoch: 4101/10000 || Item: 0/85 || Loss: 0.845513641834259\n",
      "--------------------------------------------------\n",
      "##### Epoch: 4101/10000 || Loss: 1.146635890007019\n",
      "--------------------------------------------------\n",
      "Validation || Epoch: 4101 || Loss: 0.8919039314443414 || Accuracy: 0.6225854158401489 || F1-score: 0.25579975579975583\n",
      "Epoch: 4201/10000 || Item: 0/85 || Loss: 0.8193478584289551\n",
      "--------------------------------------------------\n",
      "##### Epoch: 4201/10000 || Loss: 0.868416428565979\n",
      "--------------------------------------------------\n",
      "Validation || Epoch: 4201 || Loss: 0.8938493999567899 || Accuracy: 0.6225854158401489 || F1-score: 0.25579975579975583\n",
      "Epoch: 4301/10000 || Item: 0/85 || Loss: 0.8499759435653687\n",
      "--------------------------------------------------\n",
      "##### Epoch: 4301/10000 || Loss: 1.2505544424057007\n",
      "--------------------------------------------------\n",
      "Validation || Epoch: 4301 || Loss: 0.8996834050525319 || Accuracy: 0.6225854158401489 || F1-score: 0.25579975579975583\n",
      "Epoch: 4401/10000 || Item: 0/85 || Loss: 0.9499950408935547\n",
      "--------------------------------------------------\n",
      "##### Epoch: 4401/10000 || Loss: 1.0572316646575928\n",
      "--------------------------------------------------\n",
      "Validation || Epoch: 4401 || Loss: 0.8952419812029059 || Accuracy: 0.6225854158401489 || F1-score: 0.25579975579975583\n",
      "Epoch: 4501/10000 || Item: 0/85 || Loss: 0.8672632575035095\n",
      "--------------------------------------------------\n",
      "##### Epoch: 4501/10000 || Loss: 0.8617123365402222\n",
      "--------------------------------------------------\n",
      "Validation || Epoch: 4501 || Loss: 0.8907280347564004 || Accuracy: 0.6225854158401489 || F1-score: 0.25579975579975583\n",
      "Epoch: 4601/10000 || Item: 0/85 || Loss: 0.8777040839195251\n",
      "--------------------------------------------------\n",
      "##### Epoch: 4601/10000 || Loss: 0.48187851905822754\n",
      "--------------------------------------------------\n",
      "Validation || Epoch: 4601 || Loss: 0.9053340933539651 || Accuracy: 0.6225854158401489 || F1-score: 0.25579975579975583\n",
      "Epoch: 4701/10000 || Item: 0/85 || Loss: 0.9160411953926086\n",
      "--------------------------------------------------\n",
      "##### Epoch: 4701/10000 || Loss: 0.464448481798172\n",
      "--------------------------------------------------\n",
      "Validation || Epoch: 4701 || Loss: 0.898536438291723 || Accuracy: 0.6225854158401489 || F1-score: 0.25579975579975583\n",
      "Epoch: 4801/10000 || Item: 0/85 || Loss: 0.9698026776313782\n",
      "--------------------------------------------------\n",
      "##### Epoch: 4801/10000 || Loss: 0.967130184173584\n",
      "--------------------------------------------------\n",
      "Validation || Epoch: 4801 || Loss: 0.902824342250824 || Accuracy: 0.6225854158401489 || F1-score: 0.25579975579975583\n",
      "Epoch: 4901/10000 || Item: 0/85 || Loss: 0.819697916507721\n",
      "--------------------------------------------------\n",
      "##### Epoch: 4901/10000 || Loss: 1.1914732456207275\n",
      "--------------------------------------------------\n",
      "Validation || Epoch: 4901 || Loss: 0.894544547254389 || Accuracy: 0.6225854158401489 || F1-score: 0.25579975579975583\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 5001/10000 || Item: 0/85 || Loss: 0.8928083181381226\n",
      "--------------------------------------------------\n",
      "##### Epoch: 5001/10000 || Loss: 1.3953959941864014\n",
      "--------------------------------------------------\n",
      "Validation || Epoch: 5001 || Loss: 0.8895294774662365 || Accuracy: 0.6225854158401489 || F1-score: 0.25579975579975583\n",
      "Epoch: 5101/10000 || Item: 0/85 || Loss: 0.8683613538742065\n",
      "--------------------------------------------------\n",
      "##### Epoch: 5101/10000 || Loss: 0.7241466045379639\n",
      "--------------------------------------------------\n",
      "Validation || Epoch: 5101 || Loss: 0.8980912132696672 || Accuracy: 0.6225854158401489 || F1-score: 0.25579975579975583\n",
      "Epoch: 5201/10000 || Item: 0/85 || Loss: 0.9704111218452454\n",
      "--------------------------------------------------\n",
      "##### Epoch: 5201/10000 || Loss: 1.094663381576538\n",
      "--------------------------------------------------\n",
      "Validation || Epoch: 5201 || Loss: 0.890712174502286 || Accuracy: 0.6225854158401489 || F1-score: 0.25579975579975583\n",
      "Epoch: 5301/10000 || Item: 0/85 || Loss: 0.9008483290672302\n",
      "--------------------------------------------------\n",
      "##### Epoch: 5301/10000 || Loss: 0.9192893505096436\n",
      "--------------------------------------------------\n",
      "Validation || Epoch: 5301 || Loss: 0.8978798931295221 || Accuracy: 0.6225854158401489 || F1-score: 0.25579975579975583\n",
      "Epoch: 5401/10000 || Item: 0/85 || Loss: 0.834121823310852\n",
      "--------------------------------------------------\n",
      "##### Epoch: 5401/10000 || Loss: 1.2104614973068237\n",
      "--------------------------------------------------\n",
      "Validation || Epoch: 5401 || Loss: 0.8956526951356367 || Accuracy: 0.6225854158401489 || F1-score: 0.25579975579975583\n",
      "Epoch: 5501/10000 || Item: 0/85 || Loss: 0.9977482557296753\n",
      "--------------------------------------------------\n",
      "##### Epoch: 5501/10000 || Loss: 0.8787502646446228\n",
      "--------------------------------------------------\n",
      "Validation || Epoch: 5501 || Loss: 0.8934154077009722 || Accuracy: 0.6225854158401489 || F1-score: 0.25579975579975583\n",
      "Epoch: 5601/10000 || Item: 0/85 || Loss: 0.9437742233276367\n",
      "--------------------------------------------------\n",
      "##### Epoch: 5601/10000 || Loss: 0.8646911382675171\n",
      "--------------------------------------------------\n",
      "Validation || Epoch: 5601 || Loss: 0.8923540657216852 || Accuracy: 0.6225854158401489 || F1-score: 0.25579975579975583\n",
      "Epoch: 5701/10000 || Item: 0/85 || Loss: 0.8781591057777405\n",
      "--------------------------------------------------\n",
      "##### Epoch: 5701/10000 || Loss: 1.4201326370239258\n",
      "--------------------------------------------------\n",
      "Validation || Epoch: 5701 || Loss: 0.8891090425578031 || Accuracy: 0.6225854158401489 || F1-score: 0.25579975579975583\n",
      "Epoch: 5801/10000 || Item: 0/85 || Loss: 0.987232506275177\n",
      "--------------------------------------------------\n",
      "##### Epoch: 5801/10000 || Loss: 1.1922005414962769\n",
      "--------------------------------------------------\n",
      "Validation || Epoch: 5801 || Loss: 0.89729750698263 || Accuracy: 0.6225854158401489 || F1-score: 0.25579975579975583\n",
      "Epoch: 5901/10000 || Item: 0/85 || Loss: 1.009472370147705\n",
      "--------------------------------------------------\n",
      "##### Epoch: 5901/10000 || Loss: 0.7092387080192566\n",
      "--------------------------------------------------\n",
      "Validation || Epoch: 5901 || Loss: 0.895554011518305 || Accuracy: 0.6225854158401489 || F1-score: 0.25579975579975583\n",
      "Epoch: 6001/10000 || Item: 0/85 || Loss: 0.9022743105888367\n",
      "--------------------------------------------------\n",
      "##### Epoch: 6001/10000 || Loss: 0.7002466320991516\n",
      "--------------------------------------------------\n",
      "Validation || Epoch: 6001 || Loss: 0.8971127542582426 || Accuracy: 0.6225854158401489 || F1-score: 0.25579975579975583\n",
      "Epoch: 6101/10000 || Item: 0/85 || Loss: 0.8041243553161621\n",
      "--------------------------------------------------\n",
      "##### Epoch: 6101/10000 || Loss: 0.930661678314209\n",
      "--------------------------------------------------\n",
      "Validation || Epoch: 6101 || Loss: 0.8995804028077559 || Accuracy: 0.6225854158401489 || F1-score: 0.25579975579975583\n",
      "Epoch: 6201/10000 || Item: 0/85 || Loss: 0.8984094262123108\n",
      "--------------------------------------------------\n",
      "##### Epoch: 6201/10000 || Loss: 1.4119594097137451\n",
      "--------------------------------------------------\n",
      "Validation || Epoch: 6201 || Loss: 0.8912519487467679 || Accuracy: 0.6225854158401489 || F1-score: 0.25579975579975583\n",
      "Epoch: 6301/10000 || Item: 0/85 || Loss: 0.9197641015052795\n",
      "--------------------------------------------------\n",
      "##### Epoch: 6301/10000 || Loss: 1.079084873199463\n",
      "--------------------------------------------------\n",
      "Validation || Epoch: 6301 || Loss: 0.9027784249999307 || Accuracy: 0.6225854158401489 || F1-score: 0.25579975579975583\n",
      "Epoch: 6401/10000 || Item: 0/85 || Loss: 0.9093582034111023\n",
      "--------------------------------------------------\n",
      "##### Epoch: 6401/10000 || Loss: 0.6702166795730591\n",
      "--------------------------------------------------\n",
      "Validation || Epoch: 6401 || Loss: 0.888096576387232 || Accuracy: 0.6225854158401489 || F1-score: 0.25579975579975583\n",
      "Epoch: 6501/10000 || Item: 0/85 || Loss: 0.8434486985206604\n",
      "--------------------------------------------------\n",
      "##### Epoch: 6501/10000 || Loss: 0.936194658279419\n",
      "--------------------------------------------------\n",
      "Validation || Epoch: 6501 || Loss: 0.8957905877720226 || Accuracy: 0.6225854158401489 || F1-score: 0.25579975579975583\n",
      "Epoch: 6601/10000 || Item: 0/85 || Loss: 0.977651059627533\n",
      "--------------------------------------------------\n",
      "##### Epoch: 6601/10000 || Loss: 0.9468894004821777\n",
      "--------------------------------------------------\n",
      "Validation || Epoch: 6601 || Loss: 0.9059946211901578 || Accuracy: 0.6225854158401489 || F1-score: 0.25579975579975583\n",
      "Epoch: 6701/10000 || Item: 0/85 || Loss: 0.7674525380134583\n",
      "--------------------------------------------------\n",
      "##### Epoch: 6701/10000 || Loss: 0.45254290103912354\n",
      "--------------------------------------------------\n",
      "Validation || Epoch: 6701 || Loss: 0.8941601514816284 || Accuracy: 0.6225854158401489 || F1-score: 0.25579975579975583\n",
      "Epoch: 6801/10000 || Item: 0/85 || Loss: 0.887119710445404\n",
      "--------------------------------------------------\n",
      "##### Epoch: 6801/10000 || Loss: 0.683815062046051\n",
      "--------------------------------------------------\n",
      "Validation || Epoch: 6801 || Loss: 0.8949338522824374 || Accuracy: 0.6225854158401489 || F1-score: 0.25579975579975583\n",
      "Epoch: 6901/10000 || Item: 0/85 || Loss: 0.916212797164917\n",
      "--------------------------------------------------\n",
      "##### Epoch: 6901/10000 || Loss: 0.9768090844154358\n",
      "--------------------------------------------------\n",
      "Validation || Epoch: 6901 || Loss: 0.8937475843863054 || Accuracy: 0.6225854158401489 || F1-score: 0.25579975579975583\n",
      "Epoch: 7001/10000 || Item: 0/85 || Loss: 0.9721081256866455\n",
      "--------------------------------------------------\n",
      "##### Epoch: 7001/10000 || Loss: 0.4918386936187744\n",
      "--------------------------------------------------\n",
      "Validation || Epoch: 7001 || Loss: 0.9022821187973022 || Accuracy: 0.6225854158401489 || F1-score: 0.25579975579975583\n",
      "Epoch: 7101/10000 || Item: 0/85 || Loss: 0.729519248008728\n",
      "--------------------------------------------------\n",
      "##### Epoch: 7101/10000 || Loss: 0.6784827709197998\n",
      "--------------------------------------------------\n",
      "Validation || Epoch: 7101 || Loss: 0.9019473411820151 || Accuracy: 0.6225854158401489 || F1-score: 0.25579975579975583\n",
      "Epoch: 7201/10000 || Item: 0/85 || Loss: 0.9179778695106506\n",
      "--------------------------------------------------\n",
      "##### Epoch: 7201/10000 || Loss: 0.6989461183547974\n",
      "--------------------------------------------------\n",
      "Validation || Epoch: 7201 || Loss: 0.8925618691877886 || Accuracy: 0.6225854158401489 || F1-score: 0.25579975579975583\n",
      "Epoch: 7301/10000 || Item: 0/85 || Loss: 0.8566362261772156\n",
      "--------------------------------------------------\n",
      "##### Epoch: 7301/10000 || Loss: 1.2888150215148926\n",
      "--------------------------------------------------\n",
      "Validation || Epoch: 7301 || Loss: 0.8934044404463335 || Accuracy: 0.6225854158401489 || F1-score: 0.25579975579975583\n",
      "Epoch: 7401/10000 || Item: 0/85 || Loss: 0.7877389788627625\n",
      "--------------------------------------------------\n",
      "##### Epoch: 7401/10000 || Loss: 1.0987142324447632\n",
      "--------------------------------------------------\n",
      "Validation || Epoch: 7401 || Loss: 0.8944644386118109 || Accuracy: 0.6225854158401489 || F1-score: 0.25579975579975583\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 7501/10000 || Item: 0/85 || Loss: 0.8392974138259888\n",
      "--------------------------------------------------\n",
      "##### Epoch: 7501/10000 || Loss: 1.0813897848129272\n",
      "--------------------------------------------------\n",
      "Validation || Epoch: 7501 || Loss: 0.8951859853484414 || Accuracy: 0.6225854158401489 || F1-score: 0.25579975579975583\n",
      "Epoch: 7601/10000 || Item: 0/85 || Loss: 0.9864221811294556\n",
      "--------------------------------------------------\n",
      "##### Epoch: 7601/10000 || Loss: 0.753416895866394\n",
      "--------------------------------------------------\n",
      "Validation || Epoch: 7601 || Loss: 0.8959530971267007 || Accuracy: 0.6225854158401489 || F1-score: 0.25579975579975583\n",
      "Epoch: 7701/10000 || Item: 0/85 || Loss: 0.9221744537353516\n",
      "--------------------------------------------------\n",
      "##### Epoch: 7701/10000 || Loss: 0.9736170768737793\n",
      "--------------------------------------------------\n",
      "Validation || Epoch: 7701 || Loss: 0.8940104191953485 || Accuracy: 0.6225854158401489 || F1-score: 0.25579975579975583\n",
      "Epoch: 7801/10000 || Item: 0/85 || Loss: 0.9722543954849243\n",
      "--------------------------------------------------\n",
      "##### Epoch: 7801/10000 || Loss: 1.2510547637939453\n",
      "--------------------------------------------------\n",
      "Validation || Epoch: 7801 || Loss: 0.8912665193731134 || Accuracy: 0.6225854158401489 || F1-score: 0.25579975579975583\n",
      "Epoch: 7901/10000 || Item: 0/85 || Loss: 0.9723970293998718\n",
      "--------------------------------------------------\n",
      "##### Epoch: 7901/10000 || Loss: 1.2482144832611084\n",
      "--------------------------------------------------\n",
      "Validation || Epoch: 7901 || Loss: 0.8983863158659502 || Accuracy: 0.6225854158401489 || F1-score: 0.25579975579975583\n",
      "Epoch: 8001/10000 || Item: 0/85 || Loss: 0.8709710836410522\n",
      "--------------------------------------------------\n",
      "##### Epoch: 8001/10000 || Loss: 0.6760426163673401\n",
      "--------------------------------------------------\n",
      "Validation || Epoch: 8001 || Loss: 0.8917130394415422 || Accuracy: 0.6225854158401489 || F1-score: 0.25579975579975583\n",
      "Epoch: 8101/10000 || Item: 0/85 || Loss: 0.8244829773902893\n",
      "--------------------------------------------------\n",
      "##### Epoch: 8101/10000 || Loss: 0.6780440807342529\n",
      "--------------------------------------------------\n",
      "Validation || Epoch: 8101 || Loss: 0.89744356545535 || Accuracy: 0.6225854158401489 || F1-score: 0.25579975579975583\n",
      "Epoch: 8201/10000 || Item: 0/85 || Loss: 0.827260434627533\n",
      "--------------------------------------------------\n",
      "##### Epoch: 8201/10000 || Loss: 1.4912025928497314\n",
      "--------------------------------------------------\n",
      "Validation || Epoch: 8201 || Loss: 0.9026182077147744 || Accuracy: 0.6225854158401489 || F1-score: 0.25579975579975583\n",
      "Epoch: 8301/10000 || Item: 0/85 || Loss: 0.8268581628799438\n",
      "--------------------------------------------------\n",
      "##### Epoch: 8301/10000 || Loss: 1.112681269645691\n",
      "--------------------------------------------------\n",
      "Validation || Epoch: 8301 || Loss: 0.8987118872729215 || Accuracy: 0.6225854158401489 || F1-score: 0.25579975579975583\n",
      "Epoch: 8401/10000 || Item: 0/85 || Loss: 0.8779600262641907\n",
      "--------------------------------------------------\n",
      "##### Epoch: 8401/10000 || Loss: 0.9228230714797974\n",
      "--------------------------------------------------\n",
      "Validation || Epoch: 8401 || Loss: 0.8955238190564242 || Accuracy: 0.6225854158401489 || F1-score: 0.25579975579975583\n",
      "Epoch: 8501/10000 || Item: 0/85 || Loss: 0.8864381909370422\n",
      "--------------------------------------------------\n",
      "##### Epoch: 8501/10000 || Loss: 1.1629083156585693\n",
      "--------------------------------------------------\n",
      "Validation || Epoch: 8501 || Loss: 0.8988537571646951 || Accuracy: 0.6225854158401489 || F1-score: 0.25579975579975583\n",
      "Epoch: 8601/10000 || Item: 0/85 || Loss: 0.9562093615531921\n",
      "--------------------------------------------------\n",
      "##### Epoch: 8601/10000 || Loss: 0.7129865884780884\n",
      "--------------------------------------------------\n",
      "Validation || Epoch: 8601 || Loss: 0.8923431905833158 || Accuracy: 0.6225854158401489 || F1-score: 0.25579975579975583\n",
      "Epoch: 8701/10000 || Item: 0/85 || Loss: 1.037233591079712\n",
      "--------------------------------------------------\n",
      "##### Epoch: 8701/10000 || Loss: 0.47033077478408813\n",
      "--------------------------------------------------\n",
      "Validation || Epoch: 8701 || Loss: 0.8906298063018105 || Accuracy: 0.6225854158401489 || F1-score: 0.25579975579975583\n",
      "Epoch: 8801/10000 || Item: 0/85 || Loss: 0.9174902439117432\n",
      "--------------------------------------------------\n",
      "##### Epoch: 8801/10000 || Loss: 0.6919140219688416\n",
      "--------------------------------------------------\n",
      "Validation || Epoch: 8801 || Loss: 0.8949633565816012 || Accuracy: 0.6225854158401489 || F1-score: 0.25579975579975583\n",
      "Epoch: 8901/10000 || Item: 0/85 || Loss: 0.8863216042518616\n",
      "--------------------------------------------------\n",
      "##### Epoch: 8901/10000 || Loss: 1.240889310836792\n",
      "--------------------------------------------------\n",
      "Validation || Epoch: 8901 || Loss: 0.891063164580952 || Accuracy: 0.6225854158401489 || F1-score: 0.25579975579975583\n",
      "Epoch: 9001/10000 || Item: 0/85 || Loss: 0.9393225908279419\n",
      "--------------------------------------------------\n",
      "##### Epoch: 9001/10000 || Loss: 1.1298567056655884\n",
      "--------------------------------------------------\n",
      "Validation || Epoch: 9001 || Loss: 0.8912229646335948 || Accuracy: 0.6225854158401489 || F1-score: 0.25579975579975583\n",
      "Epoch: 9101/10000 || Item: 0/85 || Loss: 0.7443323135375977\n",
      "--------------------------------------------------\n",
      "##### Epoch: 9101/10000 || Loss: 1.1098326444625854\n",
      "--------------------------------------------------\n",
      "Validation || Epoch: 9101 || Loss: 0.898152308030562 || Accuracy: 0.6225854158401489 || F1-score: 0.25579975579975583\n",
      "Epoch: 9201/10000 || Item: 0/85 || Loss: 0.7647362947463989\n",
      "--------------------------------------------------\n",
      "##### Epoch: 9201/10000 || Loss: 1.0025534629821777\n",
      "--------------------------------------------------\n",
      "Validation || Epoch: 9201 || Loss: 0.8933216387575323 || Accuracy: 0.6225854158401489 || F1-score: 0.25579975579975583\n",
      "Epoch: 9301/10000 || Item: 0/85 || Loss: 0.882254958152771\n",
      "--------------------------------------------------\n",
      "##### Epoch: 9301/10000 || Loss: 1.3583186864852905\n",
      "--------------------------------------------------\n",
      "Validation || Epoch: 9301 || Loss: 0.8943870663642883 || Accuracy: 0.6225854158401489 || F1-score: 0.25579975579975583\n",
      "Epoch: 9401/10000 || Item: 0/85 || Loss: 1.0765587091445923\n",
      "--------------------------------------------------\n",
      "##### Epoch: 9401/10000 || Loss: 0.40554699301719666\n",
      "--------------------------------------------------\n",
      "Validation || Epoch: 9401 || Loss: 0.8952629349448464 || Accuracy: 0.6225854158401489 || F1-score: 0.25579975579975583\n",
      "Epoch: 9501/10000 || Item: 0/85 || Loss: 0.925381064414978\n",
      "--------------------------------------------------\n",
      "##### Epoch: 9501/10000 || Loss: 0.6154918670654297\n",
      "--------------------------------------------------\n",
      "Validation || Epoch: 9501 || Loss: 0.9034494811838324 || Accuracy: 0.6225854158401489 || F1-score: 0.25579975579975583\n",
      "Epoch: 9601/10000 || Item: 0/85 || Loss: 0.8728574514389038\n",
      "--------------------------------------------------\n",
      "##### Epoch: 9601/10000 || Loss: 0.6580603718757629\n",
      "--------------------------------------------------\n",
      "Validation || Epoch: 9601 || Loss: 0.8914136994968761 || Accuracy: 0.6225854158401489 || F1-score: 0.25579975579975583\n",
      "Epoch: 9701/10000 || Item: 0/85 || Loss: 0.8574585318565369\n",
      "--------------------------------------------------\n",
      "##### Epoch: 9701/10000 || Loss: 0.8953169584274292\n",
      "--------------------------------------------------\n",
      "Validation || Epoch: 9701 || Loss: 0.8955869728868658 || Accuracy: 0.6225854158401489 || F1-score: 0.25579975579975583\n",
      "Epoch: 9801/10000 || Item: 0/85 || Loss: 0.9274888038635254\n",
      "--------------------------------------------------\n",
      "##### Epoch: 9801/10000 || Loss: 0.6856828927993774\n",
      "--------------------------------------------------\n",
      "Validation || Epoch: 9801 || Loss: 0.9034217541868036 || Accuracy: 0.6225854158401489 || F1-score: 0.25579975579975583\n",
      "Epoch: 9901/10000 || Item: 0/85 || Loss: 0.9073330163955688\n",
      "--------------------------------------------------\n",
      "##### Epoch: 9901/10000 || Loss: 1.290252685546875\n",
      "--------------------------------------------------\n",
      "Validation || Epoch: 9901 || Loss: 0.8938043063337152 || Accuracy: 0.6225854158401489 || F1-score: 0.25579975579975583\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy on dataset of size 672: 62.35118865966797 %.\n",
      "Average loss: 0.9195525429465554\n",
      "proportion of labels in prediction: [tensor(1.), tensor(0.), tensor(0.)]\n",
      "proportion of labels in data: [tensor(0.6235), tensor(0.2232), tensor(0.1533)]\n",
      "- f1: [0.76810266 0.         0.        ]\n",
      "- f1 (average): 0.25603421937060805\n",
      "- accuracy: 0.6235119104385376\n"
     ]
    }
   ],
   "source": [
    "path_history = obtain_mean_history(pooled_max_pretrained, path_specifics, concatenate_current=False)\n",
    "for hidden_dim in hidden_dim_trials:\n",
    "    print(f\"\\n********** hidden_dim: {hidden_dim}\")\n",
    "    implement_ffn(x_data=path_history,\n",
    "                  y_data=y_data,\n",
    "                  hidden_dim=hidden_dim,\n",
    "                  learning_rate=learning_rate,\n",
    "                  loss=loss)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d3de06ed",
   "metadata": {},
   "source": [
    "### Sum pooled"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 191,
   "id": "9dc056af",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[INFO] Concatenating the embeddings to the dataframe...\n",
      "[INFO] - columns beginning with 'e' denote the full embddings.\n",
      "[INFO] Adding time feature columns into dataframe in `.df`.\n",
      "[INFO] Adding 'time_encoding' and feature...\n",
      "[INFO] Adding 'time_diff' and feature...\n",
      "[INFO] Adding 'timeline_index' feature...\n",
      "[INFO] Padding ids and storing in `.df_padded` and `.array_padded` attributes.\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "839ad98bb3a54b26858421a28f69cfff",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/13551 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "********** hidden_dim: [100]\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "d115e45699b74635b6115c91159302bf",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/10000 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 1/10000 || Item: 0/85 || Loss: 1.678933024406433\n",
      "--------------------------------------------------\n",
      "##### Epoch: 1/10000 || Loss: 0.6816810369491577\n",
      "--------------------------------------------------\n",
      "Validation || Epoch: 1 || Loss: 0.8064220114187761 || Accuracy: 0.6612184047698975 || F1-score: 0.4829433471752409\n",
      "Early stopping at epoch 30!\n",
      "Accuracy on dataset of size 672: 70.38690185546875 %.\n",
      "Average loss: 0.7885038473389365\n",
      "proportion of labels in prediction: [tensor(0.7128), tensor(0.2128), tensor(0.0744)]\n",
      "proportion of labels in data: [tensor(0.6235), tensor(0.2232), tensor(0.1533)]\n",
      "- f1: [0.80178174 0.55972696 0.40522876]\n",
      "- f1 (average): 0.5889124859403455\n",
      "- accuracy: 0.7038690447807312\n",
      "\n",
      "********** hidden_dim: [100, 100]\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "4e1747bd488a4b2bb378ebad60ab4c05",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/10000 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 1/10000 || Item: 0/85 || Loss: 1.1401394605636597\n",
      "--------------------------------------------------\n",
      "##### Epoch: 1/10000 || Loss: 0.8598620891571045\n",
      "--------------------------------------------------\n",
      "Validation || Epoch: 1 || Loss: 0.8176196921955455 || Accuracy: 0.6404160261154175 || F1-score: 0.36396288832429863\n",
      "Early stopping at epoch 40!\n",
      "Accuracy on dataset of size 672: 72.02381134033203 %.\n",
      "Average loss: 0.8952876275235956\n",
      "proportion of labels in prediction: [tensor(0.6994), tensor(0.2158), tensor(0.0848)]\n",
      "proportion of labels in data: [tensor(0.6235), tensor(0.2232), tensor(0.1533)]\n",
      "- f1: [0.8143982  0.58305085 0.45      ]\n",
      "- f1 (average): 0.615816349227533\n",
      "- accuracy: 0.7202380895614624\n",
      "\n",
      "********** hidden_dim: [100, 100, 100]\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "fc46aaa2f2fc44e48e220766726044b0",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/10000 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 1/10000 || Item: 0/85 || Loss: 1.0784506797790527\n",
      "--------------------------------------------------\n",
      "##### Epoch: 1/10000 || Loss: 0.9166842699050903\n",
      "--------------------------------------------------\n",
      "Validation || Epoch: 1 || Loss: 0.8573870333758268 || Accuracy: 0.6404160261154175 || F1-score: 0.34531878329609894\n",
      "Early stopping at epoch 29!\n",
      "Accuracy on dataset of size 672: 71.42857360839844 %.\n",
      "Average loss: 0.8035102594982494\n",
      "proportion of labels in prediction: [tensor(0.6711), tensor(0.2440), tensor(0.0848)]\n",
      "proportion of labels in data: [tensor(0.6235), tensor(0.2232), tensor(0.1533)]\n",
      "- f1: [0.80689655 0.58598726 0.4625    ]\n",
      "- f1 (average): 0.6184612709568782\n",
      "- accuracy: 0.7142857313156128\n",
      "\n",
      "********** hidden_dim: [100, 100, 100, 100]\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "de7a83e55dc442b78e6757b03db3a9f2",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/10000 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 1/10000 || Item: 0/85 || Loss: 1.0932745933532715\n",
      "--------------------------------------------------\n",
      "##### Epoch: 1/10000 || Loss: 0.8824105262756348\n",
      "--------------------------------------------------\n",
      "Validation || Epoch: 1 || Loss: 0.8603054230863397 || Accuracy: 0.6255571842193604 || F1-score: 0.27827678720682164\n",
      "Early stopping at epoch 39!\n",
      "Accuracy on dataset of size 672: 72.17262268066406 %.\n",
      "Average loss: 0.9165262634103949\n",
      "proportion of labels in prediction: [tensor(0.6696), tensor(0.2307), tensor(0.0997)]\n",
      "proportion of labels in data: [tensor(0.6235), tensor(0.2232), tensor(0.1533)]\n",
      "- f1: [0.81242808 0.58360656 0.50588235]\n",
      "- f1 (average): 0.6339723295230296\n",
      "- accuracy: 0.7217261791229248\n",
      "\n",
      "********** hidden_dim: [100, 100, 100, 100, 100]\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "6c78be1fdeab49f491cbdb7a8638e7d3",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/10000 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 1/10000 || Item: 0/85 || Loss: 1.0838981866836548\n",
      "--------------------------------------------------\n",
      "##### Epoch: 1/10000 || Loss: 0.9220653176307678\n",
      "--------------------------------------------------\n",
      "Validation || Epoch: 1 || Loss: 0.8925879922780123 || Accuracy: 0.6240713000297546 || F1-score: 0.30644148769599383\n",
      "Early stopping at epoch 35!\n",
      "Accuracy on dataset of size 672: 72.4702377319336 %.\n",
      "Average loss: 0.8119913393800909\n",
      "proportion of labels in prediction: [tensor(0.6786), tensor(0.2217), tensor(0.0997)]\n",
      "proportion of labels in data: [tensor(0.6235), tensor(0.2232), tensor(0.1533)]\n",
      "- f1: [0.81371429 0.58862876 0.50588235]\n",
      "- f1 (average): 0.6360751337324227\n",
      "- accuracy: 0.7247023582458496\n"
     ]
    }
   ],
   "source": [
    "path_history = obtain_mean_history(pooled_sum_pretrained, path_specifics)\n",
    "for hidden_dim in hidden_dim_trials:\n",
    "    print(f\"\\n********** hidden_dim: {hidden_dim}\")\n",
    "    implement_ffn(x_data=path_history,\n",
    "                  y_data=y_data,\n",
    "                  hidden_dim=hidden_dim,\n",
    "                  learning_rate=learning_rate,\n",
    "                  loss=loss)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 192,
   "id": "9305aa2e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[INFO] Concatenating the embeddings to the dataframe...\n",
      "[INFO] - columns beginning with 'e' denote the full embddings.\n",
      "[INFO] Adding time feature columns into dataframe in `.df`.\n",
      "[INFO] Adding 'time_encoding' and feature...\n",
      "[INFO] Adding 'time_diff' and feature...\n",
      "[INFO] Adding 'timeline_index' feature...\n",
      "[INFO] Padding ids and storing in `.df_padded` and `.array_padded` attributes.\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "2fd665d867e64c22b587fbc6fa612d2b",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/13551 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "********** hidden_dim: [100]\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "caeaf75b8c494725ba52b2dc3af32a81",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/10000 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 1/10000 || Item: 0/85 || Loss: 1.4307332038879395\n",
      "--------------------------------------------------\n",
      "##### Epoch: 1/10000 || Loss: 1.2255232334136963\n",
      "--------------------------------------------------\n",
      "Validation || Epoch: 1 || Loss: 0.8943042809312994 || Accuracy: 0.6240713000297546 || F1-score: 0.2598877839178142\n",
      "Early stopping at epoch 55!\n",
      "Accuracy on dataset of size 672: 68.1547622680664 %.\n",
      "Average loss: 0.8286942893808539\n",
      "proportion of labels in prediction: [tensor(0.7798), tensor(0.1905), tensor(0.0298)]\n",
      "proportion of labels in data: [tensor(0.6235), tensor(0.2232), tensor(0.1533)]\n",
      "- f1: [0.7804878 0.5323741 0.2601626]\n",
      "- f1 (average): 0.5243415024078298\n",
      "- accuracy: 0.6815476417541504\n",
      "\n",
      "********** hidden_dim: [100, 100]\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "d26644978ae94b49a76ba6181f9058b2",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/10000 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 1/10000 || Item: 0/85 || Loss: 1.0660560131072998\n",
      "--------------------------------------------------\n",
      "##### Epoch: 1/10000 || Loss: 1.0853500366210938\n",
      "--------------------------------------------------\n",
      "Validation || Epoch: 1 || Loss: 0.9064192284237255 || Accuracy: 0.6240713000297546 || F1-score: 0.2598877839178142\n",
      "Early stopping at epoch 43!\n",
      "Accuracy on dataset of size 672: 69.04762268066406 %.\n",
      "Average loss: 0.8946376009420915\n",
      "proportion of labels in prediction: [tensor(0.7961), tensor(0.1399), tensor(0.0640)]\n",
      "proportion of labels in data: [tensor(0.6235), tensor(0.2232), tensor(0.1533)]\n",
      "- f1: [0.78616352 0.49180328 0.39726027]\n",
      "- f1 (average): 0.5584090248912353\n",
      "- accuracy: 0.6904761791229248\n",
      "\n",
      "********** hidden_dim: [100, 100, 100]\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "e9f6f38c851149f19904190619888550",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/10000 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 1/10000 || Item: 0/85 || Loss: 1.0890377759933472\n",
      "--------------------------------------------------\n",
      "##### Epoch: 1/10000 || Loss: 0.994349479675293\n",
      "--------------------------------------------------\n",
      "Validation || Epoch: 1 || Loss: 0.9262414086948741 || Accuracy: 0.6225854158401489 || F1-score: 0.25579975579975583\n",
      "Early stopping at epoch 52!\n",
      "Accuracy on dataset of size 672: 71.13095092773438 %.\n",
      "Average loss: 0.9046879681673917\n",
      "proportion of labels in prediction: [tensor(0.7039), tensor(0.2202), tensor(0.0759)]\n",
      "proportion of labels in data: [tensor(0.6235), tensor(0.2232), tensor(0.1533)]\n",
      "- f1: [0.79596413 0.58389262 0.46753247]\n",
      "- f1 (average): 0.6157964035142234\n",
      "- accuracy: 0.711309552192688\n",
      "\n",
      "********** hidden_dim: [100, 100, 100, 100]\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "a9babcd7d0284c2ea553f6c60f8cbed9",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/10000 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 1/10000 || Item: 0/85 || Loss: 1.0921019315719604\n",
      "--------------------------------------------------\n",
      "##### Epoch: 1/10000 || Loss: 0.9744298458099365\n",
      "--------------------------------------------------\n",
      "Validation || Epoch: 1 || Loss: 0.9363620552149686 || Accuracy: 0.6225854158401489 || F1-score: 0.25579975579975583\n",
      "Early stopping at epoch 47!\n",
      "Accuracy on dataset of size 672: 70.98213958740234 %.\n",
      "Average loss: 0.8467710018157959\n",
      "proportion of labels in prediction: [tensor(0.6786), tensor(0.2158), tensor(0.1057)]\n",
      "proportion of labels in data: [tensor(0.6235), tensor(0.2232), tensor(0.1533)]\n",
      "- f1: [0.79542857 0.57627119 0.50574713]\n",
      "- f1 (average): 0.6258156281020103\n",
      "- accuracy: 0.7098214030265808\n",
      "\n",
      "********** hidden_dim: [100, 100, 100, 100, 100]\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "912ce190a9044cf9bff3957d3dd76c97",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/10000 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 1/10000 || Item: 0/85 || Loss: 1.1097633838653564\n",
      "--------------------------------------------------\n",
      "##### Epoch: 1/10000 || Loss: 1.0565688610076904\n",
      "--------------------------------------------------\n",
      "Validation || Epoch: 1 || Loss: 0.9436568238518455 || Accuracy: 0.6225854158401489 || F1-score: 0.25579975579975583\n",
      "Early stopping at epoch 67!\n",
      "Accuracy on dataset of size 672: 68.45237731933594 %.\n",
      "Average loss: 0.9079169901934537\n",
      "proportion of labels in prediction: [tensor(0.6711), tensor(0.2381), tensor(0.0908)]\n",
      "proportion of labels in data: [tensor(0.6235), tensor(0.2232), tensor(0.1533)]\n",
      "- f1: [0.77471264 0.54193548 0.47560976]\n",
      "- f1 (average): 0.5974192945488966\n",
      "- accuracy: 0.6845238208770752\n"
     ]
    }
   ],
   "source": [
    "path_history = obtain_mean_history(pooled_sum_pretrained, path_specifics, concatenate_current=False)\n",
    "for hidden_dim in hidden_dim_trials:\n",
    "    print(f\"\\n********** hidden_dim: {hidden_dim}\")\n",
    "    implement_ffn(x_data=path_history,\n",
    "                  y_data=y_data,\n",
    "                  hidden_dim=hidden_dim,\n",
    "                  learning_rate=learning_rate,\n",
    "                  loss=loss)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8eb7c58b",
   "metadata": {},
   "source": [
    "### CLS"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 193,
   "id": "33e8bd3b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[INFO] Concatenating the embeddings to the dataframe...\n",
      "[INFO] - columns beginning with 'e' denote the full embddings.\n",
      "[INFO] Adding time feature columns into dataframe in `.df`.\n",
      "[INFO] Adding 'time_encoding' and feature...\n",
      "[INFO] Adding 'time_diff' and feature...\n",
      "[INFO] Adding 'timeline_index' feature...\n",
      "[INFO] Padding ids and storing in `.df_padded` and `.array_padded` attributes.\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "727050ba0ab94b898c7f028008a31118",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/13551 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "********** hidden_dim: [100]\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "7e31c1ed8faf44b6842d349a89415703",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/10000 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 1/10000 || Item: 0/85 || Loss: 1.1000295877456665\n",
      "--------------------------------------------------\n",
      "##### Epoch: 1/10000 || Loss: 0.7801932096481323\n",
      "--------------------------------------------------\n",
      "Validation || Epoch: 1 || Loss: 0.8587136810476129 || Accuracy: 0.6225854158401489 || F1-score: 0.25579975579975583\n",
      "Early stopping at epoch 43!\n",
      "Accuracy on dataset of size 672: 72.61904907226562 %.\n",
      "Average loss: 0.6759935102679513\n",
      "proportion of labels in prediction: [tensor(0.7500), tensor(0.1801), tensor(0.0699)]\n",
      "proportion of labels in data: [tensor(0.6235), tensor(0.2232), tensor(0.1533)]\n",
      "- f1: [0.82340195 0.54612546 0.45333333]\n",
      "- f1 (average): 0.6076202482501531\n",
      "- accuracy: 0.726190447807312\n",
      "\n",
      "********** hidden_dim: [100, 100]\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "9fbb6cbcb7a346a6946c6d607dd72989",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/10000 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 1/10000 || Item: 0/85 || Loss: 1.081039309501648\n",
      "--------------------------------------------------\n",
      "##### Epoch: 1/10000 || Loss: 0.8311998844146729\n",
      "--------------------------------------------------\n",
      "Validation || Epoch: 1 || Loss: 0.8527723713354631 || Accuracy: 0.6225854158401489 || F1-score: 0.25579975579975583\n",
      "Early stopping at epoch 40!\n",
      "Accuracy on dataset of size 672: 72.91666412353516 %.\n",
      "Average loss: 0.6840411153706637\n",
      "proportion of labels in prediction: [tensor(0.7396), tensor(0.1741), tensor(0.0863)]\n",
      "proportion of labels in data: [tensor(0.6235), tensor(0.2232), tensor(0.1533)]\n",
      "- f1: [0.8209607  0.54681648 0.50931677]\n",
      "- f1 (average): 0.6256979827590136\n",
      "- accuracy: 0.7291666865348816\n",
      "\n",
      "********** hidden_dim: [100, 100, 100]\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "6760af0435de47639366ef24c6da7df0",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/10000 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 1/10000 || Item: 0/85 || Loss: 1.0732282400131226\n",
      "--------------------------------------------------\n",
      "##### Epoch: 1/10000 || Loss: 0.8942330479621887\n",
      "--------------------------------------------------\n",
      "Validation || Epoch: 1 || Loss: 0.8833736777305603 || Accuracy: 0.6225854158401489 || F1-score: 0.25579975579975583\n",
      "Early stopping at epoch 48!\n",
      "Accuracy on dataset of size 672: 72.91666412353516 %.\n",
      "Average loss: 0.6757068634033203\n",
      "proportion of labels in prediction: [tensor(0.7262), tensor(0.1905), tensor(0.0833)]\n",
      "proportion of labels in data: [tensor(0.6235), tensor(0.2232), tensor(0.1533)]\n",
      "- f1: [0.82249173 0.56115108 0.49056604]\n",
      "- f1 (average): 0.6247362826179322\n",
      "- accuracy: 0.7291666865348816\n",
      "\n",
      "********** hidden_dim: [100, 100, 100, 100]\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "b32dfa822ec94c88ba84f9c95d95e49b",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/10000 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 1/10000 || Item: 0/85 || Loss: 1.0949422121047974\n",
      "--------------------------------------------------\n",
      "##### Epoch: 1/10000 || Loss: 0.9760374426841736\n",
      "--------------------------------------------------\n",
      "Validation || Epoch: 1 || Loss: 0.885305794802579 || Accuracy: 0.6225854158401489 || F1-score: 0.25579975579975583\n",
      "Early stopping at epoch 47!\n",
      "Accuracy on dataset of size 672: 73.80952453613281 %.\n",
      "Average loss: 0.7112683599645441\n",
      "proportion of labels in prediction: [tensor(0.6726), tensor(0.2381), tensor(0.0893)]\n",
      "proportion of labels in data: [tensor(0.6235), tensor(0.2232), tensor(0.1533)]\n",
      "- f1: [0.82204363 0.59354839 0.56441718]\n",
      "- f1 (average): 0.6600030643415539\n",
      "- accuracy: 0.738095223903656\n",
      "\n",
      "********** hidden_dim: [100, 100, 100, 100, 100]\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "6cabeb759d07411c85f28137b0e54b5d",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/10000 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 1/10000 || Item: 0/85 || Loss: 1.0791540145874023\n",
      "--------------------------------------------------\n",
      "##### Epoch: 1/10000 || Loss: 1.025408148765564\n",
      "--------------------------------------------------\n",
      "Validation || Epoch: 1 || Loss: 0.8963234532963146 || Accuracy: 0.6225854158401489 || F1-score: 0.25579975579975583\n",
      "Early stopping at epoch 56!\n",
      "Accuracy on dataset of size 672: 72.32142639160156 %.\n",
      "Average loss: 0.7038171291351318\n",
      "proportion of labels in prediction: [tensor(0.7113), tensor(0.1979), tensor(0.0908)]\n",
      "proportion of labels in data: [tensor(0.6235), tensor(0.2232), tensor(0.1533)]\n",
      "- f1: [0.81605351 0.55123675 0.51219512]\n",
      "- f1 (average): 0.6264951275911711\n",
      "- accuracy: 0.7232142686843872\n"
     ]
    }
   ],
   "source": [
    "path_history = obtain_mean_history(pooled_cls_pretrained, path_specifics)\n",
    "for hidden_dim in hidden_dim_trials:\n",
    "    print(f\"\\n********** hidden_dim: {hidden_dim}\")\n",
    "    implement_ffn(x_data=path_history,\n",
    "                  y_data=y_data,\n",
    "                  hidden_dim=hidden_dim,\n",
    "                  learning_rate=learning_rate,\n",
    "                  loss=loss)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 194,
   "id": "1e21d094",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[INFO] Concatenating the embeddings to the dataframe...\n",
      "[INFO] - columns beginning with 'e' denote the full embddings.\n",
      "[INFO] Adding time feature columns into dataframe in `.df`.\n",
      "[INFO] Adding 'time_encoding' and feature...\n",
      "[INFO] Adding 'time_diff' and feature...\n",
      "[INFO] Adding 'timeline_index' feature...\n",
      "[INFO] Padding ids and storing in `.df_padded` and `.array_padded` attributes.\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "e2aaebd1d80a43058bc819ac665c2c5e",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/13551 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "********** hidden_dim: [100]\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "5e5bfe5d61cb4fc5ae98d04185329196",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/10000 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 1/10000 || Item: 0/85 || Loss: 1.072155475616455\n",
      "--------------------------------------------------\n",
      "##### Epoch: 1/10000 || Loss: 0.9787630438804626\n",
      "--------------------------------------------------\n",
      "Validation || Epoch: 1 || Loss: 0.899658896706321 || Accuracy: 0.6225854158401489 || F1-score: 0.25579975579975583\n",
      "Early stopping at epoch 43!\n",
      "Accuracy on dataset of size 672: 61.30952453613281 %.\n",
      "Average loss: 0.8787896578962152\n",
      "proportion of labels in prediction: [tensor(0.9405), tensor(0.0580), tensor(0.0015)]\n",
      "proportion of labels in data: [tensor(0.6235), tensor(0.2232), tensor(0.1533)]\n",
      "- f1: [0.75547098 0.14814815 0.01923077]\n",
      "- f1 (average): 0.3076166324659823\n",
      "- accuracy: 0.613095223903656\n",
      "\n",
      "********** hidden_dim: [100, 100]\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "a205935867c14e98804a3108b533a467",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/10000 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 1/10000 || Item: 0/85 || Loss: 1.1162080764770508\n",
      "--------------------------------------------------\n",
      "##### Epoch: 1/10000 || Loss: 0.9712219834327698\n",
      "--------------------------------------------------\n",
      "Validation || Epoch: 1 || Loss: 0.8967102224176581 || Accuracy: 0.6225854158401489 || F1-score: 0.25579975579975583\n",
      "Early stopping at epoch 62!\n",
      "Accuracy on dataset of size 672: 62.7976188659668 %.\n",
      "Average loss: 0.8612691326574846\n",
      "proportion of labels in prediction: [tensor(0.8705), tensor(0.1116), tensor(0.0179)]\n",
      "proportion of labels in data: [tensor(0.6235), tensor(0.2232), tensor(0.1533)]\n",
      "- f1: [0.75697211 0.29333333 0.15652174]\n",
      "- f1 (average): 0.40227572800585093\n",
      "- accuracy: 0.6279761791229248\n",
      "\n",
      "********** hidden_dim: [100, 100, 100]\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "a2727f1ca58b4f108f047b9676937ba1",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/10000 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 1/10000 || Item: 0/85 || Loss: 1.100602149963379\n",
      "--------------------------------------------------\n",
      "##### Epoch: 1/10000 || Loss: 1.0084004402160645\n",
      "--------------------------------------------------\n",
      "Validation || Epoch: 1 || Loss: 0.9075343175367876 || Accuracy: 0.6225854158401489 || F1-score: 0.25579975579975583\n",
      "Early stopping at epoch 59!\n",
      "Accuracy on dataset of size 672: 64.28571319580078 %.\n",
      "Average loss: 0.8615717346018011\n",
      "proportion of labels in prediction: [tensor(0.7872), tensor(0.1771), tensor(0.0357)]\n",
      "proportion of labels in data: [tensor(0.6235), tensor(0.2232), tensor(0.1533)]\n",
      "- f1: [0.75738397 0.43122677 0.23622047]\n",
      "- f1 (average): 0.474943734828309\n",
      "- accuracy: 0.6428571343421936\n",
      "\n",
      "********** hidden_dim: [100, 100, 100, 100]\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "a3f6e2623d564ec7a74f9e4fac005462",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/10000 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 1/10000 || Item: 0/85 || Loss: 1.0736695528030396\n",
      "--------------------------------------------------\n",
      "##### Epoch: 1/10000 || Loss: 0.8818268775939941\n",
      "--------------------------------------------------\n",
      "Validation || Epoch: 1 || Loss: 0.9055995561859824 || Accuracy: 0.6225854158401489 || F1-score: 0.25579975579975583\n",
      "Early stopping at epoch 43!\n",
      "Accuracy on dataset of size 672: 62.35118865966797 %.\n",
      "Average loss: 0.9054542292248119\n",
      "proportion of labels in prediction: [tensor(0.9509), tensor(0.0223), tensor(0.0268)]\n",
      "proportion of labels in data: [tensor(0.6235), tensor(0.2232), tensor(0.1533)]\n",
      "- f1: [0.76559546 0.02424242 0.19834711]\n",
      "- f1 (average): 0.3293949982728123\n",
      "- accuracy: 0.6235119104385376\n",
      "\n",
      "********** hidden_dim: [100, 100, 100, 100, 100]\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "210ac2aa2aff4aef9cdde5a99e8c478b",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/10000 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 1/10000 || Item: 0/85 || Loss: 1.1050196886062622\n",
      "--------------------------------------------------\n",
      "##### Epoch: 1/10000 || Loss: 1.0802828073501587\n",
      "--------------------------------------------------\n",
      "Validation || Epoch: 1 || Loss: 0.9039598269896074 || Accuracy: 0.6225854158401489 || F1-score: 0.25579975579975583\n",
      "Early stopping at epoch 57!\n",
      "Accuracy on dataset of size 672: 61.755950927734375 %.\n",
      "Average loss: 0.8949943401596763\n",
      "proportion of labels in prediction: [tensor(0.9152), tensor(0.0774), tensor(0.0074)]\n",
      "proportion of labels in data: [tensor(0.6235), tensor(0.2232), tensor(0.1533)]\n",
      "- f1: [0.77176015 0.12871287 0.05555556]\n",
      "- f1 (average): 0.3186761938605209\n",
      "- accuracy: 0.617559552192688\n"
     ]
    }
   ],
   "source": [
    "path_history = obtain_mean_history(pooled_cls_pretrained, path_specifics, concatenate_current=False)\n",
    "for hidden_dim in hidden_dim_trials:\n",
    "    print(f\"\\n********** hidden_dim: {hidden_dim}\")\n",
    "    implement_ffn(x_data=path_history,\n",
    "                  y_data=y_data,\n",
    "                  hidden_dim=hidden_dim,\n",
    "                  learning_rate=learning_rate,\n",
    "                  loss=loss)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d21e4abf",
   "metadata": {},
   "source": [
    "## Fine-tuned BERT"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d34fc3cf",
   "metadata": {},
   "source": [
    "### Mean pooled"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 175,
   "id": "f4e5c5c0",
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'pooled_mean' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[175], line 1\u001b[0m\n\u001b[0;32m----> 1\u001b[0m path_history \u001b[38;5;241m=\u001b[39m obtain_mean_history(\u001b[43mpooled_mean\u001b[49m, path_specifics)\n\u001b[1;32m      2\u001b[0m \u001b[38;5;28;01mfor\u001b[39;00m hidden_dim \u001b[38;5;129;01min\u001b[39;00m hidden_dim_trials:\n\u001b[1;32m      3\u001b[0m     \u001b[38;5;28mprint\u001b[39m(\u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;130;01m\\n\u001b[39;00m\u001b[38;5;124m********** hidden_dim: \u001b[39m\u001b[38;5;132;01m{\u001b[39;00mhidden_dim\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m\"\u001b[39m)\n",
      "\u001b[0;31mNameError\u001b[0m: name 'pooled_mean' is not defined"
     ]
    }
   ],
   "source": [
    "path_history = obtain_mean_history(pooled_mean, path_specifics)\n",
    "for hidden_dim in hidden_dim_trials:\n",
    "    print(f\"\\n********** hidden_dim: {hidden_dim}\")\n",
    "    implement_ffn(x_data=path_history,\n",
    "                  y_data=y_data,\n",
    "                  hidden_dim=hidden_dim,\n",
    "                  learning_rate=learning_rate,\n",
    "                  loss=loss)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "dea829e1",
   "metadata": {},
   "outputs": [],
   "source": [
    "path_history = obtain_mean_history(pooled_mean, path_specifics, concatenate_current=False)\n",
    "for hidden_dim in hidden_dim_trials:\n",
    "    print(f\"\\n********** hidden_dim: {hidden_dim}\")\n",
    "    implement_ffn(x_data=path_history,\n",
    "                  y_data=y_data,\n",
    "                  hidden_dim=hidden_dim,\n",
    "                  learning_rate=learning_rate,\n",
    "                  loss=loss)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a8720da8",
   "metadata": {},
   "source": [
    "### Max pooled"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3089c705",
   "metadata": {},
   "outputs": [],
   "source": [
    "path_history = obtain_mean_history(pooled_max, path_specifics)\n",
    "for hidden_dim in hidden_dim_trials:\n",
    "    print(f\"\\n********** hidden_dim: {hidden_dim}\")\n",
    "    implement_ffn(x_data=path_history,\n",
    "                  y_data=y_data,\n",
    "                  hidden_dim=hidden_dim,\n",
    "                  learning_rate=learning_rate,\n",
    "                  loss=loss)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "77d8853b",
   "metadata": {},
   "outputs": [],
   "source": [
    "path_history = obtain_mean_history(pooled_max, path_specifics, concatenate_current=False)\n",
    "for hidden_dim in hidden_dim_trials:\n",
    "    print(f\"\\n********** hidden_dim: {hidden_dim}\")\n",
    "    implement_ffn(x_data=path_history,\n",
    "                  y_data=y_data,\n",
    "                  hidden_dim=hidden_dim,\n",
    "                  learning_rate=learning_rate,\n",
    "                  loss=loss)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5ce42787",
   "metadata": {},
   "source": [
    "### Sum pooled"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "47ebc04c",
   "metadata": {},
   "outputs": [],
   "source": [
    "path_history = obtain_mean_history(pooled_sum, path_specifics, concatenate_current=False)\n",
    "for hidden_dim in hidden_dim_trials:\n",
    "    print(f\"\\n********** hidden_dim: {hidden_dim}\")\n",
    "    implement_ffn(x_data=path_history,\n",
    "                  y_data=y_data,\n",
    "                  hidden_dim=hidden_dim,\n",
    "                  learning_rate=learning_rate,\n",
    "                  loss=loss)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2a1c5060",
   "metadata": {},
   "outputs": [],
   "source": [
    "path_history = obtain_mean_history(pooled_sum, path_specifics)\n",
    "for hidden_dim in hidden_dim_trials:\n",
    "    print(f\"\\n********** hidden_dim: {hidden_dim}\")\n",
    "    implement_ffn(x_data=path_history,\n",
    "                  y_data=y_data,\n",
    "                  hidden_dim=hidden_dim,\n",
    "                  learning_rate=learning_rate,\n",
    "                  loss=loss)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "dbc6a899",
   "metadata": {},
   "source": [
    "### CLS"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "20c92720",
   "metadata": {},
   "outputs": [],
   "source": [
    "path_history = obtain_mean_history(pooled_cls, path_specifics)\n",
    "for hidden_dim in hidden_dim_trials:\n",
    "    print(f\"\\n********** hidden_dim: {hidden_dim}\")\n",
    "    implement_ffn(x_data=path_history,\n",
    "                  y_data=y_data,\n",
    "                  hidden_dim=hidden_dim,\n",
    "                  learning_rate=learning_rate,\n",
    "                  loss=loss)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4f02b861",
   "metadata": {},
   "outputs": [],
   "source": [
    "path_history = obtain_mean_history(pooled_cls, path_specifics, concatenate_current=False)\n",
    "for hidden_dim in hidden_dim_trials:\n",
    "    print(f\"\\n********** hidden_dim: {hidden_dim}\")\n",
    "    implement_ffn(x_data=path_history,\n",
    "                  y_data=y_data,\n",
    "                  hidden_dim=hidden_dim,\n",
    "                  learning_rate=learning_rate,\n",
    "                  loss=loss)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "87498827",
   "metadata": {},
   "source": [
    "# Baseline 3: LSTM classification"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f06601d3",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0b2a26fd",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "af381bb9",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "0cf51402",
   "metadata": {},
   "source": [
    "# Baseline 4: FFN using signatures\n",
    "\n",
    "First, we dimension reduce these and then take signatures. We use the path signature as input to the FFN for classification."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 195,
   "id": "2c3949e7",
   "metadata": {},
   "outputs": [],
   "source": [
    "path_specifics = {\"pad_by\": \"history\",\n",
    "                  \"zero_padding\": False,\n",
    "                  \"method\": \"k_last\",\n",
    "                  \"k\": 10,\n",
    "                  \"time_feature\": None,\n",
    "                  \"embeddings\": \"dim_reduced\",\n",
    "                  \"include_current_embedding\": True}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 196,
   "id": "8d21e0d6",
   "metadata": {},
   "outputs": [],
   "source": [
    "def obtain_signatures_history(embeddings, path_specifics, dimension, sig_depth, concatenate_current=True):\n",
    "    # dimension reduce\n",
    "    reduction = nlpsig.DimReduce(method=\"gaussian_random_projection\", n_components=dimension)\n",
    "    # reduction = nlpsig.DimReduce(method=\"umap\", n_components=dimension)\n",
    "    embeddings_reduced = reduction.fit_transform(embeddings, random_state=seed)\n",
    "    \n",
    "    paths = nlpsig.PrepareData(anno_mi,\n",
    "                               id_column=\"transcript_id\",\n",
    "                               label_column=\"client_talk_type\",\n",
    "                               embeddings=embeddings,\n",
    "                               embeddings_reduced=embeddings_reduced)\n",
    "    path = paths.pad(**path_specifics)\n",
    "    # remove last two columns (which contains the id and the label)\n",
    "    path = path[client_index][:,:,:-2].astype(\"float\")\n",
    "    \n",
    "    # convert to torch tensor to compute signature using signatory\n",
    "    path = torch.from_numpy(path).float()\n",
    "    sig = signatory.signature(path, sig_depth).float()\n",
    "    \n",
    "    # concatenate with current embedding\n",
    "    if concatenate_current:\n",
    "        sig = torch.cat([sig, torch.tensor(embeddings[client_index])], dim=1)\n",
    "\n",
    "    return sig"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 197,
   "id": "aa98763b",
   "metadata": {},
   "outputs": [],
   "source": [
    "dimension = 5\n",
    "sig_depth = 4"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f1845722",
   "metadata": {},
   "source": [
    "## SBERT 768"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 198,
   "id": "d38e91a8",
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[INFO] Concatenating the embeddings to the dataframe...\n",
      "[INFO] - columns beginning with 'e' denote the full embddings.\n",
      "[INFO] - columns beginning with 'd' denote the dimension reduced embeddings.\n",
      "[INFO] Adding time feature columns into dataframe in `.df`.\n",
      "[INFO] Adding 'time_encoding' and feature...\n",
      "[INFO] Adding 'time_diff' and feature...\n",
      "[INFO] Adding 'timeline_index' feature...\n",
      "[INFO] Padding ids and storing in `.df_padded` and `.array_padded` attributes.\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "1159945ef7d8443d8b88a546d6bbc49b",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/13551 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "signature_history.shape = torch.Size([6725, 1548])\n",
      "\n",
      "********** hidden_dim: [100]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/var/folders/l7/bnn1j6bs3bqfskq2jlq55yh80000gr/T/ipykernel_51169/2802342863.py:18: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  train, valid, test = split_dataset(x_data=torch.tensor(x_data).float(),\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "dd57cc4029ac4666861ca7ef910f583f",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/10000 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 1/10000 || Item: 0/85 || Loss: 1.1170718669891357\n",
      "--------------------------------------------------\n",
      "##### Epoch: 1/10000 || Loss: 1.0491938591003418\n",
      "--------------------------------------------------\n",
      "Validation || Epoch: 1 || Loss: 1.0329104553569446 || Accuracy: 0.6225854158401489 || F1-score: 0.25579975579975583\n",
      "Early stopping at epoch 33!\n",
      "Accuracy on dataset of size 672: 68.89881134033203 %.\n",
      "Average loss: 0.7490293329412286\n",
      "proportion of labels in prediction: [tensor(0.7292), tensor(0.1815), tensor(0.0893)]\n",
      "proportion of labels in data: [tensor(0.6235), tensor(0.2232), tensor(0.1533)]\n",
      "- f1: [0.78987899 0.52205882 0.40490798]\n",
      "- f1 (average): 0.5722819289627749\n",
      "- accuracy: 0.6889880895614624\n",
      "\n",
      "********** hidden_dim: [100, 100]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/var/folders/l7/bnn1j6bs3bqfskq2jlq55yh80000gr/T/ipykernel_51169/2802342863.py:18: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  train, valid, test = split_dataset(x_data=torch.tensor(x_data).float(),\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "6fe70af30eee42499955c2e842bca173",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/10000 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 1/10000 || Item: 0/85 || Loss: 1.1023259162902832\n",
      "--------------------------------------------------\n",
      "##### Epoch: 1/10000 || Loss: 1.0158472061157227\n",
      "--------------------------------------------------\n",
      "Validation || Epoch: 1 || Loss: 0.9904605096036737 || Accuracy: 0.6225854158401489 || F1-score: 0.25579975579975583\n",
      "Early stopping at epoch 32!\n",
      "Accuracy on dataset of size 672: 66.96428680419922 %.\n",
      "Average loss: 0.8423257361758839\n",
      "proportion of labels in prediction: [tensor(0.6964), tensor(0.2083), tensor(0.0952)]\n",
      "proportion of labels in data: [tensor(0.6235), tensor(0.2232), tensor(0.1533)]\n",
      "- f1: [0.77790304 0.48965517 0.40718563]\n",
      "- f1 (average): 0.5582479483749138\n",
      "- accuracy: 0.6696428656578064\n",
      "\n",
      "********** hidden_dim: [100, 100, 100]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/var/folders/l7/bnn1j6bs3bqfskq2jlq55yh80000gr/T/ipykernel_51169/2802342863.py:18: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  train, valid, test = split_dataset(x_data=torch.tensor(x_data).float(),\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "a598d2e2998945beba8f946652d5b65b",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/10000 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 1/10000 || Item: 0/85 || Loss: 1.0874525308609009\n",
      "--------------------------------------------------\n",
      "##### Epoch: 1/10000 || Loss: 1.0108987092971802\n",
      "--------------------------------------------------\n",
      "Validation || Epoch: 1 || Loss: 0.9790441718968478 || Accuracy: 0.6225854158401489 || F1-score: 0.25579975579975583\n",
      "Epoch: 101/10000 || Item: 0/85 || Loss: 0.35277339816093445\n",
      "--------------------------------------------------\n",
      "##### Epoch: 101/10000 || Loss: 0.047096773982048035\n",
      "--------------------------------------------------\n",
      "Validation || Epoch: 101 || Loss: 1.0158505927432666 || Accuracy: 0.6627042889595032 || F1-score: 0.5273227238831266\n",
      "Epoch: 201/10000 || Item: 0/85 || Loss: 0.307134211063385\n",
      "--------------------------------------------------\n",
      "##### Epoch: 201/10000 || Loss: 0.03561379015445709\n",
      "--------------------------------------------------\n",
      "Validation || Epoch: 201 || Loss: 1.013514291156422 || Accuracy: 0.6627042889595032 || F1-score: 0.5273227238831266\n",
      "Epoch: 301/10000 || Item: 0/85 || Loss: 0.3549908995628357\n",
      "--------------------------------------------------\n",
      "##### Epoch: 301/10000 || Loss: 0.19271552562713623\n",
      "--------------------------------------------------\n",
      "Validation || Epoch: 301 || Loss: 1.0070652148940347 || Accuracy: 0.6627042889595032 || F1-score: 0.5273227238831266\n",
      "Epoch: 401/10000 || Item: 0/85 || Loss: 0.34233078360557556\n",
      "--------------------------------------------------\n",
      "##### Epoch: 401/10000 || Loss: 0.16187064349651337\n",
      "--------------------------------------------------\n",
      "Validation || Epoch: 401 || Loss: 1.0251420194452459 || Accuracy: 0.6627042889595032 || F1-score: 0.5273227238831266\n",
      "Epoch: 501/10000 || Item: 0/85 || Loss: 0.3399404287338257\n",
      "--------------------------------------------------\n",
      "##### Epoch: 501/10000 || Loss: 0.31645774841308594\n",
      "--------------------------------------------------\n",
      "Validation || Epoch: 501 || Loss: 1.0027437210083008 || Accuracy: 0.6627042889595032 || F1-score: 0.5273227238831266\n",
      "Epoch: 601/10000 || Item: 0/85 || Loss: 0.4448460340499878\n",
      "--------------------------------------------------\n",
      "##### Epoch: 601/10000 || Loss: 0.19499094784259796\n",
      "--------------------------------------------------\n",
      "Validation || Epoch: 601 || Loss: 0.9950929771770131 || Accuracy: 0.6627042889595032 || F1-score: 0.5273227238831266\n",
      "Epoch: 701/10000 || Item: 0/85 || Loss: 0.32733187079429626\n",
      "--------------------------------------------------\n",
      "##### Epoch: 701/10000 || Loss: 0.18196961283683777\n",
      "--------------------------------------------------\n",
      "Validation || Epoch: 701 || Loss: 1.0075758370486172 || Accuracy: 0.6627042889595032 || F1-score: 0.5273227238831266\n",
      "Epoch: 801/10000 || Item: 0/85 || Loss: 0.4632386267185211\n",
      "--------------------------------------------------\n",
      "##### Epoch: 801/10000 || Loss: 0.5295335650444031\n",
      "--------------------------------------------------\n",
      "Validation || Epoch: 801 || Loss: 1.0000360608100891 || Accuracy: 0.6627042889595032 || F1-score: 0.5273227238831266\n",
      "Epoch: 901/10000 || Item: 0/85 || Loss: 0.322378009557724\n",
      "--------------------------------------------------\n",
      "##### Epoch: 901/10000 || Loss: 0.1623852699995041\n",
      "--------------------------------------------------\n",
      "Validation || Epoch: 901 || Loss: 1.00759126923301 || Accuracy: 0.6627042889595032 || F1-score: 0.5273227238831266\n",
      "Epoch: 1001/10000 || Item: 0/85 || Loss: 0.34978988766670227\n",
      "--------------------------------------------------\n",
      "##### Epoch: 1001/10000 || Loss: 0.3219338059425354\n",
      "--------------------------------------------------\n",
      "Validation || Epoch: 1001 || Loss: 1.0127936493266712 || Accuracy: 0.6627042889595032 || F1-score: 0.5273227238831266\n",
      "Epoch: 1101/10000 || Item: 0/85 || Loss: 0.31371212005615234\n",
      "--------------------------------------------------\n",
      "##### Epoch: 1101/10000 || Loss: 0.11052975058555603\n",
      "--------------------------------------------------\n",
      "Validation || Epoch: 1101 || Loss: 1.0185090628537266 || Accuracy: 0.6627042889595032 || F1-score: 0.5273227238831266\n",
      "Epoch: 1201/10000 || Item: 0/85 || Loss: 0.4929957389831543\n",
      "--------------------------------------------------\n",
      "##### Epoch: 1201/10000 || Loss: 0.3081212639808655\n",
      "--------------------------------------------------\n",
      "Validation || Epoch: 1201 || Loss: 1.0233854759823193 || Accuracy: 0.6627042889595032 || F1-score: 0.5273227238831266\n",
      "Epoch: 1301/10000 || Item: 0/85 || Loss: 0.38834813237190247\n",
      "--------------------------------------------------\n",
      "##### Epoch: 1301/10000 || Loss: 0.12593841552734375\n",
      "--------------------------------------------------\n",
      "Validation || Epoch: 1301 || Loss: 1.001588068225167 || Accuracy: 0.6627042889595032 || F1-score: 0.5273227238831266\n",
      "Epoch: 1401/10000 || Item: 0/85 || Loss: 0.33964404463768005\n",
      "--------------------------------------------------\n",
      "##### Epoch: 1401/10000 || Loss: 0.4332423210144043\n",
      "--------------------------------------------------\n",
      "Validation || Epoch: 1401 || Loss: 1.009011376987804 || Accuracy: 0.6627042889595032 || F1-score: 0.5273227238831266\n",
      "Epoch: 1501/10000 || Item: 0/85 || Loss: 0.19621801376342773\n",
      "--------------------------------------------------\n",
      "##### Epoch: 1501/10000 || Loss: 0.42389026284217834\n",
      "--------------------------------------------------\n",
      "Validation || Epoch: 1501 || Loss: 0.9903806989843195 || Accuracy: 0.6627042889595032 || F1-score: 0.5273227238831266\n",
      "Epoch: 1601/10000 || Item: 0/85 || Loss: 0.32583194971084595\n",
      "--------------------------------------------------\n",
      "##### Epoch: 1601/10000 || Loss: 0.6535390615463257\n",
      "--------------------------------------------------\n",
      "Validation || Epoch: 1601 || Loss: 1.0110886855558916 || Accuracy: 0.6627042889595032 || F1-score: 0.5273227238831266\n",
      "Epoch: 1701/10000 || Item: 0/85 || Loss: 0.32704001665115356\n",
      "--------------------------------------------------\n",
      "##### Epoch: 1701/10000 || Loss: 0.06418068706989288\n",
      "--------------------------------------------------\n",
      "Validation || Epoch: 1701 || Loss: 1.0133724429390647 || Accuracy: 0.6627042889595032 || F1-score: 0.5273227238831266\n",
      "Epoch: 1801/10000 || Item: 0/85 || Loss: 0.35044780373573303\n",
      "--------------------------------------------------\n",
      "##### Epoch: 1801/10000 || Loss: 0.2060719132423401\n",
      "--------------------------------------------------\n",
      "Validation || Epoch: 1801 || Loss: 1.0228667042472146 || Accuracy: 0.6597325205802917 || F1-score: 0.5253988229227068\n",
      "Early stopping at epoch 1805!\n",
      "Accuracy on dataset of size 672: 68.75 %.\n",
      "Average loss: 0.9893316626548767\n",
      "proportion of labels in prediction: [tensor(0.7009), tensor(0.2054), tensor(0.0938)]\n",
      "proportion of labels in data: [tensor(0.6235), tensor(0.2232), tensor(0.1533)]\n",
      "- f1: [0.78651685 0.51388889 0.45783133]\n",
      "- f1 (average): 0.5860790227075593\n",
      "- accuracy: 0.6875\n",
      "\n",
      "********** hidden_dim: [100, 100, 100, 100]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/var/folders/l7/bnn1j6bs3bqfskq2jlq55yh80000gr/T/ipykernel_51169/2802342863.py:18: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  train, valid, test = split_dataset(x_data=torch.tensor(x_data).float(),\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "9aceae39ea184669ada7c9867ffbfe84",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/10000 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 1/10000 || Item: 0/85 || Loss: 1.0767083168029785\n",
      "--------------------------------------------------\n",
      "##### Epoch: 1/10000 || Loss: 1.0194463729858398\n",
      "--------------------------------------------------\n",
      "Validation || Epoch: 1 || Loss: 0.9741700129075483 || Accuracy: 0.6225854158401489 || F1-score: 0.25579975579975583\n",
      "Early stopping at epoch 26!\n",
      "Accuracy on dataset of size 672: 64.43452453613281 %.\n",
      "Average loss: 0.9960732893510298\n",
      "proportion of labels in prediction: [tensor(0.6756), tensor(0.3244), tensor(0.)]\n",
      "proportion of labels in data: [tensor(0.6235), tensor(0.2232), tensor(0.1533)]\n",
      "- f1: [0.79266896 0.47282609 0.        ]\n",
      "- f1 (average): 0.42183168152464434\n",
      "- accuracy: 0.644345223903656\n",
      "\n",
      "********** hidden_dim: [100, 100, 100, 100, 100]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/var/folders/l7/bnn1j6bs3bqfskq2jlq55yh80000gr/T/ipykernel_51169/2802342863.py:18: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  train, valid, test = split_dataset(x_data=torch.tensor(x_data).float(),\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "1c420bf93cdb41d9a569dd07fe144cd2",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/10000 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 1/10000 || Item: 0/85 || Loss: 1.069919466972351\n",
      "--------------------------------------------------\n",
      "##### Epoch: 1/10000 || Loss: 0.971297025680542\n",
      "--------------------------------------------------\n",
      "Validation || Epoch: 1 || Loss: 0.9626090797511014 || Accuracy: 0.6225854158401489 || F1-score: 0.25579975579975583\n",
      "Early stopping at epoch 25!\n",
      "Accuracy on dataset of size 672: 62.5 %.\n",
      "Average loss: 0.995502157644792\n",
      "proportion of labels in prediction: [tensor(0.6771), tensor(0.3229), tensor(0.)]\n",
      "proportion of labels in data: [tensor(0.6235), tensor(0.2232), tensor(0.1533)]\n",
      "- f1: [0.78032037 0.43051771 0.        ]\n",
      "- f1 (average): 0.4036126924347951\n",
      "- accuracy: 0.625\n"
     ]
    }
   ],
   "source": [
    "signature_history = obtain_signatures_history(sbert_768_embeddings, path_specifics, dimension, sig_depth)\n",
    "print(f\"signature_history.shape = {signature_history.shape}\")\n",
    "for hidden_dim in hidden_dim_trials:\n",
    "    print(f\"\\n********** hidden_dim: {hidden_dim}\")\n",
    "    implement_ffn(x_data=signature_history,\n",
    "                  y_data=y_data,\n",
    "                  hidden_dim=hidden_dim,\n",
    "                  learning_rate=learning_rate,\n",
    "                  loss=loss)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 199,
   "id": "acc86065",
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[INFO] Concatenating the embeddings to the dataframe...\n",
      "[INFO] - columns beginning with 'e' denote the full embddings.\n",
      "[INFO] - columns beginning with 'd' denote the dimension reduced embeddings.\n",
      "[INFO] Adding time feature columns into dataframe in `.df`.\n",
      "[INFO] Adding 'time_encoding' and feature...\n",
      "[INFO] Adding 'time_diff' and feature...\n",
      "[INFO] Adding 'timeline_index' feature...\n",
      "[INFO] Padding ids and storing in `.df_padded` and `.array_padded` attributes.\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "917a001327a442af96844c2e47062901",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/13551 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "signature_history.shape = torch.Size([6725, 780])\n",
      "\n",
      "********** hidden_dim: [100]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/var/folders/l7/bnn1j6bs3bqfskq2jlq55yh80000gr/T/ipykernel_51169/2802342863.py:18: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  train, valid, test = split_dataset(x_data=torch.tensor(x_data).float(),\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "c6d546c9f13a4e18a344b073f84571d0",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/10000 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 1/10000 || Item: 0/85 || Loss: 1.1303646564483643\n",
      "--------------------------------------------------\n",
      "##### Epoch: 1/10000 || Loss: 1.091691493988037\n",
      "--------------------------------------------------\n",
      "Validation || Epoch: 1 || Loss: 1.081595540046692 || Accuracy: 0.5661218166351318 || F1-score: 0.26659070853300276\n",
      "Early stopping at epoch 12!\n",
      "Accuracy on dataset of size 672: 62.35118865966797 %.\n",
      "Average loss: 0.9293696771968495\n",
      "proportion of labels in prediction: [tensor(1.), tensor(0.), tensor(0.)]\n",
      "proportion of labels in data: [tensor(0.6235), tensor(0.2232), tensor(0.1533)]\n",
      "- f1: [0.76810266 0.         0.        ]\n",
      "- f1 (average): 0.25603421937060805\n",
      "- accuracy: 0.6235119104385376\n",
      "\n",
      "********** hidden_dim: [100, 100]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/var/folders/l7/bnn1j6bs3bqfskq2jlq55yh80000gr/T/ipykernel_51169/2802342863.py:18: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  train, valid, test = split_dataset(x_data=torch.tensor(x_data).float(),\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "f8a5eb717d624e8a8db9fbadbff0b306",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/10000 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 1/10000 || Item: 0/85 || Loss: 1.1389836072921753\n",
      "--------------------------------------------------\n",
      "##### Epoch: 1/10000 || Loss: 1.0764942169189453\n",
      "--------------------------------------------------\n",
      "Validation || Epoch: 1 || Loss: 1.080633813684637 || Accuracy: 0.6225854158401489 || F1-score: 0.25579975579975583\n",
      "Epoch: 101/10000 || Item: 0/85 || Loss: 0.7909097671508789\n",
      "--------------------------------------------------\n",
      "##### Epoch: 101/10000 || Loss: 0.34067660570144653\n",
      "--------------------------------------------------\n",
      "Validation || Epoch: 101 || Loss: 1.0206401619044216 || Accuracy: 0.5839524269104004 || F1-score: 0.2900596392089845\n",
      "Epoch: 201/10000 || Item: 0/85 || Loss: 0.7610502243041992\n",
      "--------------------------------------------------\n",
      "##### Epoch: 201/10000 || Loss: 1.6069424152374268\n",
      "--------------------------------------------------\n",
      "Validation || Epoch: 201 || Loss: 1.0220239487561313 || Accuracy: 0.5839524269104004 || F1-score: 0.2900596392089845\n",
      "Epoch: 301/10000 || Item: 0/85 || Loss: 0.6017809510231018\n",
      "--------------------------------------------------\n",
      "##### Epoch: 301/10000 || Loss: 0.3013290762901306\n",
      "--------------------------------------------------\n",
      "Validation || Epoch: 301 || Loss: 1.0240678949789568 || Accuracy: 0.5839524269104004 || F1-score: 0.2900596392089845\n",
      "Epoch: 401/10000 || Item: 0/85 || Loss: 0.6536638140678406\n",
      "--------------------------------------------------\n",
      "##### Epoch: 401/10000 || Loss: 0.8510763645172119\n",
      "--------------------------------------------------\n",
      "Validation || Epoch: 401 || Loss: 1.0142746838656338 || Accuracy: 0.5839524269104004 || F1-score: 0.2900596392089845\n",
      "Epoch: 501/10000 || Item: 0/85 || Loss: 0.7594322562217712\n",
      "--------------------------------------------------\n",
      "##### Epoch: 501/10000 || Loss: 0.7612527012825012\n",
      "--------------------------------------------------\n",
      "Validation || Epoch: 501 || Loss: 1.035748384215615 || Accuracy: 0.5839524269104004 || F1-score: 0.2900596392089845\n",
      "Epoch: 601/10000 || Item: 0/85 || Loss: 0.818913459777832\n",
      "--------------------------------------------------\n",
      "##### Epoch: 601/10000 || Loss: 0.39642009139060974\n",
      "--------------------------------------------------\n",
      "Validation || Epoch: 601 || Loss: 1.0199749198826877 || Accuracy: 0.5839524269104004 || F1-score: 0.2900596392089845\n",
      "Epoch: 701/10000 || Item: 0/85 || Loss: 0.7395969033241272\n",
      "--------------------------------------------------\n",
      "##### Epoch: 701/10000 || Loss: 0.6796536445617676\n",
      "--------------------------------------------------\n",
      "Validation || Epoch: 701 || Loss: 1.0194926316087896 || Accuracy: 0.5839524269104004 || F1-score: 0.2900596392089845\n",
      "Epoch: 801/10000 || Item: 0/85 || Loss: 0.7444193363189697\n",
      "--------------------------------------------------\n",
      "##### Epoch: 801/10000 || Loss: 0.27402952313423157\n",
      "--------------------------------------------------\n",
      "Validation || Epoch: 801 || Loss: 1.0305965596979314 || Accuracy: 0.5839524269104004 || F1-score: 0.2900596392089845\n",
      "Epoch: 901/10000 || Item: 0/85 || Loss: 0.7348619699478149\n",
      "--------------------------------------------------\n",
      "##### Epoch: 901/10000 || Loss: 0.6896936893463135\n",
      "--------------------------------------------------\n",
      "Validation || Epoch: 901 || Loss: 1.0195377631620928 || Accuracy: 0.5839524269104004 || F1-score: 0.2900596392089845\n",
      "Epoch: 1001/10000 || Item: 0/85 || Loss: 0.8507397770881653\n",
      "--------------------------------------------------\n",
      "##### Epoch: 1001/10000 || Loss: 0.8875517845153809\n",
      "--------------------------------------------------\n",
      "Validation || Epoch: 1001 || Loss: 1.019605040550232 || Accuracy: 0.5839524269104004 || F1-score: 0.2900596392089845\n",
      "Epoch: 1101/10000 || Item: 0/85 || Loss: 0.8200878500938416\n",
      "--------------------------------------------------\n",
      "##### Epoch: 1101/10000 || Loss: 0.26162806153297424\n",
      "--------------------------------------------------\n",
      "Validation || Epoch: 1101 || Loss: 1.0286336486989802 || Accuracy: 0.5839524269104004 || F1-score: 0.2900596392089845\n",
      "Epoch: 1201/10000 || Item: 0/85 || Loss: 0.7372498512268066\n",
      "--------------------------------------------------\n",
      "##### Epoch: 1201/10000 || Loss: 0.35588812828063965\n",
      "--------------------------------------------------\n",
      "Validation || Epoch: 1201 || Loss: 1.0260084054686807 || Accuracy: 0.5839524269104004 || F1-score: 0.2900596392089845\n",
      "Epoch: 1301/10000 || Item: 0/85 || Loss: 0.7382517457008362\n",
      "--------------------------------------------------\n",
      "##### Epoch: 1301/10000 || Loss: 0.7368510961532593\n",
      "--------------------------------------------------\n",
      "Validation || Epoch: 1301 || Loss: 1.0360616066239097 || Accuracy: 0.5839524269104004 || F1-score: 0.2900596392089845\n",
      "Epoch: 1401/10000 || Item: 0/85 || Loss: 0.7018652558326721\n",
      "--------------------------------------------------\n",
      "##### Epoch: 1401/10000 || Loss: 0.8101451396942139\n",
      "--------------------------------------------------\n",
      "Validation || Epoch: 1401 || Loss: 1.032921400937167 || Accuracy: 0.5839524269104004 || F1-score: 0.2900596392089845\n",
      "Epoch: 1501/10000 || Item: 0/85 || Loss: 0.7596960663795471\n",
      "--------------------------------------------------\n",
      "##### Epoch: 1501/10000 || Loss: 0.5489036440849304\n",
      "--------------------------------------------------\n",
      "Validation || Epoch: 1501 || Loss: 1.0148417299444026 || Accuracy: 0.5839524269104004 || F1-score: 0.2900596392089845\n",
      "Epoch: 1601/10000 || Item: 0/85 || Loss: 0.6844766736030579\n",
      "--------------------------------------------------\n",
      "##### Epoch: 1601/10000 || Loss: 0.3689526915550232\n",
      "--------------------------------------------------\n",
      "Validation || Epoch: 1601 || Loss: 1.0271451039747759 || Accuracy: 0.5839524269104004 || F1-score: 0.2900596392089845\n",
      "Epoch: 1701/10000 || Item: 0/85 || Loss: 0.6950874924659729\n",
      "--------------------------------------------------\n",
      "##### Epoch: 1701/10000 || Loss: 1.0212862491607666\n",
      "--------------------------------------------------\n",
      "Validation || Epoch: 1701 || Loss: 1.0164977799762378 || Accuracy: 0.5839524269104004 || F1-score: 0.2900596392089845\n",
      "Epoch: 1801/10000 || Item: 0/85 || Loss: 0.7125709652900696\n",
      "--------------------------------------------------\n",
      "##### Epoch: 1801/10000 || Loss: 0.574393630027771\n",
      "--------------------------------------------------\n",
      "Validation || Epoch: 1801 || Loss: 1.0248628150333057 || Accuracy: 0.5839524269104004 || F1-score: 0.2900596392089845\n",
      "Epoch: 1901/10000 || Item: 0/85 || Loss: 0.7909501194953918\n",
      "--------------------------------------------------\n",
      "##### Epoch: 1901/10000 || Loss: 0.8576972484588623\n",
      "--------------------------------------------------\n",
      "Validation || Epoch: 1901 || Loss: 1.0284272757443516 || Accuracy: 0.5839524269104004 || F1-score: 0.2900596392089845\n",
      "Epoch: 2001/10000 || Item: 0/85 || Loss: 0.7362021207809448\n",
      "--------------------------------------------------\n",
      "##### Epoch: 2001/10000 || Loss: 0.9884616732597351\n",
      "--------------------------------------------------\n",
      "Validation || Epoch: 2001 || Loss: 1.0168042237108403 || Accuracy: 0.5839524269104004 || F1-score: 0.2900596392089845\n",
      "Epoch: 2101/10000 || Item: 0/85 || Loss: 0.6751823425292969\n",
      "--------------------------------------------------\n",
      "##### Epoch: 2101/10000 || Loss: 1.333046793937683\n",
      "--------------------------------------------------\n",
      "Validation || Epoch: 2101 || Loss: 1.0153035033832898 || Accuracy: 0.5839524269104004 || F1-score: 0.2900596392089845\n",
      "Epoch: 2201/10000 || Item: 0/85 || Loss: 0.6793947815895081\n",
      "--------------------------------------------------\n",
      "##### Epoch: 2201/10000 || Loss: 0.34840062260627747\n",
      "--------------------------------------------------\n",
      "Validation || Epoch: 2201 || Loss: 1.0277892730452798 || Accuracy: 0.5839524269104004 || F1-score: 0.2900596392089845\n",
      "Epoch: 2301/10000 || Item: 0/85 || Loss: 0.6709405183792114\n",
      "--------------------------------------------------\n",
      "##### Epoch: 2301/10000 || Loss: 1.4573328495025635\n",
      "--------------------------------------------------\n",
      "Validation || Epoch: 2301 || Loss: 1.0316440246321938 || Accuracy: 0.5839524269104004 || F1-score: 0.2900596392089845\n",
      "Epoch: 2401/10000 || Item: 0/85 || Loss: 0.777057945728302\n",
      "--------------------------------------------------\n",
      "##### Epoch: 2401/10000 || Loss: 0.32546359300613403\n",
      "--------------------------------------------------\n",
      "Validation || Epoch: 2401 || Loss: 1.0195701284842058 || Accuracy: 0.5839524269104004 || F1-score: 0.2900596392089845\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 2501/10000 || Item: 0/85 || Loss: 0.7414960265159607\n",
      "--------------------------------------------------\n",
      "##### Epoch: 2501/10000 || Loss: 0.1530255824327469\n",
      "--------------------------------------------------\n",
      "Validation || Epoch: 2501 || Loss: 1.020157060839913 || Accuracy: 0.5839524269104004 || F1-score: 0.2900596392089845\n",
      "Epoch: 2601/10000 || Item: 0/85 || Loss: 0.6695468425750732\n",
      "--------------------------------------------------\n",
      "##### Epoch: 2601/10000 || Loss: 1.2219645977020264\n",
      "--------------------------------------------------\n",
      "Validation || Epoch: 2601 || Loss: 1.0266884782097556 || Accuracy: 0.5839524269104004 || F1-score: 0.2900596392089845\n",
      "Epoch: 2701/10000 || Item: 0/85 || Loss: 0.7066129446029663\n",
      "--------------------------------------------------\n",
      "##### Epoch: 2701/10000 || Loss: 1.8067954778671265\n",
      "--------------------------------------------------\n",
      "Validation || Epoch: 2701 || Loss: 1.0178581530397588 || Accuracy: 0.5839524269104004 || F1-score: 0.2900596392089845\n",
      "Epoch: 2801/10000 || Item: 0/85 || Loss: 0.7122923731803894\n",
      "--------------------------------------------------\n",
      "##### Epoch: 2801/10000 || Loss: 0.775032103061676\n",
      "--------------------------------------------------\n",
      "Validation || Epoch: 2801 || Loss: 1.0153548392382534 || Accuracy: 0.5839524269104004 || F1-score: 0.2900596392089845\n",
      "Epoch: 2901/10000 || Item: 0/85 || Loss: 0.7602384090423584\n",
      "--------------------------------------------------\n",
      "##### Epoch: 2901/10000 || Loss: 1.0588436126708984\n",
      "--------------------------------------------------\n",
      "Validation || Epoch: 2901 || Loss: 1.0221941633657976 || Accuracy: 0.5839524269104004 || F1-score: 0.2900596392089845\n",
      "Epoch: 3001/10000 || Item: 0/85 || Loss: 0.6067786812782288\n",
      "--------------------------------------------------\n",
      "##### Epoch: 3001/10000 || Loss: 0.4326931834220886\n",
      "--------------------------------------------------\n",
      "Validation || Epoch: 3001 || Loss: 1.0341209064830432 || Accuracy: 0.5839524269104004 || F1-score: 0.2900596392089845\n",
      "Epoch: 3101/10000 || Item: 0/85 || Loss: 0.5600703954696655\n",
      "--------------------------------------------------\n",
      "##### Epoch: 3101/10000 || Loss: 0.9890957474708557\n",
      "--------------------------------------------------\n",
      "Validation || Epoch: 3101 || Loss: 1.0114068063822659 || Accuracy: 0.5839524269104004 || F1-score: 0.2900596392089845\n",
      "Epoch: 3201/10000 || Item: 0/85 || Loss: 0.8043501377105713\n",
      "--------------------------------------------------\n",
      "##### Epoch: 3201/10000 || Loss: 1.1419804096221924\n",
      "--------------------------------------------------\n",
      "Validation || Epoch: 3201 || Loss: 1.0227464058182456 || Accuracy: 0.5839524269104004 || F1-score: 0.2900596392089845\n",
      "Epoch: 3301/10000 || Item: 0/85 || Loss: 0.6645026206970215\n",
      "--------------------------------------------------\n",
      "##### Epoch: 3301/10000 || Loss: 0.5534541606903076\n",
      "--------------------------------------------------\n",
      "Validation || Epoch: 3301 || Loss: 1.0325392484664917 || Accuracy: 0.5839524269104004 || F1-score: 0.2900596392089845\n",
      "Epoch: 3401/10000 || Item: 0/85 || Loss: 0.7419474720954895\n",
      "--------------------------------------------------\n",
      "##### Epoch: 3401/10000 || Loss: 0.8298396468162537\n",
      "--------------------------------------------------\n",
      "Validation || Epoch: 3401 || Loss: 1.0279435081915422 || Accuracy: 0.5839524269104004 || F1-score: 0.2900596392089845\n",
      "Epoch: 3501/10000 || Item: 0/85 || Loss: 0.6934329867362976\n",
      "--------------------------------------------------\n",
      "##### Epoch: 3501/10000 || Loss: 1.1680647134780884\n",
      "--------------------------------------------------\n",
      "Validation || Epoch: 3501 || Loss: 1.0235327157107266 || Accuracy: 0.5839524269104004 || F1-score: 0.2900596392089845\n",
      "Epoch: 3601/10000 || Item: 0/85 || Loss: 0.7338664531707764\n",
      "--------------------------------------------------\n",
      "##### Epoch: 3601/10000 || Loss: 0.893490195274353\n",
      "--------------------------------------------------\n",
      "Validation || Epoch: 3601 || Loss: 1.0230837952006946 || Accuracy: 0.5839524269104004 || F1-score: 0.2900596392089845\n",
      "Epoch: 3701/10000 || Item: 0/85 || Loss: 0.4877040386199951\n",
      "--------------------------------------------------\n",
      "##### Epoch: 3701/10000 || Loss: 1.1617934703826904\n",
      "--------------------------------------------------\n",
      "Validation || Epoch: 3701 || Loss: 1.0498186891729182 || Accuracy: 0.5839524269104004 || F1-score: 0.2900596392089845\n",
      "Epoch: 3801/10000 || Item: 0/85 || Loss: 0.7113535404205322\n",
      "--------------------------------------------------\n",
      "##### Epoch: 3801/10000 || Loss: 0.5554969310760498\n",
      "--------------------------------------------------\n",
      "Validation || Epoch: 3801 || Loss: 1.0222990079359575 || Accuracy: 0.5839524269104004 || F1-score: 0.2900596392089845\n",
      "Epoch: 3901/10000 || Item: 0/85 || Loss: 0.7068623304367065\n",
      "--------------------------------------------------\n",
      "##### Epoch: 3901/10000 || Loss: 0.7154061794281006\n",
      "--------------------------------------------------\n",
      "Validation || Epoch: 3901 || Loss: 1.028866621580991 || Accuracy: 0.5839524269104004 || F1-score: 0.2900596392089845\n",
      "Epoch: 4001/10000 || Item: 0/85 || Loss: 0.7763877511024475\n",
      "--------------------------------------------------\n",
      "##### Epoch: 4001/10000 || Loss: 0.8616691827774048\n",
      "--------------------------------------------------\n",
      "Validation || Epoch: 4001 || Loss: 1.0256619182499973 || Accuracy: 0.5839524269104004 || F1-score: 0.2900596392089845\n",
      "Epoch: 4101/10000 || Item: 0/85 || Loss: 0.6204723119735718\n",
      "--------------------------------------------------\n",
      "##### Epoch: 4101/10000 || Loss: 0.7160694599151611\n",
      "--------------------------------------------------\n",
      "Validation || Epoch: 4101 || Loss: 1.0252274166453967 || Accuracy: 0.5839524269104004 || F1-score: 0.2900596392089845\n",
      "Epoch: 4201/10000 || Item: 0/85 || Loss: 0.6633573770523071\n",
      "--------------------------------------------------\n",
      "##### Epoch: 4201/10000 || Loss: 1.042588710784912\n",
      "--------------------------------------------------\n",
      "Validation || Epoch: 4201 || Loss: 1.0257827856323936 || Accuracy: 0.5839524269104004 || F1-score: 0.2900596392089845\n",
      "Epoch: 4301/10000 || Item: 0/85 || Loss: 0.7164251208305359\n",
      "--------------------------------------------------\n",
      "##### Epoch: 4301/10000 || Loss: 0.6918572783470154\n",
      "--------------------------------------------------\n",
      "Validation || Epoch: 4301 || Loss: 1.0211814533580432 || Accuracy: 0.5839524269104004 || F1-score: 0.2900596392089845\n",
      "Epoch: 4401/10000 || Item: 0/85 || Loss: 0.6236141324043274\n",
      "--------------------------------------------------\n",
      "##### Epoch: 4401/10000 || Loss: 0.8267936110496521\n",
      "--------------------------------------------------\n",
      "Validation || Epoch: 4401 || Loss: 1.0291383483193137 || Accuracy: 0.5839524269104004 || F1-score: 0.2900596392089845\n",
      "Epoch: 4501/10000 || Item: 0/85 || Loss: 0.7498931288719177\n",
      "--------------------------------------------------\n",
      "##### Epoch: 4501/10000 || Loss: 0.5258647203445435\n",
      "--------------------------------------------------\n",
      "Validation || Epoch: 4501 || Loss: 1.0253355611454358 || Accuracy: 0.5839524269104004 || F1-score: 0.2900596392089845\n",
      "Epoch: 4601/10000 || Item: 0/85 || Loss: 0.719687819480896\n",
      "--------------------------------------------------\n",
      "##### Epoch: 4601/10000 || Loss: 0.6964466571807861\n",
      "--------------------------------------------------\n",
      "Validation || Epoch: 4601 || Loss: 1.0144033161076633 || Accuracy: 0.5839524269104004 || F1-score: 0.2900596392089845\n",
      "Epoch: 4701/10000 || Item: 0/85 || Loss: 0.6327359080314636\n",
      "--------------------------------------------------\n",
      "##### Epoch: 4701/10000 || Loss: 1.29062819480896\n",
      "--------------------------------------------------\n",
      "Validation || Epoch: 4701 || Loss: 1.0265953486615962 || Accuracy: 0.5839524269104004 || F1-score: 0.2900596392089845\n",
      "Epoch: 4801/10000 || Item: 0/85 || Loss: 0.8848784565925598\n",
      "--------------------------------------------------\n",
      "##### Epoch: 4801/10000 || Loss: 0.9465983510017395\n",
      "--------------------------------------------------\n",
      "Validation || Epoch: 4801 || Loss: 1.0323966416445645 || Accuracy: 0.5839524269104004 || F1-score: 0.2900596392089845\n",
      "Epoch: 4901/10000 || Item: 0/85 || Loss: 0.6788386702537537\n",
      "--------------------------------------------------\n",
      "##### Epoch: 4901/10000 || Loss: 0.541263997554779\n",
      "--------------------------------------------------\n",
      "Validation || Epoch: 4901 || Loss: 1.030928758057681 || Accuracy: 0.5839524269104004 || F1-score: 0.2900596392089845\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 5001/10000 || Item: 0/85 || Loss: 0.5487132668495178\n",
      "--------------------------------------------------\n",
      "##### Epoch: 5001/10000 || Loss: 0.8895431160926819\n",
      "--------------------------------------------------\n",
      "Validation || Epoch: 5001 || Loss: 1.0458341999487444 || Accuracy: 0.5839524269104004 || F1-score: 0.2900596392089845\n",
      "Epoch: 5101/10000 || Item: 0/85 || Loss: 0.6966171264648438\n",
      "--------------------------------------------------\n",
      "##### Epoch: 5101/10000 || Loss: 0.5476250648498535\n",
      "--------------------------------------------------\n",
      "Validation || Epoch: 5101 || Loss: 1.0273423086513171 || Accuracy: 0.5839524269104004 || F1-score: 0.2900596392089845\n",
      "Epoch: 5201/10000 || Item: 0/85 || Loss: 0.7137590646743774\n",
      "--------------------------------------------------\n",
      "##### Epoch: 5201/10000 || Loss: 1.2158581018447876\n",
      "--------------------------------------------------\n",
      "Validation || Epoch: 5201 || Loss: 1.0158035321669145 || Accuracy: 0.5839524269104004 || F1-score: 0.2900596392089845\n",
      "Epoch: 5301/10000 || Item: 0/85 || Loss: 0.6427876949310303\n",
      "--------------------------------------------------\n",
      "##### Epoch: 5301/10000 || Loss: 0.5905100107192993\n",
      "--------------------------------------------------\n",
      "Validation || Epoch: 5301 || Loss: 1.0312162583524531 || Accuracy: 0.5839524269104004 || F1-score: 0.2900596392089845\n",
      "Epoch: 5401/10000 || Item: 0/85 || Loss: 0.7483015656471252\n",
      "--------------------------------------------------\n",
      "##### Epoch: 5401/10000 || Loss: 0.615283191204071\n",
      "--------------------------------------------------\n",
      "Validation || Epoch: 5401 || Loss: 1.030697838826613 || Accuracy: 0.5839524269104004 || F1-score: 0.2900596392089845\n",
      "Epoch: 5501/10000 || Item: 0/85 || Loss: 0.7464392781257629\n",
      "--------------------------------------------------\n",
      "##### Epoch: 5501/10000 || Loss: 0.9083736538887024\n",
      "--------------------------------------------------\n",
      "Validation || Epoch: 5501 || Loss: 1.0290904695337468 || Accuracy: 0.5839524269104004 || F1-score: 0.2900596392089845\n",
      "Epoch: 5601/10000 || Item: 0/85 || Loss: 0.7488263249397278\n",
      "--------------------------------------------------\n",
      "##### Epoch: 5601/10000 || Loss: 0.3493186831474304\n",
      "--------------------------------------------------\n",
      "Validation || Epoch: 5601 || Loss: 1.017481104894118 || Accuracy: 0.5839524269104004 || F1-score: 0.2900596392089845\n",
      "Epoch: 5701/10000 || Item: 0/85 || Loss: 0.5793201923370361\n",
      "--------------------------------------------------\n",
      "##### Epoch: 5701/10000 || Loss: 0.587286114692688\n",
      "--------------------------------------------------\n",
      "Validation || Epoch: 5701 || Loss: 1.033555724404075 || Accuracy: 0.5839524269104004 || F1-score: 0.2900596392089845\n",
      "Epoch: 5801/10000 || Item: 0/85 || Loss: 0.6683933734893799\n",
      "--------------------------------------------------\n",
      "##### Epoch: 5801/10000 || Loss: 0.7742299437522888\n",
      "--------------------------------------------------\n",
      "Validation || Epoch: 5801 || Loss: 1.028615946119482 || Accuracy: 0.5839524269104004 || F1-score: 0.2900596392089845\n",
      "Epoch: 5901/10000 || Item: 0/85 || Loss: 0.7928056120872498\n",
      "--------------------------------------------------\n",
      "##### Epoch: 5901/10000 || Loss: 0.3896006941795349\n",
      "--------------------------------------------------\n",
      "Validation || Epoch: 5901 || Loss: 1.0181763497265903 || Accuracy: 0.5839524269104004 || F1-score: 0.2900596392089845\n",
      "Epoch: 6001/10000 || Item: 0/85 || Loss: 0.8121169805526733\n",
      "--------------------------------------------------\n",
      "##### Epoch: 6001/10000 || Loss: 0.5861197113990784\n",
      "--------------------------------------------------\n",
      "Validation || Epoch: 6001 || Loss: 1.0229660218412227 || Accuracy: 0.5839524269104004 || F1-score: 0.2900596392089845\n",
      "Epoch: 6101/10000 || Item: 0/85 || Loss: 0.6602774262428284\n",
      "--------------------------------------------------\n",
      "##### Epoch: 6101/10000 || Loss: 0.6452503204345703\n",
      "--------------------------------------------------\n",
      "Validation || Epoch: 6101 || Loss: 1.0315873622894287 || Accuracy: 0.5839524269104004 || F1-score: 0.2900596392089845\n",
      "Epoch: 6201/10000 || Item: 0/85 || Loss: 0.5883234739303589\n",
      "--------------------------------------------------\n",
      "##### Epoch: 6201/10000 || Loss: 0.7666585445404053\n",
      "--------------------------------------------------\n",
      "Validation || Epoch: 6201 || Loss: 1.0376186045733364 || Accuracy: 0.5839524269104004 || F1-score: 0.2900596392089845\n",
      "Epoch: 6301/10000 || Item: 0/85 || Loss: 0.6284408569335938\n",
      "--------------------------------------------------\n",
      "##### Epoch: 6301/10000 || Loss: 0.22407123446464539\n",
      "--------------------------------------------------\n",
      "Validation || Epoch: 6301 || Loss: 1.0268894704905422 || Accuracy: 0.5839524269104004 || F1-score: 0.2900596392089845\n",
      "Epoch: 6401/10000 || Item: 0/85 || Loss: 0.689462423324585\n",
      "--------------------------------------------------\n",
      "##### Epoch: 6401/10000 || Loss: 0.6485446691513062\n",
      "--------------------------------------------------\n",
      "Validation || Epoch: 6401 || Loss: 1.0244170481508428 || Accuracy: 0.5839524269104004 || F1-score: 0.2900596392089845\n",
      "Epoch: 6501/10000 || Item: 0/85 || Loss: 0.6163894534111023\n",
      "--------------------------------------------------\n",
      "##### Epoch: 6501/10000 || Loss: 0.6159430146217346\n",
      "--------------------------------------------------\n",
      "Validation || Epoch: 6501 || Loss: 1.025130889632485 || Accuracy: 0.5839524269104004 || F1-score: 0.2900596392089845\n",
      "Epoch: 6601/10000 || Item: 0/85 || Loss: 0.6787782907485962\n",
      "--------------------------------------------------\n",
      "##### Epoch: 6601/10000 || Loss: 0.7462596297264099\n",
      "--------------------------------------------------\n",
      "Validation || Epoch: 6601 || Loss: 1.0183778947049922 || Accuracy: 0.5839524269104004 || F1-score: 0.2900596392089845\n",
      "Epoch: 6701/10000 || Item: 0/85 || Loss: 0.6612167358398438\n",
      "--------------------------------------------------\n",
      "##### Epoch: 6701/10000 || Loss: 0.898828387260437\n",
      "--------------------------------------------------\n",
      "Validation || Epoch: 6701 || Loss: 1.0302324511788108 || Accuracy: 0.5839524269104004 || F1-score: 0.2900596392089845\n",
      "Epoch: 6801/10000 || Item: 0/85 || Loss: 0.8442970514297485\n",
      "--------------------------------------------------\n",
      "##### Epoch: 6801/10000 || Loss: 0.9217119812965393\n",
      "--------------------------------------------------\n",
      "Validation || Epoch: 6801 || Loss: 1.0427643656730652 || Accuracy: 0.5839524269104004 || F1-score: 0.2900596392089845\n",
      "Epoch: 6901/10000 || Item: 0/85 || Loss: 0.6429482698440552\n",
      "--------------------------------------------------\n",
      "##### Epoch: 6901/10000 || Loss: 0.8869894742965698\n",
      "--------------------------------------------------\n",
      "Validation || Epoch: 6901 || Loss: 1.0469629927115007 || Accuracy: 0.5839524269104004 || F1-score: 0.2900596392089845\n",
      "Epoch: 7001/10000 || Item: 0/85 || Loss: 0.683330774307251\n",
      "--------------------------------------------------\n",
      "##### Epoch: 7001/10000 || Loss: 0.1995360255241394\n",
      "--------------------------------------------------\n",
      "Validation || Epoch: 7001 || Loss: 1.0333010337569497 || Accuracy: 0.5839524269104004 || F1-score: 0.2900596392089845\n",
      "Epoch: 7101/10000 || Item: 0/85 || Loss: 0.7443293333053589\n",
      "--------------------------------------------------\n",
      "##### Epoch: 7101/10000 || Loss: 0.7138073444366455\n",
      "--------------------------------------------------\n",
      "Validation || Epoch: 7101 || Loss: 1.0232504118572583 || Accuracy: 0.5839524269104004 || F1-score: 0.2900596392089845\n",
      "Epoch: 7201/10000 || Item: 0/85 || Loss: 0.8201587796211243\n",
      "--------------------------------------------------\n",
      "##### Epoch: 7201/10000 || Loss: 0.0208016037940979\n",
      "--------------------------------------------------\n",
      "Validation || Epoch: 7201 || Loss: 1.0240194580771707 || Accuracy: 0.5839524269104004 || F1-score: 0.2900596392089845\n",
      "Epoch: 7301/10000 || Item: 0/85 || Loss: 0.824823260307312\n",
      "--------------------------------------------------\n",
      "##### Epoch: 7301/10000 || Loss: 0.8626036643981934\n",
      "--------------------------------------------------\n",
      "Validation || Epoch: 7301 || Loss: 1.0400257164781743 || Accuracy: 0.5839524269104004 || F1-score: 0.2900596392089845\n",
      "Epoch: 7401/10000 || Item: 0/85 || Loss: 0.7566732168197632\n",
      "--------------------------------------------------\n",
      "##### Epoch: 7401/10000 || Loss: 0.20788903534412384\n",
      "--------------------------------------------------\n",
      "Validation || Epoch: 7401 || Loss: 1.036156871102073 || Accuracy: 0.5839524269104004 || F1-score: 0.2900596392089845\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 7501/10000 || Item: 0/85 || Loss: 0.6385011672973633\n",
      "--------------------------------------------------\n",
      "##### Epoch: 7501/10000 || Loss: 1.1602758169174194\n",
      "--------------------------------------------------\n",
      "Validation || Epoch: 7501 || Loss: 1.0288253318179736 || Accuracy: 0.5839524269104004 || F1-score: 0.2900596392089845\n",
      "Epoch: 7601/10000 || Item: 0/85 || Loss: 0.7711106538772583\n",
      "--------------------------------------------------\n",
      "##### Epoch: 7601/10000 || Loss: 0.8622919321060181\n",
      "--------------------------------------------------\n",
      "Validation || Epoch: 7601 || Loss: 1.0367966402660718 || Accuracy: 0.5839524269104004 || F1-score: 0.2900596392089845\n",
      "Epoch: 7701/10000 || Item: 0/85 || Loss: 0.6621609330177307\n",
      "--------------------------------------------------\n",
      "##### Epoch: 7701/10000 || Loss: 1.155216932296753\n",
      "--------------------------------------------------\n",
      "Validation || Epoch: 7701 || Loss: 1.046659225767309 || Accuracy: 0.5839524269104004 || F1-score: 0.2900596392089845\n",
      "Epoch: 7801/10000 || Item: 0/85 || Loss: 0.6430836319923401\n",
      "--------------------------------------------------\n",
      "##### Epoch: 7801/10000 || Loss: 0.6912028789520264\n",
      "--------------------------------------------------\n",
      "Validation || Epoch: 7801 || Loss: 1.0360395095565103 || Accuracy: 0.5839524269104004 || F1-score: 0.2900596392089845\n",
      "Epoch: 7901/10000 || Item: 0/85 || Loss: 0.6300345063209534\n",
      "--------------------------------------------------\n",
      "##### Epoch: 7901/10000 || Loss: 0.6569400429725647\n",
      "--------------------------------------------------\n",
      "Validation || Epoch: 7901 || Loss: 1.0400786128911106 || Accuracy: 0.5839524269104004 || F1-score: 0.2900596392089845\n",
      "Epoch: 8001/10000 || Item: 0/85 || Loss: 0.5347527265548706\n",
      "--------------------------------------------------\n",
      "##### Epoch: 8001/10000 || Loss: 1.149923324584961\n",
      "--------------------------------------------------\n",
      "Validation || Epoch: 8001 || Loss: 1.0355688550255515 || Accuracy: 0.5839524269104004 || F1-score: 0.2900596392089845\n",
      "Epoch: 8101/10000 || Item: 0/85 || Loss: 0.7489898800849915\n",
      "--------------------------------------------------\n",
      "##### Epoch: 8101/10000 || Loss: 0.6062882542610168\n",
      "--------------------------------------------------\n",
      "Validation || Epoch: 8101 || Loss: 1.027721274982799 || Accuracy: 0.5839524269104004 || F1-score: 0.2900596392089845\n",
      "Epoch: 8201/10000 || Item: 0/85 || Loss: 0.5731804370880127\n",
      "--------------------------------------------------\n",
      "##### Epoch: 8201/10000 || Loss: 0.5371819734573364\n",
      "--------------------------------------------------\n",
      "Validation || Epoch: 8201 || Loss: 1.030902694572102 || Accuracy: 0.5839524269104004 || F1-score: 0.2900596392089845\n",
      "Epoch: 8301/10000 || Item: 0/85 || Loss: 0.682357132434845\n",
      "--------------------------------------------------\n",
      "##### Epoch: 8301/10000 || Loss: 0.44808560609817505\n",
      "--------------------------------------------------\n",
      "Validation || Epoch: 8301 || Loss: 1.0303212458437139 || Accuracy: 0.5839524269104004 || F1-score: 0.2900596392089845\n",
      "Epoch: 8401/10000 || Item: 0/85 || Loss: 0.6628496646881104\n",
      "--------------------------------------------------\n",
      "##### Epoch: 8401/10000 || Loss: 0.9724158048629761\n",
      "--------------------------------------------------\n",
      "Validation || Epoch: 8401 || Loss: 1.0325219360264866 || Accuracy: 0.5839524269104004 || F1-score: 0.2900596392089845\n",
      "Epoch: 8501/10000 || Item: 0/85 || Loss: 0.7595489621162415\n",
      "--------------------------------------------------\n",
      "##### Epoch: 8501/10000 || Loss: 0.6603386402130127\n",
      "--------------------------------------------------\n",
      "Validation || Epoch: 8501 || Loss: 1.0211176492951133 || Accuracy: 0.5839524269104004 || F1-score: 0.2900596392089845\n",
      "Epoch: 8601/10000 || Item: 0/85 || Loss: 0.5797843337059021\n",
      "--------------------------------------------------\n",
      "##### Epoch: 8601/10000 || Loss: 0.8320967555046082\n",
      "--------------------------------------------------\n",
      "Validation || Epoch: 8601 || Loss: 1.0245011719790371 || Accuracy: 0.5839524269104004 || F1-score: 0.2900596392089845\n",
      "Epoch: 8701/10000 || Item: 0/85 || Loss: 0.7789407968521118\n",
      "--------------------------------------------------\n",
      "##### Epoch: 8701/10000 || Loss: 0.8915852308273315\n",
      "--------------------------------------------------\n",
      "Validation || Epoch: 8701 || Loss: 1.0279362255876714 || Accuracy: 0.5839524269104004 || F1-score: 0.2900596392089845\n",
      "Epoch: 8801/10000 || Item: 0/85 || Loss: 0.9430475831031799\n",
      "--------------------------------------------------\n",
      "##### Epoch: 8801/10000 || Loss: 0.4960639476776123\n",
      "--------------------------------------------------\n",
      "Validation || Epoch: 8801 || Loss: 1.0423644293438306 || Accuracy: 0.5839524269104004 || F1-score: 0.2900596392089845\n",
      "Epoch: 8901/10000 || Item: 0/85 || Loss: 0.7335163354873657\n",
      "--------------------------------------------------\n",
      "##### Epoch: 8901/10000 || Loss: 0.24037902057170868\n",
      "--------------------------------------------------\n",
      "Validation || Epoch: 8901 || Loss: 1.0250034711577676 || Accuracy: 0.5839524269104004 || F1-score: 0.2900596392089845\n",
      "Epoch: 9001/10000 || Item: 0/85 || Loss: 0.6509809494018555\n",
      "--------------------------------------------------\n",
      "##### Epoch: 9001/10000 || Loss: 0.7194730043411255\n",
      "--------------------------------------------------\n",
      "Validation || Epoch: 9001 || Loss: 1.0420846993272954 || Accuracy: 0.5839524269104004 || F1-score: 0.2900596392089845\n",
      "Epoch: 9101/10000 || Item: 0/85 || Loss: 0.8463796377182007\n",
      "--------------------------------------------------\n",
      "##### Epoch: 9101/10000 || Loss: 0.7767298221588135\n",
      "--------------------------------------------------\n",
      "Validation || Epoch: 9101 || Loss: 1.0377811681140552 || Accuracy: 0.5839524269104004 || F1-score: 0.2900596392089845\n",
      "Epoch: 9201/10000 || Item: 0/85 || Loss: 0.6724333167076111\n",
      "--------------------------------------------------\n",
      "##### Epoch: 9201/10000 || Loss: 0.7764588594436646\n",
      "--------------------------------------------------\n",
      "Validation || Epoch: 9201 || Loss: 1.0368556000969626 || Accuracy: 0.5839524269104004 || F1-score: 0.2900596392089845\n",
      "Epoch: 9301/10000 || Item: 0/85 || Loss: 0.7563875913619995\n",
      "--------------------------------------------------\n",
      "##### Epoch: 9301/10000 || Loss: 0.6598643660545349\n",
      "--------------------------------------------------\n",
      "Validation || Epoch: 9301 || Loss: 1.0226874568245627 || Accuracy: 0.5839524269104004 || F1-score: 0.2900596392089845\n",
      "Epoch: 9401/10000 || Item: 0/85 || Loss: 0.8299878239631653\n",
      "--------------------------------------------------\n",
      "##### Epoch: 9401/10000 || Loss: 0.8106392621994019\n",
      "--------------------------------------------------\n",
      "Validation || Epoch: 9401 || Loss: 1.0297478166493503 || Accuracy: 0.5839524269104004 || F1-score: 0.2900596392089845\n",
      "Epoch: 9501/10000 || Item: 0/85 || Loss: 0.7146969437599182\n",
      "--------------------------------------------------\n",
      "##### Epoch: 9501/10000 || Loss: 0.6874171495437622\n",
      "--------------------------------------------------\n",
      "Validation || Epoch: 9501 || Loss: 1.0357261841947383 || Accuracy: 0.5839524269104004 || F1-score: 0.2900596392089845\n",
      "Epoch: 9601/10000 || Item: 0/85 || Loss: 0.660413384437561\n",
      "--------------------------------------------------\n",
      "##### Epoch: 9601/10000 || Loss: 0.6764985918998718\n",
      "--------------------------------------------------\n",
      "Validation || Epoch: 9601 || Loss: 1.0299008813771335 || Accuracy: 0.5839524269104004 || F1-score: 0.2900596392089845\n",
      "Epoch: 9701/10000 || Item: 0/85 || Loss: 0.7036582827568054\n",
      "--------------------------------------------------\n",
      "##### Epoch: 9701/10000 || Loss: 0.9826647639274597\n",
      "--------------------------------------------------\n",
      "Validation || Epoch: 9701 || Loss: 1.0341235399246216 || Accuracy: 0.5854383111000061 || F1-score: 0.29285331618986393\n",
      "Epoch: 9801/10000 || Item: 0/85 || Loss: 0.6184617877006531\n",
      "--------------------------------------------------\n",
      "##### Epoch: 9801/10000 || Loss: 0.8416128158569336\n",
      "--------------------------------------------------\n",
      "Validation || Epoch: 9801 || Loss: 1.0373673764142124 || Accuracy: 0.5854383111000061 || F1-score: 0.29285331618986393\n",
      "Epoch: 9901/10000 || Item: 0/85 || Loss: 0.7451493740081787\n",
      "--------------------------------------------------\n",
      "##### Epoch: 9901/10000 || Loss: 0.40617141127586365\n",
      "--------------------------------------------------\n",
      "Validation || Epoch: 9901 || Loss: 1.0250915722413496 || Accuracy: 0.5854383111000061 || F1-score: 0.29285331618986393\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy on dataset of size 672: 61.30952453613281 %.\n",
      "Average loss: 0.9993096535856073\n",
      "proportion of labels in prediction: [tensor(0.9092), tensor(0.0908), tensor(0.)]\n",
      "proportion of labels in data: [tensor(0.6235), tensor(0.2232), tensor(0.1533)]\n",
      "- f1: [0.76116505 0.18957346 0.        ]\n",
      "- f1 (average): 0.31691283608644305\n",
      "- accuracy: 0.613095223903656\n",
      "\n",
      "********** hidden_dim: [100, 100, 100]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/var/folders/l7/bnn1j6bs3bqfskq2jlq55yh80000gr/T/ipykernel_51169/2802342863.py:18: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  train, valid, test = split_dataset(x_data=torch.tensor(x_data).float(),\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "98923732fc8d44b98d3bc5afc692d125",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/10000 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 1/10000 || Item: 0/85 || Loss: 1.080559492111206\n",
      "--------------------------------------------------\n",
      "##### Epoch: 1/10000 || Loss: 1.0302709341049194\n",
      "--------------------------------------------------\n",
      "Validation || Epoch: 1 || Loss: 1.0186785676262595 || Accuracy: 0.6225854158401489 || F1-score: 0.25579975579975583\n",
      "Epoch: 101/10000 || Item: 0/85 || Loss: 0.7531773447990417\n",
      "--------------------------------------------------\n",
      "##### Epoch: 101/10000 || Loss: 0.4756762385368347\n",
      "--------------------------------------------------\n",
      "Validation || Epoch: 101 || Loss: 1.0462399450215427 || Accuracy: 0.5958395004272461 || F1-score: 0.2946432936752394\n",
      "Epoch: 201/10000 || Item: 0/85 || Loss: 0.7362188100814819\n",
      "--------------------------------------------------\n",
      "##### Epoch: 201/10000 || Loss: 0.28524696826934814\n",
      "--------------------------------------------------\n",
      "Validation || Epoch: 201 || Loss: 1.0541054172949358 || Accuracy: 0.5958395004272461 || F1-score: 0.2946432936752394\n",
      "Epoch: 301/10000 || Item: 0/85 || Loss: 0.8345623016357422\n",
      "--------------------------------------------------\n",
      "##### Epoch: 301/10000 || Loss: 0.8457297682762146\n",
      "--------------------------------------------------\n",
      "Validation || Epoch: 301 || Loss: 1.0497060472315007 || Accuracy: 0.5958395004272461 || F1-score: 0.2946432936752394\n",
      "Epoch: 401/10000 || Item: 0/85 || Loss: 0.8383646011352539\n",
      "--------------------------------------------------\n",
      "##### Epoch: 401/10000 || Loss: 0.7431344389915466\n",
      "--------------------------------------------------\n",
      "Validation || Epoch: 401 || Loss: 1.0416990193453701 || Accuracy: 0.5958395004272461 || F1-score: 0.2946432936752394\n",
      "Epoch: 501/10000 || Item: 0/85 || Loss: 0.720551073551178\n",
      "--------------------------------------------------\n",
      "##### Epoch: 501/10000 || Loss: 0.4752638339996338\n",
      "--------------------------------------------------\n",
      "Validation || Epoch: 501 || Loss: 1.0457149039615283 || Accuracy: 0.5958395004272461 || F1-score: 0.2946432936752394\n",
      "Epoch: 601/10000 || Item: 0/85 || Loss: 0.8500069379806519\n",
      "--------------------------------------------------\n",
      "##### Epoch: 601/10000 || Loss: 1.0879390239715576\n",
      "--------------------------------------------------\n",
      "Validation || Epoch: 601 || Loss: 1.0382095250216397 || Accuracy: 0.5958395004272461 || F1-score: 0.2946432936752394\n",
      "Epoch: 701/10000 || Item: 0/85 || Loss: 0.67674320936203\n",
      "--------------------------------------------------\n",
      "##### Epoch: 701/10000 || Loss: 0.5037963390350342\n",
      "--------------------------------------------------\n",
      "Validation || Epoch: 701 || Loss: 1.044572201642123 || Accuracy: 0.5958395004272461 || F1-score: 0.2946432936752394\n",
      "Epoch: 801/10000 || Item: 0/85 || Loss: 0.7061132192611694\n",
      "--------------------------------------------------\n",
      "##### Epoch: 801/10000 || Loss: 0.31935223937034607\n",
      "--------------------------------------------------\n",
      "Validation || Epoch: 801 || Loss: 1.0476408004760742 || Accuracy: 0.5973253846168518 || F1-score: 0.297558585048561\n",
      "Epoch: 901/10000 || Item: 0/85 || Loss: 0.8156043887138367\n",
      "--------------------------------------------------\n",
      "##### Epoch: 901/10000 || Loss: 0.6909360289573669\n",
      "--------------------------------------------------\n",
      "Validation || Epoch: 901 || Loss: 1.0518986745314165 || Accuracy: 0.5973253846168518 || F1-score: 0.297558585048561\n",
      "Epoch: 1001/10000 || Item: 0/85 || Loss: 0.8126872777938843\n",
      "--------------------------------------------------\n",
      "##### Epoch: 1001/10000 || Loss: 0.939073920249939\n",
      "--------------------------------------------------\n",
      "Validation || Epoch: 1001 || Loss: 1.039650391448628 || Accuracy: 0.5973253846168518 || F1-score: 0.297558585048561\n",
      "Epoch: 1101/10000 || Item: 0/85 || Loss: 0.7851057648658752\n",
      "--------------------------------------------------\n",
      "##### Epoch: 1101/10000 || Loss: 0.6680344343185425\n",
      "--------------------------------------------------\n",
      "Validation || Epoch: 1101 || Loss: 1.0472334731708874 || Accuracy: 0.5973253846168518 || F1-score: 0.297558585048561\n",
      "Epoch: 1201/10000 || Item: 0/85 || Loss: 0.8999869227409363\n",
      "--------------------------------------------------\n",
      "##### Epoch: 1201/10000 || Loss: 0.6274386048316956\n",
      "--------------------------------------------------\n",
      "Validation || Epoch: 1201 || Loss: 1.0455758571624756 || Accuracy: 0.5973253846168518 || F1-score: 0.297558585048561\n",
      "Epoch: 1301/10000 || Item: 0/85 || Loss: 0.6378813982009888\n",
      "--------------------------------------------------\n",
      "##### Epoch: 1301/10000 || Loss: 0.5754580497741699\n",
      "--------------------------------------------------\n",
      "Validation || Epoch: 1301 || Loss: 1.0453744422305713 || Accuracy: 0.5973253846168518 || F1-score: 0.297558585048561\n",
      "Epoch: 1401/10000 || Item: 0/85 || Loss: 0.7302572131156921\n",
      "--------------------------------------------------\n",
      "##### Epoch: 1401/10000 || Loss: 0.8464142680168152\n",
      "--------------------------------------------------\n",
      "Validation || Epoch: 1401 || Loss: 1.0469449433413418 || Accuracy: 0.5973253846168518 || F1-score: 0.297558585048561\n",
      "Epoch: 1501/10000 || Item: 0/85 || Loss: 0.5692943334579468\n",
      "--------------------------------------------------\n",
      "##### Epoch: 1501/10000 || Loss: 0.6440297365188599\n",
      "--------------------------------------------------\n",
      "Validation || Epoch: 1501 || Loss: 1.0356202017177234 || Accuracy: 0.5973253846168518 || F1-score: 0.297558585048561\n",
      "Epoch: 1601/10000 || Item: 0/85 || Loss: 0.6935449242591858\n",
      "--------------------------------------------------\n",
      "##### Epoch: 1601/10000 || Loss: 0.38476037979125977\n",
      "--------------------------------------------------\n",
      "Validation || Epoch: 1601 || Loss: 1.045200456272472 || Accuracy: 0.5973253846168518 || F1-score: 0.297558585048561\n",
      "Epoch: 1701/10000 || Item: 0/85 || Loss: 0.6277721524238586\n",
      "--------------------------------------------------\n",
      "##### Epoch: 1701/10000 || Loss: 0.31100165843963623\n",
      "--------------------------------------------------\n",
      "Validation || Epoch: 1701 || Loss: 1.0557962222532793 || Accuracy: 0.5973253846168518 || F1-score: 0.297558585048561\n",
      "Epoch: 1801/10000 || Item: 0/85 || Loss: 0.7260391712188721\n",
      "--------------------------------------------------\n",
      "##### Epoch: 1801/10000 || Loss: 1.324073314666748\n",
      "--------------------------------------------------\n",
      "Validation || Epoch: 1801 || Loss: 1.0543911998922175 || Accuracy: 0.5973253846168518 || F1-score: 0.297558585048561\n",
      "Epoch: 1901/10000 || Item: 0/85 || Loss: 0.8142526745796204\n",
      "--------------------------------------------------\n",
      "##### Epoch: 1901/10000 || Loss: 0.8015120029449463\n",
      "--------------------------------------------------\n",
      "Validation || Epoch: 1901 || Loss: 1.0461640195413069 || Accuracy: 0.5973253846168518 || F1-score: 0.297558585048561\n",
      "Epoch: 2001/10000 || Item: 0/85 || Loss: 0.5902289152145386\n",
      "--------------------------------------------------\n",
      "##### Epoch: 2001/10000 || Loss: 0.8222057223320007\n",
      "--------------------------------------------------\n",
      "Validation || Epoch: 2001 || Loss: 1.0530714880336414 || Accuracy: 0.5973253846168518 || F1-score: 0.297558585048561\n",
      "Epoch: 2101/10000 || Item: 0/85 || Loss: 0.7234140634536743\n",
      "--------------------------------------------------\n",
      "##### Epoch: 2101/10000 || Loss: 0.632175624370575\n",
      "--------------------------------------------------\n",
      "Validation || Epoch: 2101 || Loss: 1.0531732873483137 || Accuracy: 0.5973253846168518 || F1-score: 0.297558585048561\n",
      "Epoch: 2201/10000 || Item: 0/85 || Loss: 0.8143587708473206\n",
      "--------------------------------------------------\n",
      "##### Epoch: 2201/10000 || Loss: 0.5237874984741211\n",
      "--------------------------------------------------\n",
      "Validation || Epoch: 2201 || Loss: 1.0552978515625 || Accuracy: 0.5973253846168518 || F1-score: 0.297558585048561\n",
      "Epoch: 2301/10000 || Item: 0/85 || Loss: 0.7111881971359253\n",
      "--------------------------------------------------\n",
      "##### Epoch: 2301/10000 || Loss: 1.1347521543502808\n",
      "--------------------------------------------------\n",
      "Validation || Epoch: 2301 || Loss: 1.0304705067114397 || Accuracy: 0.5973253846168518 || F1-score: 0.297558585048561\n",
      "Epoch: 2401/10000 || Item: 0/85 || Loss: 0.7328231334686279\n",
      "--------------------------------------------------\n",
      "##### Epoch: 2401/10000 || Loss: 0.8000296354293823\n",
      "--------------------------------------------------\n",
      "Validation || Epoch: 2401 || Loss: 1.0398798476565967 || Accuracy: 0.5973253846168518 || F1-score: 0.297558585048561\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 2501/10000 || Item: 0/85 || Loss: 0.7218785881996155\n",
      "--------------------------------------------------\n",
      "##### Epoch: 2501/10000 || Loss: 0.8285083770751953\n",
      "--------------------------------------------------\n",
      "Validation || Epoch: 2501 || Loss: 1.0545342672954907 || Accuracy: 0.5973253846168518 || F1-score: 0.297558585048561\n",
      "Epoch: 2601/10000 || Item: 0/85 || Loss: 0.6840920448303223\n",
      "--------------------------------------------------\n",
      "##### Epoch: 2601/10000 || Loss: 0.23172909021377563\n",
      "--------------------------------------------------\n",
      "Validation || Epoch: 2601 || Loss: 1.0426749207756736 || Accuracy: 0.5973253846168518 || F1-score: 0.297558585048561\n",
      "Epoch: 2701/10000 || Item: 0/85 || Loss: 0.7298756241798401\n",
      "--------------------------------------------------\n",
      "##### Epoch: 2701/10000 || Loss: 0.25229018926620483\n",
      "--------------------------------------------------\n",
      "Validation || Epoch: 2701 || Loss: 1.0499002120711587 || Accuracy: 0.5973253846168518 || F1-score: 0.297558585048561\n",
      "Epoch: 2801/10000 || Item: 0/85 || Loss: 0.674339234828949\n",
      "--------------------------------------------------\n",
      "##### Epoch: 2801/10000 || Loss: 0.8099985122680664\n",
      "--------------------------------------------------\n",
      "Validation || Epoch: 2801 || Loss: 1.0565670078450984 || Accuracy: 0.5973253846168518 || F1-score: 0.297558585048561\n",
      "Epoch: 2901/10000 || Item: 0/85 || Loss: 0.7261624336242676\n",
      "--------------------------------------------------\n",
      "##### Epoch: 2901/10000 || Loss: 0.877582311630249\n",
      "--------------------------------------------------\n",
      "Validation || Epoch: 2901 || Loss: 1.0530114065517078 || Accuracy: 0.5973253846168518 || F1-score: 0.297558585048561\n",
      "Epoch: 3001/10000 || Item: 0/85 || Loss: 0.7678425312042236\n",
      "--------------------------------------------------\n",
      "##### Epoch: 3001/10000 || Loss: 0.24468377232551575\n",
      "--------------------------------------------------\n",
      "Validation || Epoch: 3001 || Loss: 1.0514233816753735 || Accuracy: 0.5973253846168518 || F1-score: 0.297558585048561\n",
      "Epoch: 3101/10000 || Item: 0/85 || Loss: 0.722261369228363\n",
      "--------------------------------------------------\n",
      "##### Epoch: 3101/10000 || Loss: 0.5698437690734863\n",
      "--------------------------------------------------\n",
      "Validation || Epoch: 3101 || Loss: 1.0584185827862134 || Accuracy: 0.5973253846168518 || F1-score: 0.297558585048561\n",
      "Epoch: 3201/10000 || Item: 0/85 || Loss: 0.6888555288314819\n",
      "--------------------------------------------------\n",
      "##### Epoch: 3201/10000 || Loss: 0.5478988885879517\n",
      "--------------------------------------------------\n",
      "Validation || Epoch: 3201 || Loss: 1.0542701862075112 || Accuracy: 0.5973253846168518 || F1-score: 0.297558585048561\n",
      "Epoch: 3301/10000 || Item: 0/85 || Loss: 0.6251853704452515\n",
      "--------------------------------------------------\n",
      "##### Epoch: 3301/10000 || Loss: 0.7353724837303162\n",
      "--------------------------------------------------\n",
      "Validation || Epoch: 3301 || Loss: 1.0604791207747026 || Accuracy: 0.5973253846168518 || F1-score: 0.297558585048561\n",
      "Epoch: 3401/10000 || Item: 0/85 || Loss: 0.7938744425773621\n",
      "--------------------------------------------------\n",
      "##### Epoch: 3401/10000 || Loss: 0.7845727205276489\n",
      "--------------------------------------------------\n",
      "Validation || Epoch: 3401 || Loss: 1.045058543031866 || Accuracy: 0.5973253846168518 || F1-score: 0.297558585048561\n",
      "Epoch: 3501/10000 || Item: 0/85 || Loss: 0.6024500727653503\n",
      "--------------------------------------------------\n",
      "##### Epoch: 3501/10000 || Loss: 0.7431971430778503\n",
      "--------------------------------------------------\n",
      "Validation || Epoch: 3501 || Loss: 1.0512201189994812 || Accuracy: 0.5973253846168518 || F1-score: 0.297558585048561\n",
      "Epoch: 3601/10000 || Item: 0/85 || Loss: 0.6155180931091309\n",
      "--------------------------------------------------\n",
      "##### Epoch: 3601/10000 || Loss: 0.9386842250823975\n",
      "--------------------------------------------------\n",
      "Validation || Epoch: 3601 || Loss: 1.04935945705934 || Accuracy: 0.5973253846168518 || F1-score: 0.297558585048561\n",
      "Epoch: 3701/10000 || Item: 0/85 || Loss: 0.6939562559127808\n",
      "--------------------------------------------------\n",
      "##### Epoch: 3701/10000 || Loss: 0.927262544631958\n",
      "--------------------------------------------------\n",
      "Validation || Epoch: 3701 || Loss: 1.0565711368214001 || Accuracy: 0.5973253846168518 || F1-score: 0.297558585048561\n",
      "Epoch: 3801/10000 || Item: 0/85 || Loss: 0.7250684499740601\n",
      "--------------------------------------------------\n",
      "##### Epoch: 3801/10000 || Loss: 0.5099630355834961\n",
      "--------------------------------------------------\n",
      "Validation || Epoch: 3801 || Loss: 1.0416779463941401 || Accuracy: 0.5973253846168518 || F1-score: 0.297558585048561\n",
      "Epoch: 3901/10000 || Item: 0/85 || Loss: 0.6485028266906738\n",
      "--------------------------------------------------\n",
      "##### Epoch: 3901/10000 || Loss: 0.4398355484008789\n",
      "--------------------------------------------------\n",
      "Validation || Epoch: 3901 || Loss: 1.0510683059692383 || Accuracy: 0.5973253846168518 || F1-score: 0.297558585048561\n",
      "Epoch: 4001/10000 || Item: 0/85 || Loss: 0.7812754511833191\n",
      "--------------------------------------------------\n",
      "##### Epoch: 4001/10000 || Loss: 0.3932898938655853\n",
      "--------------------------------------------------\n",
      "Validation || Epoch: 4001 || Loss: 1.0654177015477961 || Accuracy: 0.5958395004272461 || F1-score: 0.2969435344103881\n",
      "Early stopping at epoch 4011!\n",
      "Accuracy on dataset of size 672: 60.41666793823242 %.\n",
      "Average loss: 1.0449649745767766\n",
      "proportion of labels in prediction: [tensor(0.9152), tensor(0.0848), tensor(0.)]\n",
      "proportion of labels in data: [tensor(0.6235), tensor(0.2232), tensor(0.1533)]\n",
      "- f1: [0.75628627 0.14492754 0.        ]\n",
      "- f1 (average): 0.3004046010521496\n",
      "- accuracy: 0.6041666865348816\n",
      "\n",
      "********** hidden_dim: [100, 100, 100, 100]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/var/folders/l7/bnn1j6bs3bqfskq2jlq55yh80000gr/T/ipykernel_51169/2802342863.py:18: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  train, valid, test = split_dataset(x_data=torch.tensor(x_data).float(),\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "8866c695bb0147e68a62fc6ae1f00319",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/10000 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 1/10000 || Item: 0/85 || Loss: 1.0874892473220825\n",
      "--------------------------------------------------\n",
      "##### Epoch: 1/10000 || Loss: 1.041567325592041\n",
      "--------------------------------------------------\n",
      "Validation || Epoch: 1 || Loss: 1.0157562765208157 || Accuracy: 0.6225854158401489 || F1-score: 0.25579975579975583\n",
      "Early stopping at epoch 38!\n",
      "Accuracy on dataset of size 672: 59.6726188659668 %.\n",
      "Average loss: 1.2987231612205505\n",
      "proportion of labels in prediction: [tensor(0.8438), tensor(0.1280), tensor(0.0283)]\n",
      "proportion of labels in data: [tensor(0.6235), tensor(0.2232), tensor(0.1533)]\n",
      "- f1: [0.7464503  0.22033898 0.1147541 ]\n",
      "- f1 (average): 0.36051446189037933\n",
      "- accuracy: 0.5967261791229248\n",
      "\n",
      "********** hidden_dim: [100, 100, 100, 100, 100]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/var/folders/l7/bnn1j6bs3bqfskq2jlq55yh80000gr/T/ipykernel_51169/2802342863.py:18: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  train, valid, test = split_dataset(x_data=torch.tensor(x_data).float(),\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "144410478b8e4dacb48a556af36fa590",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/10000 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 1/10000 || Item: 0/85 || Loss: 1.0989830493927002\n",
      "--------------------------------------------------\n",
      "##### Epoch: 1/10000 || Loss: 1.0823333263397217\n",
      "--------------------------------------------------\n",
      "Validation || Epoch: 1 || Loss: 1.0345525308088823 || Accuracy: 0.6225854158401489 || F1-score: 0.25579975579975583\n",
      "Epoch: 101/10000 || Item: 0/85 || Loss: 0.7649714350700378\n",
      "--------------------------------------------------\n",
      "##### Epoch: 101/10000 || Loss: 0.8336163759231567\n",
      "--------------------------------------------------\n",
      "Validation || Epoch: 101 || Loss: 1.1429398655891418 || Accuracy: 0.5869241952896118 || F1-score: 0.2933159722222222\n",
      "Epoch: 201/10000 || Item: 0/85 || Loss: 0.681190013885498\n",
      "--------------------------------------------------\n",
      "##### Epoch: 201/10000 || Loss: 1.1246832609176636\n",
      "--------------------------------------------------\n",
      "Validation || Epoch: 201 || Loss: 1.1307478601282293 || Accuracy: 0.5869241952896118 || F1-score: 0.2933159722222222\n",
      "Epoch: 301/10000 || Item: 0/85 || Loss: 0.6670639514923096\n",
      "--------------------------------------------------\n",
      "##### Epoch: 301/10000 || Loss: 0.8996632099151611\n",
      "--------------------------------------------------\n",
      "Validation || Epoch: 301 || Loss: 1.141850926659324 || Accuracy: 0.5869241952896118 || F1-score: 0.2933159722222222\n",
      "Epoch: 401/10000 || Item: 0/85 || Loss: 0.6736330986022949\n",
      "--------------------------------------------------\n",
      "##### Epoch: 401/10000 || Loss: 0.9255297183990479\n",
      "--------------------------------------------------\n",
      "Validation || Epoch: 401 || Loss: 1.1490915688601406 || Accuracy: 0.5869241952896118 || F1-score: 0.2933159722222222\n",
      "Epoch: 501/10000 || Item: 0/85 || Loss: 0.8221954107284546\n",
      "--------------------------------------------------\n",
      "##### Epoch: 501/10000 || Loss: 1.1061217784881592\n",
      "--------------------------------------------------\n",
      "Validation || Epoch: 501 || Loss: 1.1199117519638755 || Accuracy: 0.5869241952896118 || F1-score: 0.2933159722222222\n",
      "Epoch: 601/10000 || Item: 0/85 || Loss: 0.6331446170806885\n",
      "--------------------------------------------------\n",
      "##### Epoch: 601/10000 || Loss: 0.3997304439544678\n",
      "--------------------------------------------------\n",
      "Validation || Epoch: 601 || Loss: 1.1317545012994246 || Accuracy: 0.5869241952896118 || F1-score: 0.2933159722222222\n",
      "Epoch: 701/10000 || Item: 0/85 || Loss: 0.7542043328285217\n",
      "--------------------------------------------------\n",
      "##### Epoch: 701/10000 || Loss: 0.8742457628250122\n",
      "--------------------------------------------------\n",
      "Validation || Epoch: 701 || Loss: 1.149196288802407 || Accuracy: 0.5869241952896118 || F1-score: 0.2933159722222222\n",
      "Epoch: 801/10000 || Item: 0/85 || Loss: 0.7312735915184021\n",
      "--------------------------------------------------\n",
      "##### Epoch: 801/10000 || Loss: 0.815049409866333\n",
      "--------------------------------------------------\n",
      "Validation || Epoch: 801 || Loss: 1.1285760077563198 || Accuracy: 0.5869241952896118 || F1-score: 0.2933159722222222\n",
      "Epoch: 901/10000 || Item: 0/85 || Loss: 0.7381253838539124\n",
      "--------------------------------------------------\n",
      "##### Epoch: 901/10000 || Loss: 0.7511359453201294\n",
      "--------------------------------------------------\n",
      "Validation || Epoch: 901 || Loss: 1.154028301889246 || Accuracy: 0.5869241952896118 || F1-score: 0.2933159722222222\n",
      "Early stopping at epoch 997!\n",
      "Accuracy on dataset of size 672: 60.119049072265625 %.\n",
      "Average loss: 1.0933474789966235\n",
      "proportion of labels in prediction: [tensor(0.9018), tensor(0.0982), tensor(0.)]\n",
      "proportion of labels in data: [tensor(0.6235), tensor(0.2232), tensor(0.1533)]\n",
      "- f1: [0.75707317 0.14814815 0.        ]\n",
      "- f1 (average): 0.3017404396266185\n",
      "- accuracy: 0.601190447807312\n"
     ]
    }
   ],
   "source": [
    "signature_history = obtain_signatures_history(sbert_768_embeddings,\n",
    "                                              path_specifics,\n",
    "                                              dimension,\n",
    "                                              sig_depth,\n",
    "                                              concatenate_current=False)\n",
    "print(f\"signature_history.shape = {signature_history.shape}\")\n",
    "for hidden_dim in hidden_dim_trials:\n",
    "    print(f\"\\n********** hidden_dim: {hidden_dim}\")\n",
    "    implement_ffn(x_data=signature_history,\n",
    "                  y_data=y_data,\n",
    "                  hidden_dim=hidden_dim,\n",
    "                  learning_rate=learning_rate,\n",
    "                  loss=loss)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7a22d5d7",
   "metadata": {},
   "source": [
    "## SBERT 384"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 200,
   "id": "92acd734",
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[INFO] Concatenating the embeddings to the dataframe...\n",
      "[INFO] - columns beginning with 'e' denote the full embddings.\n",
      "[INFO] - columns beginning with 'd' denote the dimension reduced embeddings.\n",
      "[INFO] Adding time feature columns into dataframe in `.df`.\n",
      "[INFO] Adding 'time_encoding' and feature...\n",
      "[INFO] Adding 'time_diff' and feature...\n",
      "[INFO] Adding 'timeline_index' feature...\n",
      "[INFO] Padding ids and storing in `.df_padded` and `.array_padded` attributes.\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "22cd298dd12041b2bc845799a18954f2",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/13551 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "signature_history.shape = torch.Size([6725, 1164])\n",
      "\n",
      "********** hidden_dim: [100]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/var/folders/l7/bnn1j6bs3bqfskq2jlq55yh80000gr/T/ipykernel_51169/2802342863.py:18: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  train, valid, test = split_dataset(x_data=torch.tensor(x_data).float(),\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "c420cb4357eb44a7b31dc359a406e404",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/10000 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 1/10000 || Item: 0/85 || Loss: 1.0510205030441284\n",
      "--------------------------------------------------\n",
      "##### Epoch: 1/10000 || Loss: 0.9339765310287476\n",
      "--------------------------------------------------\n",
      "Validation || Epoch: 1 || Loss: 0.9781227707862854 || Accuracy: 0.6225854158401489 || F1-score: 0.25579975579975583\n",
      "Early stopping at epoch 37!\n",
      "Accuracy on dataset of size 672: 68.45237731933594 %.\n",
      "Average loss: 0.8182277625257318\n",
      "proportion of labels in prediction: [tensor(0.6920), tensor(0.1786), tensor(0.1295)]\n",
      "proportion of labels in data: [tensor(0.6235), tensor(0.2232), tensor(0.1533)]\n",
      "- f1: [0.7918552  0.5037037  0.44210526]\n",
      "- f1 (average): 0.5792213901605027\n",
      "- accuracy: 0.6845238208770752\n",
      "\n",
      "********** hidden_dim: [100, 100]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/var/folders/l7/bnn1j6bs3bqfskq2jlq55yh80000gr/T/ipykernel_51169/2802342863.py:18: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  train, valid, test = split_dataset(x_data=torch.tensor(x_data).float(),\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "c4c0a1bdd1b0481ca05e414d8a7e3297",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/10000 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 1/10000 || Item: 0/85 || Loss: 1.093340516090393\n",
      "--------------------------------------------------\n",
      "##### Epoch: 1/10000 || Loss: 1.0354981422424316\n",
      "--------------------------------------------------\n",
      "Validation || Epoch: 1 || Loss: 1.0173125917261296 || Accuracy: 0.6225854158401489 || F1-score: 0.25579975579975583\n",
      "Early stopping at epoch 34!\n",
      "Accuracy on dataset of size 672: 68.1547622680664 %.\n",
      "Average loss: 0.9229160926558755\n",
      "proportion of labels in prediction: [tensor(0.6860), tensor(0.2024), tensor(0.1116)]\n",
      "proportion of labels in data: [tensor(0.6235), tensor(0.2232), tensor(0.1533)]\n",
      "- f1: [0.79318182 0.51048951 0.40449438]\n",
      "- f1 (average): 0.569388570231267\n",
      "- accuracy: 0.6815476417541504\n",
      "\n",
      "********** hidden_dim: [100, 100, 100]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/var/folders/l7/bnn1j6bs3bqfskq2jlq55yh80000gr/T/ipykernel_51169/2802342863.py:18: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  train, valid, test = split_dataset(x_data=torch.tensor(x_data).float(),\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "7a5edac67e9f47d4806d431103525387",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/10000 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 1/10000 || Item: 0/85 || Loss: 1.1014200448989868\n",
      "--------------------------------------------------\n",
      "##### Epoch: 1/10000 || Loss: 1.064431071281433\n",
      "--------------------------------------------------\n",
      "Validation || Epoch: 1 || Loss: 1.015446814623746 || Accuracy: 0.6225854158401489 || F1-score: 0.25579975579975583\n",
      "Early stopping at epoch 45!\n",
      "Accuracy on dataset of size 672: 64.73213958740234 %.\n",
      "Average loss: 0.9659875360402194\n",
      "proportion of labels in prediction: [tensor(0.6756), tensor(0.2872), tensor(0.0372)]\n",
      "proportion of labels in data: [tensor(0.6235), tensor(0.2232), tensor(0.1533)]\n",
      "- f1: [0.79266896 0.43731778 0.21875   ]\n",
      "- f1 (average): 0.48291224729132365\n",
      "- accuracy: 0.6473214030265808\n",
      "\n",
      "********** hidden_dim: [100, 100, 100, 100]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/var/folders/l7/bnn1j6bs3bqfskq2jlq55yh80000gr/T/ipykernel_51169/2802342863.py:18: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  train, valid, test = split_dataset(x_data=torch.tensor(x_data).float(),\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "11078b2d5ca74a96bf2e5fffa466552d",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/10000 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 1/10000 || Item: 0/85 || Loss: 1.1112401485443115\n",
      "--------------------------------------------------\n",
      "##### Epoch: 1/10000 || Loss: 1.052091121673584\n",
      "--------------------------------------------------\n",
      "Validation || Epoch: 1 || Loss: 1.0293906710364602 || Accuracy: 0.6225854158401489 || F1-score: 0.25579975579975583\n",
      "Early stopping at epoch 50!\n",
      "Accuracy on dataset of size 672: 63.69047546386719 %.\n",
      "Average loss: 1.0914304418997332\n",
      "proportion of labels in prediction: [tensor(0.6875), tensor(0.2768), tensor(0.0357)]\n",
      "proportion of labels in data: [tensor(0.6235), tensor(0.2232), tensor(0.1533)]\n",
      "- f1: [0.7877412  0.4047619  0.20472441]\n",
      "- f1 (average): 0.4657425057963101\n",
      "- accuracy: 0.636904776096344\n",
      "\n",
      "********** hidden_dim: [100, 100, 100, 100, 100]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/var/folders/l7/bnn1j6bs3bqfskq2jlq55yh80000gr/T/ipykernel_51169/2802342863.py:18: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  train, valid, test = split_dataset(x_data=torch.tensor(x_data).float(),\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "9e1dfd064dfa419f94eb6754ad4c25e3",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/10000 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 1/10000 || Item: 0/85 || Loss: 1.099615454673767\n",
      "--------------------------------------------------\n",
      "##### Epoch: 1/10000 || Loss: 1.083626389503479\n",
      "--------------------------------------------------\n",
      "Validation || Epoch: 1 || Loss: 1.0153438557278027 || Accuracy: 0.6225854158401489 || F1-score: 0.25579975579975583\n",
      "Early stopping at epoch 50!\n",
      "Accuracy on dataset of size 672: 63.83928680419922 %.\n",
      "Average loss: 1.0310841582038186\n",
      "proportion of labels in prediction: [tensor(0.6652), tensor(0.2827), tensor(0.0521)]\n",
      "proportion of labels in data: [tensor(0.6235), tensor(0.2232), tensor(0.1533)]\n",
      "- f1: [0.79214781 0.41176471 0.23188406]\n",
      "- f1 (average): 0.4785988566193287\n",
      "- accuracy: 0.6383928656578064\n"
     ]
    }
   ],
   "source": [
    "signature_history = obtain_signatures_history(sbert_384_embeddings, path_specifics, dimension, sig_depth)\n",
    "print(f\"signature_history.shape = {signature_history.shape}\")\n",
    "for hidden_dim in hidden_dim_trials:\n",
    "    print(f\"\\n********** hidden_dim: {hidden_dim}\")\n",
    "    implement_ffn(x_data=signature_history,\n",
    "                  y_data=y_data,\n",
    "                  hidden_dim=hidden_dim,\n",
    "                  learning_rate=learning_rate,\n",
    "                  loss=loss)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 201,
   "id": "4fb7de3e",
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[INFO] Concatenating the embeddings to the dataframe...\n",
      "[INFO] - columns beginning with 'e' denote the full embddings.\n",
      "[INFO] - columns beginning with 'd' denote the dimension reduced embeddings.\n",
      "[INFO] Adding time feature columns into dataframe in `.df`.\n",
      "[INFO] Adding 'time_encoding' and feature...\n",
      "[INFO] Adding 'time_diff' and feature...\n",
      "[INFO] Adding 'timeline_index' feature...\n",
      "[INFO] Padding ids and storing in `.df_padded` and `.array_padded` attributes.\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "79294ee5bac64870978e15ff66ff5c3c",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/13551 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "signature_history.shape = torch.Size([6725, 780])\n",
      "\n",
      "********** hidden_dim: [100]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/var/folders/l7/bnn1j6bs3bqfskq2jlq55yh80000gr/T/ipykernel_51169/2802342863.py:18: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  train, valid, test = split_dataset(x_data=torch.tensor(x_data).float(),\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "59e844cde5d249ad896d064c282cdc84",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/10000 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 1/10000 || Item: 0/85 || Loss: 1.1309925317764282\n",
      "--------------------------------------------------\n",
      "##### Epoch: 1/10000 || Loss: 1.0654724836349487\n",
      "--------------------------------------------------\n",
      "Validation || Epoch: 1 || Loss: 1.075578440319408 || Accuracy: 0.5884100794792175 || F1-score: 0.27091551821302323\n",
      "Early stopping at epoch 12!\n",
      "Accuracy on dataset of size 672: 62.35118865966797 %.\n",
      "Average loss: 0.9237872578881003\n",
      "proportion of labels in prediction: [tensor(1.), tensor(0.), tensor(0.)]\n",
      "proportion of labels in data: [tensor(0.6235), tensor(0.2232), tensor(0.1533)]\n",
      "- f1: [0.76810266 0.         0.        ]\n",
      "- f1 (average): 0.25603421937060805\n",
      "- accuracy: 0.6235119104385376\n",
      "\n",
      "********** hidden_dim: [100, 100]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/var/folders/l7/bnn1j6bs3bqfskq2jlq55yh80000gr/T/ipykernel_51169/2802342863.py:18: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  train, valid, test = split_dataset(x_data=torch.tensor(x_data).float(),\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "7835ff8e16ce4e5eb47f837422ac3163",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/10000 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 1/10000 || Item: 0/85 || Loss: 1.1385002136230469\n",
      "--------------------------------------------------\n",
      "##### Epoch: 1/10000 || Loss: 1.0628207921981812\n",
      "--------------------------------------------------\n",
      "Validation || Epoch: 1 || Loss: 1.0754418156363748 || Accuracy: 0.6225854158401489 || F1-score: 0.25579975579975583\n",
      "Early stopping at epoch 36!\n",
      "Accuracy on dataset of size 672: 61.16071319580078 %.\n",
      "Average loss: 0.9524058645421808\n",
      "proportion of labels in prediction: [tensor(0.9539), tensor(0.0387), tensor(0.0074)]\n",
      "proportion of labels in data: [tensor(0.6235), tensor(0.2232), tensor(0.1533)]\n",
      "- f1: [0.75849057 0.09090909 0.01851852]\n",
      "- f1 (average): 0.2893060584884484\n",
      "- accuracy: 0.6116071343421936\n",
      "\n",
      "********** hidden_dim: [100, 100, 100]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/var/folders/l7/bnn1j6bs3bqfskq2jlq55yh80000gr/T/ipykernel_51169/2802342863.py:18: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  train, valid, test = split_dataset(x_data=torch.tensor(x_data).float(),\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "e882869ed0ef4e348f0606b816724320",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/10000 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 1/10000 || Item: 0/85 || Loss: 1.0802196264266968\n",
      "--------------------------------------------------\n",
      "##### Epoch: 1/10000 || Loss: 1.0205280780792236\n",
      "--------------------------------------------------\n",
      "Validation || Epoch: 1 || Loss: 1.0158289670944214 || Accuracy: 0.6225854158401489 || F1-score: 0.25579975579975583\n",
      "Epoch: 101/10000 || Item: 0/85 || Loss: 0.6703686118125916\n",
      "--------------------------------------------------\n",
      "##### Epoch: 101/10000 || Loss: 0.40635591745376587\n",
      "--------------------------------------------------\n",
      "Validation || Epoch: 101 || Loss: 1.0329773263497786 || Accuracy: 0.6121842265129089 || F1-score: 0.3035511955052185\n",
      "Epoch: 201/10000 || Item: 0/85 || Loss: 0.7650904059410095\n",
      "--------------------------------------------------\n",
      "##### Epoch: 201/10000 || Loss: 0.2539656162261963\n",
      "--------------------------------------------------\n",
      "Validation || Epoch: 201 || Loss: 1.0534041036259045 || Accuracy: 0.6121842265129089 || F1-score: 0.3035511955052185\n",
      "Epoch: 301/10000 || Item: 0/85 || Loss: 0.8577815294265747\n",
      "--------------------------------------------------\n",
      "##### Epoch: 301/10000 || Loss: 0.6686550378799438\n",
      "--------------------------------------------------\n",
      "Validation || Epoch: 301 || Loss: 1.0414731773463162 || Accuracy: 0.6121842265129089 || F1-score: 0.3035511955052185\n",
      "Epoch: 401/10000 || Item: 0/85 || Loss: 0.8088697195053101\n",
      "--------------------------------------------------\n",
      "##### Epoch: 401/10000 || Loss: 0.4040028750896454\n",
      "--------------------------------------------------\n",
      "Validation || Epoch: 401 || Loss: 1.0282816615971653 || Accuracy: 0.6121842265129089 || F1-score: 0.3035511955052185\n",
      "Epoch: 501/10000 || Item: 0/85 || Loss: 0.7032424807548523\n",
      "--------------------------------------------------\n",
      "##### Epoch: 501/10000 || Loss: 0.781546950340271\n",
      "--------------------------------------------------\n",
      "Validation || Epoch: 501 || Loss: 1.0433303659612483 || Accuracy: 0.6121842265129089 || F1-score: 0.3035511955052185\n",
      "Epoch: 601/10000 || Item: 0/85 || Loss: 0.8792612552642822\n",
      "--------------------------------------------------\n",
      "##### Epoch: 601/10000 || Loss: 0.8538446426391602\n",
      "--------------------------------------------------\n",
      "Validation || Epoch: 601 || Loss: 1.042605990713293 || Accuracy: 0.6121842265129089 || F1-score: 0.3035511955052185\n",
      "Epoch: 701/10000 || Item: 0/85 || Loss: 0.691629946231842\n",
      "--------------------------------------------------\n",
      "##### Epoch: 701/10000 || Loss: 0.47936195135116577\n",
      "--------------------------------------------------\n",
      "Validation || Epoch: 701 || Loss: 1.0396194891496138 || Accuracy: 0.6121842265129089 || F1-score: 0.3035511955052185\n",
      "Epoch: 801/10000 || Item: 0/85 || Loss: 0.7166373133659363\n",
      "--------------------------------------------------\n",
      "##### Epoch: 801/10000 || Loss: 0.5291565656661987\n",
      "--------------------------------------------------\n",
      "Validation || Epoch: 801 || Loss: 1.0397986444559963 || Accuracy: 0.6121842265129089 || F1-score: 0.3035511955052185\n",
      "Epoch: 901/10000 || Item: 0/85 || Loss: 0.7624942660331726\n",
      "--------------------------------------------------\n",
      "##### Epoch: 901/10000 || Loss: 0.6794317960739136\n",
      "--------------------------------------------------\n",
      "Validation || Epoch: 901 || Loss: 1.0437820933081887 || Accuracy: 0.6121842265129089 || F1-score: 0.3035511955052185\n",
      "Epoch: 1001/10000 || Item: 0/85 || Loss: 0.8018772006034851\n",
      "--------------------------------------------------\n",
      "##### Epoch: 1001/10000 || Loss: 0.6394705176353455\n",
      "--------------------------------------------------\n",
      "Validation || Epoch: 1001 || Loss: 1.0376584042202344 || Accuracy: 0.6121842265129089 || F1-score: 0.3035511955052185\n",
      "Epoch: 1101/10000 || Item: 0/85 || Loss: 0.755102276802063\n",
      "--------------------------------------------------\n",
      "##### Epoch: 1101/10000 || Loss: 0.8238762617111206\n",
      "--------------------------------------------------\n",
      "Validation || Epoch: 1101 || Loss: 1.039155667478388 || Accuracy: 0.6121842265129089 || F1-score: 0.3035511955052185\n",
      "Epoch: 1201/10000 || Item: 0/85 || Loss: 0.7742464542388916\n",
      "--------------------------------------------------\n",
      "##### Epoch: 1201/10000 || Loss: 0.5695786476135254\n",
      "--------------------------------------------------\n",
      "Validation || Epoch: 1201 || Loss: 1.0350107929923318 || Accuracy: 0.6121842265129089 || F1-score: 0.3035511955052185\n",
      "Epoch: 1301/10000 || Item: 0/85 || Loss: 0.6456558108329773\n",
      "--------------------------------------------------\n",
      "##### Epoch: 1301/10000 || Loss: 0.5297935605049133\n",
      "--------------------------------------------------\n",
      "Validation || Epoch: 1301 || Loss: 1.0481699921868064 || Accuracy: 0.6121842265129089 || F1-score: 0.3035511955052185\n",
      "Epoch: 1401/10000 || Item: 0/85 || Loss: 0.7781500816345215\n",
      "--------------------------------------------------\n",
      "##### Epoch: 1401/10000 || Loss: 0.7771915793418884\n",
      "--------------------------------------------------\n",
      "Validation || Epoch: 1401 || Loss: 1.0440667271614075 || Accuracy: 0.6121842265129089 || F1-score: 0.3035511955052185\n",
      "Epoch: 1501/10000 || Item: 0/85 || Loss: 0.5717569589614868\n",
      "--------------------------------------------------\n",
      "##### Epoch: 1501/10000 || Loss: 0.6279369592666626\n",
      "--------------------------------------------------\n",
      "Validation || Epoch: 1501 || Loss: 1.03675730120052 || Accuracy: 0.6121842265129089 || F1-score: 0.3035511955052185\n",
      "Epoch: 1601/10000 || Item: 0/85 || Loss: 0.677112340927124\n",
      "--------------------------------------------------\n",
      "##### Epoch: 1601/10000 || Loss: 0.48243600130081177\n",
      "--------------------------------------------------\n",
      "Validation || Epoch: 1601 || Loss: 1.0402579415928235 || Accuracy: 0.6121842265129089 || F1-score: 0.3035511955052185\n",
      "Epoch: 1701/10000 || Item: 0/85 || Loss: 0.6036952137947083\n",
      "--------------------------------------------------\n",
      "##### Epoch: 1701/10000 || Loss: 0.34049350023269653\n",
      "--------------------------------------------------\n",
      "Validation || Epoch: 1701 || Loss: 1.0465830672870984 || Accuracy: 0.6121842265129089 || F1-score: 0.3035511955052185\n",
      "Epoch: 1801/10000 || Item: 0/85 || Loss: 0.7061054110527039\n",
      "--------------------------------------------------\n",
      "##### Epoch: 1801/10000 || Loss: 1.4854031801223755\n",
      "--------------------------------------------------\n",
      "Validation || Epoch: 1801 || Loss: 1.0528442859649658 || Accuracy: 0.6121842265129089 || F1-score: 0.3035511955052185\n",
      "Epoch: 1901/10000 || Item: 0/85 || Loss: 0.7772749662399292\n",
      "--------------------------------------------------\n",
      "##### Epoch: 1901/10000 || Loss: 1.0093204975128174\n",
      "--------------------------------------------------\n",
      "Validation || Epoch: 1901 || Loss: 1.0384135083718733 || Accuracy: 0.6121842265129089 || F1-score: 0.3035511955052185\n",
      "Epoch: 2001/10000 || Item: 0/85 || Loss: 0.6252080202102661\n",
      "--------------------------------------------------\n",
      "##### Epoch: 2001/10000 || Loss: 1.0060830116271973\n",
      "--------------------------------------------------\n",
      "Validation || Epoch: 2001 || Loss: 1.0323768312280828 || Accuracy: 0.6121842265129089 || F1-score: 0.3035511955052185\n",
      "Epoch: 2101/10000 || Item: 0/85 || Loss: 0.6958518028259277\n",
      "--------------------------------------------------\n",
      "##### Epoch: 2101/10000 || Loss: 0.7321773767471313\n",
      "--------------------------------------------------\n",
      "Validation || Epoch: 2101 || Loss: 1.0509000691500576 || Accuracy: 0.6121842265129089 || F1-score: 0.3035511955052185\n",
      "Epoch: 2201/10000 || Item: 0/85 || Loss: 0.8251916170120239\n",
      "--------------------------------------------------\n",
      "##### Epoch: 2201/10000 || Loss: 0.38101065158843994\n",
      "--------------------------------------------------\n",
      "Validation || Epoch: 2201 || Loss: 1.04849342324517 || Accuracy: 0.6121842265129089 || F1-score: 0.3035511955052185\n",
      "Epoch: 2301/10000 || Item: 0/85 || Loss: 0.7907506227493286\n",
      "--------------------------------------------------\n",
      "##### Epoch: 2301/10000 || Loss: 0.581000566482544\n",
      "--------------------------------------------------\n",
      "Validation || Epoch: 2301 || Loss: 1.0284584869037976 || Accuracy: 0.6121842265129089 || F1-score: 0.3035511955052185\n",
      "Early stopping at epoch 2383!\n",
      "Accuracy on dataset of size 672: 60.56547546386719 %.\n",
      "Average loss: 1.0035254630175503\n",
      "proportion of labels in prediction: [tensor(0.9286), tensor(0.0610), tensor(0.0104)]\n",
      "proportion of labels in data: [tensor(0.6235), tensor(0.2232), tensor(0.1533)]\n",
      "- f1: [0.7535954  0.13612565 0.01818182]\n",
      "- f1 (average): 0.30263429017425997\n",
      "- accuracy: 0.605654776096344\n",
      "\n",
      "********** hidden_dim: [100, 100, 100, 100]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/var/folders/l7/bnn1j6bs3bqfskq2jlq55yh80000gr/T/ipykernel_51169/2802342863.py:18: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  train, valid, test = split_dataset(x_data=torch.tensor(x_data).float(),\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "6a80812e8bce4c12aba1072529caf679",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/10000 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 1/10000 || Item: 0/85 || Loss: 1.08750581741333\n",
      "--------------------------------------------------\n",
      "##### Epoch: 1/10000 || Loss: 1.0394604206085205\n",
      "--------------------------------------------------\n",
      "Validation || Epoch: 1 || Loss: 1.0141970677809282 || Accuracy: 0.6225854158401489 || F1-score: 0.25579975579975583\n",
      "Epoch: 101/10000 || Item: 0/85 || Loss: 0.7286522388458252\n",
      "--------------------------------------------------\n",
      "##### Epoch: 101/10000 || Loss: 0.36709776520729065\n",
      "--------------------------------------------------\n",
      "Validation || Epoch: 101 || Loss: 1.1960249543190002 || Accuracy: 0.5854383111000061 || F1-score: 0.32956290998530163\n",
      "Epoch: 201/10000 || Item: 0/85 || Loss: 0.6445213556289673\n",
      "--------------------------------------------------\n",
      "##### Epoch: 201/10000 || Loss: 0.9375444650650024\n",
      "--------------------------------------------------\n",
      "Validation || Epoch: 201 || Loss: 1.1644412983547558 || Accuracy: 0.5854383111000061 || F1-score: 0.32956290998530163\n",
      "Early stopping at epoch 236!\n",
      "Accuracy on dataset of size 672: 58.630950927734375 %.\n",
      "Average loss: 1.1721110073002903\n",
      "proportion of labels in prediction: [tensor(0.8512), tensor(0.1042), tensor(0.0446)]\n",
      "proportion of labels in data: [tensor(0.6235), tensor(0.2232), tensor(0.1533)]\n",
      "- f1: [0.74672048 0.19090909 0.04511278]\n",
      "- f1 (average): 0.32758078574107036\n",
      "- accuracy: 0.586309552192688\n",
      "\n",
      "********** hidden_dim: [100, 100, 100, 100, 100]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/var/folders/l7/bnn1j6bs3bqfskq2jlq55yh80000gr/T/ipykernel_51169/2802342863.py:18: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  train, valid, test = split_dataset(x_data=torch.tensor(x_data).float(),\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "863dcfaf364c4f4ba07345b3c562c00b",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/10000 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 1/10000 || Item: 0/85 || Loss: 1.099061131477356\n",
      "--------------------------------------------------\n",
      "##### Epoch: 1/10000 || Loss: 1.0810621976852417\n",
      "--------------------------------------------------\n",
      "Validation || Epoch: 1 || Loss: 1.033886107531461 || Accuracy: 0.6225854158401489 || F1-score: 0.25579975579975583\n",
      "Early stopping at epoch 44!\n",
      "Accuracy on dataset of size 672: 59.52381134033203 %.\n",
      "Average loss: 1.0715742653066462\n",
      "proportion of labels in prediction: [tensor(0.9107), tensor(0.0625), tensor(0.0268)]\n",
      "proportion of labels in data: [tensor(0.6235), tensor(0.2232), tensor(0.1533)]\n",
      "- f1: [0.74490786 0.13541667 0.04958678]\n",
      "- f1 (average): 0.3099704333254064\n",
      "- accuracy: 0.5952380895614624\n"
     ]
    }
   ],
   "source": [
    "signature_history = obtain_signatures_history(sbert_384_embeddings,\n",
    "                                              path_specifics,\n",
    "                                              dimension,\n",
    "                                              sig_depth,\n",
    "                                              concatenate_current=False)\n",
    "print(f\"signature_history.shape = {signature_history.shape}\")\n",
    "for hidden_dim in hidden_dim_trials:\n",
    "    print(f\"\\n********** hidden_dim: {hidden_dim}\")\n",
    "    implement_ffn(x_data=signature_history,\n",
    "                  y_data=y_data,\n",
    "                  hidden_dim=hidden_dim,\n",
    "                  learning_rate=learning_rate,\n",
    "                  loss=loss)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "abb9891d",
   "metadata": {},
   "source": [
    "## Pretrained BERT"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b91d08b1",
   "metadata": {},
   "source": [
    "### Mean pooled"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 202,
   "id": "73fcb44a",
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[INFO] Concatenating the embeddings to the dataframe...\n",
      "[INFO] - columns beginning with 'e' denote the full embddings.\n",
      "[INFO] - columns beginning with 'd' denote the dimension reduced embeddings.\n",
      "[INFO] Adding time feature columns into dataframe in `.df`.\n",
      "[INFO] Adding 'time_encoding' and feature...\n",
      "[INFO] Adding 'time_diff' and feature...\n",
      "[INFO] Adding 'timeline_index' feature...\n",
      "[INFO] Padding ids and storing in `.df_padded` and `.array_padded` attributes.\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "2cc56f4891724c6588d778da5637072e",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/13551 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "signature_history.shape = torch.Size([6725, 1548])\n",
      "\n",
      "********** hidden_dim: [100]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/var/folders/l7/bnn1j6bs3bqfskq2jlq55yh80000gr/T/ipykernel_51169/2802342863.py:18: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  train, valid, test = split_dataset(x_data=torch.tensor(x_data).float(),\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "66b7155f9de841c495aca63dc7a05ad1",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/10000 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 1/10000 || Item: 0/85 || Loss: 12.36815357208252\n",
      "--------------------------------------------------\n",
      "##### Epoch: 1/10000 || Loss: 4.970185279846191\n",
      "--------------------------------------------------\n",
      "Validation || Epoch: 1 || Loss: 3.070787104693326 || Accuracy: 0.5512629747390747 || F1-score: 0.34108076344111987\n",
      "Early stopping at epoch 59!\n",
      "Accuracy on dataset of size 672: 61.755950927734375 %.\n",
      "Average loss: 1.7640220468694514\n",
      "proportion of labels in prediction: [tensor(0.7857), tensor(0.1741), tensor(0.0402)]\n",
      "proportion of labels in data: [tensor(0.6235), tensor(0.2232), tensor(0.1533)]\n",
      "- f1: [0.75395987 0.33707865 0.2       ]\n",
      "- f1 (average): 0.4303461749898161\n",
      "- accuracy: 0.617559552192688\n",
      "\n",
      "********** hidden_dim: [100, 100]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/var/folders/l7/bnn1j6bs3bqfskq2jlq55yh80000gr/T/ipykernel_51169/2802342863.py:18: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  train, valid, test = split_dataset(x_data=torch.tensor(x_data).float(),\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "b7408d7423a840ed91fa970afa3cc1e7",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/10000 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 1/10000 || Item: 0/85 || Loss: 2.2733423709869385\n",
      "--------------------------------------------------\n",
      "##### Epoch: 1/10000 || Loss: 3.630249500274658\n",
      "--------------------------------------------------\n",
      "Validation || Epoch: 1 || Loss: 1.3257284923033281 || Accuracy: 0.5765230059623718 || F1-score: 0.34099252887105136\n",
      "Early stopping at epoch 33!\n",
      "Accuracy on dataset of size 672: 61.755950927734375 %.\n",
      "Average loss: 1.2828571091998706\n",
      "proportion of labels in prediction: [tensor(0.7917), tensor(0.1518), tensor(0.0565)]\n",
      "proportion of labels in data: [tensor(0.6235), tensor(0.2232), tensor(0.1533)]\n",
      "- f1: [0.75499474 0.34920635 0.17021277]\n",
      "- f1 (average): 0.42480461918008067\n",
      "- accuracy: 0.617559552192688\n",
      "\n",
      "********** hidden_dim: [100, 100, 100]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/var/folders/l7/bnn1j6bs3bqfskq2jlq55yh80000gr/T/ipykernel_51169/2802342863.py:18: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  train, valid, test = split_dataset(x_data=torch.tensor(x_data).float(),\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "aef57ef014b74fbbb32378195917e80e",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/10000 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 1/10000 || Item: 0/85 || Loss: 1.4547653198242188\n",
      "--------------------------------------------------\n",
      "##### Epoch: 1/10000 || Loss: 0.8083280324935913\n",
      "--------------------------------------------------\n",
      "Validation || Epoch: 1 || Loss: 1.0537812818180432 || Accuracy: 0.5943536162376404 || F1-score: 0.29167526009441314\n",
      "Early stopping at epoch 28!\n",
      "Accuracy on dataset of size 672: 63.54166793823242 %.\n",
      "Average loss: 1.2546936652877114\n",
      "proportion of labels in prediction: [tensor(0.8080), tensor(0.1399), tensor(0.0521)]\n",
      "proportion of labels in data: [tensor(0.6235), tensor(0.2232), tensor(0.1533)]\n",
      "- f1: [0.76923077 0.36065574 0.1884058 ]\n",
      "- f1 (average): 0.4394307680123788\n",
      "- accuracy: 0.6354166865348816\n",
      "\n",
      "********** hidden_dim: [100, 100, 100, 100]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/var/folders/l7/bnn1j6bs3bqfskq2jlq55yh80000gr/T/ipykernel_51169/2802342863.py:18: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  train, valid, test = split_dataset(x_data=torch.tensor(x_data).float(),\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "36355ecd635f4a679c5c7d08d9601a95",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/10000 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 1/10000 || Item: 0/85 || Loss: 1.1313300132751465\n",
      "--------------------------------------------------\n",
      "##### Epoch: 1/10000 || Loss: 0.8110309839248657\n",
      "--------------------------------------------------\n",
      "Validation || Epoch: 1 || Loss: 0.9856763482093811 || Accuracy: 0.6210995316505432 || F1-score: 0.25542315918117936\n",
      "Early stopping at epoch 30!\n",
      "Accuracy on dataset of size 672: 61.30952453613281 %.\n",
      "Average loss: 1.539837192405354\n",
      "proportion of labels in prediction: [tensor(0.7232), tensor(0.2173), tensor(0.0595)]\n",
      "proportion of labels in data: [tensor(0.6235), tensor(0.2232), tensor(0.1533)]\n",
      "- f1: [0.7558011  0.35810811 0.23776224]\n",
      "- f1 (average): 0.45055715028090715\n",
      "- accuracy: 0.613095223903656\n",
      "\n",
      "********** hidden_dim: [100, 100, 100, 100, 100]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/var/folders/l7/bnn1j6bs3bqfskq2jlq55yh80000gr/T/ipykernel_51169/2802342863.py:18: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  train, valid, test = split_dataset(x_data=torch.tensor(x_data).float(),\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "7fa80ce5e53e4c0785682e28ce4865d2",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/10000 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 1/10000 || Item: 0/85 || Loss: 0.9986205697059631\n",
      "--------------------------------------------------\n",
      "##### Epoch: 1/10000 || Loss: 0.821330189704895\n",
      "--------------------------------------------------\n",
      "Validation || Epoch: 1 || Loss: 0.9696343107657 || Accuracy: 0.6225854158401489 || F1-score: 0.25579975579975583\n",
      "Early stopping at epoch 27!\n",
      "Accuracy on dataset of size 672: 62.5 %.\n",
      "Average loss: 1.586189324205572\n",
      "proportion of labels in prediction: [tensor(0.7128), tensor(0.2039), tensor(0.0833)]\n",
      "proportion of labels in data: [tensor(0.6235), tensor(0.2232), tensor(0.1533)]\n",
      "- f1: [0.75723831 0.3902439  0.30188679]\n",
      "- f1 (average): 0.48312300074717357\n",
      "- accuracy: 0.625\n"
     ]
    }
   ],
   "source": [
    "signature_history = obtain_signatures_history(pooled_mean_pretrained, path_specifics, dimension, sig_depth)\n",
    "print(f\"signature_history.shape = {signature_history.shape}\")\n",
    "for hidden_dim in hidden_dim_trials:\n",
    "    print(f\"\\n********** hidden_dim: {hidden_dim}\")\n",
    "    implement_ffn(x_data=signature_history,\n",
    "                  y_data=y_data,\n",
    "                  hidden_dim=hidden_dim,\n",
    "                  learning_rate=learning_rate,\n",
    "                  loss=loss)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 203,
   "id": "187feeb8",
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[INFO] Concatenating the embeddings to the dataframe...\n",
      "[INFO] - columns beginning with 'e' denote the full embddings.\n",
      "[INFO] - columns beginning with 'd' denote the dimension reduced embeddings.\n",
      "[INFO] Adding time feature columns into dataframe in `.df`.\n",
      "[INFO] Adding 'time_encoding' and feature...\n",
      "[INFO] Adding 'time_diff' and feature...\n",
      "[INFO] Adding 'timeline_index' feature...\n",
      "[INFO] Padding ids and storing in `.df_padded` and `.array_padded` attributes.\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "2009c4ad28bf4b9fb1f1d34a02824ffd",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/13551 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "signature_history.shape = torch.Size([6725, 780])\n",
      "\n",
      "********** hidden_dim: [100]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/var/folders/l7/bnn1j6bs3bqfskq2jlq55yh80000gr/T/ipykernel_51169/2802342863.py:18: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  train, valid, test = split_dataset(x_data=torch.tensor(x_data).float(),\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "97dee6bdcee643ccb9a4590f205f0f2c",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/10000 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 1/10000 || Item: 0/85 || Loss: 10.014762878417969\n",
      "--------------------------------------------------\n",
      "##### Epoch: 1/10000 || Loss: 3.304849863052368\n",
      "--------------------------------------------------\n",
      "Validation || Epoch: 1 || Loss: 4.3514087200164795 || Accuracy: 0.4591381847858429 || F1-score: 0.2953730684985743\n",
      "Early stopping at epoch 19!\n",
      "Accuracy on dataset of size 672: 58.03571319580078 %.\n",
      "Average loss: 1.9879371361298994\n",
      "proportion of labels in prediction: [tensor(0.8080), tensor(0.1324), tensor(0.0595)]\n",
      "proportion of labels in data: [tensor(0.6235), tensor(0.2232), tensor(0.1533)]\n",
      "- f1: [0.73596674 0.23430962 0.11188811]\n",
      "- f1 (average): 0.3607214904286034\n",
      "- accuracy: 0.5803571343421936\n",
      "\n",
      "********** hidden_dim: [100, 100]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/var/folders/l7/bnn1j6bs3bqfskq2jlq55yh80000gr/T/ipykernel_51169/2802342863.py:18: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  train, valid, test = split_dataset(x_data=torch.tensor(x_data).float(),\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "3ea8a0daf14a46bcaef2fa0630c8c01c",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/10000 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 1/10000 || Item: 0/85 || Loss: 2.8463900089263916\n",
      "--------------------------------------------------\n",
      "##### Epoch: 1/10000 || Loss: 0.8160141110420227\n",
      "--------------------------------------------------\n",
      "Validation || Epoch: 1 || Loss: 1.5734508362683384 || Accuracy: 0.528974711894989 || F1-score: 0.3664071715027129\n",
      "Early stopping at epoch 13!\n",
      "Accuracy on dataset of size 672: 56.994049072265625 %.\n",
      "Average loss: 1.2242309938777576\n",
      "proportion of labels in prediction: [tensor(0.8557), tensor(0.1027), tensor(0.0417)]\n",
      "proportion of labels in data: [tensor(0.6235), tensor(0.2232), tensor(0.1533)]\n",
      "- f1: [0.722334   0.14611872 0.1221374 ]\n",
      "- f1 (average): 0.33019671002182827\n",
      "- accuracy: 0.569940447807312\n",
      "\n",
      "********** hidden_dim: [100, 100, 100]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/var/folders/l7/bnn1j6bs3bqfskq2jlq55yh80000gr/T/ipykernel_51169/2802342863.py:18: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  train, valid, test = split_dataset(x_data=torch.tensor(x_data).float(),\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "2322680e2e25460693c99f70f17a4396",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/10000 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 1/10000 || Item: 0/85 || Loss: 1.8513818979263306\n",
      "--------------------------------------------------\n",
      "##### Epoch: 1/10000 || Loss: 1.2975270748138428\n",
      "--------------------------------------------------\n",
      "Validation || Epoch: 1 || Loss: 1.1273438117720864 || Accuracy: 0.5720653533935547 || F1-score: 0.3091042633090347\n",
      "Early stopping at epoch 35!\n",
      "Accuracy on dataset of size 672: 58.92856979370117 %.\n",
      "Average loss: 1.1692784970456904\n",
      "proportion of labels in prediction: [tensor(0.8676), tensor(0.0818), tensor(0.0506)]\n",
      "proportion of labels in data: [tensor(0.6235), tensor(0.2232), tensor(0.1533)]\n",
      "- f1: [0.73852295 0.16585366 0.13138686]\n",
      "- f1 (average): 0.3452544913140901\n",
      "- accuracy: 0.5892857313156128\n",
      "\n",
      "********** hidden_dim: [100, 100, 100, 100]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/var/folders/l7/bnn1j6bs3bqfskq2jlq55yh80000gr/T/ipykernel_51169/2802342863.py:18: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  train, valid, test = split_dataset(x_data=torch.tensor(x_data).float(),\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "0d25859e360f4e6aa60b9056894b7835",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/10000 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 1/10000 || Item: 0/85 || Loss: 1.0843513011932373\n",
      "--------------------------------------------------\n",
      "##### Epoch: 1/10000 || Loss: 0.8570678234100342\n",
      "--------------------------------------------------\n",
      "Validation || Epoch: 1 || Loss: 0.9876446398821744 || Accuracy: 0.6240713000297546 || F1-score: 0.2601005307743682\n",
      "Early stopping at epoch 25!\n",
      "Accuracy on dataset of size 672: 58.92856979370117 %.\n",
      "Average loss: 1.4376066381281072\n",
      "proportion of labels in prediction: [tensor(0.8229), tensor(0.1161), tensor(0.0610)]\n",
      "proportion of labels in data: [tensor(0.6235), tensor(0.2232), tensor(0.1533)]\n",
      "- f1: [0.7345679  0.23684211 0.16666667]\n",
      "- f1 (average): 0.3793588910547974\n",
      "- accuracy: 0.5892857313156128\n",
      "\n",
      "********** hidden_dim: [100, 100, 100, 100, 100]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/var/folders/l7/bnn1j6bs3bqfskq2jlq55yh80000gr/T/ipykernel_51169/2802342863.py:18: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  train, valid, test = split_dataset(x_data=torch.tensor(x_data).float(),\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "9897e1fada374cb3aeeace49c37d0dcd",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/10000 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 1/10000 || Item: 0/85 || Loss: 1.082446575164795\n",
      "--------------------------------------------------\n",
      "##### Epoch: 1/10000 || Loss: 0.7274391651153564\n",
      "--------------------------------------------------\n",
      "Validation || Epoch: 1 || Loss: 0.9836958755146373 || Accuracy: 0.6225854158401489 || F1-score: 0.25579975579975583\n",
      "Early stopping at epoch 34!\n",
      "Accuracy on dataset of size 672: 58.33333206176758 %.\n",
      "Average loss: 1.7019806991923938\n",
      "proportion of labels in prediction: [tensor(0.7976), tensor(0.1577), tensor(0.0446)]\n",
      "proportion of labels in data: [tensor(0.6235), tensor(0.2232), tensor(0.1533)]\n",
      "- f1: [0.72670157 0.296875   0.10526316]\n",
      "- f1 (average): 0.3762799095251217\n",
      "- accuracy: 0.5833333134651184\n"
     ]
    }
   ],
   "source": [
    "signature_history = obtain_signatures_history(pooled_mean_pretrained,\n",
    "                                              path_specifics,\n",
    "                                              dimension,\n",
    "                                              sig_depth,\n",
    "                                              concatenate_current=False)\n",
    "print(f\"signature_history.shape = {signature_history.shape}\")\n",
    "for hidden_dim in hidden_dim_trials:\n",
    "    print(f\"\\n********** hidden_dim: {hidden_dim}\")\n",
    "    implement_ffn(x_data=signature_history,\n",
    "                  y_data=y_data,\n",
    "                  hidden_dim=hidden_dim,\n",
    "                  learning_rate=learning_rate,\n",
    "                  loss=loss)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "724d9196",
   "metadata": {},
   "source": [
    "### Max pooled"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 204,
   "id": "e4127c04",
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[INFO] Concatenating the embeddings to the dataframe...\n",
      "[INFO] - columns beginning with 'e' denote the full embddings.\n",
      "[INFO] - columns beginning with 'd' denote the dimension reduced embeddings.\n",
      "[INFO] Adding time feature columns into dataframe in `.df`.\n",
      "[INFO] Adding 'time_encoding' and feature...\n",
      "[INFO] Adding 'time_diff' and feature...\n",
      "[INFO] Adding 'timeline_index' feature...\n",
      "[INFO] Padding ids and storing in `.df_padded` and `.array_padded` attributes.\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "10c364f615ba41a786abfe2150fe388c",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/13551 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "signature_history.shape = torch.Size([6725, 1548])\n",
      "\n",
      "********** hidden_dim: [100]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/var/folders/l7/bnn1j6bs3bqfskq2jlq55yh80000gr/T/ipykernel_51169/2802342863.py:18: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  train, valid, test = split_dataset(x_data=torch.tensor(x_data).float(),\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "25c1b1a55124484087e6bc010d2a5aa0",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/10000 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 1/10000 || Item: 0/85 || Loss: 41.86736297607422\n",
      "--------------------------------------------------\n",
      "##### Epoch: 1/10000 || Loss: 0.32370734214782715\n",
      "--------------------------------------------------\n",
      "Validation || Epoch: 1 || Loss: 10.394998983903365 || Accuracy: 0.5319464802742004 || F1-score: 0.34935121774930217\n",
      "Early stopping at epoch 26!\n",
      "Accuracy on dataset of size 672: 57.14285659790039 %.\n",
      "Average loss: 4.556642554023049\n",
      "proportion of labels in prediction: [tensor(0.7857), tensor(0.1652), tensor(0.0491)]\n",
      "proportion of labels in data: [tensor(0.6235), tensor(0.2232), tensor(0.1533)]\n",
      "- f1: [0.71805702 0.2835249  0.10294118]\n",
      "- f1 (average): 0.36817436762014605\n",
      "- accuracy: 0.5714285969734192\n",
      "\n",
      "********** hidden_dim: [100, 100]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/var/folders/l7/bnn1j6bs3bqfskq2jlq55yh80000gr/T/ipykernel_51169/2802342863.py:18: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  train, valid, test = split_dataset(x_data=torch.tensor(x_data).float(),\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "f63d837859874651b913b7e7b96fe339",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/10000 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 1/10000 || Item: 0/85 || Loss: 10.795247077941895\n",
      "--------------------------------------------------\n",
      "##### Epoch: 1/10000 || Loss: 1.251486897468567\n",
      "--------------------------------------------------\n",
      "Validation || Epoch: 1 || Loss: 3.5041382096030493 || Accuracy: 0.4962852895259857 || F1-score: 0.3553498062472953\n",
      "Early stopping at epoch 47!\n",
      "Accuracy on dataset of size 672: 57.58928680419922 %.\n",
      "Average loss: 1.7531447302211414\n",
      "proportion of labels in prediction: [tensor(0.7872), tensor(0.1726), tensor(0.0402)]\n",
      "proportion of labels in data: [tensor(0.6235), tensor(0.2232), tensor(0.1533)]\n",
      "- f1: [0.72151899 0.27067669 0.13846154]\n",
      "- f1 (average): 0.37688573917754464\n",
      "- accuracy: 0.5758928656578064\n",
      "\n",
      "********** hidden_dim: [100, 100, 100]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/var/folders/l7/bnn1j6bs3bqfskq2jlq55yh80000gr/T/ipykernel_51169/2802342863.py:18: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  train, valid, test = split_dataset(x_data=torch.tensor(x_data).float(),\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "581d6c53b3b346bf9a3babfb4e8634d9",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/10000 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 1/10000 || Item: 0/85 || Loss: 4.3066487312316895\n",
      "--------------------------------------------------\n",
      "##### Epoch: 1/10000 || Loss: 1.1174490451812744\n",
      "--------------------------------------------------\n",
      "Validation || Epoch: 1 || Loss: 1.5548003803599963 || Accuracy: 0.5720653533935547 || F1-score: 0.31359240471312305\n",
      "Early stopping at epoch 17!\n",
      "Accuracy on dataset of size 672: 61.011905670166016 %.\n",
      "Average loss: 1.147129405628551\n",
      "proportion of labels in prediction: [tensor(0.8973), tensor(0.0908), tensor(0.0119)]\n",
      "proportion of labels in data: [tensor(0.6235), tensor(0.2232), tensor(0.1533)]\n",
      "- f1: [0.7592955  0.19905213 0.01801802]\n",
      "- f1 (average): 0.3254552165803221\n",
      "- accuracy: 0.6101190447807312\n",
      "\n",
      "********** hidden_dim: [100, 100, 100, 100]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/var/folders/l7/bnn1j6bs3bqfskq2jlq55yh80000gr/T/ipykernel_51169/2802342863.py:18: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  train, valid, test = split_dataset(x_data=torch.tensor(x_data).float(),\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "3538492af4fe4c5ea3a7d1ff8eda519e",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/10000 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 1/10000 || Item: 0/85 || Loss: 2.816965341567993\n",
      "--------------------------------------------------\n",
      "##### Epoch: 1/10000 || Loss: 0.8566218614578247\n",
      "--------------------------------------------------\n",
      "Validation || Epoch: 1 || Loss: 1.0994054783474316 || Accuracy: 0.5780088901519775 || F1-score: 0.28734479295882803\n",
      "Early stopping at epoch 39!\n",
      "Accuracy on dataset of size 672: 60.119049072265625 %.\n",
      "Average loss: 1.2287907871333035\n",
      "proportion of labels in prediction: [tensor(0.8467), tensor(0.1295), tensor(0.0238)]\n",
      "proportion of labels in data: [tensor(0.6235), tensor(0.2232), tensor(0.1533)]\n",
      "- f1: [0.75303644 0.23628692 0.06722689]\n",
      "- f1 (average): 0.3521834159448299\n",
      "- accuracy: 0.601190447807312\n",
      "\n",
      "********** hidden_dim: [100, 100, 100, 100, 100]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/var/folders/l7/bnn1j6bs3bqfskq2jlq55yh80000gr/T/ipykernel_51169/2802342863.py:18: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  train, valid, test = split_dataset(x_data=torch.tensor(x_data).float(),\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "a3c9395b7f214a2aaf8eabcfc4c4152d",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/10000 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 1/10000 || Item: 0/85 || Loss: 1.064578652381897\n",
      "--------------------------------------------------\n",
      "##### Epoch: 1/10000 || Loss: 0.8209261894226074\n",
      "--------------------------------------------------\n",
      "Validation || Epoch: 1 || Loss: 0.9802968881346963 || Accuracy: 0.6210995316505432 || F1-score: 0.25542315918117936\n",
      "Epoch: 101/10000 || Item: 0/85 || Loss: 0.42258596420288086\n",
      "--------------------------------------------------\n",
      "##### Epoch: 101/10000 || Loss: 1.0013890266418457\n",
      "--------------------------------------------------\n",
      "Validation || Epoch: 101 || Loss: 1.4297857176173816 || Accuracy: 0.5988112688064575 || F1-score: 0.41115125800543234\n",
      "Epoch: 201/10000 || Item: 0/85 || Loss: 0.44800621271133423\n",
      "--------------------------------------------------\n",
      "##### Epoch: 201/10000 || Loss: 0.4109724164009094\n",
      "--------------------------------------------------\n",
      "Validation || Epoch: 201 || Loss: 1.4138996601104736 || Accuracy: 0.6002971529960632 || F1-score: 0.4137447070634401\n",
      "Early stopping at epoch 222!\n",
      "Accuracy on dataset of size 672: 58.779762268066406 %.\n",
      "Average loss: 1.77183706110174\n",
      "proportion of labels in prediction: [tensor(0.8274), tensor(0.1280), tensor(0.0446)]\n",
      "proportion of labels in data: [tensor(0.6235), tensor(0.2232), tensor(0.1533)]\n",
      "- f1: [0.73846154 0.24576271 0.09022556]\n",
      "- f1 (average): 0.35814993807857315\n",
      "- accuracy: 0.5877976417541504\n"
     ]
    }
   ],
   "source": [
    "signature_history = obtain_signatures_history(pooled_max_pretrained, path_specifics, dimension, sig_depth)\n",
    "print(f\"signature_history.shape = {signature_history.shape}\")\n",
    "for hidden_dim in hidden_dim_trials:\n",
    "    print(f\"\\n********** hidden_dim: {hidden_dim}\")\n",
    "    implement_ffn(x_data=signature_history,\n",
    "                  y_data=y_data,\n",
    "                  hidden_dim=hidden_dim,\n",
    "                  learning_rate=learning_rate,\n",
    "                  loss=loss)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 205,
   "id": "6514d038",
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[INFO] Concatenating the embeddings to the dataframe...\n",
      "[INFO] - columns beginning with 'e' denote the full embddings.\n",
      "[INFO] - columns beginning with 'd' denote the dimension reduced embeddings.\n",
      "[INFO] Adding time feature columns into dataframe in `.df`.\n",
      "[INFO] Adding 'time_encoding' and feature...\n",
      "[INFO] Adding 'time_diff' and feature...\n",
      "[INFO] Adding 'timeline_index' feature...\n",
      "[INFO] Padding ids and storing in `.df_padded` and `.array_padded` attributes.\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "bb73ebef8b39497eab1bf44324b0e2bc",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/13551 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "signature_history.shape = torch.Size([6725, 780])\n",
      "\n",
      "********** hidden_dim: [100]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/var/folders/l7/bnn1j6bs3bqfskq2jlq55yh80000gr/T/ipykernel_51169/2802342863.py:18: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  train, valid, test = split_dataset(x_data=torch.tensor(x_data).float(),\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "bc1e623278cd41aca768d014ac9cc015",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/10000 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 1/10000 || Item: 0/85 || Loss: 43.17559051513672\n",
      "--------------------------------------------------\n",
      "##### Epoch: 1/10000 || Loss: 9.364212036132812\n",
      "--------------------------------------------------\n",
      "Validation || Epoch: 1 || Loss: 15.230800888755105 || Accuracy: 0.44279345870018005 || F1-score: 0.3035218237972311\n",
      "Early stopping at epoch 51!\n",
      "Accuracy on dataset of size 672: 56.994049072265625 %.\n",
      "Average loss: 4.35618029941212\n",
      "proportion of labels in prediction: [tensor(0.7708), tensor(0.1607), tensor(0.0685)]\n",
      "proportion of labels in data: [tensor(0.6235), tensor(0.2232), tensor(0.1533)]\n",
      "- f1: [0.71291355 0.29457364 0.14765101]\n",
      "- f1 (average): 0.385046068005891\n",
      "- accuracy: 0.569940447807312\n",
      "\n",
      "********** hidden_dim: [100, 100]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/var/folders/l7/bnn1j6bs3bqfskq2jlq55yh80000gr/T/ipykernel_51169/2802342863.py:18: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  train, valid, test = split_dataset(x_data=torch.tensor(x_data).float(),\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "00153846b69242d09f828aec2fbe05ef",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/10000 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 1/10000 || Item: 0/85 || Loss: 13.599725723266602\n",
      "--------------------------------------------------\n",
      "##### Epoch: 1/10000 || Loss: 1.0887997150421143\n",
      "--------------------------------------------------\n",
      "Validation || Epoch: 1 || Loss: 4.617391954768788 || Accuracy: 0.48439821600914 || F1-score: 0.32343614258256476\n",
      "Early stopping at epoch 39!\n",
      "Accuracy on dataset of size 672: 59.52381134033203 %.\n",
      "Average loss: 1.5854438705877825\n",
      "proportion of labels in prediction: [tensor(0.8170), tensor(0.1205), tensor(0.0625)]\n",
      "proportion of labels in data: [tensor(0.6235), tensor(0.2232), tensor(0.1533)]\n",
      "- f1: [0.73966942 0.25974026 0.16551724]\n",
      "- f1 (average): 0.3883089742023911\n",
      "- accuracy: 0.5952380895614624\n",
      "\n",
      "********** hidden_dim: [100, 100, 100]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/var/folders/l7/bnn1j6bs3bqfskq2jlq55yh80000gr/T/ipykernel_51169/2802342863.py:18: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  train, valid, test = split_dataset(x_data=torch.tensor(x_data).float(),\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "0bc6b88631234c3ba0f35ce0e7efad68",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/10000 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 1/10000 || Item: 0/85 || Loss: 5.205721378326416\n",
      "--------------------------------------------------\n",
      "##### Epoch: 1/10000 || Loss: 6.816487789154053\n",
      "--------------------------------------------------\n",
      "Validation || Epoch: 1 || Loss: 2.1266170631755483 || Accuracy: 0.5408617854118347 || F1-score: 0.3081200844252588\n",
      "Early stopping at epoch 15!\n",
      "Accuracy on dataset of size 672: 58.03571319580078 %.\n",
      "Average loss: 1.0712444999001243\n",
      "proportion of labels in prediction: [tensor(0.9062), tensor(0.0729), tensor(0.0208)]\n",
      "proportion of labels in data: [tensor(0.6235), tensor(0.2232), tensor(0.1533)]\n",
      "- f1: [0.73346304 0.12060302 0.01709402]\n",
      "- f1 (average): 0.2903866890629498\n",
      "- accuracy: 0.5803571343421936\n",
      "\n",
      "********** hidden_dim: [100, 100, 100, 100]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/var/folders/l7/bnn1j6bs3bqfskq2jlq55yh80000gr/T/ipykernel_51169/2802342863.py:18: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  train, valid, test = split_dataset(x_data=torch.tensor(x_data).float(),\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "44ee634192234d39bd4378590e5f6014",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/10000 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 1/10000 || Item: 0/85 || Loss: 1.9819138050079346\n",
      "--------------------------------------------------\n",
      "##### Epoch: 1/10000 || Loss: 1.1245191097259521\n",
      "--------------------------------------------------\n",
      "Validation || Epoch: 1 || Loss: 1.0592117580500515 || Accuracy: 0.6062406897544861 || F1-score: 0.3250462856162642\n",
      "Early stopping at epoch 12!\n",
      "Accuracy on dataset of size 672: 61.45833206176758 %.\n",
      "Average loss: 0.9830409288406372\n",
      "proportion of labels in prediction: [tensor(0.9717), tensor(0.0253), tensor(0.0030)]\n",
      "proportion of labels in data: [tensor(0.6235), tensor(0.2232), tensor(0.1533)]\n",
      "- f1: [0.75932836 0.05988024 0.01904762]\n",
      "- f1 (average): 0.2794187389258442\n",
      "- accuracy: 0.6145833134651184\n",
      "\n",
      "********** hidden_dim: [100, 100, 100, 100, 100]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/var/folders/l7/bnn1j6bs3bqfskq2jlq55yh80000gr/T/ipykernel_51169/2802342863.py:18: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  train, valid, test = split_dataset(x_data=torch.tensor(x_data).float(),\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "57573369009b4a5db60a1aa439825be0",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/10000 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 1/10000 || Item: 0/85 || Loss: 1.3260524272918701\n",
      "--------------------------------------------------\n",
      "##### Epoch: 1/10000 || Loss: 0.7130478024482727\n",
      "--------------------------------------------------\n",
      "Validation || Epoch: 1 || Loss: 1.0144050338051536 || Accuracy: 0.6181277632713318 || F1-score: 0.2846696731126907\n",
      "Early stopping at epoch 12!\n",
      "Accuracy on dataset of size 672: 62.05356979370117 %.\n",
      "Average loss: 0.9950303597883745\n",
      "proportion of labels in prediction: [tensor(0.9792), tensor(0.0208), tensor(0.)]\n",
      "proportion of labels in data: [tensor(0.6235), tensor(0.2232), tensor(0.1533)]\n",
      "- f1: [0.76508821 0.06097561 0.        ]\n",
      "- f1 (average): 0.2753546059137472\n",
      "- accuracy: 0.6205357313156128\n"
     ]
    }
   ],
   "source": [
    "signature_history = obtain_signatures_history(pooled_max_pretrained,\n",
    "                                              path_specifics,\n",
    "                                              dimension,\n",
    "                                              sig_depth,\n",
    "                                              concatenate_current=False)\n",
    "print(f\"signature_history.shape = {signature_history.shape}\")\n",
    "for hidden_dim in hidden_dim_trials:\n",
    "    print(f\"\\n********** hidden_dim: {hidden_dim}\")\n",
    "    implement_ffn(x_data=signature_history,\n",
    "                  y_data=y_data,\n",
    "                  hidden_dim=hidden_dim,\n",
    "                  learning_rate=learning_rate,\n",
    "                  loss=loss)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1d7e106d",
   "metadata": {},
   "source": [
    "### Sum pooled"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 206,
   "id": "3a87841a",
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[INFO] Concatenating the embeddings to the dataframe...\n",
      "[INFO] - columns beginning with 'e' denote the full embddings.\n",
      "[INFO] - columns beginning with 'd' denote the dimension reduced embeddings.\n",
      "[INFO] Adding time feature columns into dataframe in `.df`.\n",
      "[INFO] Adding 'time_encoding' and feature...\n",
      "[INFO] Adding 'time_diff' and feature...\n",
      "[INFO] Adding 'timeline_index' feature...\n",
      "[INFO] Padding ids and storing in `.df_padded` and `.array_padded` attributes.\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "265e5228f5c448b885023f99907aefc8",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/13551 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "signature_history.shape = torch.Size([6725, 1548])\n",
      "\n",
      "********** hidden_dim: [100]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/var/folders/l7/bnn1j6bs3bqfskq2jlq55yh80000gr/T/ipykernel_51169/2802342863.py:18: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  train, valid, test = split_dataset(x_data=torch.tensor(x_data).float(),\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "ef55719fd83841be8aec596e160a8f95",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/10000 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 1/10000 || Item: 0/85 || Loss: 9646180.0\n",
      "--------------------------------------------------\n",
      "##### Epoch: 1/10000 || Loss: 750286.75\n",
      "--------------------------------------------------\n",
      "Validation || Epoch: 1 || Loss: 3691685.3181818184 || Accuracy: 0.4472511112689972 || F1-score: 0.3391099913158737\n",
      "Early stopping at epoch 21!\n",
      "Accuracy on dataset of size 672: 53.27381134033203 %.\n",
      "Average loss: 2804424.9261363638\n",
      "proportion of labels in prediction: [tensor(0.6860), tensor(0.2262), tensor(0.0878)]\n",
      "proportion of labels in data: [tensor(0.6235), tensor(0.2232), tensor(0.1533)]\n",
      "- f1: [0.67954545 0.2781457  0.20987654]\n",
      "- f1 (average): 0.38918923103985653\n",
      "- accuracy: 0.5327380895614624\n",
      "\n",
      "********** hidden_dim: [100, 100]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/var/folders/l7/bnn1j6bs3bqfskq2jlq55yh80000gr/T/ipykernel_51169/2802342863.py:18: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  train, valid, test = split_dataset(x_data=torch.tensor(x_data).float(),\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "5cc1d260932748928c1e1fc09a10ea1d",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/10000 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 1/10000 || Item: 0/85 || Loss: 13514473.0\n",
      "--------------------------------------------------\n",
      "##### Epoch: 1/10000 || Loss: 1135117.375\n",
      "--------------------------------------------------\n",
      "Validation || Epoch: 1 || Loss: 1282761.9375 || Accuracy: 0.47696879506111145 || F1-score: 0.3518560625458767\n",
      "Early stopping at epoch 25!\n",
      "Accuracy on dataset of size 672: 47.1726188659668 %.\n",
      "Average loss: 755310.5710227273\n",
      "proportion of labels in prediction: [tensor(0.5833), tensor(0.3318), tensor(0.0848)]\n",
      "proportion of labels in data: [tensor(0.6235), tensor(0.2232), tensor(0.1533)]\n",
      "- f1: [0.61159063 0.28954424 0.1875    ]\n",
      "- f1 (average): 0.36287828825940016\n",
      "- accuracy: 0.4717261791229248\n",
      "\n",
      "********** hidden_dim: [100, 100, 100]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/var/folders/l7/bnn1j6bs3bqfskq2jlq55yh80000gr/T/ipykernel_51169/2802342863.py:18: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  train, valid, test = split_dataset(x_data=torch.tensor(x_data).float(),\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "3e2a9e6538664e22bc43bf426441db9f",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/10000 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 1/10000 || Item: 0/85 || Loss: 4648848.5\n",
      "--------------------------------------------------\n",
      "##### Epoch: 1/10000 || Loss: 324156.4375\n",
      "--------------------------------------------------\n",
      "Validation || Epoch: 1 || Loss: 504357.2507102273 || Accuracy: 0.5141158699989319 || F1-score: 0.31151505894239595\n",
      "Early stopping at epoch 24!\n",
      "Accuracy on dataset of size 672: 51.636905670166016 %.\n",
      "Average loss: 176146.10795454544\n",
      "proportion of labels in prediction: [tensor(0.6577), tensor(0.2664), tensor(0.0759)]\n",
      "proportion of labels in data: [tensor(0.6235), tensor(0.2232), tensor(0.1533)]\n",
      "- f1: [0.66434379 0.29179331 0.16883117]\n",
      "- f1 (average): 0.3749894227320278\n",
      "- accuracy: 0.5163690447807312\n",
      "\n",
      "********** hidden_dim: [100, 100, 100, 100]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/var/folders/l7/bnn1j6bs3bqfskq2jlq55yh80000gr/T/ipykernel_51169/2802342863.py:18: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  train, valid, test = split_dataset(x_data=torch.tensor(x_data).float(),\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "60c96ebe8cc040c18029c9f5b1df0ec3",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/10000 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 1/10000 || Item: 0/85 || Loss: 3004850.5\n",
      "--------------------------------------------------\n",
      "##### Epoch: 1/10000 || Loss: 8283.3017578125\n",
      "--------------------------------------------------\n",
      "Validation || Epoch: 1 || Loss: 202068.43678977274 || Accuracy: 0.6002971529960632 || F1-score: 0.31219192788378086\n",
      "Early stopping at epoch 19!\n",
      "Accuracy on dataset of size 672: 46.5773811340332 %.\n",
      "Average loss: 56099.005415482956\n",
      "proportion of labels in prediction: [tensor(0.5952), tensor(0.2917), tensor(0.1131)]\n",
      "proportion of labels in data: [tensor(0.6235), tensor(0.2232), tensor(0.1533)]\n",
      "- f1: [0.61782662 0.28323699 0.12290503]\n",
      "- f1 (average): 0.34132287999307726\n",
      "- accuracy: 0.4657738208770752\n",
      "\n",
      "********** hidden_dim: [100, 100, 100, 100, 100]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/var/folders/l7/bnn1j6bs3bqfskq2jlq55yh80000gr/T/ipykernel_51169/2802342863.py:18: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  train, valid, test = split_dataset(x_data=torch.tensor(x_data).float(),\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "ff7c5e7f79bc4f99836e3bbb57df8280",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/10000 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 1/10000 || Item: 0/85 || Loss: 749476.4375\n",
      "--------------------------------------------------\n",
      "##### Epoch: 1/10000 || Loss: 17405.90234375\n",
      "--------------------------------------------------\n",
      "Validation || Epoch: 1 || Loss: 42518.084783380684 || Accuracy: 0.5334323644638062 || F1-score: 0.32656029180214935\n",
      "Early stopping at epoch 42!\n",
      "Accuracy on dataset of size 672: 51.78571319580078 %.\n",
      "Average loss: 8601.425892223011\n",
      "proportion of labels in prediction: [tensor(0.6741), tensor(0.2574), tensor(0.0685)]\n",
      "proportion of labels in data: [tensor(0.6235), tensor(0.2232), tensor(0.1533)]\n",
      "- f1: [0.66055046 0.29102167 0.17449664]\n",
      "- f1 (average): 0.37535625827917457\n",
      "- accuracy: 0.5178571343421936\n"
     ]
    }
   ],
   "source": [
    "signature_history = obtain_signatures_history(pooled_sum_pretrained, path_specifics, dimension, sig_depth)\n",
    "print(f\"signature_history.shape = {signature_history.shape}\")\n",
    "for hidden_dim in hidden_dim_trials:\n",
    "    print(f\"\\n********** hidden_dim: {hidden_dim}\")\n",
    "    implement_ffn(x_data=signature_history,\n",
    "                  y_data=y_data,\n",
    "                  hidden_dim=hidden_dim,\n",
    "                  learning_rate=learning_rate,\n",
    "                  loss=loss)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 207,
   "id": "3b34b7c9",
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[INFO] Concatenating the embeddings to the dataframe...\n",
      "[INFO] - columns beginning with 'e' denote the full embddings.\n",
      "[INFO] - columns beginning with 'd' denote the dimension reduced embeddings.\n",
      "[INFO] Adding time feature columns into dataframe in `.df`.\n",
      "[INFO] Adding 'time_encoding' and feature...\n",
      "[INFO] Adding 'time_diff' and feature...\n",
      "[INFO] Adding 'timeline_index' feature...\n",
      "[INFO] Padding ids and storing in `.df_padded` and `.array_padded` attributes.\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "88c29a5d6d2e4976b624c78ab8d7d47c",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/13551 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "signature_history.shape = torch.Size([6725, 780])\n",
      "\n",
      "********** hidden_dim: [100]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/var/folders/l7/bnn1j6bs3bqfskq2jlq55yh80000gr/T/ipykernel_51169/2802342863.py:18: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  train, valid, test = split_dataset(x_data=torch.tensor(x_data).float(),\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "62b00cf68ca340c3888a16aab7c47ec2",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/10000 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 1/10000 || Item: 0/85 || Loss: 32241886.0\n",
      "--------------------------------------------------\n",
      "##### Epoch: 1/10000 || Loss: 4276127.0\n",
      "--------------------------------------------------\n",
      "Validation || Epoch: 1 || Loss: 5265692.409090909 || Accuracy: 0.37444278597831726 || F1-score: 0.2946142118966263\n",
      "Early stopping at epoch 30!\n",
      "Accuracy on dataset of size 672: 51.93452453613281 %.\n",
      "Average loss: 3327280.5\n",
      "proportion of labels in prediction: [tensor(0.6801), tensor(0.2143), tensor(0.1057)]\n",
      "proportion of labels in data: [tensor(0.6235), tensor(0.2232), tensor(0.1533)]\n",
      "- f1: [0.66666667 0.29251701 0.16091954]\n",
      "- f1 (average): 0.3733677378997577\n",
      "- accuracy: 0.519345223903656\n",
      "\n",
      "********** hidden_dim: [100, 100]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/var/folders/l7/bnn1j6bs3bqfskq2jlq55yh80000gr/T/ipykernel_51169/2802342863.py:18: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  train, valid, test = split_dataset(x_data=torch.tensor(x_data).float(),\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "0047addbfcc64d2195ec3cab9c6b2ccc",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/10000 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 1/10000 || Item: 0/85 || Loss: 6498777.0\n",
      "--------------------------------------------------\n",
      "##### Epoch: 1/10000 || Loss: 1248412.25\n",
      "--------------------------------------------------\n",
      "Validation || Epoch: 1 || Loss: 1394622.0113636365 || Accuracy: 0.4962852895259857 || F1-score: 0.3341336637145378\n",
      "Early stopping at epoch 29!\n",
      "Accuracy on dataset of size 672: 52.97618865966797 %.\n",
      "Average loss: 959525.3267045454\n",
      "proportion of labels in prediction: [tensor(0.7113), tensor(0.2173), tensor(0.0714)]\n",
      "proportion of labels in data: [tensor(0.6235), tensor(0.2232), tensor(0.1533)]\n",
      "- f1: [0.68227425 0.27027027 0.13245033]\n",
      "- f1 (average): 0.3616649496292456\n",
      "- accuracy: 0.5297619104385376\n",
      "\n",
      "********** hidden_dim: [100, 100, 100]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/var/folders/l7/bnn1j6bs3bqfskq2jlq55yh80000gr/T/ipykernel_51169/2802342863.py:18: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  train, valid, test = split_dataset(x_data=torch.tensor(x_data).float(),\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "f5b72c7e035649e3b0e5a9b7b5d4ac47",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/10000 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 1/10000 || Item: 0/85 || Loss: 7915275.0\n",
      "--------------------------------------------------\n",
      "##### Epoch: 1/10000 || Loss: 776393.75\n",
      "--------------------------------------------------\n",
      "Validation || Epoch: 1 || Loss: 519197.6122159091 || Accuracy: 0.4933135211467743 || F1-score: 0.3531816632344769\n",
      "Early stopping at epoch 40!\n",
      "Accuracy on dataset of size 672: 51.488094329833984 %.\n",
      "Average loss: 176253.0909090909\n",
      "proportion of labels in prediction: [tensor(0.7039), tensor(0.2158), tensor(0.0804)]\n",
      "proportion of labels in data: [tensor(0.6235), tensor(0.2232), tensor(0.1533)]\n",
      "- f1: [0.67040359 0.2440678  0.14012739]\n",
      "- f1 (average): 0.35153292419638255\n",
      "- accuracy: 0.5148809552192688\n",
      "\n",
      "********** hidden_dim: [100, 100, 100, 100]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/var/folders/l7/bnn1j6bs3bqfskq2jlq55yh80000gr/T/ipykernel_51169/2802342863.py:18: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  train, valid, test = split_dataset(x_data=torch.tensor(x_data).float(),\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "904cef87ecf146b5957980f905382dcf",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/10000 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 1/10000 || Item: 0/85 || Loss: 2379226.5\n",
      "--------------------------------------------------\n",
      "##### Epoch: 1/10000 || Loss: 1228.6171875\n",
      "--------------------------------------------------\n",
      "Validation || Epoch: 1 || Loss: 197744.39382102274 || Accuracy: 0.5156017541885376 || F1-score: 0.35254415560248226\n",
      "Early stopping at epoch 15!\n",
      "Accuracy on dataset of size 672: 56.39881134033203 %.\n",
      "Average loss: 80701.58220880682\n",
      "proportion of labels in prediction: [tensor(0.8318), tensor(0.0997), tensor(0.0685)]\n",
      "proportion of labels in data: [tensor(0.6235), tensor(0.2232), tensor(0.1533)]\n",
      "- f1: [0.72801636 0.14746544 0.09395973]\n",
      "- f1 (average): 0.3231471764166143\n",
      "- accuracy: 0.5639880895614624\n",
      "\n",
      "********** hidden_dim: [100, 100, 100, 100, 100]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/var/folders/l7/bnn1j6bs3bqfskq2jlq55yh80000gr/T/ipykernel_51169/2802342863.py:18: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  train, valid, test = split_dataset(x_data=torch.tensor(x_data).float(),\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "f8ab3a87246542dc8827adce1bd3c4fc",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/10000 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 1/10000 || Item: 0/85 || Loss: 565282.0\n",
      "--------------------------------------------------\n",
      "##### Epoch: 1/10000 || Loss: 13193.2734375\n",
      "--------------------------------------------------\n",
      "Validation || Epoch: 1 || Loss: 55157.63831676136 || Accuracy: 0.5720653533935547 || F1-score: 0.3683501325308396\n",
      "Early stopping at epoch 35!\n",
      "Accuracy on dataset of size 672: 48.80952453613281 %.\n",
      "Average loss: 9056.40780362216\n",
      "proportion of labels in prediction: [tensor(0.6592), tensor(0.2113), tensor(0.1295)]\n",
      "proportion of labels in data: [tensor(0.6235), tensor(0.2232), tensor(0.1533)]\n",
      "- f1: [0.6450116  0.23287671 0.16842105]\n",
      "- f1 (average): 0.34876978862947344\n",
      "- accuracy: 0.488095223903656\n"
     ]
    }
   ],
   "source": [
    "signature_history = obtain_signatures_history(pooled_sum_pretrained,\n",
    "                                              path_specifics,\n",
    "                                              dimension,\n",
    "                                              sig_depth,\n",
    "                                              concatenate_current=False)\n",
    "print(f\"signature_history.shape = {signature_history.shape}\")\n",
    "for hidden_dim in hidden_dim_trials:\n",
    "    print(f\"\\n********** hidden_dim: {hidden_dim}\")\n",
    "    implement_ffn(x_data=signature_history,\n",
    "                  y_data=y_data,\n",
    "                  hidden_dim=hidden_dim,\n",
    "                  learning_rate=learning_rate,\n",
    "                  loss=loss)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ddb2b76f",
   "metadata": {},
   "source": [
    "### CLS"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 208,
   "id": "528445a6",
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[INFO] Concatenating the embeddings to the dataframe...\n",
      "[INFO] - columns beginning with 'e' denote the full embddings.\n",
      "[INFO] - columns beginning with 'd' denote the dimension reduced embeddings.\n",
      "[INFO] Adding time feature columns into dataframe in `.df`.\n",
      "[INFO] Adding 'time_encoding' and feature...\n",
      "[INFO] Adding 'time_diff' and feature...\n",
      "[INFO] Adding 'timeline_index' feature...\n",
      "[INFO] Padding ids and storing in `.df_padded` and `.array_padded` attributes.\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "294a85ff504947918660c99b604623d4",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/13551 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "signature_history.shape = torch.Size([6725, 1548])\n",
      "\n",
      "********** hidden_dim: [100]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/var/folders/l7/bnn1j6bs3bqfskq2jlq55yh80000gr/T/ipykernel_51169/2802342863.py:18: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  train, valid, test = split_dataset(x_data=torch.tensor(x_data).float(),\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "3c27d868080746a7b6a1d82678833b96",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/10000 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 1/10000 || Item: 0/85 || Loss: 10.57669734954834\n",
      "--------------------------------------------------\n",
      "##### Epoch: 1/10000 || Loss: 2.36376953125\n",
      "--------------------------------------------------\n",
      "Validation || Epoch: 1 || Loss: 2.4741791053251787 || Accuracy: 0.5364041328430176 || F1-score: 0.3467733673264639\n",
      "Early stopping at epoch 56!\n",
      "Accuracy on dataset of size 672: 62.2023811340332 %.\n",
      "Average loss: 1.6854703697291287\n",
      "proportion of labels in prediction: [tensor(0.7768), tensor(0.1786), tensor(0.0446)]\n",
      "proportion of labels in data: [tensor(0.6235), tensor(0.2232), tensor(0.1533)]\n",
      "- f1: [0.75451647 0.38518519 0.16541353]\n",
      "- f1 (average): 0.4350383969527471\n",
      "- accuracy: 0.6220238208770752\n",
      "\n",
      "********** hidden_dim: [100, 100]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/var/folders/l7/bnn1j6bs3bqfskq2jlq55yh80000gr/T/ipykernel_51169/2802342863.py:18: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  train, valid, test = split_dataset(x_data=torch.tensor(x_data).float(),\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "a606ade87da940538a9f5ac33a2a6d32",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/10000 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 1/10000 || Item: 0/85 || Loss: 2.5529911518096924\n",
      "--------------------------------------------------\n",
      "##### Epoch: 1/10000 || Loss: 0.6177814602851868\n",
      "--------------------------------------------------\n",
      "Validation || Epoch: 1 || Loss: 1.1614464900710366 || Accuracy: 0.6062406897544861 || F1-score: 0.3556703459870922\n",
      "Early stopping at epoch 37!\n",
      "Accuracy on dataset of size 672: 61.16071319580078 %.\n",
      "Average loss: 1.1803450746969744\n",
      "proportion of labels in prediction: [tensor(0.7946), tensor(0.1622), tensor(0.0432)]\n",
      "proportion of labels in data: [tensor(0.6235), tensor(0.2232), tensor(0.1533)]\n",
      "- f1: [0.75131165 0.30888031 0.1969697 ]\n",
      "- f1 (average): 0.4190538844263924\n",
      "- accuracy: 0.6116071343421936\n",
      "\n",
      "********** hidden_dim: [100, 100, 100]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/var/folders/l7/bnn1j6bs3bqfskq2jlq55yh80000gr/T/ipykernel_51169/2802342863.py:18: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  train, valid, test = split_dataset(x_data=torch.tensor(x_data).float(),\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "3fbc15bef4464a6fb327ed53e3ed5e19",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/10000 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 1/10000 || Item: 0/85 || Loss: 1.468880295753479\n",
      "--------------------------------------------------\n",
      "##### Epoch: 1/10000 || Loss: 0.9828745722770691\n",
      "--------------------------------------------------\n",
      "Validation || Epoch: 1 || Loss: 1.0218017047101802 || Accuracy: 0.5869241952896118 || F1-score: 0.28628988499656216\n",
      "Early stopping at epoch 46!\n",
      "Accuracy on dataset of size 672: 61.60714340209961 %.\n",
      "Average loss: 1.1165391206741333\n",
      "proportion of labels in prediction: [tensor(0.7842), tensor(0.1711), tensor(0.0446)]\n",
      "proportion of labels in data: [tensor(0.6235), tensor(0.2232), tensor(0.1533)]\n",
      "- f1: [0.74841438 0.36226415 0.18045113]\n",
      "- f1 (average): 0.430376551694766\n",
      "- accuracy: 0.6160714030265808\n",
      "\n",
      "********** hidden_dim: [100, 100, 100, 100]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/var/folders/l7/bnn1j6bs3bqfskq2jlq55yh80000gr/T/ipykernel_51169/2802342863.py:18: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  train, valid, test = split_dataset(x_data=torch.tensor(x_data).float(),\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "f42fe1f40e214e22b09ac302c4548097",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/10000 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 1/10000 || Item: 0/85 || Loss: 1.1732434034347534\n",
      "--------------------------------------------------\n",
      "##### Epoch: 1/10000 || Loss: 0.688827633857727\n",
      "--------------------------------------------------\n",
      "Validation || Epoch: 1 || Loss: 0.9776950857856057 || Accuracy: 0.6225854158401489 || F1-score: 0.25579975579975583\n",
      "Early stopping at epoch 25!\n",
      "Accuracy on dataset of size 672: 60.71428680419922 %.\n",
      "Average loss: 1.4647020914337852\n",
      "proportion of labels in prediction: [tensor(0.7068), tensor(0.2307), tensor(0.0625)]\n",
      "proportion of labels in data: [tensor(0.6235), tensor(0.2232), tensor(0.1533)]\n",
      "- f1: [0.75615213 0.36065574 0.20689655]\n",
      "- f1 (average): 0.44123480490289935\n",
      "- accuracy: 0.6071428656578064\n",
      "\n",
      "********** hidden_dim: [100, 100, 100, 100, 100]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/var/folders/l7/bnn1j6bs3bqfskq2jlq55yh80000gr/T/ipykernel_51169/2802342863.py:18: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  train, valid, test = split_dataset(x_data=torch.tensor(x_data).float(),\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "359a543159fe4ed4a9b08a33ec66c44e",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/10000 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 1/10000 || Item: 0/85 || Loss: 1.0346287488937378\n",
      "--------------------------------------------------\n",
      "##### Epoch: 1/10000 || Loss: 0.8615090847015381\n",
      "--------------------------------------------------\n",
      "Validation || Epoch: 1 || Loss: 0.9569483724507418 || Accuracy: 0.6225854158401489 || F1-score: 0.25579975579975583\n",
      "Early stopping at epoch 24!\n",
      "Accuracy on dataset of size 672: 61.011905670166016 %.\n",
      "Average loss: 1.5974636511369185\n",
      "proportion of labels in prediction: [tensor(0.7098), tensor(0.2173), tensor(0.0729)]\n",
      "proportion of labels in data: [tensor(0.6235), tensor(0.2232), tensor(0.1533)]\n",
      "- f1: [0.75446429 0.34459459 0.27631579]\n",
      "- f1 (average): 0.4584582232608548\n",
      "- accuracy: 0.6101190447807312\n"
     ]
    }
   ],
   "source": [
    "signature_history = obtain_signatures_history(pooled_cls_pretrained, path_specifics, dimension, sig_depth)\n",
    "print(f\"signature_history.shape = {signature_history.shape}\")\n",
    "for hidden_dim in hidden_dim_trials:\n",
    "    print(f\"\\n********** hidden_dim: {hidden_dim}\")\n",
    "    implement_ffn(x_data=signature_history,\n",
    "                  y_data=y_data,\n",
    "                  hidden_dim=hidden_dim,\n",
    "                  learning_rate=learning_rate,\n",
    "                  loss=loss)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 209,
   "id": "61751a4c",
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[INFO] Concatenating the embeddings to the dataframe...\n",
      "[INFO] - columns beginning with 'e' denote the full embddings.\n",
      "[INFO] - columns beginning with 'd' denote the dimension reduced embeddings.\n",
      "[INFO] Adding time feature columns into dataframe in `.df`.\n",
      "[INFO] Adding 'time_encoding' and feature...\n",
      "[INFO] Adding 'time_diff' and feature...\n",
      "[INFO] Adding 'timeline_index' feature...\n",
      "[INFO] Padding ids and storing in `.df_padded` and `.array_padded` attributes.\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "c48c99acaea942309df30a383a80239e",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/13551 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "signature_history.shape = torch.Size([6725, 780])\n",
      "\n",
      "********** hidden_dim: [100]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/var/folders/l7/bnn1j6bs3bqfskq2jlq55yh80000gr/T/ipykernel_51169/2802342863.py:18: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  train, valid, test = split_dataset(x_data=torch.tensor(x_data).float(),\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "e755868252a3466c8e7d224f069a21f2",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/10000 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 1/10000 || Item: 0/85 || Loss: 7.455470085144043\n",
      "--------------------------------------------------\n",
      "##### Epoch: 1/10000 || Loss: 5.963819980621338\n",
      "--------------------------------------------------\n",
      "Validation || Epoch: 1 || Loss: 3.0283126397566362 || Accuracy: 0.4591381847858429 || F1-score: 0.3215615329780235\n",
      "Early stopping at epoch 20!\n",
      "Accuracy on dataset of size 672: 61.16071319580078 %.\n",
      "Average loss: 1.650571259585294\n",
      "proportion of labels in prediction: [tensor(0.8185), tensor(0.1414), tensor(0.0402)]\n",
      "proportion of labels in data: [tensor(0.6235), tensor(0.2232), tensor(0.1533)]\n",
      "- f1: [0.74716202 0.30204082 0.18461538]\n",
      "- f1 (average): 0.41127274121524454\n",
      "- accuracy: 0.6116071343421936\n",
      "\n",
      "********** hidden_dim: [100, 100]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/var/folders/l7/bnn1j6bs3bqfskq2jlq55yh80000gr/T/ipykernel_51169/2802342863.py:18: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  train, valid, test = split_dataset(x_data=torch.tensor(x_data).float(),\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "5e6dd85fbe904a3c9fec29d37c039eee",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/10000 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 1/10000 || Item: 0/85 || Loss: 3.409783124923706\n",
      "--------------------------------------------------\n",
      "##### Epoch: 1/10000 || Loss: 0.9901486039161682\n",
      "--------------------------------------------------\n",
      "Validation || Epoch: 1 || Loss: 1.5267160155556418 || Accuracy: 0.48736998438835144 || F1-score: 0.32956307880308083\n",
      "Early stopping at epoch 40!\n",
      "Accuracy on dataset of size 672: 59.82143020629883 %.\n",
      "Average loss: 1.1799353198571638\n",
      "proportion of labels in prediction: [tensor(0.8438), tensor(0.1205), tensor(0.0357)]\n",
      "proportion of labels in data: [tensor(0.6235), tensor(0.2232), tensor(0.1533)]\n",
      "- f1: [0.74036511 0.24242424 0.14173228]\n",
      "- f1 (average): 0.3748405458168918\n",
      "- accuracy: 0.5982142686843872\n",
      "\n",
      "********** hidden_dim: [100, 100, 100]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/var/folders/l7/bnn1j6bs3bqfskq2jlq55yh80000gr/T/ipykernel_51169/2802342863.py:18: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  train, valid, test = split_dataset(x_data=torch.tensor(x_data).float(),\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "1a2e6eeb560e442cbe16fcf9cc9c22aa",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/10000 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 1/10000 || Item: 0/85 || Loss: 1.4429852962493896\n",
      "--------------------------------------------------\n",
      "##### Epoch: 1/10000 || Loss: 1.142116665840149\n",
      "--------------------------------------------------\n",
      "Validation || Epoch: 1 || Loss: 1.0459776791659268 || Accuracy: 0.5958395004272461 || F1-score: 0.28203765227021044\n",
      "Early stopping at epoch 32!\n",
      "Accuracy on dataset of size 672: 57.44047546386719 %.\n",
      "Average loss: 1.2916027849370784\n",
      "proportion of labels in prediction: [tensor(0.8051), tensor(0.1429), tensor(0.0521)]\n",
      "proportion of labels in data: [tensor(0.6235), tensor(0.2232), tensor(0.1533)]\n",
      "- f1: [0.725      0.24390244 0.11594203]\n",
      "- f1 (average): 0.36161482266996586\n",
      "- accuracy: 0.574404776096344\n",
      "\n",
      "********** hidden_dim: [100, 100, 100, 100]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/var/folders/l7/bnn1j6bs3bqfskq2jlq55yh80000gr/T/ipykernel_51169/2802342863.py:18: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  train, valid, test = split_dataset(x_data=torch.tensor(x_data).float(),\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "4ebcaaa79f774900895f8aee9f439a51",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/10000 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 1/10000 || Item: 0/85 || Loss: 1.1479626893997192\n",
      "--------------------------------------------------\n",
      "##### Epoch: 1/10000 || Loss: 0.8195385336875916\n",
      "--------------------------------------------------\n",
      "Validation || Epoch: 1 || Loss: 0.9821810668165033 || Accuracy: 0.6210995316505432 || F1-score: 0.2590895972714155\n",
      "Early stopping at epoch 29!\n",
      "Accuracy on dataset of size 672: 59.0773811340332 %.\n",
      "Average loss: 1.3834776282310486\n",
      "proportion of labels in prediction: [tensor(0.8095), tensor(0.1369), tensor(0.0536)]\n",
      "proportion of labels in data: [tensor(0.6235), tensor(0.2232), tensor(0.1533)]\n",
      "- f1: [0.73520249 0.24793388 0.18705036]\n",
      "- f1 (average): 0.39006224540719625\n",
      "- accuracy: 0.5907738208770752\n",
      "\n",
      "********** hidden_dim: [100, 100, 100, 100, 100]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/var/folders/l7/bnn1j6bs3bqfskq2jlq55yh80000gr/T/ipykernel_51169/2802342863.py:18: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  train, valid, test = split_dataset(x_data=torch.tensor(x_data).float(),\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "1f13c295925a4219a4f64a641e97e136",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/10000 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 1/10000 || Item: 0/85 || Loss: 1.0760245323181152\n",
      "--------------------------------------------------\n",
      "##### Epoch: 1/10000 || Loss: 0.8654565215110779\n",
      "--------------------------------------------------\n",
      "Validation || Epoch: 1 || Loss: 0.9872191548347473 || Accuracy: 0.6225854158401489 || F1-score: 0.25579975579975583\n",
      "Early stopping at epoch 24!\n",
      "Accuracy on dataset of size 672: 59.6726188659668 %.\n",
      "Average loss: 1.5003969073295593\n",
      "proportion of labels in prediction: [tensor(0.7649), tensor(0.1741), tensor(0.0610)]\n",
      "proportion of labels in data: [tensor(0.6235), tensor(0.2232), tensor(0.1533)]\n",
      "- f1: [0.74169346 0.32209738 0.16666667]\n",
      "- f1 (average): 0.4101525022981723\n",
      "- accuracy: 0.5967261791229248\n"
     ]
    }
   ],
   "source": [
    "signature_history = obtain_signatures_history(pooled_cls_pretrained,\n",
    "                                              path_specifics,\n",
    "                                              dimension,\n",
    "                                              sig_depth,\n",
    "                                              concatenate_current=False)\n",
    "print(f\"signature_history.shape = {signature_history.shape}\")\n",
    "for hidden_dim in hidden_dim_trials:\n",
    "    print(f\"\\n********** hidden_dim: {hidden_dim}\")\n",
    "    implement_ffn(x_data=signature_history,\n",
    "                  y_data=y_data,\n",
    "                  hidden_dim=hidden_dim,\n",
    "                  learning_rate=learning_rate,\n",
    "                  loss=loss)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "be0e46a9",
   "metadata": {},
   "source": [
    "### Fine-tuned BERT"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "080076bc",
   "metadata": {},
   "source": [
    "### Mean pooled"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f2e3d72c",
   "metadata": {},
   "outputs": [],
   "source": [
    "signature_history = obtain_signatures_history(pooled_mean, path_specifics, dimension, sig_depth)\n",
    "print(f\"signature_history.shape = {signature_history.shape}\")\n",
    "for hidden_dim in hidden_dim_trials:\n",
    "    print(f\"\\n********** hidden_dim: {hidden_dim}\")\n",
    "    implement_ffn(x_data=signature_history,\n",
    "                  y_data=y_data,\n",
    "                  hidden_dim=hidden_dim,\n",
    "                  learning_rate=learning_rate,\n",
    "                  loss=loss)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d1630a68",
   "metadata": {},
   "outputs": [],
   "source": [
    "signature_history = obtain_signatures_history(pooled_mean,\n",
    "                                              path_specifics,\n",
    "                                              dimension,\n",
    "                                              sig_depth,\n",
    "                                              concatenate_current=False)\n",
    "print(f\"signature_history.shape = {signature_history.shape}\")\n",
    "for hidden_dim in hidden_dim_trials:\n",
    "    print(f\"\\n********** hidden_dim: {hidden_dim}\")\n",
    "    implement_ffn(x_data=signature_history,\n",
    "                  y_data=y_data,\n",
    "                  hidden_dim=hidden_dim,\n",
    "                  learning_rate=learning_rate,\n",
    "                  loss=loss)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4c58113f",
   "metadata": {},
   "source": [
    "### Max pooled"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "873dcbe4",
   "metadata": {},
   "outputs": [],
   "source": [
    "signature_history = obtain_signatures_history(pooled_max,\n",
    "                                              path_specifics,\n",
    "                                              dimension,\n",
    "                                              sig_depth)\n",
    "print(f\"signature_history.shape = {signature_history.shape}\")\n",
    "for hidden_dim in hidden_dim_trials:\n",
    "    print(f\"\\n********** hidden_dim: {hidden_dim}\")\n",
    "    implement_ffn(x_data=signature_history,\n",
    "                  y_data=y_data,\n",
    "                  hidden_dim=hidden_dim,\n",
    "                  learning_rate=learning_rate,\n",
    "                  loss=loss)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4bff8e9f",
   "metadata": {},
   "outputs": [],
   "source": [
    "signature_history = obtain_signatures_history(pooled_max,\n",
    "                                              path_specifics,\n",
    "                                              dimension,\n",
    "                                              sig_depth,\n",
    "                                              concatenate_current=False)\n",
    "print(f\"signature_history.shape = {signature_history.shape}\")\n",
    "for hidden_dim in hidden_dim_trials:\n",
    "    print(f\"\\n********** hidden_dim: {hidden_dim}\")\n",
    "    implement_ffn(x_data=signature_history,\n",
    "                  y_data=y_data,\n",
    "                  hidden_dim=hidden_dim,\n",
    "                  learning_rate=learning_rate,\n",
    "                  loss=loss)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1adb3ed2",
   "metadata": {},
   "source": [
    "### Sum pooled"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fa2599d8",
   "metadata": {},
   "outputs": [],
   "source": [
    "signature_history = obtain_signatures_history(pooled_sum, path_specifics, dimension, sig_depth)\n",
    "print(f\"signature_history.shape = {signature_history.shape}\")\n",
    "for hidden_dim in hidden_dim_trials:\n",
    "    print(f\"\\n********** hidden_dim: {hidden_dim}\")\n",
    "    implement_ffn(x_data=signature_history,\n",
    "                  y_data=y_data,\n",
    "                  hidden_dim=hidden_dim,\n",
    "                  learning_rate=learning_rate,\n",
    "                  loss=loss)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "96ba4c94",
   "metadata": {},
   "outputs": [],
   "source": [
    "signature_history = obtain_signatures_history(pooled_sum,\n",
    "                                              path_specifics,\n",
    "                                              dimension,\n",
    "                                              sig_depth,\n",
    "                                              concatenate_current=False)\n",
    "print(f\"signature_history.shape = {signature_history.shape}\")\n",
    "for hidden_dim in hidden_dim_trials:\n",
    "    print(f\"\\n********** hidden_dim: {hidden_dim}\")\n",
    "    implement_ffn(x_data=signature_history,\n",
    "                  y_data=y_data,\n",
    "                  hidden_dim=hidden_dim,\n",
    "                  learning_rate=learning_rate,\n",
    "                  loss=loss)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a1065273",
   "metadata": {},
   "source": [
    "### CLS"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e78c0ce4",
   "metadata": {},
   "outputs": [],
   "source": [
    "signature_history = obtain_signatures_history(pooled_cls, path_specifics, dimension, sig_depth)\n",
    "print(f\"signature_history.shape = {signature_history.shape}\")\n",
    "for hidden_dim in hidden_dim_trials:\n",
    "    print(f\"\\n********** hidden_dim: {hidden_dim}\")\n",
    "    implement_ffn(x_data=signature_history,\n",
    "                  y_data=y_data,\n",
    "                  hidden_dim=hidden_dim,\n",
    "                  learning_rate=learning_rate,\n",
    "                  loss=loss)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "04dab2fa",
   "metadata": {},
   "outputs": [],
   "source": [
    "signature_history = obtain_signatures_history(pooled_cls,\n",
    "                                              path_specifics,\n",
    "                                              dimension,\n",
    "                                              sig_depth,\n",
    "                                              concatenate_current=False)\n",
    "print(f\"signature_history.shape = {signature_history.shape}\")\n",
    "for hidden_dim in hidden_dim_trials:\n",
    "    print(f\"\\n********** hidden_dim: {hidden_dim}\")\n",
    "    implement_ffn(x_data=signature_history,\n",
    "                  y_data=y_data,\n",
    "                  hidden_dim=hidden_dim,\n",
    "                  learning_rate=learning_rate,\n",
    "                  loss=loss)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "da4ff92d",
   "metadata": {},
   "source": [
    "# StackedDeepSigNet"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "32ae1a72",
   "metadata": {},
   "source": [
    "## Obtaining path by looking at post history\n",
    "\n",
    "We can obtain a path by looking at the history of each post. Here we look at the last 10 posts (and pad with vectors of zeros if there are less than 10 posts) including the current post.\n",
    "\n",
    "We only want to consider paths that correspond to a client's utterance as we want to model a change in mood at that time. Their history will still contain the therapist's utterances too."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 210,
   "id": "90bfd87c",
   "metadata": {},
   "outputs": [],
   "source": [
    "time_features = [\"time_encoding\", \"timeline_index\"]\n",
    "path_specifics = {\"pad_by\": \"history\",\n",
    "                  \"zero_padding\": True,\n",
    "                  \"method\": \"k_last\",\n",
    "                  \"k\": 10,\n",
    "                  \"time_feature\": time_features,\n",
    "                  \"standardise_method\": [\"minmax\", None],\n",
    "                  \"embeddings\": \"dim_reduced\",\n",
    "                  \"include_current_embedding\": True,\n",
    "                  \"pad_from_below\": False}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 211,
   "id": "99ea44d9",
   "metadata": {},
   "outputs": [],
   "source": [
    "def obtain_SDSN_input(embeddings, path_specifics):\n",
    "    reduction = nlpsig.DimReduce(method=\"gaussian_random_projection\", n_components=50)\n",
    "    embeddings_reduced = reduction.fit_transform(embeddings, random_state=seed)\n",
    "    \n",
    "    paths = nlpsig.PrepareData(anno_mi,\n",
    "                               id_column=\"transcript_id\",\n",
    "                               label_column=\"client_talk_type\",\n",
    "                               embeddings=embeddings,\n",
    "                               embeddings_reduced=embeddings_reduced)\n",
    "    \n",
    "    paths.pad(**path_specifics)\n",
    "    \n",
    "    paths.array_padded = paths.array_padded[client_index]\n",
    "    paths.embeddings = paths.embeddings[client_index]\n",
    "    paths.embeddings_reduced = paths.embeddings_reduced[client_index]\n",
    "    \n",
    "    return paths.get_torch_path_for_SDSN(\n",
    "        include_time_features_in_path=True,\n",
    "        include_time_features_in_input=True,\n",
    "        include_embedding_in_input=True,\n",
    "        reduced_embeddings=False\n",
    "    )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 212,
   "id": "b18e243a",
   "metadata": {},
   "outputs": [],
   "source": [
    "def implement_sdsn(x_data,\n",
    "                   y_data,\n",
    "                   sig_depth,\n",
    "                   input_channels,\n",
    "                   output_channels,\n",
    "                   lstm_hidden_dim,\n",
    "                   ffn_hidden_dim,\n",
    "                   BiLSTM,\n",
    "                   learning_rate,\n",
    "                   loss,\n",
    "                   gamma = 0):\n",
    "    SDSN_args = {\n",
    "        \"input_channels\": input_channels,\n",
    "        \"output_channels\": output_channels,\n",
    "        \"num_time_features\": len(time_features),\n",
    "        \"embedding_dim\": x_data.shape[2]-input_channels-len(time_features),\n",
    "        \"sig_depth\": sig_depth,\n",
    "        \"hidden_dim_lstm\": lstm_hidden_dim,\n",
    "        \"hidden_dim_ffn\": ffn_hidden_dim,\n",
    "        \"output_dim\": len(label_to_id),\n",
    "        \"dropout_rate\": 0.1,\n",
    "        \"augmentation_type\": \"Conv1d\",\n",
    "        \"BiLSTM\": BiLSTM,\n",
    "        \"comb_method\": \"concatenation\"\n",
    "    }\n",
    "    \n",
    "    sdsn_model = StackedDeepSigNet(**SDSN_args)\n",
    "    # print(sdsn_model)\n",
    "    \n",
    "    # split dataset\n",
    "    train, valid, test = split_dataset(x_data=torch.tensor(x_data).float(),\n",
    "                                       y_data=torch.tensor(y_data),\n",
    "                                       train_size=0.8,\n",
    "                                       valid_size=0.5,\n",
    "                                       shuffle=True,\n",
    "                                       as_DataLoader=True,\n",
    "                                       seed=seed)\n",
    "    \n",
    "    # define loss\n",
    "    if loss == \"focal\":    \n",
    "        criterion = FocalLoss(gamma = gamma)\n",
    "    elif loss == \"cross_entropy\":\n",
    "        criterion = torch.nn.CrossEntropyLoss()\n",
    "\n",
    "    # define optimizer\n",
    "    optimizer = torch.optim.Adam(sdsn_model.parameters(), lr=learning_rate)\n",
    "    # define scheduler for adjusting the learning rate\n",
    "    scheduler = ReduceLROnPlateau(optimizer, 'min')\n",
    "    # scheduler = StepLR(optimizer, step_size = 10, gamma = 0.5)\n",
    "    # scheduler = CosineAnnealingWarmRestarts(optimizer, \n",
    "    #                                         T_0 = 8,# Number of iterations for the first restart\n",
    "    #                                         T_mult = 1, # A factor increases TiTi after a restart\n",
    "    #                                         eta_min = learning_rate*0.1)\n",
    "    # scheduler = None\n",
    "    \n",
    "    sdsn_model = training_pytorch(model=sdsn_model,\n",
    "                                  train_loader=train,\n",
    "                                  criterion=criterion,\n",
    "                                  optimizer=optimizer,\n",
    "                                  num_epochs=10000,\n",
    "                                  scheduler=scheduler,\n",
    "                                  valid_loader=valid,\n",
    "                                  early_stopping=True,\n",
    "                                  early_stopping_metric=\"f1\",\n",
    "                                  patience=100,\n",
    "                                  verbose=True,\n",
    "                                  verbose_epoch=100,\n",
    "                                  seed=seed)\n",
    "\n",
    "    pred, label = testing_pytorch(sdsn_model, test, criterion)\n",
    "    print(f\"proportion of labels in prediction: {[sum(pred==i)/len(pred) for i in label_to_id.values()]}\")\n",
    "    print(f\"proportion of labels in data: {[sum(label==i)/len(label) for i in label_to_id.values()]}\")\n",
    "    \n",
    "    f1_scores = metrics.f1_score(label, pred, average=None)\n",
    "    print(f\"- f1: {f1_scores}\")\n",
    "    print(f\"- f1 (average): {sum(f1_scores)/len(f1_scores)}\")\n",
    "    print(f\"- accuracy: {sum(pred==label)/len(pred)}\")\n",
    "    \n",
    "    return sdsn_model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 213,
   "id": "43dbc33f",
   "metadata": {},
   "outputs": [],
   "source": [
    "lstm_hidden_dim_trial = [[8,8], [12,12,8], [12,12,12,8]]\n",
    "ffn_hidden_dim_trial = [[100]*i for i in range(2, 6)]\n",
    "sig_depth = 3\n",
    "output_channels = 10\n",
    "BiLSTM = True\n",
    "learning_rate = 1e-4"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a7ec0e9c",
   "metadata": {},
   "source": [
    "## SBERT 768"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 214,
   "id": "1b5d0ef6",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "52"
      ]
     },
     "execution_count": 214,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "input_channels"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 215,
   "id": "fffd2914",
   "metadata": {},
   "outputs": [],
   "source": [
    "from __future__ import annotations\n",
    "import signatory\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "\n",
    "\n",
    "class StackedDeepSigNet(nn.Module):\n",
    "    \"\"\"\n",
    "    Stacked Deep Signature Neural Network for classification.\n",
    "    \"\"\"\n",
    "\n",
    "    def __init__(\n",
    "        self,\n",
    "        input_channels: int,\n",
    "        output_channels: int,\n",
    "        num_time_features: int,\n",
    "        embedding_dim: int,\n",
    "        sig_depth: int,\n",
    "        hidden_dim_lstm: list[int] | int,\n",
    "        hidden_dim_ffn: list[int] | int,\n",
    "        output_dim: int,\n",
    "        dropout_rate: float,\n",
    "        augmentation_type: str = \"Conv1d\",\n",
    "        augmentation_args: dict | None = None,\n",
    "        hidden_dim_aug: list[int] | int | None = None,\n",
    "        BiLSTM: bool = False,\n",
    "        comb_method: str = \"gated_addition\",\n",
    "    ):\n",
    "        \"\"\"\n",
    "        Stacked Deep Signature Neural Network for classification.\n",
    "\n",
    "        Parameters\n",
    "        ----------\n",
    "        input_channels : int\n",
    "            Dimension of the embeddings that will be passed in.\n",
    "        output_channels : int\n",
    "            Requested dimension of the embeddings after convolution layer.\n",
    "        num_time_features : int\n",
    "            Number of time features to add to FFN input. If none, set to zero.\n",
    "        embedding_dim : int\n",
    "            Dimension of embedding to add to FFN input. If none, set to zero.\n",
    "        sig_depth : int\n",
    "            The depth to truncate the path signature at.\n",
    "        hidden_dim_lstm : list[int] | int\n",
    "            Dimensions of the hidden layers in the LSTM blocks.\n",
    "        hidden_dim_ffn : list[int] | int\n",
    "            Dimension of the hidden layers in the FFN.\n",
    "        output_dim : int\n",
    "            Dimension of the output layer in the FFN.\n",
    "        dropout_rate : float\n",
    "            Dropout rate in the FFN.\n",
    "        augmentation_type : str, optional\n",
    "            Method of augmenting the path, by default \"Conv1d\".\n",
    "            Options are:\n",
    "            - \"Conv1d\": passes path through 1D convolution layer.\n",
    "            - \"signatory\": passes path through `Augment` layer from `signatory` package.\n",
    "        augmentation_args : dict | None, optional\n",
    "            Arguments to pass into `torch.Conv1d` or `signatory.Augment`, by default None.\n",
    "            If None, by default will set `kernel_size=3`, `stride=1`, `padding=0`.\n",
    "        hidden_dim_aug : list[int] | int | None\n",
    "            Dimensions of the hidden layers in the augmentation layer.\n",
    "            Passed into `Augment` class from `signatory` package if\n",
    "            `augmentation_type='signatory'`, by default None.\n",
    "        BiLSTM : bool, optional\n",
    "            Whether or not a birectional LSTM is used,\n",
    "            by default False (unidirectional LSTM is used in this case).\n",
    "        comb_method : str, optional\n",
    "            Determines how to combine the path signature and embeddings,\n",
    "            by default \"gated_addition\".\n",
    "            Options are:\n",
    "            - concatenation: concatenation of path signature and embedding vector\n",
    "            - gated_addition: element-wise addition of path signature and embedding vector\n",
    "        \"\"\"\n",
    "        super(StackedDeepSigNet, self).__init__()\n",
    "        self.input_channels = input_channels\n",
    "        \n",
    "        if isinstance(hidden_dim_lstm, int):\n",
    "            hidden_dim_lstm = [hidden_dim_lstm]\n",
    "        if isinstance(hidden_dim_ffn, int):\n",
    "            hidden_dim_ffn = [hidden_dim_ffn]\n",
    "        self.hidden_dim_lstm = hidden_dim_lstm\n",
    "        self.hidden_dim_ffn = hidden_dim_ffn\n",
    "        \n",
    "        self.embedding_dim = embedding_dim\n",
    "        self.num_time_features = num_time_features\n",
    "        if comb_method not in [\"concatenation\", \"gated_addition\"]:\n",
    "            raise ValueError(\n",
    "                \"`comb_method` must be either 'concatenation' or 'gated_addition'.\"\n",
    "            )\n",
    "        self.comb_method = comb_method\n",
    "        if augmentation_type not in [\"Conv1d\", \"signatory\"]:\n",
    "            raise ValueError(\"`augmentation_type` must be 'Conv1d' or 'signatory'.\")\n",
    "        \n",
    "        self.augmentation_type = augmentation_type\n",
    "        if isinstance(hidden_dim_aug, int):\n",
    "            hidden_dim_aug = [hidden_dim_aug]\n",
    "        elif hidden_dim_aug is None:\n",
    "            hidden_dim_aug = []\n",
    "        self.hidden_dim_aug = hidden_dim_aug\n",
    "        if augmentation_args is None:\n",
    "            augmentation_args = {\"kernel_size\": 3,\n",
    "                                 \"stride\": 1,\n",
    "                                 \"padding\": 1}\n",
    "        # convolution\n",
    "        self.conv = nn.Conv1d(\n",
    "            in_channels=input_channels,\n",
    "            out_channels=output_channels,\n",
    "            **augmentation_args,\n",
    "        )\n",
    "        self.augment = signatory.Augment(\n",
    "            in_channels=input_channels,\n",
    "            layer_sizes=self.hidden_dim_aug + [output_channels],\n",
    "            include_original=False,\n",
    "            include_time=False,\n",
    "            **augmentation_args,\n",
    "        )\n",
    "        # non-linearity\n",
    "        self.tanh1 = nn.Tanh()\n",
    "\n",
    "        self.signature_layers = []\n",
    "        self.lstm_layers = []\n",
    "        for l in range(len(self.hidden_dim_lstm)):\n",
    "            self.signature_layers.append(signatory.LogSignature(depth=sig_depth, stream=True))\n",
    "            if l == 0:\n",
    "                input_dim_lstm = signatory.logsignature_channels(output_channels, sig_depth)\n",
    "            else:\n",
    "                input_dim_lstm = signatory.logsignature_channels(self.hidden_dim_lstm[l-1], sig_depth)\n",
    "            self.lstm_layers.append(nn.LSTM(\n",
    "                input_size=input_dim_lstm,\n",
    "                hidden_size=self.hidden_dim_lstm[l],\n",
    "                num_layers=1,\n",
    "                batch_first=True,\n",
    "                bidirectional=False if l!=(len(self.hidden_dim_lstm)-1) else BiLSTM,\n",
    "            ))\n",
    "        \n",
    "        self.signature_layers = nn.ModuleList(self.signature_layers)\n",
    "        self.lstm_layers = nn.ModuleList(self.lstm_layers)\n",
    "\n",
    "        # signature without lift (for passing into FFN)\n",
    "        mult = 2 if BiLSTM else 1\n",
    "        self.signature2 = signatory.LogSignature(depth=sig_depth, stream=False)\n",
    "\n",
    "        # find dimension of features to pass through FFN\n",
    "        if self.comb_method == \"concatenation\":\n",
    "            input_dim = (\n",
    "                signatory.logsignature_channels(\n",
    "                    in_channels=mult * self.hidden_dim_lstm[-1], depth=sig_depth\n",
    "                )\n",
    "                + self.num_time_features\n",
    "                + self.embedding_dim\n",
    "            )\n",
    "        elif self.comb_method == \"gated_addition\":\n",
    "            input_dim = self.embedding_dim\n",
    "            input_gated_linear = (\n",
    "                signatory.logsignature_channels(\n",
    "                    in_channels=mult * self.hidden_dim_lstm[-1], depth=sig_depth\n",
    "                )\n",
    "                + self.num_time_features\n",
    "            )\n",
    "            if self.embedding_dim > 0:\n",
    "                self.fc_scale = nn.Linear(input_gated_linear, self.embedding_dim)\n",
    "                self.scaler = torch.nn.Parameter(torch.zeros(1, self.embedding_dim))\n",
    "            else:\n",
    "                self.fc_scale = nn.Linear(input_gated_linear, input_gated_linear)\n",
    "                self.scaler = torch.nn.Parameter(torch.zeros(1, input_gated_linear))\n",
    "            # non-linearity\n",
    "            self.tanh2 = nn.Tanh()\n",
    "\n",
    "        # FFN: input layer\n",
    "        self.ffn_input_layer = nn.Linear(input_dim, self.hidden_dim_ffn[0])\n",
    "        self.relu = nn.ReLU()\n",
    "        self.dropout = nn.Dropout(dropout_rate)\n",
    "        input_dim = self.hidden_dim_ffn[0]\n",
    "        \n",
    "        # FFN: hidden layers\n",
    "        self.ffn_linear_layers = []\n",
    "        self.ffn_non_linear_layers = []\n",
    "        self.dropout_layers = []\n",
    "        for l in range(len(self.hidden_dim_ffn)):\n",
    "            self.ffn_linear_layers.append(nn.Linear(input_dim, self.hidden_dim_ffn[l]))\n",
    "            self.ffn_non_linear_layers.append(nn.ReLU())\n",
    "            self.dropout_layers.append(nn.Dropout(dropout_rate))\n",
    "            input_dim = self.hidden_dim_ffn[l]\n",
    "        \n",
    "        self.ffn_linear_layers = nn.ModuleList(self.ffn_linear_layers)\n",
    "        self.ffn_non_linear_layers = nn.ModuleList(self.ffn_non_linear_layers)\n",
    "        self.dropout_layers = nn.ModuleList(self.dropout_layers)\n",
    "        \n",
    "        # FFN: readout\n",
    "        self.ffn_final_layer = nn.Linear(input_dim, output_dim)\n",
    "\n",
    "    def forward(self, x: torch.Tensor):\n",
    "        # x has dimensions [batch, length of signal, channels]\n",
    "        \n",
    "        print(f\"input size: {x.shape}\")\n",
    "        \n",
    "        # convolution\n",
    "        if self.augmentation_type == \"Conv1d\":\n",
    "            # input has dimensions [batch, length of signal, channels]\n",
    "            # swap dimensions to get [batch, channels, length of signal]\n",
    "            # (nn.Conv1d expects this)\n",
    "            out = torch.transpose(x, 1, 2)\n",
    "            # get only the path information\n",
    "            out = self.conv(out[:, : self.input_channels, :])\n",
    "            out = self.tanh1(out)\n",
    "            # make output have dimensions [batch, length of signal, channels]\n",
    "            out = torch.transpose(out, 1, 2)\n",
    "        elif self.augmentation_type == \"signatory\":\n",
    "            # input has dimensions [batch, length of signal, channels]\n",
    "            # (signatory.Augment expects this)\n",
    "            # and get only the path information\n",
    "            # output has dimensions [batch, length of signal, channels]\n",
    "            out = self.augment(x[:, :, : self.input_channels])\n",
    "\n",
    "        print(f\"after conv: {out.shape}\")\n",
    "        \n",
    "        # take signature lifts and lstm\n",
    "        for l in range(len(self.hidden_dim_lstm)):\n",
    "            out = self.signature_layers[l](out)\n",
    "            print(f\"after signature: {out.shape}\")\n",
    "            out, _ = self.lstm_layers[l](out)\n",
    "            print(f\"after lstm: {out.shape}\")\n",
    "        \n",
    "        print(f\"after snwu: {out.shape}\")\n",
    "        # signature\n",
    "        out = self.signature2(out)\n",
    "        print(f\"after last signature: {out.shape}\")\n",
    "\n",
    "        # combine last post embedding\n",
    "        if x.shape[2] > self.input_channels:\n",
    "            # we have things to concatenate to the path\n",
    "            if self.comb_method == \"concatenation\":\n",
    "                if self.num_time_features > 0:\n",
    "                    # concatenate any time features\n",
    "                    # take the maximum for the latest time\n",
    "                    out = torch.cat(\n",
    "                        (\n",
    "                            out,\n",
    "                            x[\n",
    "                                :,\n",
    "                                :,\n",
    "                                self.input_channels : (\n",
    "                                    self.input_channels + self.num_time_features\n",
    "                                ),\n",
    "                            ].max(1)[0],\n",
    "                        ),\n",
    "                        dim=1,\n",
    "                    )\n",
    "                if x.shape[2] > self.input_channels + self.num_time_features:\n",
    "                    # concatenate current post embedding if provided\n",
    "                    out = torch.cat(\n",
    "                        (\n",
    "                            out,\n",
    "                            x[:, 0, (self.input_channels + self.num_time_features) :],\n",
    "                        ),\n",
    "                        dim=1,\n",
    "                    )\n",
    "            elif self.comb_method == \"gated_addition\":\n",
    "                if self.num_time_features > 0:\n",
    "                    # concatenate any time features\n",
    "                    out_gated = torch.cat(\n",
    "                        (\n",
    "                            out,\n",
    "                            x[\n",
    "                                :,\n",
    "                                :,\n",
    "                                self.input_channels : (\n",
    "                                    self.input_channels + self.num_time_features\n",
    "                                ),\n",
    "                            ].max(1)[0],\n",
    "                        ),\n",
    "                        dim=1,\n",
    "                    )\n",
    "                else:\n",
    "                    out_gated = out\n",
    "                out_gated = self.fc_scale(out_gated.float())\n",
    "                out_gated = self.tanh2(out_gated)\n",
    "                out_gated = torch.mul(self.scaler, out_gated)\n",
    "                if x.shape[2] > self.input_channels + self.num_time_features:\n",
    "                    # concatenate current post embedding if provided\n",
    "                    out = (\n",
    "                        out_gated\n",
    "                        + x[:, 0, (self.input_channels + self.num_time_features) :],\n",
    "                    )\n",
    "                else:\n",
    "                    out = out_gated\n",
    "\n",
    "        # FFN: input layer\n",
    "        out = self.ffn_input_layer(out)\n",
    "        out = self.relu(out)\n",
    "        out = self.dropout(out)\n",
    "        \n",
    "        # FFN: hidden layers    \n",
    "        for l in range(len(self.hidden_dim_ffn)):\n",
    "            out = self.ffn_linear_layers[l](out)\n",
    "            out = self.ffn_non_linear_layers[l](out)\n",
    "            out = self.dropout_layers[l](out)\n",
    "\n",
    "        # FFN: readout\n",
    "        out = self.ffn_final_layer(out)\n",
    "\n",
    "        return out"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 216,
   "id": "5b8392ac",
   "metadata": {},
   "outputs": [],
   "source": [
    "from __future__ import annotations\n",
    "import signatory\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "\n",
    "\n",
    "class StackedDeepSigNet(nn.Module):\n",
    "    \"\"\"\n",
    "    Stacked Deep Signature Neural Network for classification.\n",
    "    \"\"\"\n",
    "\n",
    "    def __init__(\n",
    "        self,\n",
    "        input_channels: int,\n",
    "        output_channels: int,\n",
    "        num_time_features: int,\n",
    "        embedding_dim: int,\n",
    "        sig_depth: int,\n",
    "        hidden_dim_lstm: list[int] | int,\n",
    "        hidden_dim_ffn: list[int] | int,\n",
    "        output_dim: int,\n",
    "        dropout_rate: float,\n",
    "        augmentation_type: str = \"Conv1d\",\n",
    "        augmentation_args: dict | None = None,\n",
    "        hidden_dim_aug: list[int] | int | None = None,\n",
    "        BiLSTM: bool = False,\n",
    "        comb_method: str = \"gated_addition\",\n",
    "    ):\n",
    "        \"\"\"\n",
    "        Stacked Deep Signature Neural Network for classification.\n",
    "\n",
    "        Parameters\n",
    "        ----------\n",
    "        input_channels : int\n",
    "            Dimension of the embeddings that will be passed in.\n",
    "        output_channels : int\n",
    "            Requested dimension of the embeddings after convolution layer.\n",
    "        num_time_features : int\n",
    "            Number of time features to add to FFN input. If none, set to zero.\n",
    "        embedding_dim : int\n",
    "            Dimension of embedding to add to FFN input. If none, set to zero.\n",
    "        sig_depth : int\n",
    "            The depth to truncate the path signature at.\n",
    "        hidden_dim_lstm : list[int] | int\n",
    "            Dimensions of the hidden layers in the LSTM blocks.\n",
    "        hidden_dim_ffn : list[int] | int\n",
    "            Dimension of the hidden layers in the FFN.\n",
    "        output_dim : int\n",
    "            Dimension of the output layer in the FFN.\n",
    "        dropout_rate : float\n",
    "            Dropout rate in the FFN.\n",
    "        augmentation_type : str, optional\n",
    "            Method of augmenting the path, by default \"Conv1d\".\n",
    "            Options are:\n",
    "            - \"Conv1d\": passes path through 1D convolution layer.\n",
    "            - \"signatory\": passes path through `Augment` layer from `signatory` package.\n",
    "        augmentation_args : dict | None, optional\n",
    "            Arguments to pass into `torch.Conv1d` or `signatory.Augment`, by default None.\n",
    "            If None, by default will set `kernel_size=3`, `stride=1`, `padding=0`.\n",
    "        hidden_dim_aug : list[int] | int | None\n",
    "            Dimensions of the hidden layers in the augmentation layer.\n",
    "            Passed into `Augment` class from `signatory` package if\n",
    "            `augmentation_type='signatory'`, by default None.\n",
    "        BiLSTM : bool, optional\n",
    "            Whether or not a birectional LSTM is used,\n",
    "            by default False (unidirectional LSTM is used in this case).\n",
    "        comb_method : str, optional\n",
    "            Determines how to combine the path signature and embeddings,\n",
    "            by default \"gated_addition\".\n",
    "            Options are:\n",
    "            - concatenation: concatenation of path signature and embedding vector\n",
    "            - gated_addition: element-wise addition of path signature and embedding vector\n",
    "        \"\"\"\n",
    "        super(StackedDeepSigNet, self).__init__()\n",
    "        self.input_channels = input_channels\n",
    "        \n",
    "        if isinstance(hidden_dim_lstm, int):\n",
    "            hidden_dim_lstm = [hidden_dim_lstm]\n",
    "        if isinstance(hidden_dim_ffn, int):\n",
    "            hidden_dim_ffn = [hidden_dim_ffn]\n",
    "        self.hidden_dim_lstm = hidden_dim_lstm\n",
    "        self.hidden_dim_ffn = hidden_dim_ffn\n",
    "        \n",
    "        self.embedding_dim = embedding_dim\n",
    "        self.num_time_features = num_time_features\n",
    "        if comb_method not in [\"concatenation\", \"gated_addition\"]:\n",
    "            raise ValueError(\n",
    "                \"`comb_method` must be either 'concatenation' or 'gated_addition'.\"\n",
    "            )\n",
    "        self.comb_method = comb_method\n",
    "        if augmentation_type not in [\"Conv1d\", \"signatory\"]:\n",
    "            raise ValueError(\"`augmentation_type` must be 'Conv1d' or 'signatory'.\")\n",
    "        \n",
    "        self.augmentation_type = augmentation_type\n",
    "        if isinstance(hidden_dim_aug, int):\n",
    "            hidden_dim_aug = [hidden_dim_aug]\n",
    "        elif hidden_dim_aug is None:\n",
    "            hidden_dim_aug = []\n",
    "        self.hidden_dim_aug = hidden_dim_aug\n",
    "        if augmentation_args is None:\n",
    "            augmentation_args = {\"kernel_size\": 3,\n",
    "                                 \"stride\": 1,\n",
    "                                 \"padding\": 1}\n",
    "        # convolution\n",
    "        self.conv = nn.Conv1d(\n",
    "            in_channels=input_channels,\n",
    "            out_channels=output_channels,\n",
    "            **augmentation_args,\n",
    "        )\n",
    "        self.augment = signatory.Augment(\n",
    "            in_channels=input_channels,\n",
    "            layer_sizes=self.hidden_dim_aug + [output_channels],\n",
    "            include_original=False,\n",
    "            include_time=False,\n",
    "            **augmentation_args,\n",
    "        )\n",
    "        # non-linearity\n",
    "        self.tanh1 = nn.Tanh()\n",
    "\n",
    "        self.signature_layers = []\n",
    "        self.lstm_layers = []\n",
    "        for l in range(len(self.hidden_dim_lstm)):\n",
    "            self.signature_layers.append(signatory.LogSignature(depth=sig_depth, stream=True))\n",
    "            if l == 0:\n",
    "                input_dim_lstm = signatory.logsignature_channels(output_channels, sig_depth)\n",
    "            else:\n",
    "                input_dim_lstm = signatory.logsignature_channels(self.hidden_dim_lstm[l-1], sig_depth)\n",
    "            self.lstm_layers.append(nn.LSTM(\n",
    "                input_size=input_dim_lstm,\n",
    "                hidden_size=self.hidden_dim_lstm[l],\n",
    "                num_layers=1,\n",
    "                batch_first=True,\n",
    "                bidirectional=False if l!=(len(self.hidden_dim_lstm)-1) else BiLSTM,\n",
    "            ))\n",
    "        \n",
    "        self.signature_layers = nn.ModuleList(self.signature_layers)\n",
    "        self.lstm_layers = nn.ModuleList(self.lstm_layers)\n",
    "\n",
    "        # signature without lift (for passing into FFN)\n",
    "        mult = 2 if BiLSTM else 1\n",
    "        self.signature2 = signatory.LogSignature(depth=sig_depth, stream=False)\n",
    "\n",
    "        # find dimension of features to pass through FFN\n",
    "        if self.comb_method == \"concatenation\":\n",
    "            input_dim = (\n",
    "                signatory.logsignature_channels(\n",
    "                    in_channels=mult * self.hidden_dim_lstm[-1], depth=sig_depth\n",
    "                )\n",
    "                + self.num_time_features\n",
    "                + self.embedding_dim\n",
    "            )\n",
    "        elif self.comb_method == \"gated_addition\":\n",
    "            input_dim = self.embedding_dim\n",
    "            input_gated_linear = (\n",
    "                signatory.logsignature_channels(\n",
    "                    in_channels=mult * self.hidden_dim_lstm[-1], depth=sig_depth\n",
    "                )\n",
    "                + self.num_time_features\n",
    "            )\n",
    "            if self.embedding_dim > 0:\n",
    "                self.fc_scale = nn.Linear(input_gated_linear, self.embedding_dim)\n",
    "                self.scaler = torch.nn.Parameter(torch.zeros(1, self.embedding_dim))\n",
    "            else:\n",
    "                self.fc_scale = nn.Linear(input_gated_linear, input_gated_linear)\n",
    "                self.scaler = torch.nn.Parameter(torch.zeros(1, input_gated_linear))\n",
    "            # non-linearity\n",
    "            self.tanh2 = nn.Tanh()\n",
    "\n",
    "        # FFN: input layer\n",
    "        self.ffn_input_layer = nn.Linear(input_dim, self.hidden_dim_ffn[0])\n",
    "        self.relu = nn.ReLU()\n",
    "        self.dropout = nn.Dropout(dropout_rate)\n",
    "        input_dim = self.hidden_dim_ffn[0]\n",
    "        \n",
    "        # FFN: hidden layers\n",
    "        self.ffn_linear_layers = []\n",
    "        self.ffn_non_linear_layers = []\n",
    "        self.dropout_layers = []\n",
    "        for l in range(len(self.hidden_dim_ffn)):\n",
    "            self.ffn_linear_layers.append(nn.Linear(input_dim, self.hidden_dim_ffn[l]))\n",
    "            self.ffn_non_linear_layers.append(nn.ReLU())\n",
    "            self.dropout_layers.append(nn.Dropout(dropout_rate))\n",
    "            input_dim = self.hidden_dim_ffn[l]\n",
    "        \n",
    "        self.ffn_linear_layers = nn.ModuleList(self.ffn_linear_layers)\n",
    "        self.ffn_non_linear_layers = nn.ModuleList(self.ffn_non_linear_layers)\n",
    "        self.dropout_layers = nn.ModuleList(self.dropout_layers)\n",
    "        \n",
    "        # FFN: readout\n",
    "        self.ffn_final_layer = nn.Linear(input_dim, output_dim)\n",
    "\n",
    "    def forward(self, x: torch.Tensor):\n",
    "        # x has dimensions [batch, length of signal, channels]\n",
    "\n",
    "        # convolution\n",
    "        if self.augmentation_type == \"Conv1d\":\n",
    "            # input has dimensions [batch, length of signal, channels]\n",
    "            # swap dimensions to get [batch, channels, length of signal]\n",
    "            # (nn.Conv1d expects this)\n",
    "            out = torch.transpose(x, 1, 2)\n",
    "            # get only the path information\n",
    "            out = self.conv(out[:, : self.input_channels, :])\n",
    "            out = self.tanh1(out)\n",
    "            # make output have dimensions [batch, length of signal, channels]\n",
    "            out = torch.transpose(out, 1, 2)\n",
    "        elif self.augmentation_type == \"signatory\":\n",
    "            # input has dimensions [batch, length of signal, channels]\n",
    "            # (signatory.Augment expects this)\n",
    "            # and get only the path information\n",
    "            # output has dimensions [batch, length of signal, channels]\n",
    "            out = self.augment(x[:, :, : self.input_channels])\n",
    "\n",
    "        # take signature lifts and lstm\n",
    "        for l in range(len(self.hidden_dim_lstm)):\n",
    "            out = self.signature_layers[l](out)\n",
    "            out, _ = self.lstm_layers[l](out)\n",
    "        \n",
    "        # signature\n",
    "        out = self.signature2(out)\n",
    "\n",
    "        # combine last post embedding\n",
    "        if x.shape[2] > self.input_channels:\n",
    "            # we have things to concatenate to the path\n",
    "            if self.comb_method == \"concatenation\":\n",
    "                if self.num_time_features > 0:\n",
    "                    # concatenate any time features\n",
    "                    # take the maximum for the latest time\n",
    "                    out = torch.cat(\n",
    "                        (\n",
    "                            out,\n",
    "                            x[\n",
    "                                :,\n",
    "                                :,\n",
    "                                self.input_channels : (\n",
    "                                    self.input_channels + self.num_time_features\n",
    "                                ),\n",
    "                            ].max(1)[0],\n",
    "                        ),\n",
    "                        dim=1,\n",
    "                    )\n",
    "                if x.shape[2] > self.input_channels + self.num_time_features:\n",
    "                    # concatenate current post embedding if provided\n",
    "                    out = torch.cat(\n",
    "                        (\n",
    "                            out,\n",
    "                            x[:, 0, (self.input_channels + self.num_time_features) :],\n",
    "                        ),\n",
    "                        dim=1,\n",
    "                    )\n",
    "            elif self.comb_method == \"gated_addition\":\n",
    "                if self.num_time_features > 0:\n",
    "                    # concatenate any time features\n",
    "                    out_gated = torch.cat(\n",
    "                        (\n",
    "                            out,\n",
    "                            x[\n",
    "                                :,\n",
    "                                :,\n",
    "                                self.input_channels : (\n",
    "                                    self.input_channels + self.num_time_features\n",
    "                                ),\n",
    "                            ].max(1)[0],\n",
    "                        ),\n",
    "                        dim=1,\n",
    "                    )\n",
    "                else:\n",
    "                    out_gated = out\n",
    "                out_gated = self.fc_scale(out_gated.float())\n",
    "                out_gated = self.tanh2(out_gated)\n",
    "                out_gated = torch.mul(self.scaler, out_gated)\n",
    "                if x.shape[2] > self.input_channels + self.num_time_features:\n",
    "                    # concatenate current post embedding if provided\n",
    "                    out = (\n",
    "                        out_gated\n",
    "                        + x[:, 0, (self.input_channels + self.num_time_features) :],\n",
    "                    )\n",
    "                else:\n",
    "                    out = out_gated\n",
    "\n",
    "        # FFN: input layer\n",
    "        out = self.ffn_input_layer(out)\n",
    "        out = self.relu(out)\n",
    "        out = self.dropout(out)\n",
    "        \n",
    "        # FFN: hidden layers    \n",
    "        for l in range(len(self.hidden_dim_ffn)):\n",
    "            out = self.ffn_linear_layers[l](out)\n",
    "            out = self.ffn_non_linear_layers[l](out)\n",
    "            out = self.dropout_layers[l](out)\n",
    "\n",
    "        # FFN: readout\n",
    "        out = self.ffn_final_layer(out)\n",
    "\n",
    "        return out\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 217,
   "id": "57cabd51",
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[INFO] Concatenating the embeddings to the dataframe...\n",
      "[INFO] - columns beginning with 'e' denote the full embddings.\n",
      "[INFO] - columns beginning with 'd' denote the dimension reduced embeddings.\n",
      "[INFO] Adding time feature columns into dataframe in `.df`.\n",
      "[INFO] Adding 'time_encoding' and feature...\n",
      "[INFO] Adding 'time_diff' and feature...\n",
      "[INFO] Adding 'timeline_index' feature...\n",
      "[INFO] Padding ids and storing in `.df_padded` and `.array_padded` attributes.\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "2658498aa3f043ccb3a52321e2408124",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/13551 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[INFO] The path was created for each item in the dataframe, by looking at its history, so to include embeddings in the FFN input, we concatenate the embeddings for each sentence / text.\n",
      "\n",
      "********** lstm_hidden_dim: [8, 8] || ffnhidden_dim: [100, 100]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/var/folders/l7/bnn1j6bs3bqfskq2jlq55yh80000gr/T/ipykernel_51169/2493663396.py:31: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  train, valid, test = split_dataset(x_data=torch.tensor(x_data).float(),\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "4324169baad048189970a3a16e7ddbab",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/10000 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 1/10000 || Item: 0/85 || Loss: 1.06357741355896\n",
      "--------------------------------------------------\n",
      "##### Epoch: 1/10000 || Loss: 1.0295138359069824\n",
      "--------------------------------------------------\n",
      "Validation || Epoch: 1 || Loss: 0.9790611267089844 || Accuracy: 0.6225854158401489 || F1-score: 0.25579975579975583\n",
      "Epoch: 101/10000 || Item: 0/85 || Loss: 0.6608085036277771\n",
      "--------------------------------------------------\n",
      "##### Epoch: 101/10000 || Loss: 0.4031231105327606\n",
      "--------------------------------------------------\n",
      "Validation || Epoch: 101 || Loss: 0.6909303990277377 || Accuracy: 0.7043090462684631 || F1-score: 0.57423324479462\n",
      "Early stopping at epoch 143!\n",
      "Accuracy on dataset of size 672: 70.68452453613281 %.\n",
      "Average loss: 0.7206933064894243\n",
      "proportion of labels in prediction: [tensor(0.7247), tensor(0.1815), tensor(0.0938)]\n",
      "proportion of labels in data: [tensor(0.6235), tensor(0.2232), tensor(0.1533)]\n",
      "- f1: [0.81236203 0.53676471 0.40963855]\n",
      "- f1 (average): 0.5862550970014325\n",
      "- accuracy: 0.706845223903656\n",
      "\n",
      "********** lstm_hidden_dim: [8, 8] || ffnhidden_dim: [100, 100, 100]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/var/folders/l7/bnn1j6bs3bqfskq2jlq55yh80000gr/T/ipykernel_51169/2493663396.py:31: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  train, valid, test = split_dataset(x_data=torch.tensor(x_data).float(),\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "f0a088d6cbf74f5e97f1166965cda996",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/10000 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 1/10000 || Item: 0/85 || Loss: 1.0883405208587646\n",
      "--------------------------------------------------\n",
      "##### Epoch: 1/10000 || Loss: 1.0826038122177124\n",
      "--------------------------------------------------\n",
      "Validation || Epoch: 1 || Loss: 1.011209325356917 || Accuracy: 0.6225854158401489 || F1-score: 0.25579975579975583\n",
      "Epoch: 101/10000 || Item: 0/85 || Loss: 0.7276307940483093\n",
      "--------------------------------------------------\n",
      "##### Epoch: 101/10000 || Loss: 0.10399860888719559\n",
      "--------------------------------------------------\n",
      "Validation || Epoch: 101 || Loss: 0.736944171515378 || Accuracy: 0.7132243514060974 || F1-score: 0.5956179878008959\n",
      "Early stopping at epoch 150!\n",
      "Accuracy on dataset of size 672: 71.2797622680664 %.\n",
      "Average loss: 0.7714293544942682\n",
      "proportion of labels in prediction: [tensor(0.7217), tensor(0.1741), tensor(0.1042)]\n",
      "proportion of labels in data: [tensor(0.6235), tensor(0.2232), tensor(0.1533)]\n",
      "- f1: [0.8119469  0.55430712 0.43930636]\n",
      "- f1 (average): 0.6018534590470797\n",
      "- accuracy: 0.7127976417541504\n",
      "\n",
      "********** lstm_hidden_dim: [8, 8] || ffnhidden_dim: [100, 100, 100, 100]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/var/folders/l7/bnn1j6bs3bqfskq2jlq55yh80000gr/T/ipykernel_51169/2493663396.py:31: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  train, valid, test = split_dataset(x_data=torch.tensor(x_data).float(),\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "4be0f1f22e5e4d279b0a2654f3b2429a",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/10000 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 1/10000 || Item: 0/85 || Loss: 1.115033507347107\n",
      "--------------------------------------------------\n",
      "##### Epoch: 1/10000 || Loss: 1.0796059370040894\n",
      "--------------------------------------------------\n",
      "Validation || Epoch: 1 || Loss: 1.0137215581807224 || Accuracy: 0.6225854158401489 || F1-score: 0.25579975579975583\n",
      "Epoch: 101/10000 || Item: 0/85 || Loss: 0.7191870212554932\n",
      "--------------------------------------------------\n",
      "##### Epoch: 101/10000 || Loss: 0.17231343686580658\n",
      "--------------------------------------------------\n",
      "Validation || Epoch: 101 || Loss: 0.7580459117889404 || Accuracy: 0.7132243514060974 || F1-score: 0.5737328833974377\n",
      "Early stopping at epoch 171!\n",
      "Accuracy on dataset of size 672: 70.98213958740234 %.\n",
      "Average loss: 0.7812599377198652\n",
      "proportion of labels in prediction: [tensor(0.7396), tensor(0.1607), tensor(0.0997)]\n",
      "proportion of labels in data: [tensor(0.6235), tensor(0.2232), tensor(0.1533)]\n",
      "- f1: [0.81441048 0.51162791 0.44705882]\n",
      "- f1 (average): 0.5910324036185003\n",
      "- accuracy: 0.7098214030265808\n",
      "\n",
      "********** lstm_hidden_dim: [8, 8] || ffnhidden_dim: [100, 100, 100, 100, 100]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/var/folders/l7/bnn1j6bs3bqfskq2jlq55yh80000gr/T/ipykernel_51169/2493663396.py:31: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  train, valid, test = split_dataset(x_data=torch.tensor(x_data).float(),\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "da3cf25949d645a59c82b18f9afb1e9c",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/10000 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 1/10000 || Item: 0/85 || Loss: 1.0850569009780884\n",
      "--------------------------------------------------\n",
      "##### Epoch: 1/10000 || Loss: 1.0340579748153687\n",
      "--------------------------------------------------\n",
      "Validation || Epoch: 1 || Loss: 0.9858841733499006 || Accuracy: 0.6225854158401489 || F1-score: 0.25579975579975583\n",
      "Epoch: 101/10000 || Item: 0/85 || Loss: 0.7220345735549927\n",
      "--------------------------------------------------\n",
      "##### Epoch: 101/10000 || Loss: 1.0345451831817627\n",
      "--------------------------------------------------\n",
      "Validation || Epoch: 101 || Loss: 0.7413348393006758 || Accuracy: 0.6805348992347717 || F1-score: 0.4281073446327684\n",
      "Early stopping at epoch 132!\n",
      "Accuracy on dataset of size 672: 67.41071319580078 %.\n",
      "Average loss: 0.7796666893092069\n",
      "proportion of labels in prediction: [tensor(0.7738), tensor(0.2262), tensor(0.)]\n",
      "proportion of labels in data: [tensor(0.6235), tensor(0.2232), tensor(0.1533)]\n",
      "- f1: [0.81576145 0.46357616 0.        ]\n",
      "- f1 (average): 0.4264458690965684\n",
      "- accuracy: 0.6741071343421936\n",
      "\n",
      "********** lstm_hidden_dim: [12, 12, 8] || ffnhidden_dim: [100, 100]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/var/folders/l7/bnn1j6bs3bqfskq2jlq55yh80000gr/T/ipykernel_51169/2493663396.py:31: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  train, valid, test = split_dataset(x_data=torch.tensor(x_data).float(),\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "3d9fe5876b6f416aa03ee35c5e7c37ae",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/10000 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 1/10000 || Item: 0/85 || Loss: 1.2992570400238037\n",
      "--------------------------------------------------\n",
      "##### Epoch: 1/10000 || Loss: 1.0141891241073608\n",
      "--------------------------------------------------\n",
      "Validation || Epoch: 1 || Loss: 0.9963395866480741 || Accuracy: 0.6225854158401489 || F1-score: 0.25579975579975583\n",
      "Epoch: 101/10000 || Item: 0/85 || Loss: 0.6954364776611328\n",
      "--------------------------------------------------\n",
      "##### Epoch: 101/10000 || Loss: 0.3070055842399597\n",
      "--------------------------------------------------\n",
      "Validation || Epoch: 101 || Loss: 0.7299812002615496 || Accuracy: 0.7087666988372803 || F1-score: 0.5842389192171975\n",
      "Early stopping at epoch 143!\n",
      "Accuracy on dataset of size 672: 70.83333587646484 %.\n",
      "Average loss: 0.7468507777560841\n",
      "proportion of labels in prediction: [tensor(0.7455), tensor(0.1622), tensor(0.0923)]\n",
      "proportion of labels in data: [tensor(0.6235), tensor(0.2232), tensor(0.1533)]\n",
      "- f1: [0.81304348 0.51737452 0.42424242]\n",
      "- f1 (average): 0.5848868066259371\n",
      "- accuracy: 0.7083333134651184\n",
      "\n",
      "********** lstm_hidden_dim: [12, 12, 8] || ffnhidden_dim: [100, 100, 100]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/var/folders/l7/bnn1j6bs3bqfskq2jlq55yh80000gr/T/ipykernel_51169/2493663396.py:31: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  train, valid, test = split_dataset(x_data=torch.tensor(x_data).float(),\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "97ddccbb15cd4813ad9cfbd70abf2aca",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/10000 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 1/10000 || Item: 0/85 || Loss: 1.0792440176010132\n",
      "--------------------------------------------------\n",
      "##### Epoch: 1/10000 || Loss: 1.0634193420410156\n",
      "--------------------------------------------------\n",
      "Validation || Epoch: 1 || Loss: 1.004805174740878 || Accuracy: 0.6225854158401489 || F1-score: 0.25579975579975583\n",
      "Epoch: 101/10000 || Item: 0/85 || Loss: 0.7142853736877441\n",
      "--------------------------------------------------\n",
      "##### Epoch: 101/10000 || Loss: 0.10122737288475037\n",
      "--------------------------------------------------\n",
      "Validation || Epoch: 101 || Loss: 0.7249864664944735 || Accuracy: 0.699851393699646 || F1-score: 0.5725833083379148\n",
      "Early stopping at epoch 146!\n",
      "Accuracy on dataset of size 672: 70.08928680419922 %.\n",
      "Average loss: 0.766713722185655\n",
      "proportion of labels in prediction: [tensor(0.7158), tensor(0.1652), tensor(0.1190)]\n",
      "proportion of labels in data: [tensor(0.6235), tensor(0.2232), tensor(0.1533)]\n",
      "- f1: [0.81111111 0.49808429 0.44808743]\n",
      "- f1 (average): 0.5857609446642799\n",
      "- accuracy: 0.7008928656578064\n",
      "\n",
      "********** lstm_hidden_dim: [12, 12, 8] || ffnhidden_dim: [100, 100, 100, 100]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/var/folders/l7/bnn1j6bs3bqfskq2jlq55yh80000gr/T/ipykernel_51169/2493663396.py:31: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  train, valid, test = split_dataset(x_data=torch.tensor(x_data).float(),\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "07f55bcc4f7f4b16a045d1e3ebb937c2",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/10000 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 1/10000 || Item: 0/85 || Loss: 1.138651967048645\n",
      "--------------------------------------------------\n",
      "##### Epoch: 1/10000 || Loss: 1.0537822246551514\n",
      "--------------------------------------------------\n",
      "Validation || Epoch: 1 || Loss: 1.0088018070567737 || Accuracy: 0.6225854158401489 || F1-score: 0.25579975579975583\n",
      "Epoch: 101/10000 || Item: 0/85 || Loss: 0.7623844742774963\n",
      "--------------------------------------------------\n",
      "##### Epoch: 101/10000 || Loss: 0.11575664579868317\n",
      "--------------------------------------------------\n",
      "Validation || Epoch: 101 || Loss: 0.7634969407861883 || Accuracy: 0.7087666988372803 || F1-score: 0.572342995169082\n",
      "Early stopping at epoch 157!\n",
      "Accuracy on dataset of size 672: 70.38690185546875 %.\n",
      "Average loss: 0.7467622756958008\n",
      "proportion of labels in prediction: [tensor(0.7202), tensor(0.1756), tensor(0.1042)]\n",
      "proportion of labels in data: [tensor(0.6235), tensor(0.2232), tensor(0.1533)]\n",
      "- f1: [0.81284607 0.51492537 0.42774566]\n",
      "- f1 (average): 0.585172368844745\n",
      "- accuracy: 0.7038690447807312\n",
      "\n",
      "********** lstm_hidden_dim: [12, 12, 8] || ffnhidden_dim: [100, 100, 100, 100, 100]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/var/folders/l7/bnn1j6bs3bqfskq2jlq55yh80000gr/T/ipykernel_51169/2493663396.py:31: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  train, valid, test = split_dataset(x_data=torch.tensor(x_data).float(),\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "387fc30fb364455ba97488b6ac1d726a",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/10000 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 1/10000 || Item: 0/85 || Loss: 1.1052340269088745\n",
      "--------------------------------------------------\n",
      "##### Epoch: 1/10000 || Loss: 1.070438027381897\n",
      "--------------------------------------------------\n",
      "Validation || Epoch: 1 || Loss: 1.0075113394043662 || Accuracy: 0.6225854158401489 || F1-score: 0.25579975579975583\n",
      "Epoch: 101/10000 || Item: 0/85 || Loss: 0.738377571105957\n",
      "--------------------------------------------------\n",
      "##### Epoch: 101/10000 || Loss: 1.0748851299285889\n",
      "--------------------------------------------------\n",
      "Validation || Epoch: 101 || Loss: 0.7502310384403575 || Accuracy: 0.689450204372406 || F1-score: 0.43603099875600565\n",
      "Epoch: 201/10000 || Item: 0/85 || Loss: 0.5760343074798584\n",
      "--------------------------------------------------\n",
      "##### Epoch: 201/10000 || Loss: 1.0272172689437866\n",
      "--------------------------------------------------\n",
      "Validation || Epoch: 201 || Loss: 0.7527173920111223 || Accuracy: 0.689450204372406 || F1-score: 0.43603099875600565\n",
      "Epoch: 301/10000 || Item: 0/85 || Loss: 0.6388217806816101\n",
      "--------------------------------------------------\n",
      "##### Epoch: 301/10000 || Loss: 0.21651318669319153\n",
      "--------------------------------------------------\n",
      "Validation || Epoch: 301 || Loss: 0.7550506754354998 || Accuracy: 0.6879643201828003 || F1-score: 0.43417475214979695\n",
      "Epoch: 401/10000 || Item: 0/85 || Loss: 0.676782488822937\n",
      "--------------------------------------------------\n",
      "##### Epoch: 401/10000 || Loss: 0.8313260674476624\n",
      "--------------------------------------------------\n",
      "Validation || Epoch: 401 || Loss: 0.7544802156361666 || Accuracy: 0.689450204372406 || F1-score: 0.43603099875600565\n",
      "Epoch: 501/10000 || Item: 0/85 || Loss: 0.8746481537818909\n",
      "--------------------------------------------------\n",
      "##### Epoch: 501/10000 || Loss: 1.1310193538665771\n",
      "--------------------------------------------------\n",
      "Validation || Epoch: 501 || Loss: 0.7444753755222667 || Accuracy: 0.689450204372406 || F1-score: 0.43603099875600565\n",
      "Epoch: 601/10000 || Item: 0/85 || Loss: 0.657050609588623\n",
      "--------------------------------------------------\n",
      "##### Epoch: 601/10000 || Loss: 0.13497105240821838\n",
      "--------------------------------------------------\n",
      "Validation || Epoch: 601 || Loss: 0.7478301741860129 || Accuracy: 0.689450204372406 || F1-score: 0.43625159534813546\n",
      "Epoch: 701/10000 || Item: 0/85 || Loss: 0.7538775205612183\n",
      "--------------------------------------------------\n",
      "##### Epoch: 701/10000 || Loss: 0.486049085855484\n",
      "--------------------------------------------------\n",
      "Validation || Epoch: 701 || Loss: 0.7560241330753673 || Accuracy: 0.689450204372406 || F1-score: 0.43625159534813546\n",
      "Epoch: 801/10000 || Item: 0/85 || Loss: 0.6554787158966064\n",
      "--------------------------------------------------\n",
      "##### Epoch: 801/10000 || Loss: 1.0868604183197021\n",
      "--------------------------------------------------\n",
      "Validation || Epoch: 801 || Loss: 0.7449611858888106 || Accuracy: 0.689450204372406 || F1-score: 0.43625159534813546\n",
      "Epoch: 901/10000 || Item: 0/85 || Loss: 0.7631614208221436\n",
      "--------------------------------------------------\n",
      "##### Epoch: 901/10000 || Loss: 0.9777164459228516\n",
      "--------------------------------------------------\n",
      "Validation || Epoch: 901 || Loss: 0.7626806660131975 || Accuracy: 0.689450204372406 || F1-score: 0.43625159534813546\n",
      "Epoch: 1001/10000 || Item: 0/85 || Loss: 0.902120053768158\n",
      "--------------------------------------------------\n",
      "##### Epoch: 1001/10000 || Loss: 0.7022605538368225\n",
      "--------------------------------------------------\n",
      "Validation || Epoch: 1001 || Loss: 0.7566509246826172 || Accuracy: 0.689450204372406 || F1-score: 0.43625159534813546\n",
      "Epoch: 1101/10000 || Item: 0/85 || Loss: 0.6397838592529297\n",
      "--------------------------------------------------\n",
      "##### Epoch: 1101/10000 || Loss: 0.9946888089179993\n",
      "--------------------------------------------------\n",
      "Validation || Epoch: 1101 || Loss: 0.7539483471350237 || Accuracy: 0.689450204372406 || F1-score: 0.43625159534813546\n",
      "Epoch: 1201/10000 || Item: 0/85 || Loss: 0.6906268000602722\n",
      "--------------------------------------------------\n",
      "##### Epoch: 1201/10000 || Loss: 0.671633243560791\n",
      "--------------------------------------------------\n",
      "Validation || Epoch: 1201 || Loss: 0.7480889829722318 || Accuracy: 0.689450204372406 || F1-score: 0.43625159534813546\n",
      "Epoch: 1301/10000 || Item: 0/85 || Loss: 0.7535486221313477\n",
      "--------------------------------------------------\n",
      "##### Epoch: 1301/10000 || Loss: 0.1467968225479126\n",
      "--------------------------------------------------\n",
      "Validation || Epoch: 1301 || Loss: 0.7608666149052706 || Accuracy: 0.689450204372406 || F1-score: 0.43625159534813546\n",
      "Epoch: 1401/10000 || Item: 0/85 || Loss: 0.7018153667449951\n",
      "--------------------------------------------------\n",
      "##### Epoch: 1401/10000 || Loss: 0.5142464637756348\n",
      "--------------------------------------------------\n",
      "Validation || Epoch: 1401 || Loss: 0.7509182745760138 || Accuracy: 0.689450204372406 || F1-score: 0.43625159534813546\n",
      "Epoch: 1501/10000 || Item: 0/85 || Loss: 0.7131308913230896\n",
      "--------------------------------------------------\n",
      "##### Epoch: 1501/10000 || Loss: 0.6685365438461304\n",
      "--------------------------------------------------\n",
      "Validation || Epoch: 1501 || Loss: 0.7537955425002358 || Accuracy: 0.689450204372406 || F1-score: 0.43625159534813546\n",
      "Epoch: 1601/10000 || Item: 0/85 || Loss: 0.6028388738632202\n",
      "--------------------------------------------------\n",
      "##### Epoch: 1601/10000 || Loss: 0.14773590862751007\n",
      "--------------------------------------------------\n",
      "Validation || Epoch: 1601 || Loss: 0.7525812983512878 || Accuracy: 0.689450204372406 || F1-score: 0.43625159534813546\n",
      "Epoch: 1701/10000 || Item: 0/85 || Loss: 0.7918387651443481\n",
      "--------------------------------------------------\n",
      "##### Epoch: 1701/10000 || Loss: 0.9049937129020691\n",
      "--------------------------------------------------\n",
      "Validation || Epoch: 1701 || Loss: 0.7506674853238192 || Accuracy: 0.689450204372406 || F1-score: 0.43625159534813546\n",
      "Epoch: 1801/10000 || Item: 0/85 || Loss: 0.9321761727333069\n",
      "--------------------------------------------------\n",
      "##### Epoch: 1801/10000 || Loss: 0.3448408246040344\n",
      "--------------------------------------------------\n",
      "Validation || Epoch: 1801 || Loss: 0.7518258094787598 || Accuracy: 0.689450204372406 || F1-score: 0.43625159534813546\n",
      "Epoch: 1901/10000 || Item: 0/85 || Loss: 0.6119500994682312\n",
      "--------------------------------------------------\n",
      "##### Epoch: 1901/10000 || Loss: 0.3660503327846527\n",
      "--------------------------------------------------\n",
      "Validation || Epoch: 1901 || Loss: 0.75157677043568 || Accuracy: 0.689450204372406 || F1-score: 0.43625159534813546\n",
      "Epoch: 2001/10000 || Item: 0/85 || Loss: 0.47512897849082947\n",
      "--------------------------------------------------\n",
      "##### Epoch: 2001/10000 || Loss: 0.6459852457046509\n",
      "--------------------------------------------------\n",
      "Validation || Epoch: 2001 || Loss: 0.7620697184042498 || Accuracy: 0.689450204372406 || F1-score: 0.43625159534813546\n",
      "Epoch: 2101/10000 || Item: 0/85 || Loss: 0.766838788986206\n",
      "--------------------------------------------------\n",
      "##### Epoch: 2101/10000 || Loss: 0.807350754737854\n",
      "--------------------------------------------------\n",
      "Validation || Epoch: 2101 || Loss: 0.7556932622736151 || Accuracy: 0.689450204372406 || F1-score: 0.43625159534813546\n",
      "Epoch: 2201/10000 || Item: 0/85 || Loss: 0.7125132083892822\n",
      "--------------------------------------------------\n",
      "##### Epoch: 2201/10000 || Loss: 0.6175326108932495\n",
      "--------------------------------------------------\n",
      "Validation || Epoch: 2201 || Loss: 0.7533401846885681 || Accuracy: 0.689450204372406 || F1-score: 0.43625159534813546\n",
      "Epoch: 2301/10000 || Item: 0/85 || Loss: 0.6771906018257141\n",
      "--------------------------------------------------\n",
      "##### Epoch: 2301/10000 || Loss: 0.7682132124900818\n",
      "--------------------------------------------------\n",
      "Validation || Epoch: 2301 || Loss: 0.7533803907307711 || Accuracy: 0.689450204372406 || F1-score: 0.43625159534813546\n",
      "Epoch: 2401/10000 || Item: 0/85 || Loss: 0.8423407077789307\n",
      "--------------------------------------------------\n",
      "##### Epoch: 2401/10000 || Loss: 0.5043448805809021\n",
      "--------------------------------------------------\n",
      "Validation || Epoch: 2401 || Loss: 0.7563231045549567 || Accuracy: 0.689450204372406 || F1-score: 0.43625159534813546\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 2501/10000 || Item: 0/85 || Loss: 0.7550318837165833\n",
      "--------------------------------------------------\n",
      "##### Epoch: 2501/10000 || Loss: 0.6395190954208374\n",
      "--------------------------------------------------\n",
      "Validation || Epoch: 2501 || Loss: 0.7601532719352029 || Accuracy: 0.689450204372406 || F1-score: 0.43625159534813546\n",
      "Epoch: 2601/10000 || Item: 0/85 || Loss: 0.7484893798828125\n",
      "--------------------------------------------------\n",
      "##### Epoch: 2601/10000 || Loss: 0.6841627359390259\n",
      "--------------------------------------------------\n",
      "Validation || Epoch: 2601 || Loss: 0.7601483139124784 || Accuracy: 0.689450204372406 || F1-score: 0.43625159534813546\n",
      "Epoch: 2701/10000 || Item: 0/85 || Loss: 0.6809874773025513\n",
      "--------------------------------------------------\n",
      "##### Epoch: 2701/10000 || Loss: 0.5480964779853821\n",
      "--------------------------------------------------\n",
      "Validation || Epoch: 2701 || Loss: 0.7565477219494906 || Accuracy: 0.689450204372406 || F1-score: 0.43625159534813546\n",
      "Early stopping at epoch 2763!\n",
      "Accuracy on dataset of size 672: 67.85713958740234 %.\n",
      "Average loss: 0.7775472077456388\n",
      "proportion of labels in prediction: [tensor(0.7783), tensor(0.2217), tensor(0.)]\n",
      "proportion of labels in data: [tensor(0.6235), tensor(0.2232), tensor(0.1533)]\n",
      "- f1: [0.81953291 0.46822742 0.        ]\n",
      "- f1 (average): 0.42925344448468233\n",
      "- accuracy: 0.6785714030265808\n",
      "\n",
      "********** lstm_hidden_dim: [12, 12, 12, 8] || ffnhidden_dim: [100, 100]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/var/folders/l7/bnn1j6bs3bqfskq2jlq55yh80000gr/T/ipykernel_51169/2493663396.py:31: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  train, valid, test = split_dataset(x_data=torch.tensor(x_data).float(),\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "76316e9208b34b588a8c9f1b6320ab99",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/10000 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 1/10000 || Item: 0/85 || Loss: 1.1839221715927124\n",
      "--------------------------------------------------\n",
      "##### Epoch: 1/10000 || Loss: 1.058618426322937\n",
      "--------------------------------------------------\n",
      "Validation || Epoch: 1 || Loss: 0.9997325431216847 || Accuracy: 0.6225854158401489 || F1-score: 0.25579975579975583\n",
      "Epoch: 101/10000 || Item: 0/85 || Loss: 0.6837211847305298\n",
      "--------------------------------------------------\n",
      "##### Epoch: 101/10000 || Loss: 0.3611336648464203\n",
      "--------------------------------------------------\n",
      "Validation || Epoch: 101 || Loss: 0.6946919939734719 || Accuracy: 0.7087666988372803 || F1-score: 0.5921402965791092\n",
      "Early stopping at epoch 143!\n",
      "Accuracy on dataset of size 672: 71.13095092773438 %.\n",
      "Average loss: 0.7421822385354475\n",
      "proportion of labels in prediction: [tensor(0.7292), tensor(0.1756), tensor(0.0952)]\n",
      "proportion of labels in data: [tensor(0.6235), tensor(0.2232), tensor(0.1533)]\n",
      "- f1: [0.81628163 0.54477612 0.40718563]\n",
      "- f1 (average): 0.5894144587694389\n",
      "- accuracy: 0.711309552192688\n",
      "\n",
      "********** lstm_hidden_dim: [12, 12, 12, 8] || ffnhidden_dim: [100, 100, 100]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/var/folders/l7/bnn1j6bs3bqfskq2jlq55yh80000gr/T/ipykernel_51169/2493663396.py:31: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  train, valid, test = split_dataset(x_data=torch.tensor(x_data).float(),\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "bf6cd682867d41b4b38dd600531db581",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/10000 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 1/10000 || Item: 0/85 || Loss: 1.107619047164917\n",
      "--------------------------------------------------\n",
      "##### Epoch: 1/10000 || Loss: 1.0343412160873413\n",
      "--------------------------------------------------\n",
      "Validation || Epoch: 1 || Loss: 0.9972853606397455 || Accuracy: 0.6225854158401489 || F1-score: 0.25579975579975583\n",
      "Epoch: 101/10000 || Item: 0/85 || Loss: 0.736257791519165\n",
      "--------------------------------------------------\n",
      "##### Epoch: 101/10000 || Loss: 0.0675061047077179\n",
      "--------------------------------------------------\n",
      "Validation || Epoch: 101 || Loss: 0.7377959814938632 || Accuracy: 0.7043090462684631 || F1-score: 0.5648561298637451\n",
      "Early stopping at epoch 146!\n",
      "Accuracy on dataset of size 672: 71.57737731933594 %.\n",
      "Average loss: 0.7729015296155756\n",
      "proportion of labels in prediction: [tensor(0.7277), tensor(0.1756), tensor(0.0967)]\n",
      "proportion of labels in data: [tensor(0.6235), tensor(0.2232), tensor(0.1533)]\n",
      "- f1: [0.81938326 0.52985075 0.45238095]\n",
      "- f1 (average): 0.6005383195205011\n",
      "- accuracy: 0.7157738208770752\n",
      "\n",
      "********** lstm_hidden_dim: [12, 12, 12, 8] || ffnhidden_dim: [100, 100, 100, 100]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/var/folders/l7/bnn1j6bs3bqfskq2jlq55yh80000gr/T/ipykernel_51169/2493663396.py:31: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  train, valid, test = split_dataset(x_data=torch.tensor(x_data).float(),\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "bdda3e4acd334bca91c709de6a8e104d",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/10000 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 1/10000 || Item: 0/85 || Loss: 1.1259416341781616\n",
      "--------------------------------------------------\n",
      "##### Epoch: 1/10000 || Loss: 1.0837455987930298\n",
      "--------------------------------------------------\n",
      "Validation || Epoch: 1 || Loss: 1.0123418732122942 || Accuracy: 0.6225854158401489 || F1-score: 0.25579975579975583\n",
      "Epoch: 101/10000 || Item: 0/85 || Loss: 0.9185170531272888\n",
      "--------------------------------------------------\n",
      "##### Epoch: 101/10000 || Loss: 0.23807857930660248\n",
      "--------------------------------------------------\n",
      "Validation || Epoch: 101 || Loss: 0.7706064636057074 || Accuracy: 0.6671619415283203 || F1-score: 0.42035928143712575\n",
      "Early stopping at epoch 130!\n",
      "Accuracy on dataset of size 672: 67.41071319580078 %.\n",
      "Average loss: 0.7694918459111993\n",
      "proportion of labels in prediction: [tensor(0.7649), tensor(0.2351), tensor(0.)]\n",
      "proportion of labels in data: [tensor(0.6235), tensor(0.2232), tensor(0.1533)]\n",
      "- f1: [0.81672026 0.46753247 0.        ]\n",
      "- f1 (average): 0.4280842415890647\n",
      "- accuracy: 0.6741071343421936\n",
      "\n",
      "********** lstm_hidden_dim: [12, 12, 12, 8] || ffnhidden_dim: [100, 100, 100, 100, 100]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/var/folders/l7/bnn1j6bs3bqfskq2jlq55yh80000gr/T/ipykernel_51169/2493663396.py:31: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  train, valid, test = split_dataset(x_data=torch.tensor(x_data).float(),\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "a3ecb7c208cb41d4aa89e9cdf3841d8f",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/10000 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 1/10000 || Item: 0/85 || Loss: 1.0599114894866943\n",
      "--------------------------------------------------\n",
      "##### Epoch: 1/10000 || Loss: 1.0687390565872192\n",
      "--------------------------------------------------\n",
      "Validation || Epoch: 1 || Loss: 0.9648291631178423 || Accuracy: 0.6225854158401489 || F1-score: 0.25579975579975583\n",
      "Epoch: 101/10000 || Item: 0/85 || Loss: 0.7561215758323669\n",
      "--------------------------------------------------\n",
      "##### Epoch: 101/10000 || Loss: 0.990820050239563\n",
      "--------------------------------------------------\n",
      "Validation || Epoch: 101 || Loss: 0.7462477900765159 || Accuracy: 0.6849925518035889 || F1-score: 0.4368428578954895\n",
      "Early stopping at epoch 133!\n",
      "Accuracy on dataset of size 672: 66.66666412353516 %.\n",
      "Average loss: 0.7871717052026228\n",
      "proportion of labels in prediction: [tensor(0.7604), tensor(0.2396), tensor(0.)]\n",
      "proportion of labels in data: [tensor(0.6235), tensor(0.2232), tensor(0.1533)]\n",
      "- f1: [0.80860215 0.46302251 0.        ]\n",
      "- f1 (average): 0.42387488619207314\n",
      "- accuracy: 0.6666666865348816\n"
     ]
    }
   ],
   "source": [
    "x_data, input_channels = obtain_SDSN_input(sbert_768_embeddings, path_specifics)\n",
    "for lstm_hidden_dim in lstm_hidden_dim_trial:\n",
    "    for ffn_hidden_dim in ffn_hidden_dim_trial:\n",
    "        print(f\"\\n********** lstm_hidden_dim: {lstm_hidden_dim} \"\n",
    "              f\"|| ffnhidden_dim: {ffn_hidden_dim}\")\n",
    "        implement_sdsn(x_data=x_data,\n",
    "                       y_data=y_data,\n",
    "                       sig_depth=sig_depth,\n",
    "                       input_channels=input_channels,\n",
    "                       output_channels=output_channels,\n",
    "                       lstm_hidden_dim=lstm_hidden_dim,\n",
    "                       ffn_hidden_dim=ffn_hidden_dim,\n",
    "                       BiLSTM=BiLSTM,\n",
    "                       learning_rate=learning_rate,\n",
    "                       loss=loss)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ab0c9840",
   "metadata": {},
   "source": [
    "## SBERT 384"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 218,
   "id": "c29394db",
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[INFO] Concatenating the embeddings to the dataframe...\n",
      "[INFO] - columns beginning with 'e' denote the full embddings.\n",
      "[INFO] - columns beginning with 'd' denote the dimension reduced embeddings.\n",
      "[INFO] Adding time feature columns into dataframe in `.df`.\n",
      "[INFO] Adding 'time_encoding' and feature...\n",
      "[INFO] Adding 'time_diff' and feature...\n",
      "[INFO] Adding 'timeline_index' feature...\n",
      "[INFO] Padding ids and storing in `.df_padded` and `.array_padded` attributes.\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "bf41cb213e404ed99ec231081bda1ed5",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/13551 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[INFO] The path was created for each item in the dataframe, by looking at its history, so to include embeddings in the FFN input, we concatenate the embeddings for each sentence / text.\n",
      "\n",
      "********** lstm_hidden_dim: [8, 8] || ffnhidden_dim: [100, 100]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/var/folders/l7/bnn1j6bs3bqfskq2jlq55yh80000gr/T/ipykernel_51169/2493663396.py:31: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  train, valid, test = split_dataset(x_data=torch.tensor(x_data).float(),\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "9fb16f7d2edc479ea44af6bf900c91d6",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/10000 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 1/10000 || Item: 0/85 || Loss: 1.121998906135559\n",
      "--------------------------------------------------\n",
      "##### Epoch: 1/10000 || Loss: 1.0471062660217285\n",
      "--------------------------------------------------\n",
      "Validation || Epoch: 1 || Loss: 0.993124701760032 || Accuracy: 0.6225854158401489 || F1-score: 0.25579975579975583\n",
      "Epoch: 101/10000 || Item: 0/85 || Loss: 0.7265946269035339\n",
      "--------------------------------------------------\n",
      "##### Epoch: 101/10000 || Loss: 0.08941896259784698\n",
      "--------------------------------------------------\n",
      "Validation || Epoch: 101 || Loss: 0.7369477315382524 || Accuracy: 0.6939078569412231 || F1-score: 0.5744239507379422\n",
      "Early stopping at epoch 162!\n",
      "Accuracy on dataset of size 672: 70.83333587646484 %.\n",
      "Average loss: 0.7321670651435852\n",
      "proportion of labels in prediction: [tensor(0.7128), tensor(0.1905), tensor(0.0967)]\n",
      "proportion of labels in data: [tensor(0.6235), tensor(0.2232), tensor(0.1533)]\n",
      "- f1: [0.81514477 0.51079137 0.46428571]\n",
      "- f1 (average): 0.5967406157797276\n",
      "- accuracy: 0.7083333134651184\n",
      "\n",
      "********** lstm_hidden_dim: [8, 8] || ffnhidden_dim: [100, 100, 100]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/var/folders/l7/bnn1j6bs3bqfskq2jlq55yh80000gr/T/ipykernel_51169/2493663396.py:31: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  train, valid, test = split_dataset(x_data=torch.tensor(x_data).float(),\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "983f910d03e24cc6ab2b8a41f256e1d0",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/10000 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 1/10000 || Item: 0/85 || Loss: 1.1142566204071045\n",
      "--------------------------------------------------\n",
      "##### Epoch: 1/10000 || Loss: 1.003860354423523\n",
      "--------------------------------------------------\n",
      "Validation || Epoch: 1 || Loss: 0.996264788237485 || Accuracy: 0.6225854158401489 || F1-score: 0.25579975579975583\n",
      "Epoch: 101/10000 || Item: 0/85 || Loss: 0.7522861957550049\n",
      "--------------------------------------------------\n",
      "##### Epoch: 101/10000 || Loss: 0.11122745275497437\n",
      "--------------------------------------------------\n",
      "Validation || Epoch: 101 || Loss: 0.7394544698975303 || Accuracy: 0.6953937411308289 || F1-score: 0.5757383840516413\n",
      "Early stopping at epoch 156!\n",
      "Accuracy on dataset of size 672: 69.94047546386719 %.\n",
      "Average loss: 0.7624564875255931\n",
      "proportion of labels in prediction: [tensor(0.6964), tensor(0.1860), tensor(0.1176)]\n",
      "proportion of labels in data: [tensor(0.6235), tensor(0.2232), tensor(0.1533)]\n",
      "- f1: [0.80045096 0.51636364 0.48351648]\n",
      "- f1 (average): 0.6001103593888262\n",
      "- accuracy: 0.699404776096344\n",
      "\n",
      "********** lstm_hidden_dim: [8, 8] || ffnhidden_dim: [100, 100, 100, 100]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/var/folders/l7/bnn1j6bs3bqfskq2jlq55yh80000gr/T/ipykernel_51169/2493663396.py:31: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  train, valid, test = split_dataset(x_data=torch.tensor(x_data).float(),\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "57472f982c0342cc9197ab5c3e94860f",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/10000 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 1/10000 || Item: 0/85 || Loss: 1.1017228364944458\n",
      "--------------------------------------------------\n",
      "##### Epoch: 1/10000 || Loss: 1.025413990020752\n",
      "--------------------------------------------------\n",
      "Validation || Epoch: 1 || Loss: 0.9970488927581094 || Accuracy: 0.6225854158401489 || F1-score: 0.25579975579975583\n",
      "Epoch: 101/10000 || Item: 0/85 || Loss: 0.9822747707366943\n",
      "--------------------------------------------------\n",
      "##### Epoch: 101/10000 || Loss: 0.37978965044021606\n",
      "--------------------------------------------------\n",
      "Validation || Epoch: 101 || Loss: 0.7980571822686628 || Accuracy: 0.6419019103050232 || F1-score: 0.394701168668628\n",
      "Early stopping at epoch 124!\n",
      "Accuracy on dataset of size 672: 65.92262268066406 %.\n",
      "Average loss: 0.7764183337038214\n",
      "proportion of labels in prediction: [tensor(0.7440), tensor(0.2560), tensor(0.)]\n",
      "proportion of labels in data: [tensor(0.6235), tensor(0.2232), tensor(0.1533)]\n",
      "- f1: [0.81828074 0.41614907 0.        ]\n",
      "- f1 (average): 0.4114766027525644\n",
      "- accuracy: 0.6592261791229248\n",
      "\n",
      "********** lstm_hidden_dim: [8, 8] || ffnhidden_dim: [100, 100, 100, 100, 100]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/var/folders/l7/bnn1j6bs3bqfskq2jlq55yh80000gr/T/ipykernel_51169/2493663396.py:31: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  train, valid, test = split_dataset(x_data=torch.tensor(x_data).float(),\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "1d04deb41e5a48f59521aa850a670ab9",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/10000 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 1/10000 || Item: 0/85 || Loss: 1.1493381261825562\n",
      "--------------------------------------------------\n",
      "##### Epoch: 1/10000 || Loss: 1.092268705368042\n",
      "--------------------------------------------------\n",
      "Validation || Epoch: 1 || Loss: 1.0237938599152998 || Accuracy: 0.6225854158401489 || F1-score: 0.25579975579975583\n",
      "Epoch: 101/10000 || Item: 0/85 || Loss: 0.8685616850852966\n",
      "--------------------------------------------------\n",
      "##### Epoch: 101/10000 || Loss: 0.9867019057273865\n",
      "--------------------------------------------------\n",
      "Validation || Epoch: 101 || Loss: 0.7764909755099904 || Accuracy: 0.6508172154426575 || F1-score: 0.39535462001215427\n",
      "Early stopping at epoch 139!\n",
      "Accuracy on dataset of size 672: 67.11309814453125 %.\n",
      "Average loss: 0.7776664007793773\n",
      "proportion of labels in prediction: [tensor(0.7619), tensor(0.2381), tensor(0.)]\n",
      "proportion of labels in data: [tensor(0.6235), tensor(0.2232), tensor(0.1533)]\n",
      "- f1: [0.82277121 0.43870968 0.        ]\n",
      "- f1 (average): 0.4204936303893374\n",
      "- accuracy: 0.6711309552192688\n",
      "\n",
      "********** lstm_hidden_dim: [12, 12, 8] || ffnhidden_dim: [100, 100]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/var/folders/l7/bnn1j6bs3bqfskq2jlq55yh80000gr/T/ipykernel_51169/2493663396.py:31: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  train, valid, test = split_dataset(x_data=torch.tensor(x_data).float(),\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "f049b7c5fae1460bb7f2094e9c031339",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/10000 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 1/10000 || Item: 0/85 || Loss: 1.2206028699874878\n",
      "--------------------------------------------------\n",
      "##### Epoch: 1/10000 || Loss: 1.0377821922302246\n",
      "--------------------------------------------------\n",
      "Validation || Epoch: 1 || Loss: 0.9940246831287037 || Accuracy: 0.6225854158401489 || F1-score: 0.25579975579975583\n",
      "Epoch: 101/10000 || Item: 0/85 || Loss: 0.7519584894180298\n",
      "--------------------------------------------------\n",
      "##### Epoch: 101/10000 || Loss: 0.13576968014240265\n",
      "--------------------------------------------------\n",
      "Validation || Epoch: 101 || Loss: 0.7378264719789679 || Accuracy: 0.6879643201828003 || F1-score: 0.5288787549764749\n",
      "Early stopping at epoch 148!\n",
      "Accuracy on dataset of size 672: 70.08928680419922 %.\n",
      "Average loss: 0.7749998461116444\n",
      "proportion of labels in prediction: [tensor(0.7307), tensor(0.1756), tensor(0.0938)]\n",
      "proportion of labels in data: [tensor(0.6235), tensor(0.2232), tensor(0.1533)]\n",
      "- f1: [0.80879121 0.50746269 0.42168675]\n",
      "- f1 (average): 0.5793135474487748\n",
      "- accuracy: 0.7008928656578064\n",
      "\n",
      "********** lstm_hidden_dim: [12, 12, 8] || ffnhidden_dim: [100, 100, 100]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/var/folders/l7/bnn1j6bs3bqfskq2jlq55yh80000gr/T/ipykernel_51169/2493663396.py:31: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  train, valid, test = split_dataset(x_data=torch.tensor(x_data).float(),\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "ee7add4f51d249a1a1a3b123fd0c8b73",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/10000 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 1/10000 || Item: 0/85 || Loss: 1.1506388187408447\n",
      "--------------------------------------------------\n",
      "##### Epoch: 1/10000 || Loss: 1.0329482555389404\n",
      "--------------------------------------------------\n",
      "Validation || Epoch: 1 || Loss: 1.014827999201688 || Accuracy: 0.6225854158401489 || F1-score: 0.25579975579975583\n",
      "Epoch: 101/10000 || Item: 0/85 || Loss: 0.7141520380973816\n",
      "--------------------------------------------------\n",
      "##### Epoch: 101/10000 || Loss: 0.15407924354076385\n",
      "--------------------------------------------------\n",
      "Validation || Epoch: 101 || Loss: 0.768506342714483 || Accuracy: 0.6731054782867432 || F1-score: 0.5451255843164818\n",
      "Early stopping at epoch 146!\n",
      "Accuracy on dataset of size 672: 70.23809814453125 %.\n",
      "Average loss: 0.7854068333452399\n",
      "proportion of labels in prediction: [tensor(0.7232), tensor(0.1756), tensor(0.1012)]\n",
      "proportion of labels in data: [tensor(0.6235), tensor(0.2232), tensor(0.1533)]\n",
      "- f1: [0.81104972 0.50746269 0.43274854]\n",
      "- f1 (average): 0.5837536494452552\n",
      "- accuracy: 0.7023809552192688\n",
      "\n",
      "********** lstm_hidden_dim: [12, 12, 8] || ffnhidden_dim: [100, 100, 100, 100]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/var/folders/l7/bnn1j6bs3bqfskq2jlq55yh80000gr/T/ipykernel_51169/2493663396.py:31: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  train, valid, test = split_dataset(x_data=torch.tensor(x_data).float(),\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "024503b0a9864d5496ba90481fa24d66",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/10000 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 1/10000 || Item: 0/85 || Loss: 1.1001724004745483\n",
      "--------------------------------------------------\n",
      "##### Epoch: 1/10000 || Loss: 1.0368224382400513\n",
      "--------------------------------------------------\n",
      "Validation || Epoch: 1 || Loss: 0.9815603982318531 || Accuracy: 0.6225854158401489 || F1-score: 0.25579975579975583\n",
      "Epoch: 101/10000 || Item: 0/85 || Loss: 0.9649040699005127\n",
      "--------------------------------------------------\n",
      "##### Epoch: 101/10000 || Loss: 0.39289215207099915\n",
      "--------------------------------------------------\n",
      "Validation || Epoch: 101 || Loss: 0.7823824503205039 || Accuracy: 0.6656760573387146 || F1-score: 0.4195811292511829\n",
      "Epoch: 201/10000 || Item: 0/85 || Loss: 0.7215513586997986\n",
      "--------------------------------------------------\n",
      "##### Epoch: 201/10000 || Loss: 0.8300783038139343\n",
      "--------------------------------------------------\n",
      "Validation || Epoch: 201 || Loss: 0.772163217717951 || Accuracy: 0.6656760573387146 || F1-score: 0.4195811292511829\n",
      "Epoch: 301/10000 || Item: 0/85 || Loss: 0.6804020404815674\n",
      "--------------------------------------------------\n",
      "##### Epoch: 301/10000 || Loss: 0.24764585494995117\n",
      "--------------------------------------------------\n",
      "Validation || Epoch: 301 || Loss: 0.7764354619112882 || Accuracy: 0.6656760573387146 || F1-score: 0.4195811292511829\n",
      "Epoch: 401/10000 || Item: 0/85 || Loss: 0.6793972253799438\n",
      "--------------------------------------------------\n",
      "##### Epoch: 401/10000 || Loss: 0.8684984445571899\n",
      "--------------------------------------------------\n",
      "Validation || Epoch: 401 || Loss: 0.7801534208384427 || Accuracy: 0.6656760573387146 || F1-score: 0.4195811292511829\n",
      "Epoch: 501/10000 || Item: 0/85 || Loss: 0.7652665376663208\n",
      "--------------------------------------------------\n",
      "##### Epoch: 501/10000 || Loss: 0.3731147050857544\n",
      "--------------------------------------------------\n",
      "Validation || Epoch: 501 || Loss: 0.77033085714687 || Accuracy: 0.6656760573387146 || F1-score: 0.4195811292511829\n",
      "Epoch: 601/10000 || Item: 0/85 || Loss: 0.7626375555992126\n",
      "--------------------------------------------------\n",
      "##### Epoch: 601/10000 || Loss: 0.7281454801559448\n",
      "--------------------------------------------------\n",
      "Validation || Epoch: 601 || Loss: 0.7759761051698164 || Accuracy: 0.6656760573387146 || F1-score: 0.4195811292511829\n",
      "Epoch: 701/10000 || Item: 0/85 || Loss: 0.6168580055236816\n",
      "--------------------------------------------------\n",
      "##### Epoch: 701/10000 || Loss: 0.6262463331222534\n",
      "--------------------------------------------------\n",
      "Validation || Epoch: 701 || Loss: 0.7805378978902643 || Accuracy: 0.6656760573387146 || F1-score: 0.4195811292511829\n",
      "Epoch: 801/10000 || Item: 0/85 || Loss: 0.7934896349906921\n",
      "--------------------------------------------------\n",
      "##### Epoch: 801/10000 || Loss: 0.5733293890953064\n",
      "--------------------------------------------------\n",
      "Validation || Epoch: 801 || Loss: 0.7720185789194974 || Accuracy: 0.6656760573387146 || F1-score: 0.4195811292511829\n",
      "Epoch: 901/10000 || Item: 0/85 || Loss: 0.5904755592346191\n",
      "--------------------------------------------------\n",
      "##### Epoch: 901/10000 || Loss: 1.2016282081604004\n",
      "--------------------------------------------------\n",
      "Validation || Epoch: 901 || Loss: 0.777793136509982 || Accuracy: 0.6656760573387146 || F1-score: 0.4195811292511829\n",
      "Epoch: 1001/10000 || Item: 0/85 || Loss: 0.6871069669723511\n",
      "--------------------------------------------------\n",
      "##### Epoch: 1001/10000 || Loss: 1.061781406402588\n",
      "--------------------------------------------------\n",
      "Validation || Epoch: 1001 || Loss: 0.7875593575564298 || Accuracy: 0.6656760573387146 || F1-score: 0.4195811292511829\n",
      "Epoch: 1101/10000 || Item: 0/85 || Loss: 0.5938020944595337\n",
      "--------------------------------------------------\n",
      "##### Epoch: 1101/10000 || Loss: 0.2842135727405548\n",
      "--------------------------------------------------\n",
      "Validation || Epoch: 1101 || Loss: 0.7774399410594593 || Accuracy: 0.6656760573387146 || F1-score: 0.4195811292511829\n",
      "Epoch: 1201/10000 || Item: 0/85 || Loss: 0.6855154037475586\n",
      "--------------------------------------------------\n",
      "##### Epoch: 1201/10000 || Loss: 0.8981250524520874\n",
      "--------------------------------------------------\n",
      "Validation || Epoch: 1201 || Loss: 0.7741416259245439 || Accuracy: 0.6656760573387146 || F1-score: 0.4195811292511829\n",
      "Epoch: 1301/10000 || Item: 0/85 || Loss: 0.7678601741790771\n",
      "--------------------------------------------------\n",
      "##### Epoch: 1301/10000 || Loss: 0.36237725615501404\n",
      "--------------------------------------------------\n",
      "Validation || Epoch: 1301 || Loss: 0.7710180336778815 || Accuracy: 0.6656760573387146 || F1-score: 0.4195811292511829\n",
      "Epoch: 1401/10000 || Item: 0/85 || Loss: 0.8205592632293701\n",
      "--------------------------------------------------\n",
      "##### Epoch: 1401/10000 || Loss: 0.8933357000350952\n",
      "--------------------------------------------------\n",
      "Validation || Epoch: 1401 || Loss: 0.7815206863663413 || Accuracy: 0.6656760573387146 || F1-score: 0.4195811292511829\n",
      "Epoch: 1501/10000 || Item: 0/85 || Loss: 0.6202898621559143\n",
      "--------------------------------------------------\n",
      "##### Epoch: 1501/10000 || Loss: 0.36562031507492065\n",
      "--------------------------------------------------\n",
      "Validation || Epoch: 1501 || Loss: 0.7805278084494851 || Accuracy: 0.6656760573387146 || F1-score: 0.4195811292511829\n",
      "Epoch: 1601/10000 || Item: 0/85 || Loss: 0.8109805583953857\n",
      "--------------------------------------------------\n",
      "##### Epoch: 1601/10000 || Loss: 0.5002390742301941\n",
      "--------------------------------------------------\n",
      "Validation || Epoch: 1601 || Loss: 0.778558308427984 || Accuracy: 0.6656760573387146 || F1-score: 0.4195811292511829\n",
      "Epoch: 1701/10000 || Item: 0/85 || Loss: 0.6557213068008423\n",
      "--------------------------------------------------\n",
      "##### Epoch: 1701/10000 || Loss: 0.780206561088562\n",
      "--------------------------------------------------\n",
      "Validation || Epoch: 1701 || Loss: 0.7741358442740007 || Accuracy: 0.6656760573387146 || F1-score: 0.4195811292511829\n",
      "Epoch: 1801/10000 || Item: 0/85 || Loss: 0.6853817105293274\n",
      "--------------------------------------------------\n",
      "##### Epoch: 1801/10000 || Loss: 0.5650882720947266\n",
      "--------------------------------------------------\n",
      "Validation || Epoch: 1801 || Loss: 0.7780148061839017 || Accuracy: 0.6656760573387146 || F1-score: 0.4195811292511829\n",
      "Epoch: 1901/10000 || Item: 0/85 || Loss: 0.709121584892273\n",
      "--------------------------------------------------\n",
      "##### Epoch: 1901/10000 || Loss: 0.6893901228904724\n",
      "--------------------------------------------------\n",
      "Validation || Epoch: 1901 || Loss: 0.7790610085834156 || Accuracy: 0.6656760573387146 || F1-score: 0.4195811292511829\n",
      "Epoch: 2001/10000 || Item: 0/85 || Loss: 0.7390385866165161\n",
      "--------------------------------------------------\n",
      "##### Epoch: 2001/10000 || Loss: 0.5710920095443726\n",
      "--------------------------------------------------\n",
      "Validation || Epoch: 2001 || Loss: 0.7809955206784335 || Accuracy: 0.6656760573387146 || F1-score: 0.4195811292511829\n",
      "Epoch: 2101/10000 || Item: 0/85 || Loss: 0.8520440459251404\n",
      "--------------------------------------------------\n",
      "##### Epoch: 2101/10000 || Loss: 0.11140234768390656\n",
      "--------------------------------------------------\n",
      "Validation || Epoch: 2101 || Loss: 0.7786682573231783 || Accuracy: 0.6656760573387146 || F1-score: 0.4195811292511829\n",
      "Epoch: 2201/10000 || Item: 0/85 || Loss: 0.6739664673805237\n",
      "--------------------------------------------------\n",
      "##### Epoch: 2201/10000 || Loss: 1.057503342628479\n",
      "--------------------------------------------------\n",
      "Validation || Epoch: 2201 || Loss: 0.7767439430410211 || Accuracy: 0.6656760573387146 || F1-score: 0.4195811292511829\n",
      "Epoch: 2301/10000 || Item: 0/85 || Loss: 0.8146728277206421\n",
      "--------------------------------------------------\n",
      "##### Epoch: 2301/10000 || Loss: 1.415852665901184\n",
      "--------------------------------------------------\n",
      "Validation || Epoch: 2301 || Loss: 0.7832458236000754 || Accuracy: 0.6656760573387146 || F1-score: 0.4195811292511829\n",
      "Epoch: 2401/10000 || Item: 0/85 || Loss: 0.6634531021118164\n",
      "--------------------------------------------------\n",
      "##### Epoch: 2401/10000 || Loss: 0.7553052306175232\n",
      "--------------------------------------------------\n",
      "Validation || Epoch: 2401 || Loss: 0.7807835069569674 || Accuracy: 0.6656760573387146 || F1-score: 0.4195811292511829\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 2501/10000 || Item: 0/85 || Loss: 0.6634032726287842\n",
      "--------------------------------------------------\n",
      "##### Epoch: 2501/10000 || Loss: 1.3026859760284424\n",
      "--------------------------------------------------\n",
      "Validation || Epoch: 2501 || Loss: 0.7831812826069918 || Accuracy: 0.6656760573387146 || F1-score: 0.4195811292511829\n",
      "Epoch: 2601/10000 || Item: 0/85 || Loss: 0.7258135676383972\n",
      "--------------------------------------------------\n",
      "##### Epoch: 2601/10000 || Loss: 1.1447083950042725\n",
      "--------------------------------------------------\n",
      "Validation || Epoch: 2601 || Loss: 0.7705647891218012 || Accuracy: 0.6656760573387146 || F1-score: 0.4195811292511829\n",
      "Epoch: 2701/10000 || Item: 0/85 || Loss: 0.7064722180366516\n",
      "--------------------------------------------------\n",
      "##### Epoch: 2701/10000 || Loss: 0.6171582341194153\n",
      "--------------------------------------------------\n",
      "Validation || Epoch: 2701 || Loss: 0.7781545357270674 || Accuracy: 0.6656760573387146 || F1-score: 0.4195811292511829\n",
      "Epoch: 2801/10000 || Item: 0/85 || Loss: 0.6882654428482056\n",
      "--------------------------------------------------\n",
      "##### Epoch: 2801/10000 || Loss: 0.19142131507396698\n",
      "--------------------------------------------------\n",
      "Validation || Epoch: 2801 || Loss: 0.7747199697927996 || Accuracy: 0.6656760573387146 || F1-score: 0.4195811292511829\n",
      "Epoch: 2901/10000 || Item: 0/85 || Loss: 0.7472724318504333\n",
      "--------------------------------------------------\n",
      "##### Epoch: 2901/10000 || Loss: 0.6118499040603638\n",
      "--------------------------------------------------\n",
      "Validation || Epoch: 2901 || Loss: 0.7772102085026827 || Accuracy: 0.6656760573387146 || F1-score: 0.4195811292511829\n",
      "Epoch: 3001/10000 || Item: 0/85 || Loss: 0.6140167117118835\n",
      "--------------------------------------------------\n",
      "##### Epoch: 3001/10000 || Loss: 0.07141904532909393\n",
      "--------------------------------------------------\n",
      "Validation || Epoch: 3001 || Loss: 0.7842843153259971 || Accuracy: 0.6656760573387146 || F1-score: 0.4195811292511829\n",
      "Epoch: 3101/10000 || Item: 0/85 || Loss: 0.8865576386451721\n",
      "--------------------------------------------------\n",
      "##### Epoch: 3101/10000 || Loss: 0.6352939605712891\n",
      "--------------------------------------------------\n",
      "Validation || Epoch: 3101 || Loss: 0.7780776890841398 || Accuracy: 0.6656760573387146 || F1-score: 0.4195811292511829\n",
      "Epoch: 3201/10000 || Item: 0/85 || Loss: 0.7669878005981445\n",
      "--------------------------------------------------\n",
      "##### Epoch: 3201/10000 || Loss: 0.45886340737342834\n",
      "--------------------------------------------------\n",
      "Validation || Epoch: 3201 || Loss: 0.7748976620760831 || Accuracy: 0.6656760573387146 || F1-score: 0.4195811292511829\n",
      "Epoch: 3301/10000 || Item: 0/85 || Loss: 0.6943668723106384\n",
      "--------------------------------------------------\n",
      "##### Epoch: 3301/10000 || Loss: 1.0346832275390625\n",
      "--------------------------------------------------\n",
      "Validation || Epoch: 3301 || Loss: 0.7824961272152987 || Accuracy: 0.6656760573387146 || F1-score: 0.4195811292511829\n",
      "Epoch: 3401/10000 || Item: 0/85 || Loss: 0.7139015793800354\n",
      "--------------------------------------------------\n",
      "##### Epoch: 3401/10000 || Loss: 0.32558563351631165\n",
      "--------------------------------------------------\n",
      "Validation || Epoch: 3401 || Loss: 0.7744346315210516 || Accuracy: 0.6656760573387146 || F1-score: 0.4195811292511829\n",
      "Epoch: 3501/10000 || Item: 0/85 || Loss: 0.7359917163848877\n",
      "--------------------------------------------------\n",
      "##### Epoch: 3501/10000 || Loss: 0.6408799290657043\n",
      "--------------------------------------------------\n",
      "Validation || Epoch: 3501 || Loss: 0.7728600068525835 || Accuracy: 0.6656760573387146 || F1-score: 0.4195811292511829\n",
      "Epoch: 3601/10000 || Item: 0/85 || Loss: 0.7135698795318604\n",
      "--------------------------------------------------\n",
      "##### Epoch: 3601/10000 || Loss: 0.4015403985977173\n",
      "--------------------------------------------------\n",
      "Validation || Epoch: 3601 || Loss: 0.7704942768270319 || Accuracy: 0.6656760573387146 || F1-score: 0.4195811292511829\n",
      "Epoch: 3701/10000 || Item: 0/85 || Loss: 0.7102751135826111\n",
      "--------------------------------------------------\n",
      "##### Epoch: 3701/10000 || Loss: 1.2180644273757935\n",
      "--------------------------------------------------\n",
      "Validation || Epoch: 3701 || Loss: 0.7761905572631143 || Accuracy: 0.6656760573387146 || F1-score: 0.4195811292511829\n",
      "Epoch: 3801/10000 || Item: 0/85 || Loss: 0.777874231338501\n",
      "--------------------------------------------------\n",
      "##### Epoch: 3801/10000 || Loss: 0.4193372428417206\n",
      "--------------------------------------------------\n",
      "Validation || Epoch: 3801 || Loss: 0.77295767177235 || Accuracy: 0.6656760573387146 || F1-score: 0.4195811292511829\n",
      "Epoch: 3901/10000 || Item: 0/85 || Loss: 0.6759376525878906\n",
      "--------------------------------------------------\n",
      "##### Epoch: 3901/10000 || Loss: 0.5251417756080627\n",
      "--------------------------------------------------\n",
      "Validation || Epoch: 3901 || Loss: 0.7779302271929655 || Accuracy: 0.6656760573387146 || F1-score: 0.4195811292511829\n",
      "Epoch: 4001/10000 || Item: 0/85 || Loss: 0.9027791023254395\n",
      "--------------------------------------------------\n",
      "##### Epoch: 4001/10000 || Loss: 1.175036072731018\n",
      "--------------------------------------------------\n",
      "Validation || Epoch: 4001 || Loss: 0.7826201319694519 || Accuracy: 0.6656760573387146 || F1-score: 0.4195811292511829\n",
      "Epoch: 4101/10000 || Item: 0/85 || Loss: 0.5941818952560425\n",
      "--------------------------------------------------\n",
      "##### Epoch: 4101/10000 || Loss: 1.1591159105300903\n",
      "--------------------------------------------------\n",
      "Validation || Epoch: 4101 || Loss: 0.7811801054260947 || Accuracy: 0.6656760573387146 || F1-score: 0.4195811292511829\n",
      "Epoch: 4201/10000 || Item: 0/85 || Loss: 0.6122838854789734\n",
      "--------------------------------------------------\n",
      "##### Epoch: 4201/10000 || Loss: 0.7861940860748291\n",
      "--------------------------------------------------\n",
      "Validation || Epoch: 4201 || Loss: 0.7732108018615029 || Accuracy: 0.6656760573387146 || F1-score: 0.4195811292511829\n",
      "Epoch: 4301/10000 || Item: 0/85 || Loss: 0.5969501733779907\n",
      "--------------------------------------------------\n",
      "##### Epoch: 4301/10000 || Loss: 0.8426077365875244\n",
      "--------------------------------------------------\n",
      "Validation || Epoch: 4301 || Loss: 0.7783894105391069 || Accuracy: 0.6656760573387146 || F1-score: 0.4195811292511829\n",
      "Epoch: 4401/10000 || Item: 0/85 || Loss: 0.7438439726829529\n",
      "--------------------------------------------------\n",
      "##### Epoch: 4401/10000 || Loss: 0.9331285357475281\n",
      "--------------------------------------------------\n",
      "Validation || Epoch: 4401 || Loss: 0.7746000018986788 || Accuracy: 0.6656760573387146 || F1-score: 0.4195811292511829\n",
      "Epoch: 4501/10000 || Item: 0/85 || Loss: 0.6664619445800781\n",
      "--------------------------------------------------\n",
      "##### Epoch: 4501/10000 || Loss: 0.753149688243866\n",
      "--------------------------------------------------\n",
      "Validation || Epoch: 4501 || Loss: 0.781297358599576 || Accuracy: 0.6656760573387146 || F1-score: 0.4195811292511829\n",
      "Epoch: 4601/10000 || Item: 0/85 || Loss: 0.6983456015586853\n",
      "--------------------------------------------------\n",
      "##### Epoch: 4601/10000 || Loss: 0.43056657910346985\n",
      "--------------------------------------------------\n",
      "Validation || Epoch: 4601 || Loss: 0.7801696874878623 || Accuracy: 0.6656760573387146 || F1-score: 0.4195811292511829\n",
      "Epoch: 4701/10000 || Item: 0/85 || Loss: 0.7215011715888977\n",
      "--------------------------------------------------\n",
      "##### Epoch: 4701/10000 || Loss: 0.4466157853603363\n",
      "--------------------------------------------------\n",
      "Validation || Epoch: 4701 || Loss: 0.7719637372277 || Accuracy: 0.6656760573387146 || F1-score: 0.4195811292511829\n",
      "Epoch: 4801/10000 || Item: 0/85 || Loss: 0.7399188280105591\n",
      "--------------------------------------------------\n",
      "##### Epoch: 4801/10000 || Loss: 1.1691539287567139\n",
      "--------------------------------------------------\n",
      "Validation || Epoch: 4801 || Loss: 0.7672278339212592 || Accuracy: 0.6656760573387146 || F1-score: 0.4195811292511829\n",
      "Epoch: 4901/10000 || Item: 0/85 || Loss: 0.7537015080451965\n",
      "--------------------------------------------------\n",
      "##### Epoch: 4901/10000 || Loss: 0.6327916979789734\n",
      "--------------------------------------------------\n",
      "Validation || Epoch: 4901 || Loss: 0.7727669910951094 || Accuracy: 0.6656760573387146 || F1-score: 0.4195811292511829\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 5001/10000 || Item: 0/85 || Loss: 0.9182127714157104\n",
      "--------------------------------------------------\n",
      "##### Epoch: 5001/10000 || Loss: 0.42393115162849426\n",
      "--------------------------------------------------\n",
      "Validation || Epoch: 5001 || Loss: 0.7761146859689192 || Accuracy: 0.6656760573387146 || F1-score: 0.4195811292511829\n",
      "Epoch: 5101/10000 || Item: 0/85 || Loss: 0.6947301626205444\n",
      "--------------------------------------------------\n",
      "##### Epoch: 5101/10000 || Loss: 1.0078166723251343\n",
      "--------------------------------------------------\n",
      "Validation || Epoch: 5101 || Loss: 0.7699445431882684 || Accuracy: 0.6656760573387146 || F1-score: 0.4195811292511829\n",
      "Epoch: 5201/10000 || Item: 0/85 || Loss: 0.6850304007530212\n",
      "--------------------------------------------------\n",
      "##### Epoch: 5201/10000 || Loss: 0.3822188675403595\n",
      "--------------------------------------------------\n",
      "Validation || Epoch: 5201 || Loss: 0.7812753753228621 || Accuracy: 0.6656760573387146 || F1-score: 0.4195811292511829\n",
      "Epoch: 5301/10000 || Item: 0/85 || Loss: 0.6973007917404175\n",
      "--------------------------------------------------\n",
      "##### Epoch: 5301/10000 || Loss: 1.8282413482666016\n",
      "--------------------------------------------------\n",
      "Validation || Epoch: 5301 || Loss: 0.7810570868578824 || Accuracy: 0.6656760573387146 || F1-score: 0.4195811292511829\n",
      "Epoch: 5401/10000 || Item: 0/85 || Loss: 0.7358635067939758\n",
      "--------------------------------------------------\n",
      "##### Epoch: 5401/10000 || Loss: 1.555002212524414\n",
      "--------------------------------------------------\n",
      "Validation || Epoch: 5401 || Loss: 0.7762531692331488 || Accuracy: 0.6656760573387146 || F1-score: 0.4195811292511829\n",
      "Epoch: 5501/10000 || Item: 0/85 || Loss: 0.7300479412078857\n",
      "--------------------------------------------------\n",
      "##### Epoch: 5501/10000 || Loss: 0.9067042469978333\n",
      "--------------------------------------------------\n",
      "Validation || Epoch: 5501 || Loss: 0.7746647975661538 || Accuracy: 0.6656760573387146 || F1-score: 0.4195811292511829\n",
      "Epoch: 5601/10000 || Item: 0/85 || Loss: 0.71978360414505\n",
      "--------------------------------------------------\n",
      "##### Epoch: 5601/10000 || Loss: 0.44759485125541687\n",
      "--------------------------------------------------\n",
      "Validation || Epoch: 5601 || Loss: 0.773561954498291 || Accuracy: 0.6656760573387146 || F1-score: 0.4195811292511829\n",
      "Epoch: 5701/10000 || Item: 0/85 || Loss: 0.7523018717765808\n",
      "--------------------------------------------------\n",
      "##### Epoch: 5701/10000 || Loss: 0.9321156144142151\n",
      "--------------------------------------------------\n",
      "Validation || Epoch: 5701 || Loss: 0.7800630168481306 || Accuracy: 0.6656760573387146 || F1-score: 0.4195811292511829\n",
      "Epoch: 5801/10000 || Item: 0/85 || Loss: 0.7379235625267029\n",
      "--------------------------------------------------\n",
      "##### Epoch: 5801/10000 || Loss: 0.6673509478569031\n",
      "--------------------------------------------------\n",
      "Validation || Epoch: 5801 || Loss: 0.7709588462656195 || Accuracy: 0.6656760573387146 || F1-score: 0.4195811292511829\n",
      "Epoch: 5901/10000 || Item: 0/85 || Loss: 0.8261000514030457\n",
      "--------------------------------------------------\n",
      "##### Epoch: 5901/10000 || Loss: 0.766005277633667\n",
      "--------------------------------------------------\n",
      "Validation || Epoch: 5901 || Loss: 0.7790226231921803 || Accuracy: 0.6656760573387146 || F1-score: 0.4195811292511829\n",
      "Epoch: 6001/10000 || Item: 0/85 || Loss: 0.7736097574234009\n",
      "--------------------------------------------------\n",
      "##### Epoch: 6001/10000 || Loss: 0.4614412784576416\n",
      "--------------------------------------------------\n",
      "Validation || Epoch: 6001 || Loss: 0.7797455299984325 || Accuracy: 0.6656760573387146 || F1-score: 0.4195811292511829\n",
      "Epoch: 6101/10000 || Item: 0/85 || Loss: 0.8143405914306641\n",
      "--------------------------------------------------\n",
      "##### Epoch: 6101/10000 || Loss: 0.49723631143569946\n",
      "--------------------------------------------------\n",
      "Validation || Epoch: 6101 || Loss: 0.7764472365379333 || Accuracy: 0.6656760573387146 || F1-score: 0.4195811292511829\n",
      "Epoch: 6201/10000 || Item: 0/85 || Loss: 0.624811053276062\n",
      "--------------------------------------------------\n",
      "##### Epoch: 6201/10000 || Loss: 1.033413052558899\n",
      "--------------------------------------------------\n",
      "Validation || Epoch: 6201 || Loss: 0.7781410596587441 || Accuracy: 0.6656760573387146 || F1-score: 0.4195811292511829\n",
      "Epoch: 6301/10000 || Item: 0/85 || Loss: 0.7468281388282776\n",
      "--------------------------------------------------\n",
      "##### Epoch: 6301/10000 || Loss: 0.36913132667541504\n",
      "--------------------------------------------------\n",
      "Validation || Epoch: 6301 || Loss: 0.7803683931177313 || Accuracy: 0.6656760573387146 || F1-score: 0.4195811292511829\n",
      "Epoch: 6401/10000 || Item: 0/85 || Loss: 0.7061824202537537\n",
      "--------------------------------------------------\n",
      "##### Epoch: 6401/10000 || Loss: 0.5149078369140625\n",
      "--------------------------------------------------\n",
      "Validation || Epoch: 6401 || Loss: 0.7820973342115228 || Accuracy: 0.6656760573387146 || F1-score: 0.4195811292511829\n",
      "Epoch: 6501/10000 || Item: 0/85 || Loss: 0.7203896641731262\n",
      "--------------------------------------------------\n",
      "##### Epoch: 6501/10000 || Loss: 0.1720990091562271\n",
      "--------------------------------------------------\n",
      "Validation || Epoch: 6501 || Loss: 0.7722926790064032 || Accuracy: 0.6656760573387146 || F1-score: 0.4195811292511829\n",
      "Epoch: 6601/10000 || Item: 0/85 || Loss: 0.914079487323761\n",
      "--------------------------------------------------\n",
      "##### Epoch: 6601/10000 || Loss: 0.655697226524353\n",
      "--------------------------------------------------\n",
      "Validation || Epoch: 6601 || Loss: 0.7782488411123102 || Accuracy: 0.6656760573387146 || F1-score: 0.4195811292511829\n",
      "Epoch: 6701/10000 || Item: 0/85 || Loss: 0.7460460066795349\n",
      "--------------------------------------------------\n",
      "##### Epoch: 6701/10000 || Loss: 0.3376968801021576\n",
      "--------------------------------------------------\n",
      "Validation || Epoch: 6701 || Loss: 0.7879535447467457 || Accuracy: 0.6656760573387146 || F1-score: 0.4195811292511829\n",
      "Epoch: 6801/10000 || Item: 0/85 || Loss: 0.5939730405807495\n",
      "--------------------------------------------------\n",
      "##### Epoch: 6801/10000 || Loss: 0.4648822546005249\n",
      "--------------------------------------------------\n",
      "Validation || Epoch: 6801 || Loss: 0.7789094556461681 || Accuracy: 0.6656760573387146 || F1-score: 0.4195811292511829\n",
      "Epoch: 6901/10000 || Item: 0/85 || Loss: 0.6647682189941406\n",
      "--------------------------------------------------\n",
      "##### Epoch: 6901/10000 || Loss: 0.6629979014396667\n",
      "--------------------------------------------------\n",
      "Validation || Epoch: 6901 || Loss: 0.7736300013282082 || Accuracy: 0.6656760573387146 || F1-score: 0.4195811292511829\n",
      "Epoch: 7001/10000 || Item: 0/85 || Loss: 0.8050565123558044\n",
      "--------------------------------------------------\n",
      "##### Epoch: 7001/10000 || Loss: 1.5052777528762817\n",
      "--------------------------------------------------\n",
      "Validation || Epoch: 7001 || Loss: 0.770400578325445 || Accuracy: 0.6656760573387146 || F1-score: 0.4195811292511829\n",
      "Epoch: 7101/10000 || Item: 0/85 || Loss: 0.8555044531822205\n",
      "--------------------------------------------------\n",
      "##### Epoch: 7101/10000 || Loss: 1.0024850368499756\n",
      "--------------------------------------------------\n",
      "Validation || Epoch: 7101 || Loss: 0.7802553068507802 || Accuracy: 0.6656760573387146 || F1-score: 0.4195811292511829\n",
      "Epoch: 7201/10000 || Item: 0/85 || Loss: 0.7821239829063416\n",
      "--------------------------------------------------\n",
      "##### Epoch: 7201/10000 || Loss: 1.1672521829605103\n",
      "--------------------------------------------------\n",
      "Validation || Epoch: 7201 || Loss: 0.7664627920497548 || Accuracy: 0.6656760573387146 || F1-score: 0.4195811292511829\n",
      "Epoch: 7301/10000 || Item: 0/85 || Loss: 0.6143599152565002\n",
      "--------------------------------------------------\n",
      "##### Epoch: 7301/10000 || Loss: 0.476048082113266\n",
      "--------------------------------------------------\n",
      "Validation || Epoch: 7301 || Loss: 0.7818126515908674 || Accuracy: 0.6656760573387146 || F1-score: 0.4195811292511829\n",
      "Epoch: 7401/10000 || Item: 0/85 || Loss: 0.8056416511535645\n",
      "--------------------------------------------------\n",
      "##### Epoch: 7401/10000 || Loss: 1.6158502101898193\n",
      "--------------------------------------------------\n",
      "Validation || Epoch: 7401 || Loss: 0.7750017046928406 || Accuracy: 0.6656760573387146 || F1-score: 0.4195811292511829\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 7501/10000 || Item: 0/85 || Loss: 0.7156424522399902\n",
      "--------------------------------------------------\n",
      "##### Epoch: 7501/10000 || Loss: 0.42704275250434875\n",
      "--------------------------------------------------\n",
      "Validation || Epoch: 7501 || Loss: 0.7731098207560453 || Accuracy: 0.6656760573387146 || F1-score: 0.4195811292511829\n",
      "Epoch: 7601/10000 || Item: 0/85 || Loss: 0.6039122939109802\n",
      "--------------------------------------------------\n",
      "##### Epoch: 7601/10000 || Loss: 1.1046546697616577\n",
      "--------------------------------------------------\n",
      "Validation || Epoch: 7601 || Loss: 0.7730671980164268 || Accuracy: 0.6656760573387146 || F1-score: 0.4195811292511829\n",
      "Epoch: 7701/10000 || Item: 0/85 || Loss: 0.8365492224693298\n",
      "--------------------------------------------------\n",
      "##### Epoch: 7701/10000 || Loss: 1.0123564004898071\n",
      "--------------------------------------------------\n",
      "Validation || Epoch: 7701 || Loss: 0.7661543488502502 || Accuracy: 0.6656760573387146 || F1-score: 0.4195811292511829\n",
      "Epoch: 7801/10000 || Item: 0/85 || Loss: 0.8629350662231445\n",
      "--------------------------------------------------\n",
      "##### Epoch: 7801/10000 || Loss: 0.7730066180229187\n",
      "--------------------------------------------------\n",
      "Validation || Epoch: 7801 || Loss: 0.7809011882001703 || Accuracy: 0.6656760573387146 || F1-score: 0.4195811292511829\n",
      "Epoch: 7901/10000 || Item: 0/85 || Loss: 0.7453950643539429\n",
      "--------------------------------------------------\n",
      "##### Epoch: 7901/10000 || Loss: 0.690405011177063\n",
      "--------------------------------------------------\n",
      "Validation || Epoch: 7901 || Loss: 0.7732675779949535 || Accuracy: 0.6656760573387146 || F1-score: 0.4195811292511829\n",
      "Epoch: 8001/10000 || Item: 0/85 || Loss: 0.6993293762207031\n",
      "--------------------------------------------------\n",
      "##### Epoch: 8001/10000 || Loss: 1.1900030374526978\n",
      "--------------------------------------------------\n",
      "Validation || Epoch: 8001 || Loss: 0.7729504162614996 || Accuracy: 0.6656760573387146 || F1-score: 0.4195811292511829\n",
      "Epoch: 8101/10000 || Item: 0/85 || Loss: 0.6268041729927063\n",
      "--------------------------------------------------\n",
      "##### Epoch: 8101/10000 || Loss: 0.27092495560646057\n",
      "--------------------------------------------------\n",
      "Validation || Epoch: 8101 || Loss: 0.7785962224006653 || Accuracy: 0.6656760573387146 || F1-score: 0.4195811292511829\n",
      "Epoch: 8201/10000 || Item: 0/85 || Loss: 0.6632469296455383\n",
      "--------------------------------------------------\n",
      "##### Epoch: 8201/10000 || Loss: 0.8476182222366333\n",
      "--------------------------------------------------\n",
      "Validation || Epoch: 8201 || Loss: 0.7780283147638495 || Accuracy: 0.6656760573387146 || F1-score: 0.4195811292511829\n",
      "Epoch: 8301/10000 || Item: 0/85 || Loss: 0.7460100650787354\n",
      "--------------------------------------------------\n",
      "##### Epoch: 8301/10000 || Loss: 0.40701842308044434\n",
      "--------------------------------------------------\n",
      "Validation || Epoch: 8301 || Loss: 0.7783224907788363 || Accuracy: 0.6656760573387146 || F1-score: 0.4195811292511829\n",
      "Epoch: 8401/10000 || Item: 0/85 || Loss: 0.7496022582054138\n",
      "--------------------------------------------------\n",
      "##### Epoch: 8401/10000 || Loss: 0.5640969276428223\n",
      "--------------------------------------------------\n",
      "Validation || Epoch: 8401 || Loss: 0.768335374918851 || Accuracy: 0.6656760573387146 || F1-score: 0.4195811292511829\n",
      "Epoch: 8501/10000 || Item: 0/85 || Loss: 0.6256530284881592\n",
      "--------------------------------------------------\n",
      "##### Epoch: 8501/10000 || Loss: 1.1000988483428955\n",
      "--------------------------------------------------\n",
      "Validation || Epoch: 8501 || Loss: 0.7790749343958768 || Accuracy: 0.6656760573387146 || F1-score: 0.4195811292511829\n",
      "Epoch: 8601/10000 || Item: 0/85 || Loss: 0.7535098195075989\n",
      "--------------------------------------------------\n",
      "##### Epoch: 8601/10000 || Loss: 0.4048849642276764\n",
      "--------------------------------------------------\n",
      "Validation || Epoch: 8601 || Loss: 0.7727892832322554 || Accuracy: 0.6656760573387146 || F1-score: 0.4195811292511829\n",
      "Epoch: 8701/10000 || Item: 0/85 || Loss: 0.8418823480606079\n",
      "--------------------------------------------------\n",
      "##### Epoch: 8701/10000 || Loss: 0.5078502893447876\n",
      "--------------------------------------------------\n",
      "Validation || Epoch: 8701 || Loss: 0.7766095345670526 || Accuracy: 0.6656760573387146 || F1-score: 0.4195811292511829\n",
      "Epoch: 8801/10000 || Item: 0/85 || Loss: 0.7835226655006409\n",
      "--------------------------------------------------\n",
      "##### Epoch: 8801/10000 || Loss: 0.9129669070243835\n",
      "--------------------------------------------------\n",
      "Validation || Epoch: 8801 || Loss: 0.7768222472884438 || Accuracy: 0.6656760573387146 || F1-score: 0.4195811292511829\n",
      "Epoch: 8901/10000 || Item: 0/85 || Loss: 0.759007453918457\n",
      "--------------------------------------------------\n",
      "##### Epoch: 8901/10000 || Loss: 0.4141179919242859\n",
      "--------------------------------------------------\n",
      "Validation || Epoch: 8901 || Loss: 0.7778666615486145 || Accuracy: 0.6656760573387146 || F1-score: 0.4195811292511829\n",
      "Epoch: 9001/10000 || Item: 0/85 || Loss: 0.8088655471801758\n",
      "--------------------------------------------------\n",
      "##### Epoch: 9001/10000 || Loss: 0.5922632813453674\n",
      "--------------------------------------------------\n",
      "Validation || Epoch: 9001 || Loss: 0.7742090008475564 || Accuracy: 0.6656760573387146 || F1-score: 0.4195811292511829\n",
      "Epoch: 9101/10000 || Item: 0/85 || Loss: 0.7297435402870178\n",
      "--------------------------------------------------\n",
      "##### Epoch: 9101/10000 || Loss: 1.0832326412200928\n",
      "--------------------------------------------------\n",
      "Validation || Epoch: 9101 || Loss: 0.774287917397239 || Accuracy: 0.6656760573387146 || F1-score: 0.4195811292511829\n",
      "Epoch: 9201/10000 || Item: 0/85 || Loss: 0.7970360517501831\n",
      "--------------------------------------------------\n",
      "##### Epoch: 9201/10000 || Loss: 0.8238731622695923\n",
      "--------------------------------------------------\n",
      "Validation || Epoch: 9201 || Loss: 0.7838042432611639 || Accuracy: 0.6656760573387146 || F1-score: 0.4195811292511829\n",
      "Epoch: 9301/10000 || Item: 0/85 || Loss: 0.7137271761894226\n",
      "--------------------------------------------------\n",
      "##### Epoch: 9301/10000 || Loss: 0.5948843955993652\n",
      "--------------------------------------------------\n",
      "Validation || Epoch: 9301 || Loss: 0.7941209673881531 || Accuracy: 0.6656760573387146 || F1-score: 0.4195811292511829\n",
      "Epoch: 9401/10000 || Item: 0/85 || Loss: 0.6917505264282227\n",
      "--------------------------------------------------\n",
      "##### Epoch: 9401/10000 || Loss: 0.6597242951393127\n",
      "--------------------------------------------------\n",
      "Validation || Epoch: 9401 || Loss: 0.7716411623087797 || Accuracy: 0.6656760573387146 || F1-score: 0.4195811292511829\n",
      "Epoch: 9501/10000 || Item: 0/85 || Loss: 0.7508042454719543\n",
      "--------------------------------------------------\n",
      "##### Epoch: 9501/10000 || Loss: 0.7119506001472473\n",
      "--------------------------------------------------\n",
      "Validation || Epoch: 9501 || Loss: 0.7732428149743513 || Accuracy: 0.6656760573387146 || F1-score: 0.4195811292511829\n",
      "Epoch: 9601/10000 || Item: 0/85 || Loss: 0.6606553196907043\n",
      "--------------------------------------------------\n",
      "##### Epoch: 9601/10000 || Loss: 0.6966211795806885\n",
      "--------------------------------------------------\n",
      "Validation || Epoch: 9601 || Loss: 0.7765340100635182 || Accuracy: 0.6656760573387146 || F1-score: 0.4195811292511829\n",
      "Epoch: 9701/10000 || Item: 0/85 || Loss: 0.6576550602912903\n",
      "--------------------------------------------------\n",
      "##### Epoch: 9701/10000 || Loss: 1.0574651956558228\n",
      "--------------------------------------------------\n",
      "Validation || Epoch: 9701 || Loss: 0.7749740318818525 || Accuracy: 0.6656760573387146 || F1-score: 0.4195811292511829\n",
      "Epoch: 9801/10000 || Item: 0/85 || Loss: 0.6468800902366638\n",
      "--------------------------------------------------\n",
      "##### Epoch: 9801/10000 || Loss: 0.7148799896240234\n",
      "--------------------------------------------------\n",
      "Validation || Epoch: 9801 || Loss: 0.7755096500570123 || Accuracy: 0.6656760573387146 || F1-score: 0.4195811292511829\n",
      "Epoch: 9901/10000 || Item: 0/85 || Loss: 0.7183387279510498\n",
      "--------------------------------------------------\n",
      "##### Epoch: 9901/10000 || Loss: 0.7932189106941223\n",
      "--------------------------------------------------\n",
      "Validation || Epoch: 9901 || Loss: 0.7776149836453524 || Accuracy: 0.6656760573387146 || F1-score: 0.4195811292511829\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy on dataset of size 672: 66.66666412353516 %.\n",
      "Average loss: 0.8003735433925282\n",
      "proportion of labels in prediction: [tensor(0.7366), tensor(0.2634), tensor(0.)]\n",
      "proportion of labels in data: [tensor(0.6235), tensor(0.2232), tensor(0.1533)]\n",
      "- f1: [0.81619256 0.4587156  0.        ]\n",
      "- f1 (average): 0.42496938550177665\n",
      "- accuracy: 0.6666666865348816\n",
      "\n",
      "********** lstm_hidden_dim: [12, 12, 8] || ffnhidden_dim: [100, 100, 100, 100, 100]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/var/folders/l7/bnn1j6bs3bqfskq2jlq55yh80000gr/T/ipykernel_51169/2493663396.py:31: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  train, valid, test = split_dataset(x_data=torch.tensor(x_data).float(),\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "2f7d07abfcf54bf59192fb370cd5646f",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/10000 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 1/10000 || Item: 0/85 || Loss: 1.0921334028244019\n",
      "--------------------------------------------------\n",
      "##### Epoch: 1/10000 || Loss: 1.0322431325912476\n",
      "--------------------------------------------------\n",
      "Validation || Epoch: 1 || Loss: 0.9826022440736945 || Accuracy: 0.6225854158401489 || F1-score: 0.25579975579975583\n",
      "Epoch: 101/10000 || Item: 0/85 || Loss: 0.8259876370429993\n",
      "--------------------------------------------------\n",
      "##### Epoch: 101/10000 || Loss: 0.8322278261184692\n",
      "--------------------------------------------------\n",
      "Validation || Epoch: 101 || Loss: 0.7861089543862776 || Accuracy: 0.6627042889595032 || F1-score: 0.4148525206995593\n",
      "Early stopping at epoch 128!\n",
      "Accuracy on dataset of size 672: 66.51786041259766 %.\n",
      "Average loss: 0.7913895574483004\n",
      "proportion of labels in prediction: [tensor(0.7440), tensor(0.2560), tensor(0.)]\n",
      "proportion of labels in data: [tensor(0.6235), tensor(0.2232), tensor(0.1533)]\n",
      "- f1: [0.81828074 0.44099379 0.        ]\n",
      "- f1 (average): 0.41975817625152917\n",
      "- accuracy: 0.6651785969734192\n",
      "\n",
      "********** lstm_hidden_dim: [12, 12, 12, 8] || ffnhidden_dim: [100, 100]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/var/folders/l7/bnn1j6bs3bqfskq2jlq55yh80000gr/T/ipykernel_51169/2493663396.py:31: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  train, valid, test = split_dataset(x_data=torch.tensor(x_data).float(),\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "43490e3b577b4970ade6a91bb6feebeb",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/10000 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 1/10000 || Item: 0/85 || Loss: 1.0644787549972534\n",
      "--------------------------------------------------\n",
      "##### Epoch: 1/10000 || Loss: 1.065685749053955\n",
      "--------------------------------------------------\n",
      "Validation || Epoch: 1 || Loss: 0.9856856302781538 || Accuracy: 0.6225854158401489 || F1-score: 0.25579975579975583\n",
      "Epoch: 101/10000 || Item: 0/85 || Loss: 0.7554184794425964\n",
      "--------------------------------------------------\n",
      "##### Epoch: 101/10000 || Loss: 0.09720936417579651\n",
      "--------------------------------------------------\n",
      "Validation || Epoch: 101 || Loss: 0.7491351853717457 || Accuracy: 0.6820207834243774 || F1-score: 0.5598449228738761\n",
      "Early stopping at epoch 143!\n",
      "Accuracy on dataset of size 672: 69.04762268066406 %.\n",
      "Average loss: 0.7794241146607832\n",
      "proportion of labels in prediction: [tensor(0.7113), tensor(0.1890), tensor(0.0997)]\n",
      "proportion of labels in data: [tensor(0.6235), tensor(0.2232), tensor(0.1533)]\n",
      "- f1: [0.80936455 0.49097473 0.38823529]\n",
      "- f1 (average): 0.5628581906181692\n",
      "- accuracy: 0.6904761791229248\n",
      "\n",
      "********** lstm_hidden_dim: [12, 12, 12, 8] || ffnhidden_dim: [100, 100, 100]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/var/folders/l7/bnn1j6bs3bqfskq2jlq55yh80000gr/T/ipykernel_51169/2493663396.py:31: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  train, valid, test = split_dataset(x_data=torch.tensor(x_data).float(),\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "2e0b9a65af4c414f9bd21b0721a1573d",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/10000 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 1/10000 || Item: 0/85 || Loss: 1.1146775484085083\n",
      "--------------------------------------------------\n",
      "##### Epoch: 1/10000 || Loss: 1.035070538520813\n",
      "--------------------------------------------------\n",
      "Validation || Epoch: 1 || Loss: 0.9956874630667947 || Accuracy: 0.6225854158401489 || F1-score: 0.25579975579975583\n",
      "Epoch: 101/10000 || Item: 0/85 || Loss: 0.7303361892700195\n",
      "--------------------------------------------------\n",
      "##### Epoch: 101/10000 || Loss: 0.12737801671028137\n",
      "--------------------------------------------------\n",
      "Validation || Epoch: 101 || Loss: 0.777530084956776 || Accuracy: 0.6745913624763489 || F1-score: 0.5613311220495781\n",
      "Early stopping at epoch 158!\n",
      "Accuracy on dataset of size 672: 70.08928680419922 %.\n",
      "Average loss: 0.791927532716231\n",
      "proportion of labels in prediction: [tensor(0.6994), tensor(0.1845), tensor(0.1161)]\n",
      "proportion of labels in data: [tensor(0.6235), tensor(0.2232), tensor(0.1533)]\n",
      "- f1: [0.80539933 0.51824818 0.4640884 ]\n",
      "- f1 (average): 0.5959119660189671\n",
      "- accuracy: 0.7008928656578064\n",
      "\n",
      "********** lstm_hidden_dim: [12, 12, 12, 8] || ffnhidden_dim: [100, 100, 100, 100]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/var/folders/l7/bnn1j6bs3bqfskq2jlq55yh80000gr/T/ipykernel_51169/2493663396.py:31: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  train, valid, test = split_dataset(x_data=torch.tensor(x_data).float(),\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "a3c459a9874348baafd96f261d55b0ae",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/10000 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 1/10000 || Item: 0/85 || Loss: 1.1051678657531738\n",
      "--------------------------------------------------\n",
      "##### Epoch: 1/10000 || Loss: 1.0238896608352661\n",
      "--------------------------------------------------\n",
      "Validation || Epoch: 1 || Loss: 0.995102280920202 || Accuracy: 0.6225854158401489 || F1-score: 0.25579975579975583\n",
      "Epoch: 101/10000 || Item: 0/85 || Loss: 0.9536846280097961\n",
      "--------------------------------------------------\n",
      "##### Epoch: 101/10000 || Loss: 0.4498940408229828\n",
      "--------------------------------------------------\n",
      "Validation || Epoch: 101 || Loss: 0.8075882250612433 || Accuracy: 0.6344724893569946 || F1-score: 0.3889235667634446\n",
      "Early stopping at epoch 127!\n",
      "Accuracy on dataset of size 672: 64.28571319580078 %.\n",
      "Average loss: 0.8028621727770026\n",
      "proportion of labels in prediction: [tensor(0.7485), tensor(0.2515), tensor(0.)]\n",
      "proportion of labels in data: [tensor(0.6235), tensor(0.2232), tensor(0.1533)]\n",
      "- f1: [0.80477223 0.38244514 0.        ]\n",
      "- f1 (average): 0.3957391251130498\n",
      "- accuracy: 0.6428571343421936\n",
      "\n",
      "********** lstm_hidden_dim: [12, 12, 12, 8] || ffnhidden_dim: [100, 100, 100, 100, 100]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/var/folders/l7/bnn1j6bs3bqfskq2jlq55yh80000gr/T/ipykernel_51169/2493663396.py:31: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  train, valid, test = split_dataset(x_data=torch.tensor(x_data).float(),\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "c2172d66836146239e50982163c2678a",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/10000 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 1/10000 || Item: 0/85 || Loss: 1.1041083335876465\n",
      "--------------------------------------------------\n",
      "##### Epoch: 1/10000 || Loss: 1.0664429664611816\n",
      "--------------------------------------------------\n",
      "Validation || Epoch: 1 || Loss: 0.9895215251229026 || Accuracy: 0.6225854158401489 || F1-score: 0.25579975579975583\n",
      "Epoch: 101/10000 || Item: 0/85 || Loss: 0.8241069912910461\n",
      "--------------------------------------------------\n",
      "##### Epoch: 101/10000 || Loss: 1.0187573432922363\n",
      "--------------------------------------------------\n",
      "Validation || Epoch: 101 || Loss: 0.7859444618225098 || Accuracy: 0.6508172154426575 || F1-score: 0.40133884673961034\n",
      "Early stopping at epoch 126!\n",
      "Accuracy on dataset of size 672: 66.51786041259766 %.\n",
      "Average loss: 0.7918119051239707\n",
      "proportion of labels in prediction: [tensor(0.7500), tensor(0.2500), tensor(0.)]\n",
      "proportion of labels in data: [tensor(0.6235), tensor(0.2232), tensor(0.1533)]\n",
      "- f1: [0.8212351  0.42767296 0.        ]\n",
      "- f1 (average): 0.4163026863000289\n",
      "- accuracy: 0.6651785969734192\n"
     ]
    }
   ],
   "source": [
    "x_data, input_channels = obtain_SDSN_input(sbert_384_embeddings, path_specifics)\n",
    "for lstm_hidden_dim in lstm_hidden_dim_trial:\n",
    "    for ffn_hidden_dim in ffn_hidden_dim_trial:\n",
    "        print(f\"\\n********** lstm_hidden_dim: {lstm_hidden_dim} \"\n",
    "              f\"|| ffnhidden_dim: {ffn_hidden_dim}\")\n",
    "        implement_sdsn(x_data=x_data,\n",
    "                       y_data=y_data,\n",
    "                       sig_depth=sig_depth,\n",
    "                       input_channels=input_channels,\n",
    "                       output_channels=output_channels,\n",
    "                       lstm_hidden_dim=lstm_hidden_dim,\n",
    "                       ffn_hidden_dim=ffn_hidden_dim,\n",
    "                       BiLSTM=BiLSTM,\n",
    "                       learning_rate=learning_rate,\n",
    "                       loss=loss)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9a1fcf78",
   "metadata": {},
   "source": [
    "## Pretrained BERT"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "59cbe2ae",
   "metadata": {},
   "source": [
    "### Mean pooled"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 219,
   "id": "baa4ff09",
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[INFO] Concatenating the embeddings to the dataframe...\n",
      "[INFO] - columns beginning with 'e' denote the full embddings.\n",
      "[INFO] - columns beginning with 'd' denote the dimension reduced embeddings.\n",
      "[INFO] Adding time feature columns into dataframe in `.df`.\n",
      "[INFO] Adding 'time_encoding' and feature...\n",
      "[INFO] Adding 'time_diff' and feature...\n",
      "[INFO] Adding 'timeline_index' feature...\n",
      "[INFO] Padding ids and storing in `.df_padded` and `.array_padded` attributes.\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "7a34094b65a2439d8a4a337cded83b8d",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/13551 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[INFO] The path was created for each item in the dataframe, by looking at its history, so to include embeddings in the FFN input, we concatenate the embeddings for each sentence / text.\n",
      "\n",
      "********** lstm_hidden_dim: [8, 8] || ffnhidden_dim: [100, 100]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/var/folders/l7/bnn1j6bs3bqfskq2jlq55yh80000gr/T/ipykernel_51169/2493663396.py:31: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  train, valid, test = split_dataset(x_data=torch.tensor(x_data).float(),\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "68aba0cdb8674cd09a5a0c4045e7b9ca",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/10000 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 1/10000 || Item: 0/85 || Loss: 1.1083263158798218\n",
      "--------------------------------------------------\n",
      "##### Epoch: 1/10000 || Loss: 0.9703396558761597\n",
      "--------------------------------------------------\n",
      "Validation || Epoch: 1 || Loss: 0.8777659806338224 || Accuracy: 0.6225854158401489 || F1-score: 0.25579975579975583\n",
      "Epoch: 101/10000 || Item: 0/85 || Loss: 0.6071421504020691\n",
      "--------------------------------------------------\n",
      "##### Epoch: 101/10000 || Loss: 0.29399019479751587\n",
      "--------------------------------------------------\n",
      "Validation || Epoch: 101 || Loss: 0.8207249262116172 || Accuracy: 0.679049015045166 || F1-score: 0.53183287934843\n",
      "Early stopping at epoch 119!\n",
      "Accuracy on dataset of size 672: 70.98213958740234 %.\n",
      "Average loss: 0.7458651282570579\n",
      "proportion of labels in prediction: [tensor(0.7128), tensor(0.1920), tensor(0.0952)]\n",
      "proportion of labels in data: [tensor(0.6235), tensor(0.2232), tensor(0.1533)]\n",
      "- f1: [0.81514477 0.53763441 0.43113772]\n",
      "- f1 (average): 0.5946389664333473\n",
      "- accuracy: 0.7098214030265808\n",
      "\n",
      "********** lstm_hidden_dim: [8, 8] || ffnhidden_dim: [100, 100, 100]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/var/folders/l7/bnn1j6bs3bqfskq2jlq55yh80000gr/T/ipykernel_51169/2493663396.py:31: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  train, valid, test = split_dataset(x_data=torch.tensor(x_data).float(),\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "65070d4a52e947428fc8d0e2c83d4f73",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/10000 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 1/10000 || Item: 0/85 || Loss: 1.1249394416809082\n",
      "--------------------------------------------------\n",
      "##### Epoch: 1/10000 || Loss: 0.9522772431373596\n",
      "--------------------------------------------------\n",
      "Validation || Epoch: 1 || Loss: 0.943194947459481 || Accuracy: 0.6225854158401489 || F1-score: 0.25579975579975583\n",
      "Epoch: 101/10000 || Item: 0/85 || Loss: 0.7068532705307007\n",
      "--------------------------------------------------\n",
      "##### Epoch: 101/10000 || Loss: 0.12456218898296356\n",
      "--------------------------------------------------\n",
      "Validation || Epoch: 101 || Loss: 0.8211802244186401 || Accuracy: 0.6864784359931946 || F1-score: 0.5544798456325873\n",
      "Early stopping at epoch 124!\n",
      "Accuracy on dataset of size 672: 69.04762268066406 %.\n",
      "Average loss: 0.7713598229668357\n",
      "proportion of labels in prediction: [tensor(0.6935), tensor(0.2098), tensor(0.0967)]\n",
      "proportion of labels in data: [tensor(0.6235), tensor(0.2232), tensor(0.1533)]\n",
      "- f1: [0.80677966 0.50859107 0.39285714]\n",
      "- f1 (average): 0.5694092897220627\n",
      "- accuracy: 0.6904761791229248\n",
      "\n",
      "********** lstm_hidden_dim: [8, 8] || ffnhidden_dim: [100, 100, 100, 100]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/var/folders/l7/bnn1j6bs3bqfskq2jlq55yh80000gr/T/ipykernel_51169/2493663396.py:31: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  train, valid, test = split_dataset(x_data=torch.tensor(x_data).float(),\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "7dae486307554c7e80adb8230922fb62",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/10000 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 1/10000 || Item: 0/85 || Loss: 1.0913692712783813\n",
      "--------------------------------------------------\n",
      "##### Epoch: 1/10000 || Loss: 0.9906197786331177\n",
      "--------------------------------------------------\n",
      "Validation || Epoch: 1 || Loss: 0.9287018830125983 || Accuracy: 0.6225854158401489 || F1-score: 0.25579975579975583\n",
      "Epoch: 101/10000 || Item: 0/85 || Loss: 0.8286048769950867\n",
      "--------------------------------------------------\n",
      "##### Epoch: 101/10000 || Loss: 0.20334593951702118\n",
      "--------------------------------------------------\n",
      "Validation || Epoch: 101 || Loss: 0.8711824471300299 || Accuracy: 0.6523030996322632 || F1-score: 0.5035916812232601\n",
      "Early stopping at epoch 122!\n",
      "Accuracy on dataset of size 672: 68.45237731933594 %.\n",
      "Average loss: 0.7822817184708335\n",
      "proportion of labels in prediction: [tensor(0.6949), tensor(0.2128), tensor(0.0923)]\n",
      "proportion of labels in data: [tensor(0.6235), tensor(0.2232), tensor(0.1533)]\n",
      "- f1: [0.80361174 0.49829352 0.37575758]\n",
      "- f1 (average): 0.5592209430883073\n",
      "- accuracy: 0.6845238208770752\n",
      "\n",
      "********** lstm_hidden_dim: [8, 8] || ffnhidden_dim: [100, 100, 100, 100, 100]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/var/folders/l7/bnn1j6bs3bqfskq2jlq55yh80000gr/T/ipykernel_51169/2493663396.py:31: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  train, valid, test = split_dataset(x_data=torch.tensor(x_data).float(),\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "ade35f848bbc4825a806bee09aafc832",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/10000 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 1/10000 || Item: 0/85 || Loss: 1.0686894655227661\n",
      "--------------------------------------------------\n",
      "##### Epoch: 1/10000 || Loss: 0.9680382013320923\n",
      "--------------------------------------------------\n",
      "Validation || Epoch: 1 || Loss: 0.9435630494898016 || Accuracy: 0.6225854158401489 || F1-score: 0.25579975579975583\n",
      "Epoch: 101/10000 || Item: 0/85 || Loss: 0.7456050515174866\n",
      "--------------------------------------------------\n",
      "##### Epoch: 101/10000 || Loss: 0.7053532004356384\n",
      "--------------------------------------------------\n",
      "Validation || Epoch: 101 || Loss: 0.8338342850858514 || Accuracy: 0.6641901731491089 || F1-score: 0.42409309897265546\n",
      "Early stopping at epoch 126!\n",
      "Accuracy on dataset of size 672: 65.77381134033203 %.\n",
      "Average loss: 0.8107903816483237\n",
      "proportion of labels in prediction: [tensor(0.7545), tensor(0.2455), tensor(0.)]\n",
      "proportion of labels in data: [tensor(0.6235), tensor(0.2232), tensor(0.1533)]\n",
      "- f1: [0.80561555 0.43809524 0.        ]\n",
      "- f1 (average): 0.41457026295039245\n",
      "- accuracy: 0.6577380895614624\n",
      "\n",
      "********** lstm_hidden_dim: [12, 12, 8] || ffnhidden_dim: [100, 100]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/var/folders/l7/bnn1j6bs3bqfskq2jlq55yh80000gr/T/ipykernel_51169/2493663396.py:31: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  train, valid, test = split_dataset(x_data=torch.tensor(x_data).float(),\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "4c416c0f3de14cd3946093071ec5e9e5",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/10000 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 1/10000 || Item: 0/85 || Loss: 1.207420825958252\n",
      "--------------------------------------------------\n",
      "##### Epoch: 1/10000 || Loss: 0.9080084562301636\n",
      "--------------------------------------------------\n",
      "Validation || Epoch: 1 || Loss: 0.8924839334054426 || Accuracy: 0.6225854158401489 || F1-score: 0.25579975579975583\n",
      "Epoch: 101/10000 || Item: 0/85 || Loss: 0.721686601638794\n",
      "--------------------------------------------------\n",
      "##### Epoch: 101/10000 || Loss: 0.7638161182403564\n",
      "--------------------------------------------------\n",
      "Validation || Epoch: 101 || Loss: 0.8360991965640675 || Accuracy: 0.6701337099075317 || F1-score: 0.5284795665230447\n",
      "Early stopping at epoch 131!\n",
      "Accuracy on dataset of size 672: 67.85713958740234 %.\n",
      "Average loss: 0.8351644006642428\n",
      "proportion of labels in prediction: [tensor(0.7054), tensor(0.2068), tensor(0.0878)]\n",
      "proportion of labels in data: [tensor(0.6235), tensor(0.2232), tensor(0.1533)]\n",
      "- f1: [0.79507279 0.4982699  0.35802469]\n",
      "- f1 (average): 0.5504557919685532\n",
      "- accuracy: 0.6785714030265808\n",
      "\n",
      "********** lstm_hidden_dim: [12, 12, 8] || ffnhidden_dim: [100, 100, 100]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/var/folders/l7/bnn1j6bs3bqfskq2jlq55yh80000gr/T/ipykernel_51169/2493663396.py:31: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  train, valid, test = split_dataset(x_data=torch.tensor(x_data).float(),\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "75be87026acb48fbaf0e2f7a742a2134",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/10000 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 1/10000 || Item: 0/85 || Loss: 1.1019978523254395\n",
      "--------------------------------------------------\n",
      "##### Epoch: 1/10000 || Loss: 0.9218642115592957\n",
      "--------------------------------------------------\n",
      "Validation || Epoch: 1 || Loss: 0.9295949014750394 || Accuracy: 0.6225854158401489 || F1-score: 0.25579975579975583\n",
      "Epoch: 101/10000 || Item: 0/85 || Loss: 0.6193119287490845\n",
      "--------------------------------------------------\n",
      "##### Epoch: 101/10000 || Loss: 0.1335456371307373\n",
      "--------------------------------------------------\n",
      "Validation || Epoch: 101 || Loss: 0.824391554702412 || Accuracy: 0.6745913624763489 || F1-score: 0.5329199735449736\n",
      "Early stopping at epoch 132!\n",
      "Accuracy on dataset of size 672: 68.00595092773438 %.\n",
      "Average loss: 0.8039264787327159\n",
      "proportion of labels in prediction: [tensor(0.7098), tensor(0.1994), tensor(0.0908)]\n",
      "proportion of labels in data: [tensor(0.6235), tensor(0.2232), tensor(0.1533)]\n",
      "- f1: [0.79910714 0.48591549 0.36585366]\n",
      "- f1 (average): 0.5502920981171582\n",
      "- accuracy: 0.680059552192688\n",
      "\n",
      "********** lstm_hidden_dim: [12, 12, 8] || ffnhidden_dim: [100, 100, 100, 100]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/var/folders/l7/bnn1j6bs3bqfskq2jlq55yh80000gr/T/ipykernel_51169/2493663396.py:31: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  train, valid, test = split_dataset(x_data=torch.tensor(x_data).float(),\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "e1b032ba98034df498d731739598cbcd",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/10000 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 1/10000 || Item: 0/85 || Loss: 1.1113650798797607\n",
      "--------------------------------------------------\n",
      "##### Epoch: 1/10000 || Loss: 0.9515938758850098\n",
      "--------------------------------------------------\n",
      "Validation || Epoch: 1 || Loss: 0.932028591632843 || Accuracy: 0.6225854158401489 || F1-score: 0.25579975579975583\n",
      "Epoch: 101/10000 || Item: 0/85 || Loss: 0.7567929029464722\n",
      "--------------------------------------------------\n",
      "##### Epoch: 101/10000 || Loss: 0.13789458572864532\n",
      "--------------------------------------------------\n",
      "Validation || Epoch: 101 || Loss: 0.8116248683495955 || Accuracy: 0.6805348992347717 || F1-score: 0.5538295414894473\n",
      "Epoch: 201/10000 || Item: 0/85 || Loss: 0.636617124080658\n",
      "--------------------------------------------------\n",
      "##### Epoch: 201/10000 || Loss: 0.47726404666900635\n",
      "--------------------------------------------------\n",
      "Validation || Epoch: 201 || Loss: 0.8049460432746194 || Accuracy: 0.6805348992347717 || F1-score: 0.5538295414894473\n",
      "Epoch: 301/10000 || Item: 0/85 || Loss: 0.48597198724746704\n",
      "--------------------------------------------------\n",
      "##### Epoch: 301/10000 || Loss: 0.26258134841918945\n",
      "--------------------------------------------------\n",
      "Validation || Epoch: 301 || Loss: 0.8063692233779214 || Accuracy: 0.6805348992347717 || F1-score: 0.5538295414894473\n",
      "Epoch: 401/10000 || Item: 0/85 || Loss: 0.54315584897995\n",
      "--------------------------------------------------\n",
      "##### Epoch: 401/10000 || Loss: 0.2930029630661011\n",
      "--------------------------------------------------\n",
      "Validation || Epoch: 401 || Loss: 0.8123869570818815 || Accuracy: 0.6805348992347717 || F1-score: 0.5538295414894473\n",
      "Epoch: 501/10000 || Item: 0/85 || Loss: 0.6520794034004211\n",
      "--------------------------------------------------\n",
      "##### Epoch: 501/10000 || Loss: 0.2452767789363861\n",
      "--------------------------------------------------\n",
      "Validation || Epoch: 501 || Loss: 0.8013184666633606 || Accuracy: 0.6805348992347717 || F1-score: 0.5538295414894473\n",
      "Epoch: 601/10000 || Item: 0/85 || Loss: 0.5845091938972473\n",
      "--------------------------------------------------\n",
      "##### Epoch: 601/10000 || Loss: 0.43530893325805664\n",
      "--------------------------------------------------\n",
      "Validation || Epoch: 601 || Loss: 0.8103004423054782 || Accuracy: 0.6805348992347717 || F1-score: 0.5538295414894473\n",
      "Epoch: 701/10000 || Item: 0/85 || Loss: 0.4722696542739868\n",
      "--------------------------------------------------\n",
      "##### Epoch: 701/10000 || Loss: 0.4598489999771118\n",
      "--------------------------------------------------\n",
      "Validation || Epoch: 701 || Loss: 0.8110238476233049 || Accuracy: 0.6805348992347717 || F1-score: 0.5538295414894473\n",
      "Epoch: 801/10000 || Item: 0/85 || Loss: 0.647130012512207\n",
      "--------------------------------------------------\n",
      "##### Epoch: 801/10000 || Loss: 0.6813384294509888\n",
      "--------------------------------------------------\n",
      "Validation || Epoch: 801 || Loss: 0.8040576685558666 || Accuracy: 0.6805348992347717 || F1-score: 0.5538295414894473\n",
      "Epoch: 901/10000 || Item: 0/85 || Loss: 0.4401404559612274\n",
      "--------------------------------------------------\n",
      "##### Epoch: 901/10000 || Loss: 0.35883015394210815\n",
      "--------------------------------------------------\n",
      "Validation || Epoch: 901 || Loss: 0.8012731183658947 || Accuracy: 0.6805348992347717 || F1-score: 0.5538295414894473\n",
      "Epoch: 1001/10000 || Item: 0/85 || Loss: 0.5145118236541748\n",
      "--------------------------------------------------\n",
      "##### Epoch: 1001/10000 || Loss: 1.148460030555725\n",
      "--------------------------------------------------\n",
      "Validation || Epoch: 1001 || Loss: 0.8131820830431852 || Accuracy: 0.6805348992347717 || F1-score: 0.5538295414894473\n",
      "Epoch: 1101/10000 || Item: 0/85 || Loss: 0.44342926144599915\n",
      "--------------------------------------------------\n",
      "##### Epoch: 1101/10000 || Loss: 0.21844333410263062\n",
      "--------------------------------------------------\n",
      "Validation || Epoch: 1101 || Loss: 0.806326297196475 || Accuracy: 0.6805348992347717 || F1-score: 0.5538295414894473\n",
      "Epoch: 1201/10000 || Item: 0/85 || Loss: 0.6530765891075134\n",
      "--------------------------------------------------\n",
      "##### Epoch: 1201/10000 || Loss: 0.8869455456733704\n",
      "--------------------------------------------------\n",
      "Validation || Epoch: 1201 || Loss: 0.8022932843728499 || Accuracy: 0.6805348992347717 || F1-score: 0.5538295414894473\n",
      "Epoch: 1301/10000 || Item: 0/85 || Loss: 0.5389145612716675\n",
      "--------------------------------------------------\n",
      "##### Epoch: 1301/10000 || Loss: 0.3149687647819519\n",
      "--------------------------------------------------\n",
      "Validation || Epoch: 1301 || Loss: 0.7980285341089423 || Accuracy: 0.6805348992347717 || F1-score: 0.5538295414894473\n",
      "Epoch: 1401/10000 || Item: 0/85 || Loss: 0.6944828033447266\n",
      "--------------------------------------------------\n",
      "##### Epoch: 1401/10000 || Loss: 0.17953510582447052\n",
      "--------------------------------------------------\n",
      "Validation || Epoch: 1401 || Loss: 0.8116254318844188 || Accuracy: 0.6805348992347717 || F1-score: 0.5538295414894473\n",
      "Epoch: 1501/10000 || Item: 0/85 || Loss: 0.5930138826370239\n",
      "--------------------------------------------------\n",
      "##### Epoch: 1501/10000 || Loss: 0.27026548981666565\n",
      "--------------------------------------------------\n",
      "Validation || Epoch: 1501 || Loss: 0.8074967861175537 || Accuracy: 0.6805348992347717 || F1-score: 0.5538295414894473\n",
      "Epoch: 1601/10000 || Item: 0/85 || Loss: 0.6096426844596863\n",
      "--------------------------------------------------\n",
      "##### Epoch: 1601/10000 || Loss: 0.24474436044692993\n",
      "--------------------------------------------------\n",
      "Validation || Epoch: 1601 || Loss: 0.8058392134579745 || Accuracy: 0.6805348992347717 || F1-score: 0.5538295414894473\n",
      "Epoch: 1701/10000 || Item: 0/85 || Loss: 0.6017814874649048\n",
      "--------------------------------------------------\n",
      "##### Epoch: 1701/10000 || Loss: 0.6805843710899353\n",
      "--------------------------------------------------\n",
      "Validation || Epoch: 1701 || Loss: 0.8038349585099653 || Accuracy: 0.6805348992347717 || F1-score: 0.5538295414894473\n",
      "Epoch: 1801/10000 || Item: 0/85 || Loss: 0.5052571296691895\n",
      "--------------------------------------------------\n",
      "##### Epoch: 1801/10000 || Loss: 0.5235044956207275\n",
      "--------------------------------------------------\n",
      "Validation || Epoch: 1801 || Loss: 0.8058858242901888 || Accuracy: 0.679049015045166 || F1-score: 0.5524781180776904\n",
      "Epoch: 1901/10000 || Item: 0/85 || Loss: 0.6053833961486816\n",
      "--------------------------------------------------\n",
      "##### Epoch: 1901/10000 || Loss: 0.18287207186222076\n",
      "--------------------------------------------------\n",
      "Validation || Epoch: 1901 || Loss: 0.8098889697681774 || Accuracy: 0.679049015045166 || F1-score: 0.5524781180776904\n",
      "Early stopping at epoch 1962!\n",
      "Accuracy on dataset of size 672: 68.75 %.\n",
      "Average loss: 0.7953791347416964\n",
      "proportion of labels in prediction: [tensor(0.7098), tensor(0.2009), tensor(0.0893)]\n",
      "proportion of labels in data: [tensor(0.6235), tensor(0.2232), tensor(0.1533)]\n",
      "- f1: [0.80580357 0.49824561 0.36809816]\n",
      "- f1 (average): 0.5573824483242872\n",
      "- accuracy: 0.6875\n",
      "\n",
      "********** lstm_hidden_dim: [12, 12, 8] || ffnhidden_dim: [100, 100, 100, 100, 100]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/var/folders/l7/bnn1j6bs3bqfskq2jlq55yh80000gr/T/ipykernel_51169/2493663396.py:31: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  train, valid, test = split_dataset(x_data=torch.tensor(x_data).float(),\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "6cf19fc8d1014505bc01dbeb1e42ab84",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/10000 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 1/10000 || Item: 0/85 || Loss: 1.110866665840149\n",
      "--------------------------------------------------\n",
      "##### Epoch: 1/10000 || Loss: 1.0323796272277832\n",
      "--------------------------------------------------\n",
      "Validation || Epoch: 1 || Loss: 0.9433342760259454 || Accuracy: 0.6225854158401489 || F1-score: 0.25579975579975583\n",
      "Epoch: 101/10000 || Item: 0/85 || Loss: 0.6905802488327026\n",
      "--------------------------------------------------\n",
      "##### Epoch: 101/10000 || Loss: 0.6991264224052429\n",
      "--------------------------------------------------\n",
      "Validation || Epoch: 101 || Loss: 0.8670690059661865 || Accuracy: 0.6448736786842346 || F1-score: 0.41140734684814256\n",
      "Early stopping at epoch 122!\n",
      "Accuracy on dataset of size 672: 64.28571319580078 %.\n",
      "Average loss: 0.852442280812697\n",
      "proportion of labels in prediction: [tensor(0.6979), tensor(0.3021), tensor(0.)]\n",
      "proportion of labels in data: [tensor(0.6235), tensor(0.2232), tensor(0.1533)]\n",
      "- f1: [0.7972973  0.44192635 0.        ]\n",
      "- f1 (average): 0.4130745476354542\n",
      "- accuracy: 0.6428571343421936\n",
      "\n",
      "********** lstm_hidden_dim: [12, 12, 12, 8] || ffnhidden_dim: [100, 100]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/var/folders/l7/bnn1j6bs3bqfskq2jlq55yh80000gr/T/ipykernel_51169/2493663396.py:31: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  train, valid, test = split_dataset(x_data=torch.tensor(x_data).float(),\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "a3be529f6f094942b65ed997559d6be0",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/10000 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 1/10000 || Item: 0/85 || Loss: 1.1104532480239868\n",
      "--------------------------------------------------\n",
      "##### Epoch: 1/10000 || Loss: 0.8665093183517456\n",
      "--------------------------------------------------\n",
      "Validation || Epoch: 1 || Loss: 0.893160110170191 || Accuracy: 0.6225854158401489 || F1-score: 0.25579975579975583\n",
      "Epoch: 101/10000 || Item: 0/85 || Loss: 0.6507341861724854\n",
      "--------------------------------------------------\n",
      "##### Epoch: 101/10000 || Loss: 0.34680408239364624\n",
      "--------------------------------------------------\n",
      "Validation || Epoch: 101 || Loss: 0.8093088648535989 || Accuracy: 0.6656760573387146 || F1-score: 0.5295474762916609\n",
      "Early stopping at epoch 119!\n",
      "Accuracy on dataset of size 672: 68.60118865966797 %.\n",
      "Average loss: 0.805629854852503\n",
      "proportion of labels in prediction: [tensor(0.7113), tensor(0.1964), tensor(0.0923)]\n",
      "proportion of labels in data: [tensor(0.6235), tensor(0.2232), tensor(0.1533)]\n",
      "- f1: [0.80267559 0.4964539  0.37575758]\n",
      "- f1 (average): 0.5582956872503588\n",
      "- accuracy: 0.6860119104385376\n",
      "\n",
      "********** lstm_hidden_dim: [12, 12, 12, 8] || ffnhidden_dim: [100, 100, 100]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/var/folders/l7/bnn1j6bs3bqfskq2jlq55yh80000gr/T/ipykernel_51169/2493663396.py:31: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  train, valid, test = split_dataset(x_data=torch.tensor(x_data).float(),\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "740f8d8ea6d749518e107b0c523cbe6b",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/10000 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 1/10000 || Item: 0/85 || Loss: 1.1527830362319946\n",
      "--------------------------------------------------\n",
      "##### Epoch: 1/10000 || Loss: 0.9344223141670227\n",
      "--------------------------------------------------\n",
      "Validation || Epoch: 1 || Loss: 0.9437594793059609 || Accuracy: 0.6225854158401489 || F1-score: 0.25579975579975583\n",
      "Epoch: 101/10000 || Item: 0/85 || Loss: 0.6916497945785522\n",
      "--------------------------------------------------\n",
      "##### Epoch: 101/10000 || Loss: 0.12838536500930786\n",
      "--------------------------------------------------\n",
      "Validation || Epoch: 101 || Loss: 0.8135914260690863 || Accuracy: 0.668647825717926 || F1-score: 0.522173657439358\n",
      "Early stopping at epoch 124!\n",
      "Accuracy on dataset of size 672: 68.89881134033203 %.\n",
      "Average loss: 0.7816357937726107\n",
      "proportion of labels in prediction: [tensor(0.7009), tensor(0.1979), tensor(0.1012)]\n",
      "proportion of labels in data: [tensor(0.6235), tensor(0.2232), tensor(0.1533)]\n",
      "- f1: [0.81123596 0.50176678 0.3625731 ]\n",
      "- f1 (average): 0.5585252796412271\n",
      "- accuracy: 0.6889880895614624\n",
      "\n",
      "********** lstm_hidden_dim: [12, 12, 12, 8] || ffnhidden_dim: [100, 100, 100, 100]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/var/folders/l7/bnn1j6bs3bqfskq2jlq55yh80000gr/T/ipykernel_51169/2493663396.py:31: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  train, valid, test = split_dataset(x_data=torch.tensor(x_data).float(),\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "3b6308ec1ad8438b9d91304992d35936",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/10000 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 1/10000 || Item: 0/85 || Loss: 1.0989179611206055\n",
      "--------------------------------------------------\n",
      "##### Epoch: 1/10000 || Loss: 0.936793863773346\n",
      "--------------------------------------------------\n",
      "Validation || Epoch: 1 || Loss: 0.9397207390178334 || Accuracy: 0.6225854158401489 || F1-score: 0.25579975579975583\n",
      "Epoch: 101/10000 || Item: 0/85 || Loss: 0.7860616445541382\n",
      "--------------------------------------------------\n",
      "##### Epoch: 101/10000 || Loss: 0.27014172077178955\n",
      "--------------------------------------------------\n",
      "Validation || Epoch: 101 || Loss: 0.8227900916879828 || Accuracy: 0.6567607522010803 || F1-score: 0.5141564309003757\n",
      "Early stopping at epoch 122!\n",
      "Accuracy on dataset of size 672: 68.45237731933594 %.\n",
      "Average loss: 0.7630500956015154\n",
      "proportion of labels in prediction: [tensor(0.7158), tensor(0.1920), tensor(0.0923)]\n",
      "proportion of labels in data: [tensor(0.6235), tensor(0.2232), tensor(0.1533)]\n",
      "- f1: [0.81111111 0.46594982 0.36363636]\n",
      "- f1 (average): 0.5468990985120017\n",
      "- accuracy: 0.6845238208770752\n",
      "\n",
      "********** lstm_hidden_dim: [12, 12, 12, 8] || ffnhidden_dim: [100, 100, 100, 100, 100]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/var/folders/l7/bnn1j6bs3bqfskq2jlq55yh80000gr/T/ipykernel_51169/2493663396.py:31: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  train, valid, test = split_dataset(x_data=torch.tensor(x_data).float(),\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "054981497c4f44268896015b29cb0bc4",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/10000 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 1/10000 || Item: 0/85 || Loss: 1.1213955879211426\n",
      "--------------------------------------------------\n",
      "##### Epoch: 1/10000 || Loss: 1.0499165058135986\n",
      "--------------------------------------------------\n",
      "Validation || Epoch: 1 || Loss: 0.9505978280847723 || Accuracy: 0.6225854158401489 || F1-score: 0.25579975579975583\n",
      "Epoch: 101/10000 || Item: 0/85 || Loss: 0.6903181672096252\n",
      "--------------------------------------------------\n",
      "##### Epoch: 101/10000 || Loss: 0.7371382117271423\n",
      "--------------------------------------------------\n",
      "Validation || Epoch: 101 || Loss: 0.8040579394860701 || Accuracy: 0.6627042889595032 || F1-score: 0.4252061721417711\n",
      "Early stopping at epoch 137!\n",
      "Accuracy on dataset of size 672: 65.0297622680664 %.\n",
      "Average loss: 0.8316478512503884\n",
      "proportion of labels in prediction: [tensor(0.7173), tensor(0.2827), tensor(0.)]\n",
      "proportion of labels in data: [tensor(0.6235), tensor(0.2232), tensor(0.1533)]\n",
      "- f1: [0.79689234 0.45882353 0.        ]\n",
      "- f1 (average): 0.41857195708472067\n",
      "- accuracy: 0.6502976417541504\n"
     ]
    }
   ],
   "source": [
    "x_data, input_channels = obtain_SDSN_input(pooled_mean_pretrained, path_specifics)\n",
    "for lstm_hidden_dim in lstm_hidden_dim_trial:\n",
    "    for ffn_hidden_dim in ffn_hidden_dim_trial:\n",
    "        print(f\"\\n********** lstm_hidden_dim: {lstm_hidden_dim} \"\n",
    "              f\"|| ffnhidden_dim: {ffn_hidden_dim}\")\n",
    "        implement_sdsn(x_data=x_data,\n",
    "                       y_data=y_data,\n",
    "                       sig_depth=sig_depth,\n",
    "                       input_channels=input_channels,\n",
    "                       output_channels=output_channels,\n",
    "                       lstm_hidden_dim=lstm_hidden_dim,\n",
    "                       ffn_hidden_dim=ffn_hidden_dim,\n",
    "                       BiLSTM=BiLSTM,\n",
    "                       learning_rate=learning_rate,\n",
    "                       loss=loss)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "33c8f54c",
   "metadata": {},
   "source": [
    "### Max pooled"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 220,
   "id": "a68c7242",
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[INFO] Concatenating the embeddings to the dataframe...\n",
      "[INFO] - columns beginning with 'e' denote the full embddings.\n",
      "[INFO] - columns beginning with 'd' denote the dimension reduced embeddings.\n",
      "[INFO] Adding time feature columns into dataframe in `.df`.\n",
      "[INFO] Adding 'time_encoding' and feature...\n",
      "[INFO] Adding 'time_diff' and feature...\n",
      "[INFO] Adding 'timeline_index' feature...\n",
      "[INFO] Padding ids and storing in `.df_padded` and `.array_padded` attributes.\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "446763f1f5264ad785516a8259229d4f",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/13551 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[INFO] The path was created for each item in the dataframe, by looking at its history, so to include embeddings in the FFN input, we concatenate the embeddings for each sentence / text.\n",
      "\n",
      "********** lstm_hidden_dim: [8, 8] || ffnhidden_dim: [100, 100]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/var/folders/l7/bnn1j6bs3bqfskq2jlq55yh80000gr/T/ipykernel_51169/2493663396.py:31: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  train, valid, test = split_dataset(x_data=torch.tensor(x_data).float(),\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "ab97497b2f8b40cb8fb0f53424d7ec4b",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/10000 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 1/10000 || Item: 0/85 || Loss: 1.0611822605133057\n",
      "--------------------------------------------------\n",
      "##### Epoch: 1/10000 || Loss: 0.906973659992218\n",
      "--------------------------------------------------\n",
      "Validation || Epoch: 1 || Loss: 0.9062382687221874 || Accuracy: 0.6225854158401489 || F1-score: 0.25579975579975583\n",
      "Epoch: 101/10000 || Item: 0/85 || Loss: 0.7280529141426086\n",
      "--------------------------------------------------\n",
      "##### Epoch: 101/10000 || Loss: 0.11842703819274902\n",
      "--------------------------------------------------\n",
      "Validation || Epoch: 101 || Loss: 0.7983393940058622 || Accuracy: 0.679049015045166 || F1-score: 0.5531351637546328\n",
      "Early stopping at epoch 141!\n",
      "Accuracy on dataset of size 672: 66.36904907226562 %.\n",
      "Average loss: 0.8046743111176924\n",
      "proportion of labels in prediction: [tensor(0.7113), tensor(0.2054), tensor(0.0833)]\n",
      "proportion of labels in data: [tensor(0.6235), tensor(0.2232), tensor(0.1533)]\n",
      "- f1: [0.7826087  0.47222222 0.33962264]\n",
      "- f1 (average): 0.53148451979461\n",
      "- accuracy: 0.663690447807312\n",
      "\n",
      "********** lstm_hidden_dim: [8, 8] || ffnhidden_dim: [100, 100, 100]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/var/folders/l7/bnn1j6bs3bqfskq2jlq55yh80000gr/T/ipykernel_51169/2493663396.py:31: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  train, valid, test = split_dataset(x_data=torch.tensor(x_data).float(),\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "f5d8bbc28a86494da064daffc13f6b6d",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/10000 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 1/10000 || Item: 0/85 || Loss: 1.0875803232192993\n",
      "--------------------------------------------------\n",
      "##### Epoch: 1/10000 || Loss: 0.9498467445373535\n",
      "--------------------------------------------------\n",
      "Validation || Epoch: 1 || Loss: 0.940553605556488 || Accuracy: 0.6225854158401489 || F1-score: 0.25579975579975583\n",
      "Epoch: 101/10000 || Item: 0/85 || Loss: 0.6147798895835876\n",
      "--------------------------------------------------\n",
      "##### Epoch: 101/10000 || Loss: 0.4620286226272583\n",
      "--------------------------------------------------\n",
      "Validation || Epoch: 101 || Loss: 0.8429263559254733 || Accuracy: 0.6879643201828003 || F1-score: 0.5607682417229186\n",
      "Early stopping at epoch 138!\n",
      "Accuracy on dataset of size 672: 67.26190185546875 %.\n",
      "Average loss: 0.894775005904111\n",
      "proportion of labels in prediction: [tensor(0.6935), tensor(0.2173), tensor(0.0893)]\n",
      "proportion of labels in data: [tensor(0.6235), tensor(0.2232), tensor(0.1533)]\n",
      "- f1: [0.77740113 0.50675676 0.40490798]\n",
      "- f1 (average): 0.5630219540534607\n",
      "- accuracy: 0.6726190447807312\n",
      "\n",
      "********** lstm_hidden_dim: [8, 8] || ffnhidden_dim: [100, 100, 100, 100]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/var/folders/l7/bnn1j6bs3bqfskq2jlq55yh80000gr/T/ipykernel_51169/2493663396.py:31: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  train, valid, test = split_dataset(x_data=torch.tensor(x_data).float(),\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "d41ffed1c4304bcb84ce732c6e9fe36a",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/10000 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 1/10000 || Item: 0/85 || Loss: 1.0729649066925049\n",
      "--------------------------------------------------\n",
      "##### Epoch: 1/10000 || Loss: 0.9746654033660889\n",
      "--------------------------------------------------\n",
      "Validation || Epoch: 1 || Loss: 0.9413475285876881 || Accuracy: 0.6225854158401489 || F1-score: 0.25579975579975583\n",
      "Epoch: 101/10000 || Item: 0/85 || Loss: 0.8841552734375\n",
      "--------------------------------------------------\n",
      "##### Epoch: 101/10000 || Loss: 0.3010278046131134\n",
      "--------------------------------------------------\n",
      "Validation || Epoch: 101 || Loss: 0.8812506090510975 || Accuracy: 0.6300148367881775 || F1-score: 0.3900167628981188\n",
      "Early stopping at epoch 117!\n",
      "Accuracy on dataset of size 672: 62.7976188659668 %.\n",
      "Average loss: 0.8637093468145891\n",
      "proportion of labels in prediction: [tensor(0.7292), tensor(0.2708), tensor(0.)]\n",
      "proportion of labels in data: [tensor(0.6235), tensor(0.2232), tensor(0.1533)]\n",
      "- f1: [0.78327833 0.39759036 0.        ]\n",
      "- f1 (average): 0.39362289642618875\n",
      "- accuracy: 0.6279761791229248\n",
      "\n",
      "********** lstm_hidden_dim: [8, 8] || ffnhidden_dim: [100, 100, 100, 100, 100]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/var/folders/l7/bnn1j6bs3bqfskq2jlq55yh80000gr/T/ipykernel_51169/2493663396.py:31: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  train, valid, test = split_dataset(x_data=torch.tensor(x_data).float(),\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "196d5c7e21094efbb2caba7eb4331fad",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/10000 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 1/10000 || Item: 0/85 || Loss: 1.0652843713760376\n",
      "--------------------------------------------------\n",
      "##### Epoch: 1/10000 || Loss: 1.020917534828186\n",
      "--------------------------------------------------\n",
      "Validation || Epoch: 1 || Loss: 0.9387365471233021 || Accuracy: 0.6225854158401489 || F1-score: 0.25579975579975583\n",
      "Epoch: 101/10000 || Item: 0/85 || Loss: 0.7338456511497498\n",
      "--------------------------------------------------\n",
      "##### Epoch: 101/10000 || Loss: 0.7304773926734924\n",
      "--------------------------------------------------\n",
      "Validation || Epoch: 101 || Loss: 0.819216397675601 || Accuracy: 0.6404160261154175 || F1-score: 0.40319943709774214\n",
      "Early stopping at epoch 131!\n",
      "Accuracy on dataset of size 672: 65.17857360839844 %.\n",
      "Average loss: 0.8098824078386481\n",
      "proportion of labels in prediction: [tensor(0.7143), tensor(0.2857), tensor(0.)]\n",
      "proportion of labels in data: [tensor(0.6235), tensor(0.2232), tensor(0.1533)]\n",
      "- f1: [0.80088988 0.45614035 0.        ]\n",
      "- f1 (average): 0.41901007617300573\n",
      "- accuracy: 0.6517857313156128\n",
      "\n",
      "********** lstm_hidden_dim: [12, 12, 8] || ffnhidden_dim: [100, 100]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/var/folders/l7/bnn1j6bs3bqfskq2jlq55yh80000gr/T/ipykernel_51169/2493663396.py:31: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  train, valid, test = split_dataset(x_data=torch.tensor(x_data).float(),\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "f8979abcb8d1452299d29b4a67d86472",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/10000 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 1/10000 || Item: 0/85 || Loss: 1.043005108833313\n",
      "--------------------------------------------------\n",
      "##### Epoch: 1/10000 || Loss: 0.9269269704818726\n",
      "--------------------------------------------------\n",
      "Validation || Epoch: 1 || Loss: 0.9087737690318715 || Accuracy: 0.6225854158401489 || F1-score: 0.25579975579975583\n",
      "Epoch: 101/10000 || Item: 0/85 || Loss: 0.8126065731048584\n",
      "--------------------------------------------------\n",
      "##### Epoch: 101/10000 || Loss: 0.3956730365753174\n",
      "--------------------------------------------------\n",
      "Validation || Epoch: 101 || Loss: 0.8617757721380754 || Accuracy: 0.6433877944946289 || F1-score: 0.4230753239530409\n",
      "Early stopping at epoch 131!\n",
      "Accuracy on dataset of size 672: 64.88095092773438 %.\n",
      "Average loss: 0.8578461842103438\n",
      "proportion of labels in prediction: [tensor(0.7292), tensor(0.2530), tensor(0.0179)]\n",
      "proportion of labels in data: [tensor(0.6235), tensor(0.2232), tensor(0.1533)]\n",
      "- f1: [0.78547855 0.4375     0.15652174]\n",
      "- f1 (average): 0.4598334289950734\n",
      "- accuracy: 0.648809552192688\n",
      "\n",
      "********** lstm_hidden_dim: [12, 12, 8] || ffnhidden_dim: [100, 100, 100]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/var/folders/l7/bnn1j6bs3bqfskq2jlq55yh80000gr/T/ipykernel_51169/2493663396.py:31: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  train, valid, test = split_dataset(x_data=torch.tensor(x_data).float(),\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "8c8f51801df348e4bae2d4d3d95c0cf3",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/10000 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 1/10000 || Item: 0/85 || Loss: 1.1013391017913818\n",
      "--------------------------------------------------\n",
      "##### Epoch: 1/10000 || Loss: 0.9390515089035034\n",
      "--------------------------------------------------\n",
      "Validation || Epoch: 1 || Loss: 0.9443628517064181 || Accuracy: 0.6225854158401489 || F1-score: 0.25579975579975583\n",
      "Epoch: 101/10000 || Item: 0/85 || Loss: 0.6210097074508667\n",
      "--------------------------------------------------\n",
      "##### Epoch: 101/10000 || Loss: 0.08356453478336334\n",
      "--------------------------------------------------\n",
      "Validation || Epoch: 101 || Loss: 0.8513612042773854 || Accuracy: 0.6627042889595032 || F1-score: 0.5111893471108547\n",
      "Early stopping at epoch 138!\n",
      "Accuracy on dataset of size 672: 66.36904907226562 %.\n",
      "Average loss: 0.8813020912083712\n",
      "proportion of labels in prediction: [tensor(0.7158), tensor(0.2098), tensor(0.0744)]\n",
      "proportion of labels in data: [tensor(0.6235), tensor(0.2232), tensor(0.1533)]\n",
      "- f1: [0.78666667 0.45360825 0.33986928]\n",
      "- f1 (average): 0.5267147317116997\n",
      "- accuracy: 0.663690447807312\n",
      "\n",
      "********** lstm_hidden_dim: [12, 12, 8] || ffnhidden_dim: [100, 100, 100, 100]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/var/folders/l7/bnn1j6bs3bqfskq2jlq55yh80000gr/T/ipykernel_51169/2493663396.py:31: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  train, valid, test = split_dataset(x_data=torch.tensor(x_data).float(),\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "830cbb6b357f4f2c80552ca0aaa80c05",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/10000 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 1/10000 || Item: 0/85 || Loss: 1.1034269332885742\n",
      "--------------------------------------------------\n",
      "##### Epoch: 1/10000 || Loss: 1.0152961015701294\n",
      "--------------------------------------------------\n",
      "Validation || Epoch: 1 || Loss: 0.9484180916439403 || Accuracy: 0.6225854158401489 || F1-score: 0.25579975579975583\n",
      "Epoch: 101/10000 || Item: 0/85 || Loss: 0.879435122013092\n",
      "--------------------------------------------------\n",
      "##### Epoch: 101/10000 || Loss: 0.20181603729724884\n",
      "--------------------------------------------------\n",
      "Validation || Epoch: 101 || Loss: 0.8428544510494579 || Accuracy: 0.6523030996322632 || F1-score: 0.4039750957854406\n",
      "Epoch: 201/10000 || Item: 0/85 || Loss: 0.6834601759910583\n",
      "--------------------------------------------------\n",
      "##### Epoch: 201/10000 || Loss: 0.8086645603179932\n",
      "--------------------------------------------------\n",
      "Validation || Epoch: 201 || Loss: 0.8389423977244984 || Accuracy: 0.6523030996322632 || F1-score: 0.4039750957854406\n",
      "Epoch: 301/10000 || Item: 0/85 || Loss: 0.6366521716117859\n",
      "--------------------------------------------------\n",
      "##### Epoch: 301/10000 || Loss: 0.2524992823600769\n",
      "--------------------------------------------------\n",
      "Validation || Epoch: 301 || Loss: 0.8384448750452562 || Accuracy: 0.6523030996322632 || F1-score: 0.4039750957854406\n",
      "Epoch: 401/10000 || Item: 0/85 || Loss: 0.7914009094238281\n",
      "--------------------------------------------------\n",
      "##### Epoch: 401/10000 || Loss: 0.47288984060287476\n",
      "--------------------------------------------------\n",
      "Validation || Epoch: 401 || Loss: 0.8406941999088634 || Accuracy: 0.6523030996322632 || F1-score: 0.4039750957854406\n",
      "Epoch: 501/10000 || Item: 0/85 || Loss: 0.7889343500137329\n",
      "--------------------------------------------------\n",
      "##### Epoch: 501/10000 || Loss: 0.3466920554637909\n",
      "--------------------------------------------------\n",
      "Validation || Epoch: 501 || Loss: 0.8341560634699735 || Accuracy: 0.6523030996322632 || F1-score: 0.4039750957854406\n",
      "Epoch: 601/10000 || Item: 0/85 || Loss: 0.7022749185562134\n",
      "--------------------------------------------------\n",
      "##### Epoch: 601/10000 || Loss: 0.6704635620117188\n",
      "--------------------------------------------------\n",
      "Validation || Epoch: 601 || Loss: 0.8474124344912443 || Accuracy: 0.6523030996322632 || F1-score: 0.4039750957854406\n",
      "Epoch: 701/10000 || Item: 0/85 || Loss: 0.5659341216087341\n",
      "--------------------------------------------------\n",
      "##### Epoch: 701/10000 || Loss: 0.702481210231781\n",
      "--------------------------------------------------\n",
      "Validation || Epoch: 701 || Loss: 0.8426370187239214 || Accuracy: 0.6523030996322632 || F1-score: 0.4039750957854406\n",
      "Epoch: 801/10000 || Item: 0/85 || Loss: 0.8017456531524658\n",
      "--------------------------------------------------\n",
      "##### Epoch: 801/10000 || Loss: 0.7035567164421082\n",
      "--------------------------------------------------\n",
      "Validation || Epoch: 801 || Loss: 0.8346634615551342 || Accuracy: 0.6523030996322632 || F1-score: 0.4039750957854406\n",
      "Epoch: 901/10000 || Item: 0/85 || Loss: 0.4678986966609955\n",
      "--------------------------------------------------\n",
      "##### Epoch: 901/10000 || Loss: 0.8026565909385681\n",
      "--------------------------------------------------\n",
      "Validation || Epoch: 901 || Loss: 0.8406042998487299 || Accuracy: 0.6523030996322632 || F1-score: 0.4039750957854406\n",
      "Epoch: 1001/10000 || Item: 0/85 || Loss: 0.5811099410057068\n",
      "--------------------------------------------------\n",
      "##### Epoch: 1001/10000 || Loss: 1.112053632736206\n",
      "--------------------------------------------------\n",
      "Validation || Epoch: 1001 || Loss: 0.8523851849816062 || Accuracy: 0.6523030996322632 || F1-score: 0.4039750957854406\n",
      "Epoch: 1101/10000 || Item: 0/85 || Loss: 0.6103560924530029\n",
      "--------------------------------------------------\n",
      "##### Epoch: 1101/10000 || Loss: 0.24354052543640137\n",
      "--------------------------------------------------\n",
      "Validation || Epoch: 1101 || Loss: 0.8416218486699191 || Accuracy: 0.6523030996322632 || F1-score: 0.4039750957854406\n",
      "Epoch: 1201/10000 || Item: 0/85 || Loss: 0.698611855506897\n",
      "--------------------------------------------------\n",
      "##### Epoch: 1201/10000 || Loss: 1.1285438537597656\n",
      "--------------------------------------------------\n",
      "Validation || Epoch: 1201 || Loss: 0.8375401009212841 || Accuracy: 0.6523030996322632 || F1-score: 0.4039750957854406\n",
      "Epoch: 1301/10000 || Item: 0/85 || Loss: 0.6932823061943054\n",
      "--------------------------------------------------\n",
      "##### Epoch: 1301/10000 || Loss: 0.45803552865982056\n",
      "--------------------------------------------------\n",
      "Validation || Epoch: 1301 || Loss: 0.8347963419827548 || Accuracy: 0.6523030996322632 || F1-score: 0.4039750957854406\n",
      "Epoch: 1401/10000 || Item: 0/85 || Loss: 0.6972939968109131\n",
      "--------------------------------------------------\n",
      "##### Epoch: 1401/10000 || Loss: 0.6523401737213135\n",
      "--------------------------------------------------\n",
      "Validation || Epoch: 1401 || Loss: 0.8491523645140908 || Accuracy: 0.6523030996322632 || F1-score: 0.4039750957854406\n",
      "Epoch: 1501/10000 || Item: 0/85 || Loss: 0.5826221704483032\n",
      "--------------------------------------------------\n",
      "##### Epoch: 1501/10000 || Loss: 0.4290682077407837\n",
      "--------------------------------------------------\n",
      "Validation || Epoch: 1501 || Loss: 0.840093959461559 || Accuracy: 0.6523030996322632 || F1-score: 0.4039750957854406\n",
      "Epoch: 1601/10000 || Item: 0/85 || Loss: 0.7257621884346008\n",
      "--------------------------------------------------\n",
      "##### Epoch: 1601/10000 || Loss: 0.5775905847549438\n",
      "--------------------------------------------------\n",
      "Validation || Epoch: 1601 || Loss: 0.8398607644167814 || Accuracy: 0.6523030996322632 || F1-score: 0.4039750957854406\n",
      "Epoch: 1701/10000 || Item: 0/85 || Loss: 0.5833355784416199\n",
      "--------------------------------------------------\n",
      "##### Epoch: 1701/10000 || Loss: 0.5905311107635498\n",
      "--------------------------------------------------\n",
      "Validation || Epoch: 1701 || Loss: 0.8470160690220919 || Accuracy: 0.6523030996322632 || F1-score: 0.4039750957854406\n",
      "Epoch: 1801/10000 || Item: 0/85 || Loss: 0.5471723079681396\n",
      "--------------------------------------------------\n",
      "##### Epoch: 1801/10000 || Loss: 1.400580883026123\n",
      "--------------------------------------------------\n",
      "Validation || Epoch: 1801 || Loss: 0.8426531553268433 || Accuracy: 0.6523030996322632 || F1-score: 0.4039750957854406\n",
      "Epoch: 1901/10000 || Item: 0/85 || Loss: 0.7687036395072937\n",
      "--------------------------------------------------\n",
      "##### Epoch: 1901/10000 || Loss: 0.49723467230796814\n",
      "--------------------------------------------------\n",
      "Validation || Epoch: 1901 || Loss: 0.8524254343726418 || Accuracy: 0.6523030996322632 || F1-score: 0.4039750957854406\n",
      "Epoch: 2001/10000 || Item: 0/85 || Loss: 0.6413044929504395\n",
      "--------------------------------------------------\n",
      "##### Epoch: 2001/10000 || Loss: 0.3900896906852722\n",
      "--------------------------------------------------\n",
      "Validation || Epoch: 2001 || Loss: 0.8331508961590853 || Accuracy: 0.6523030996322632 || F1-score: 0.4039750957854406\n",
      "Epoch: 2101/10000 || Item: 0/85 || Loss: 0.8290596604347229\n",
      "--------------------------------------------------\n",
      "##### Epoch: 2101/10000 || Loss: 0.3688499629497528\n",
      "--------------------------------------------------\n",
      "Validation || Epoch: 2101 || Loss: 0.8461114493283358 || Accuracy: 0.6523030996322632 || F1-score: 0.4039750957854406\n",
      "Epoch: 2201/10000 || Item: 0/85 || Loss: 0.645451545715332\n",
      "--------------------------------------------------\n",
      "##### Epoch: 2201/10000 || Loss: 0.17866075038909912\n",
      "--------------------------------------------------\n",
      "Validation || Epoch: 2201 || Loss: 0.8495119322430004 || Accuracy: 0.6523030996322632 || F1-score: 0.4039750957854406\n",
      "Epoch: 2301/10000 || Item: 0/85 || Loss: 0.6752400398254395\n",
      "--------------------------------------------------\n",
      "##### Epoch: 2301/10000 || Loss: 1.0554616451263428\n",
      "--------------------------------------------------\n",
      "Validation || Epoch: 2301 || Loss: 0.8471165028485385 || Accuracy: 0.6523030996322632 || F1-score: 0.4039750957854406\n",
      "Epoch: 2401/10000 || Item: 0/85 || Loss: 0.6309100985527039\n",
      "--------------------------------------------------\n",
      "##### Epoch: 2401/10000 || Loss: 0.795351505279541\n",
      "--------------------------------------------------\n",
      "Validation || Epoch: 2401 || Loss: 0.8402480157938871 || Accuracy: 0.6523030996322632 || F1-score: 0.4039750957854406\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Early stopping at epoch 2446!\n",
      "Accuracy on dataset of size 672: 64.43452453613281 %.\n",
      "Average loss: 0.8683453310619701\n",
      "proportion of labels in prediction: [tensor(0.7351), tensor(0.2649), tensor(0.)]\n",
      "proportion of labels in data: [tensor(0.6235), tensor(0.2232), tensor(0.1533)]\n",
      "- f1: [0.79079956 0.43902439 0.        ]\n",
      "- f1 (average): 0.40994131737593387\n",
      "- accuracy: 0.644345223903656\n",
      "\n",
      "********** lstm_hidden_dim: [12, 12, 8] || ffnhidden_dim: [100, 100, 100, 100, 100]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/var/folders/l7/bnn1j6bs3bqfskq2jlq55yh80000gr/T/ipykernel_51169/2493663396.py:31: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  train, valid, test = split_dataset(x_data=torch.tensor(x_data).float(),\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "98a5aa37a5c64731bc463f379cc50407",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/10000 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 1/10000 || Item: 0/85 || Loss: 1.074674129486084\n",
      "--------------------------------------------------\n",
      "##### Epoch: 1/10000 || Loss: 0.9654678702354431\n",
      "--------------------------------------------------\n",
      "Validation || Epoch: 1 || Loss: 0.9404152740131725 || Accuracy: 0.6225854158401489 || F1-score: 0.25579975579975583\n",
      "Epoch: 101/10000 || Item: 0/85 || Loss: 0.7875795364379883\n",
      "--------------------------------------------------\n",
      "##### Epoch: 101/10000 || Loss: 0.7538393139839172\n",
      "--------------------------------------------------\n",
      "Validation || Epoch: 101 || Loss: 0.871634450825778 || Accuracy: 0.6419019103050232 || F1-score: 0.40243998252665786\n",
      "Early stopping at epoch 127!\n",
      "Accuracy on dataset of size 672: 62.7976188659668 %.\n",
      "Average loss: 0.8363772413947366\n",
      "proportion of labels in prediction: [tensor(0.7336), tensor(0.2664), tensor(0.)]\n",
      "proportion of labels in data: [tensor(0.6235), tensor(0.2232), tensor(0.1533)]\n",
      "- f1: [0.78289474 0.39513678 0.        ]\n",
      "- f1 (average): 0.39267717165253563\n",
      "- accuracy: 0.6279761791229248\n",
      "\n",
      "********** lstm_hidden_dim: [12, 12, 12, 8] || ffnhidden_dim: [100, 100]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/var/folders/l7/bnn1j6bs3bqfskq2jlq55yh80000gr/T/ipykernel_51169/2493663396.py:31: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  train, valid, test = split_dataset(x_data=torch.tensor(x_data).float(),\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "8524713ea37a4636b4bfee15d422664e",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/10000 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 1/10000 || Item: 0/85 || Loss: 1.062619924545288\n",
      "--------------------------------------------------\n",
      "##### Epoch: 1/10000 || Loss: 1.0131422281265259\n",
      "--------------------------------------------------\n",
      "Validation || Epoch: 1 || Loss: 0.9251405325802889 || Accuracy: 0.6225854158401489 || F1-score: 0.25579975579975583\n",
      "Epoch: 101/10000 || Item: 0/85 || Loss: 0.7082000374794006\n",
      "--------------------------------------------------\n",
      "##### Epoch: 101/10000 || Loss: 0.18760985136032104\n",
      "--------------------------------------------------\n",
      "Validation || Epoch: 101 || Loss: 0.7862089655616067 || Accuracy: 0.6745913624763489 || F1-score: 0.5419391430208126\n",
      "Early stopping at epoch 129!\n",
      "Accuracy on dataset of size 672: 68.60118865966797 %.\n",
      "Average loss: 0.7925098592584784\n",
      "proportion of labels in prediction: [tensor(0.7545), tensor(0.1875), tensor(0.0580)]\n",
      "proportion of labels in data: [tensor(0.6235), tensor(0.2232), tensor(0.1533)]\n",
      "- f1: [0.80561555 0.47101449 0.32394366]\n",
      "- f1 (average): 0.5335245684937978\n",
      "- accuracy: 0.6860119104385376\n",
      "\n",
      "********** lstm_hidden_dim: [12, 12, 12, 8] || ffnhidden_dim: [100, 100, 100]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/var/folders/l7/bnn1j6bs3bqfskq2jlq55yh80000gr/T/ipykernel_51169/2493663396.py:31: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  train, valid, test = split_dataset(x_data=torch.tensor(x_data).float(),\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "594535e0c07f4ec2a9e069e90bb6e0ac",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/10000 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 1/10000 || Item: 0/85 || Loss: 1.1187163591384888\n",
      "--------------------------------------------------\n",
      "##### Epoch: 1/10000 || Loss: 0.9843406081199646\n",
      "--------------------------------------------------\n",
      "Validation || Epoch: 1 || Loss: 0.9430152882229198 || Accuracy: 0.6225854158401489 || F1-score: 0.25579975579975583\n",
      "Epoch: 101/10000 || Item: 0/85 || Loss: 0.6623855829238892\n",
      "--------------------------------------------------\n",
      "##### Epoch: 101/10000 || Loss: 0.196440652012825\n",
      "--------------------------------------------------\n",
      "Validation || Epoch: 101 || Loss: 0.8494816801764749 || Accuracy: 0.6285289525985718 || F1-score: 0.4420697964387284\n",
      "Early stopping at epoch 132!\n",
      "Accuracy on dataset of size 672: 63.69047546386719 %.\n",
      "Average loss: 0.8374193473295732\n",
      "proportion of labels in prediction: [tensor(0.7217), tensor(0.2604), tensor(0.0179)]\n",
      "proportion of labels in data: [tensor(0.6235), tensor(0.2232), tensor(0.1533)]\n",
      "- f1: [0.78761062 0.39384615 0.13913043]\n",
      "- f1 (average): 0.4401957360325964\n",
      "- accuracy: 0.636904776096344\n",
      "\n",
      "********** lstm_hidden_dim: [12, 12, 12, 8] || ffnhidden_dim: [100, 100, 100, 100]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/var/folders/l7/bnn1j6bs3bqfskq2jlq55yh80000gr/T/ipykernel_51169/2493663396.py:31: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  train, valid, test = split_dataset(x_data=torch.tensor(x_data).float(),\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "55befaf4259045ef8a2a562185e6b096",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/10000 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 1/10000 || Item: 0/85 || Loss: 1.125571846961975\n",
      "--------------------------------------------------\n",
      "##### Epoch: 1/10000 || Loss: 1.0724183320999146\n",
      "--------------------------------------------------\n",
      "Validation || Epoch: 1 || Loss: 0.9471527934074402 || Accuracy: 0.6225854158401489 || F1-score: 0.25579975579975583\n",
      "Epoch: 101/10000 || Item: 0/85 || Loss: 1.0156971216201782\n",
      "--------------------------------------------------\n",
      "##### Epoch: 101/10000 || Loss: 0.2595859467983246\n",
      "--------------------------------------------------\n",
      "Validation || Epoch: 101 || Loss: 0.8206297105008905 || Accuracy: 0.6508172154426575 || F1-score: 0.39949537150815106\n",
      "Early stopping at epoch 124!\n",
      "Accuracy on dataset of size 672: 64.73213958740234 %.\n",
      "Average loss: 0.814558663151481\n",
      "proportion of labels in prediction: [tensor(0.7396), tensor(0.2604), tensor(0.)]\n",
      "proportion of labels in data: [tensor(0.6235), tensor(0.2232), tensor(0.1533)]\n",
      "- f1: [0.79475983 0.43692308 0.        ]\n",
      "- f1 (average): 0.4105609674168626\n",
      "- accuracy: 0.6473214030265808\n",
      "\n",
      "********** lstm_hidden_dim: [12, 12, 12, 8] || ffnhidden_dim: [100, 100, 100, 100, 100]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/var/folders/l7/bnn1j6bs3bqfskq2jlq55yh80000gr/T/ipykernel_51169/2493663396.py:31: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  train, valid, test = split_dataset(x_data=torch.tensor(x_data).float(),\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "4f6c8a0d7d3d4b54b6e88da0d58b6fd6",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/10000 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 1/10000 || Item: 0/85 || Loss: 1.0989123582839966\n",
      "--------------------------------------------------\n",
      "##### Epoch: 1/10000 || Loss: 1.032710075378418\n",
      "--------------------------------------------------\n",
      "Validation || Epoch: 1 || Loss: 0.9369079145518217 || Accuracy: 0.6225854158401489 || F1-score: 0.25579975579975583\n",
      "Epoch: 101/10000 || Item: 0/85 || Loss: 0.7517858743667603\n",
      "--------------------------------------------------\n",
      "##### Epoch: 101/10000 || Loss: 0.7406988143920898\n",
      "--------------------------------------------------\n",
      "Validation || Epoch: 101 || Loss: 0.8357667110183022 || Accuracy: 0.6270430684089661 || F1-score: 0.3898856990962254\n",
      "Early stopping at epoch 120!\n",
      "Accuracy on dataset of size 672: 63.83928680419922 %.\n",
      "Average loss: 0.7939372441985391\n",
      "proportion of labels in prediction: [tensor(0.7262), tensor(0.2738), tensor(0.)]\n",
      "proportion of labels in data: [tensor(0.6235), tensor(0.2232), tensor(0.1533)]\n",
      "- f1: [0.7938258  0.41317365 0.        ]\n",
      "- f1 (average): 0.4023331506776964\n",
      "- accuracy: 0.6383928656578064\n"
     ]
    }
   ],
   "source": [
    "x_data, input_channels = obtain_SDSN_input(pooled_max_pretrained, path_specifics)\n",
    "for lstm_hidden_dim in lstm_hidden_dim_trial:\n",
    "    for ffn_hidden_dim in ffn_hidden_dim_trial:\n",
    "        print(f\"\\n********** lstm_hidden_dim: {lstm_hidden_dim} \"\n",
    "              f\"|| ffnhidden_dim: {ffn_hidden_dim}\")\n",
    "        implement_sdsn(x_data=x_data,\n",
    "                       y_data=y_data,\n",
    "                       sig_depth=sig_depth,\n",
    "                       input_channels=input_channels,\n",
    "                       output_channels=output_channels,\n",
    "                       lstm_hidden_dim=lstm_hidden_dim,\n",
    "                       ffn_hidden_dim=ffn_hidden_dim,\n",
    "                       BiLSTM=BiLSTM,\n",
    "                       learning_rate=learning_rate,\n",
    "                       loss=loss)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "193137b8",
   "metadata": {},
   "source": [
    "### Sum pooled"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 221,
   "id": "4e70a9fa",
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[INFO] Concatenating the embeddings to the dataframe...\n",
      "[INFO] - columns beginning with 'e' denote the full embddings.\n",
      "[INFO] - columns beginning with 'd' denote the dimension reduced embeddings.\n",
      "[INFO] Adding time feature columns into dataframe in `.df`.\n",
      "[INFO] Adding 'time_encoding' and feature...\n",
      "[INFO] Adding 'time_diff' and feature...\n",
      "[INFO] Adding 'timeline_index' feature...\n",
      "[INFO] Padding ids and storing in `.df_padded` and `.array_padded` attributes.\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "ebe33a1e4d414a27a90c4c0d872ae246",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/13551 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[INFO] The path was created for each item in the dataframe, by looking at its history, so to include embeddings in the FFN input, we concatenate the embeddings for each sentence / text.\n",
      "\n",
      "********** lstm_hidden_dim: [8, 8] || ffnhidden_dim: [100, 100]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/var/folders/l7/bnn1j6bs3bqfskq2jlq55yh80000gr/T/ipykernel_51169/2493663396.py:31: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  train, valid, test = split_dataset(x_data=torch.tensor(x_data).float(),\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "be269b4716ca41139e764f50e017be4a",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/10000 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 1/10000 || Item: 0/85 || Loss: 1.3013468980789185\n",
      "--------------------------------------------------\n",
      "##### Epoch: 1/10000 || Loss: 0.8354977965354919\n",
      "--------------------------------------------------\n",
      "Validation || Epoch: 1 || Loss: 0.8586074764078314 || Accuracy: 0.6404160261154175 || F1-score: 0.3696874014654228\n",
      "Epoch: 101/10000 || Item: 0/85 || Loss: 0.5119310021400452\n",
      "--------------------------------------------------\n",
      "##### Epoch: 101/10000 || Loss: 0.18847788870334625\n",
      "--------------------------------------------------\n",
      "Validation || Epoch: 101 || Loss: 0.7998412143100392 || Accuracy: 0.7057949304580688 || F1-score: 0.5972343295973432\n",
      "Early stopping at epoch 119!\n",
      "Accuracy on dataset of size 672: 70.98213958740234 %.\n",
      "Average loss: 0.8521335016597401\n",
      "proportion of labels in prediction: [tensor(0.7247), tensor(0.1860), tensor(0.0893)]\n",
      "proportion of labels in data: [tensor(0.6235), tensor(0.2232), tensor(0.1533)]\n",
      "- f1: [0.81456954 0.50909091 0.46625767]\n",
      "- f1 (average): 0.5966393714088022\n",
      "- accuracy: 0.7098214030265808\n",
      "\n",
      "********** lstm_hidden_dim: [8, 8] || ffnhidden_dim: [100, 100, 100]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/var/folders/l7/bnn1j6bs3bqfskq2jlq55yh80000gr/T/ipykernel_51169/2493663396.py:31: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  train, valid, test = split_dataset(x_data=torch.tensor(x_data).float(),\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "af2d271862444d7d83b19ddf44ccc398",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/10000 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 1/10000 || Item: 0/85 || Loss: 1.1109387874603271\n",
      "--------------------------------------------------\n",
      "##### Epoch: 1/10000 || Loss: 0.8544552326202393\n",
      "--------------------------------------------------\n",
      "Validation || Epoch: 1 || Loss: 0.9038361419330944 || Accuracy: 0.6433877944946289 || F1-score: 0.36858300812226386\n",
      "Epoch: 101/10000 || Item: 0/85 || Loss: 0.38765737414360046\n",
      "--------------------------------------------------\n",
      "##### Epoch: 101/10000 || Loss: 0.033970266580581665\n",
      "--------------------------------------------------\n",
      "Validation || Epoch: 101 || Loss: 0.9083285440098156 || Accuracy: 0.6924219727516174 || F1-score: 0.5911978988564527\n",
      "Early stopping at epoch 132!\n",
      "Accuracy on dataset of size 672: 69.04762268066406 %.\n",
      "Average loss: 0.8130029873414473\n",
      "proportion of labels in prediction: [tensor(0.6830), tensor(0.2277), tensor(0.0893)]\n",
      "proportion of labels in data: [tensor(0.6235), tensor(0.2232), tensor(0.1533)]\n",
      "- f1: [0.79726651 0.52145215 0.42944785]\n",
      "- f1 (average): 0.582722170927212\n",
      "- accuracy: 0.6904761791229248\n",
      "\n",
      "********** lstm_hidden_dim: [8, 8] || ffnhidden_dim: [100, 100, 100, 100]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/var/folders/l7/bnn1j6bs3bqfskq2jlq55yh80000gr/T/ipykernel_51169/2493663396.py:31: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  train, valid, test = split_dataset(x_data=torch.tensor(x_data).float(),\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "b2ad56d43a8c4b0696f147d9e3bc14dd",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/10000 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 1/10000 || Item: 0/85 || Loss: 1.0930824279785156\n",
      "--------------------------------------------------\n",
      "##### Epoch: 1/10000 || Loss: 0.9830728769302368\n",
      "--------------------------------------------------\n",
      "Validation || Epoch: 1 || Loss: 0.9443454850803722 || Accuracy: 0.6225854158401489 || F1-score: 0.25579975579975583\n",
      "Epoch: 101/10000 || Item: 0/85 || Loss: 0.4144074022769928\n",
      "--------------------------------------------------\n",
      "##### Epoch: 101/10000 || Loss: 0.15897485613822937\n",
      "--------------------------------------------------\n",
      "Validation || Epoch: 101 || Loss: 0.9295072176239707 || Accuracy: 0.6968796253204346 || F1-score: 0.5974639910123781\n",
      "Early stopping at epoch 127!\n",
      "Accuracy on dataset of size 672: 69.04762268066406 %.\n",
      "Average loss: 0.9161134578964927\n",
      "proportion of labels in prediction: [tensor(0.6682), tensor(0.2247), tensor(0.1071)]\n",
      "proportion of labels in data: [tensor(0.6235), tensor(0.2232), tensor(0.1533)]\n",
      "- f1: [0.79032258 0.52491694 0.48      ]\n",
      "- f1 (average): 0.598413174722252\n",
      "- accuracy: 0.6904761791229248\n",
      "\n",
      "********** lstm_hidden_dim: [8, 8] || ffnhidden_dim: [100, 100, 100, 100, 100]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/var/folders/l7/bnn1j6bs3bqfskq2jlq55yh80000gr/T/ipykernel_51169/2493663396.py:31: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  train, valid, test = split_dataset(x_data=torch.tensor(x_data).float(),\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "d1268fc3f90a4d2ba4715f2d4dc13f25",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/10000 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 1/10000 || Item: 0/85 || Loss: 1.1586970090866089\n",
      "--------------------------------------------------\n",
      "##### Epoch: 1/10000 || Loss: 1.0439859628677368\n",
      "--------------------------------------------------\n",
      "Validation || Epoch: 1 || Loss: 0.9710449901494113 || Accuracy: 0.6225854158401489 || F1-score: 0.25579975579975583\n",
      "Epoch: 101/10000 || Item: 0/85 || Loss: 0.3956676721572876\n",
      "--------------------------------------------------\n",
      "##### Epoch: 101/10000 || Loss: 0.23449645936489105\n",
      "--------------------------------------------------\n",
      "Validation || Epoch: 101 || Loss: 0.8783430619673296 || Accuracy: 0.6939078569412231 || F1-score: 0.5786841232219383\n",
      "Early stopping at epoch 123!\n",
      "Accuracy on dataset of size 672: 69.64286041259766 %.\n",
      "Average loss: 0.8908329497684132\n",
      "proportion of labels in prediction: [tensor(0.6786), tensor(0.2188), tensor(0.1027)]\n",
      "proportion of labels in data: [tensor(0.6235), tensor(0.2232), tensor(0.1533)]\n",
      "- f1: [0.8        0.53198653 0.45348837]\n",
      "- f1 (average): 0.5951583013598517\n",
      "- accuracy: 0.6964285969734192\n",
      "\n",
      "********** lstm_hidden_dim: [12, 12, 8] || ffnhidden_dim: [100, 100]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/var/folders/l7/bnn1j6bs3bqfskq2jlq55yh80000gr/T/ipykernel_51169/2493663396.py:31: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  train, valid, test = split_dataset(x_data=torch.tensor(x_data).float(),\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "474494dab21840208f8546be92a67bdf",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/10000 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 1/10000 || Item: 0/85 || Loss: 1.042363166809082\n",
      "--------------------------------------------------\n",
      "##### Epoch: 1/10000 || Loss: 0.7563664317131042\n",
      "--------------------------------------------------\n",
      "Validation || Epoch: 1 || Loss: 0.8164049712094393 || Accuracy: 0.6567607522010803 || F1-score: 0.47700207906536257\n",
      "Epoch: 101/10000 || Item: 0/85 || Loss: 0.4392238259315491\n",
      "--------------------------------------------------\n",
      "##### Epoch: 101/10000 || Loss: 0.059755731374025345\n",
      "--------------------------------------------------\n",
      "Validation || Epoch: 101 || Loss: 0.857847273349762 || Accuracy: 0.689450204372406 || F1-score: 0.5943976893780728\n",
      "Early stopping at epoch 119!\n",
      "Accuracy on dataset of size 672: 70.38690185546875 %.\n",
      "Average loss: 0.8413175073536959\n",
      "proportion of labels in prediction: [tensor(0.6845), tensor(0.2098), tensor(0.1057)]\n",
      "proportion of labels in data: [tensor(0.6235), tensor(0.2232), tensor(0.1533)]\n",
      "- f1: [0.80546075 0.52920962 0.48275862]\n",
      "- f1 (average): 0.6058096645120082\n",
      "- accuracy: 0.7038690447807312\n",
      "\n",
      "********** lstm_hidden_dim: [12, 12, 8] || ffnhidden_dim: [100, 100, 100]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/var/folders/l7/bnn1j6bs3bqfskq2jlq55yh80000gr/T/ipykernel_51169/2493663396.py:31: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  train, valid, test = split_dataset(x_data=torch.tensor(x_data).float(),\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "7027c9646ed54755bfb327cc541341d1",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/10000 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 1/10000 || Item: 0/85 || Loss: 1.1025233268737793\n",
      "--------------------------------------------------\n",
      "##### Epoch: 1/10000 || Loss: 0.9335659146308899\n",
      "--------------------------------------------------\n",
      "Validation || Epoch: 1 || Loss: 0.9173165451396595 || Accuracy: 0.6433877944946289 || F1-score: 0.3906025239031299\n",
      "Epoch: 101/10000 || Item: 0/85 || Loss: 0.3760767877101898\n",
      "--------------------------------------------------\n",
      "##### Epoch: 101/10000 || Loss: 0.003959278576076031\n",
      "--------------------------------------------------\n",
      "Validation || Epoch: 101 || Loss: 0.9313850998878479 || Accuracy: 0.6805348992347717 || F1-score: 0.5916768076746531\n",
      "Early stopping at epoch 127!\n",
      "Accuracy on dataset of size 672: 69.3452377319336 %.\n",
      "Average loss: 0.9569546471942555\n",
      "proportion of labels in prediction: [tensor(0.6652), tensor(0.2351), tensor(0.0997)]\n",
      "proportion of labels in data: [tensor(0.6235), tensor(0.2232), tensor(0.1533)]\n",
      "- f1: [0.79445727 0.54545455 0.44705882]\n",
      "- f1 (average): 0.595656881270249\n",
      "- accuracy: 0.6934523582458496\n",
      "\n",
      "********** lstm_hidden_dim: [12, 12, 8] || ffnhidden_dim: [100, 100, 100, 100]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/var/folders/l7/bnn1j6bs3bqfskq2jlq55yh80000gr/T/ipykernel_51169/2493663396.py:31: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  train, valid, test = split_dataset(x_data=torch.tensor(x_data).float(),\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "98e87f618e9a4b2fad69e53da26052ca",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/10000 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 1/10000 || Item: 0/85 || Loss: 1.088029146194458\n",
      "--------------------------------------------------\n",
      "##### Epoch: 1/10000 || Loss: 0.9533932209014893\n",
      "--------------------------------------------------\n",
      "Validation || Epoch: 1 || Loss: 0.9125539443709634 || Accuracy: 0.6210995316505432 || F1-score: 0.2705276590251193\n",
      "Epoch: 101/10000 || Item: 0/85 || Loss: 0.49797555804252625\n",
      "--------------------------------------------------\n",
      "##### Epoch: 101/10000 || Loss: 0.21526889503002167\n",
      "--------------------------------------------------\n",
      "Validation || Epoch: 101 || Loss: 0.9374861717224121 || Accuracy: 0.6953937411308289 || F1-score: 0.5977988382852487\n",
      "Early stopping at epoch 127!\n",
      "Accuracy on dataset of size 672: 68.30357360839844 %.\n",
      "Average loss: 0.9290091612122275\n",
      "proportion of labels in prediction: [tensor(0.6652), tensor(0.2307), tensor(0.1042)]\n",
      "proportion of labels in data: [tensor(0.6235), tensor(0.2232), tensor(0.1533)]\n",
      "- f1: [0.78290993 0.49836066 0.50867052]\n",
      "- f1 (average): 0.596647035561618\n",
      "- accuracy: 0.6830357313156128\n",
      "\n",
      "********** lstm_hidden_dim: [12, 12, 8] || ffnhidden_dim: [100, 100, 100, 100, 100]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/var/folders/l7/bnn1j6bs3bqfskq2jlq55yh80000gr/T/ipykernel_51169/2493663396.py:31: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  train, valid, test = split_dataset(x_data=torch.tensor(x_data).float(),\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "66d9aa85d97e4f14af397adc29894e75",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/10000 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 1/10000 || Item: 0/85 || Loss: 1.0724536180496216\n",
      "--------------------------------------------------\n",
      "##### Epoch: 1/10000 || Loss: 0.9943448901176453\n",
      "--------------------------------------------------\n",
      "Validation || Epoch: 1 || Loss: 0.941481660712849 || Accuracy: 0.6225854158401489 || F1-score: 0.25579975579975583\n",
      "Epoch: 101/10000 || Item: 0/85 || Loss: 0.2705845832824707\n",
      "--------------------------------------------------\n",
      "##### Epoch: 101/10000 || Loss: 0.24389423429965973\n",
      "--------------------------------------------------\n",
      "Validation || Epoch: 101 || Loss: 0.9391739585182883 || Accuracy: 0.6775631308555603 || F1-score: 0.5907092821166552\n",
      "Early stopping at epoch 126!\n",
      "Accuracy on dataset of size 672: 69.04762268066406 %.\n",
      "Average loss: 0.9894102215766907\n",
      "proportion of labels in prediction: [tensor(0.6741), tensor(0.2158), tensor(0.1101)]\n",
      "proportion of labels in data: [tensor(0.6235), tensor(0.2232), tensor(0.1533)]\n",
      "- f1: [0.7912844  0.50169492 0.50847458]\n",
      "- f1 (average): 0.6004846317317162\n",
      "- accuracy: 0.6904761791229248\n",
      "\n",
      "********** lstm_hidden_dim: [12, 12, 12, 8] || ffnhidden_dim: [100, 100]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/var/folders/l7/bnn1j6bs3bqfskq2jlq55yh80000gr/T/ipykernel_51169/2493663396.py:31: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  train, valid, test = split_dataset(x_data=torch.tensor(x_data).float(),\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "f51b5cfd288b4c80aec6174dae07c06a",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/10000 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 1/10000 || Item: 0/85 || Loss: 1.174203872680664\n",
      "--------------------------------------------------\n",
      "##### Epoch: 1/10000 || Loss: 0.7820780277252197\n",
      "--------------------------------------------------\n",
      "Validation || Epoch: 1 || Loss: 0.8391301848671653 || Accuracy: 0.6537889838218689 || F1-score: 0.43733071671183416\n",
      "Epoch: 101/10000 || Item: 0/85 || Loss: 0.3944697678089142\n",
      "--------------------------------------------------\n",
      "##### Epoch: 101/10000 || Loss: 0.03525356575846672\n",
      "--------------------------------------------------\n",
      "Validation || Epoch: 101 || Loss: 1.0298169417814775 || Accuracy: 0.689450204372406 || F1-score: 0.5992995500071298\n",
      "Early stopping at epoch 116!\n",
      "Accuracy on dataset of size 672: 70.53571319580078 %.\n",
      "Average loss: 1.0018632168119603\n",
      "proportion of labels in prediction: [tensor(0.6726), tensor(0.2202), tensor(0.1071)]\n",
      "proportion of labels in data: [tensor(0.6235), tensor(0.2232), tensor(0.1533)]\n",
      "- f1: [0.80367394 0.54362416 0.49142857]\n",
      "- f1 (average): 0.612908890168231\n",
      "- accuracy: 0.7053571343421936\n",
      "\n",
      "********** lstm_hidden_dim: [12, 12, 12, 8] || ffnhidden_dim: [100, 100, 100]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/var/folders/l7/bnn1j6bs3bqfskq2jlq55yh80000gr/T/ipykernel_51169/2493663396.py:31: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  train, valid, test = split_dataset(x_data=torch.tensor(x_data).float(),\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "b6fdc45652594a119456fd4c33eda1d1",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/10000 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 1/10000 || Item: 0/85 || Loss: 1.101671814918518\n",
      "--------------------------------------------------\n",
      "##### Epoch: 1/10000 || Loss: 0.8468042612075806\n",
      "--------------------------------------------------\n",
      "Validation || Epoch: 1 || Loss: 0.8828405141830444 || Accuracy: 0.6508172154426575 || F1-score: 0.4551098408913714\n",
      "Epoch: 101/10000 || Item: 0/85 || Loss: 0.42085975408554077\n",
      "--------------------------------------------------\n",
      "##### Epoch: 101/10000 || Loss: 0.00869707390666008\n",
      "--------------------------------------------------\n",
      "Validation || Epoch: 101 || Loss: 1.0599372766234658 || Accuracy: 0.6627042889595032 || F1-score: 0.5727171197627999\n",
      "Early stopping at epoch 121!\n",
      "Accuracy on dataset of size 672: 68.89881134033203 %.\n",
      "Average loss: 1.06849773905494\n",
      "proportion of labels in prediction: [tensor(0.6443), tensor(0.2426), tensor(0.1131)]\n",
      "proportion of labels in data: [tensor(0.6235), tensor(0.2232), tensor(0.1533)]\n",
      "- f1: [0.78873239 0.50479233 0.53631285]\n",
      "- f1 (average): 0.6099458585988596\n",
      "- accuracy: 0.6889880895614624\n",
      "\n",
      "********** lstm_hidden_dim: [12, 12, 12, 8] || ffnhidden_dim: [100, 100, 100, 100]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/var/folders/l7/bnn1j6bs3bqfskq2jlq55yh80000gr/T/ipykernel_51169/2493663396.py:31: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  train, valid, test = split_dataset(x_data=torch.tensor(x_data).float(),\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "eb296da6e8324f8f91fbac9123cea2c7",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/10000 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 1/10000 || Item: 0/85 || Loss: 1.042513132095337\n",
      "--------------------------------------------------\n",
      "##### Epoch: 1/10000 || Loss: 0.930135190486908\n",
      "--------------------------------------------------\n",
      "Validation || Epoch: 1 || Loss: 0.8825143304738131 || Accuracy: 0.6344724893569946 || F1-score: 0.30546387972130545\n",
      "Epoch: 101/10000 || Item: 0/85 || Loss: 0.5460414886474609\n",
      "--------------------------------------------------\n",
      "##### Epoch: 101/10000 || Loss: 0.0366196371614933\n",
      "--------------------------------------------------\n",
      "Validation || Epoch: 101 || Loss: 0.9511366432363336 || Accuracy: 0.6716195940971375 || F1-score: 0.5669770948601981\n",
      "Early stopping at epoch 115!\n",
      "Accuracy on dataset of size 672: 68.60118865966797 %.\n",
      "Average loss: 0.9354486844756387\n",
      "proportion of labels in prediction: [tensor(0.6741), tensor(0.2292), tensor(0.0967)]\n",
      "proportion of labels in data: [tensor(0.6235), tensor(0.2232), tensor(0.1533)]\n",
      "- f1: [0.79357798 0.48684211 0.48809524]\n",
      "- f1 (average): 0.5895051083365908\n",
      "- accuracy: 0.6860119104385376\n",
      "\n",
      "********** lstm_hidden_dim: [12, 12, 12, 8] || ffnhidden_dim: [100, 100, 100, 100, 100]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/var/folders/l7/bnn1j6bs3bqfskq2jlq55yh80000gr/T/ipykernel_51169/2493663396.py:31: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  train, valid, test = split_dataset(x_data=torch.tensor(x_data).float(),\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "effc3c2138d44035aecc67ed2b08bb7b",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/10000 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 1/10000 || Item: 0/85 || Loss: 1.1079468727111816\n",
      "--------------------------------------------------\n",
      "##### Epoch: 1/10000 || Loss: 0.9050264954566956\n",
      "--------------------------------------------------\n",
      "Validation || Epoch: 1 || Loss: 0.9055643948641691 || Accuracy: 0.6225854158401489 || F1-score: 0.25579975579975583\n",
      "Epoch: 101/10000 || Item: 0/85 || Loss: 0.2618783116340637\n",
      "--------------------------------------------------\n",
      "##### Epoch: 101/10000 || Loss: 0.24361050128936768\n",
      "--------------------------------------------------\n",
      "Validation || Epoch: 101 || Loss: 0.9748089367693121 || Accuracy: 0.679049015045166 || F1-score: 0.5868828704502329\n",
      "Early stopping at epoch 123!\n",
      "Accuracy on dataset of size 672: 67.85713958740234 %.\n",
      "Average loss: 1.0673792145468972\n",
      "proportion of labels in prediction: [tensor(0.6577), tensor(0.2307), tensor(0.1116)]\n",
      "proportion of labels in data: [tensor(0.6235), tensor(0.2232), tensor(0.1533)]\n",
      "- f1: [0.78513357 0.47868852 0.50561798]\n",
      "- f1 (average): 0.589813355913208\n",
      "- accuracy: 0.6785714030265808\n"
     ]
    }
   ],
   "source": [
    "x_data, input_channels = obtain_SDSN_input(pooled_sum_pretrained, path_specifics)\n",
    "for lstm_hidden_dim in lstm_hidden_dim_trial:\n",
    "    for ffn_hidden_dim in ffn_hidden_dim_trial:\n",
    "        print(f\"\\n********** lstm_hidden_dim: {lstm_hidden_dim} \"\n",
    "              f\"|| ffnhidden_dim: {ffn_hidden_dim}\")\n",
    "        implement_sdsn(x_data=x_data,\n",
    "                       y_data=y_data,\n",
    "                       sig_depth=sig_depth,\n",
    "                       input_channels=input_channels,\n",
    "                       output_channels=output_channels,\n",
    "                       lstm_hidden_dim=lstm_hidden_dim,\n",
    "                       ffn_hidden_dim=ffn_hidden_dim,\n",
    "                       BiLSTM=BiLSTM,\n",
    "                       learning_rate=learning_rate,\n",
    "                       loss=loss)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7a2a3e21",
   "metadata": {},
   "source": [
    "### CLS"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 222,
   "id": "a0d48132",
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[INFO] Concatenating the embeddings to the dataframe...\n",
      "[INFO] - columns beginning with 'e' denote the full embddings.\n",
      "[INFO] - columns beginning with 'd' denote the dimension reduced embeddings.\n",
      "[INFO] Adding time feature columns into dataframe in `.df`.\n",
      "[INFO] Adding 'time_encoding' and feature...\n",
      "[INFO] Adding 'time_diff' and feature...\n",
      "[INFO] Adding 'timeline_index' feature...\n",
      "[INFO] Padding ids and storing in `.df_padded` and `.array_padded` attributes.\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "3c5b165e04944658b56898f16ea8ba8b",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/13551 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[INFO] The path was created for each item in the dataframe, by looking at its history, so to include embeddings in the FFN input, we concatenate the embeddings for each sentence / text.\n",
      "\n",
      "********** lstm_hidden_dim: [8, 8] || ffnhidden_dim: [100, 100]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/var/folders/l7/bnn1j6bs3bqfskq2jlq55yh80000gr/T/ipykernel_51169/2493663396.py:31: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  train, valid, test = split_dataset(x_data=torch.tensor(x_data).float(),\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "7660939620854a69a0d55fcb1179e052",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/10000 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 1/10000 || Item: 0/85 || Loss: 1.2040929794311523\n",
      "--------------------------------------------------\n",
      "##### Epoch: 1/10000 || Loss: 0.9543325304985046\n",
      "--------------------------------------------------\n",
      "Validation || Epoch: 1 || Loss: 0.8827005624771118 || Accuracy: 0.6225854158401489 || F1-score: 0.25579975579975583\n",
      "Epoch: 101/10000 || Item: 0/85 || Loss: 0.7267993688583374\n",
      "--------------------------------------------------\n",
      "##### Epoch: 101/10000 || Loss: 0.19608074426651\n",
      "--------------------------------------------------\n",
      "Validation || Epoch: 101 || Loss: 0.7830820517106489 || Accuracy: 0.6805348992347717 || F1-score: 0.5370926091179745\n",
      "Early stopping at epoch 125!\n",
      "Accuracy on dataset of size 672: 70.08928680419922 %.\n",
      "Average loss: 0.7530356483025984\n",
      "proportion of labels in prediction: [tensor(0.7426), tensor(0.1696), tensor(0.0878)]\n",
      "proportion of labels in data: [tensor(0.6235), tensor(0.2232), tensor(0.1533)]\n",
      "- f1: [0.81481481 0.46969697 0.43209877]\n",
      "- f1 (average): 0.5722035166479611\n",
      "- accuracy: 0.7008928656578064\n",
      "\n",
      "********** lstm_hidden_dim: [8, 8] || ffnhidden_dim: [100, 100, 100]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/var/folders/l7/bnn1j6bs3bqfskq2jlq55yh80000gr/T/ipykernel_51169/2493663396.py:31: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  train, valid, test = split_dataset(x_data=torch.tensor(x_data).float(),\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "59d9c8a9d39e42c69e55a50660c8b468",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/10000 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 1/10000 || Item: 0/85 || Loss: 1.1437132358551025\n",
      "--------------------------------------------------\n",
      "##### Epoch: 1/10000 || Loss: 1.001387596130371\n",
      "--------------------------------------------------\n",
      "Validation || Epoch: 1 || Loss: 0.9409243518655951 || Accuracy: 0.6225854158401489 || F1-score: 0.25579975579975583\n",
      "Epoch: 101/10000 || Item: 0/85 || Loss: 0.733620285987854\n",
      "--------------------------------------------------\n",
      "##### Epoch: 101/10000 || Loss: 0.146580770611763\n",
      "--------------------------------------------------\n",
      "Validation || Epoch: 101 || Loss: 0.7862045493992892 || Accuracy: 0.679049015045166 || F1-score: 0.5387477369664612\n",
      "Early stopping at epoch 123!\n",
      "Accuracy on dataset of size 672: 69.49404907226562 %.\n",
      "Average loss: 0.7522918527776544\n",
      "proportion of labels in prediction: [tensor(0.7232), tensor(0.1801), tensor(0.0967)]\n",
      "proportion of labels in data: [tensor(0.6235), tensor(0.2232), tensor(0.1533)]\n",
      "- f1: [0.80441989 0.49446494 0.42857143]\n",
      "- f1 (average): 0.5758187542412124\n",
      "- accuracy: 0.694940447807312\n",
      "\n",
      "********** lstm_hidden_dim: [8, 8] || ffnhidden_dim: [100, 100, 100, 100]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/var/folders/l7/bnn1j6bs3bqfskq2jlq55yh80000gr/T/ipykernel_51169/2493663396.py:31: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  train, valid, test = split_dataset(x_data=torch.tensor(x_data).float(),\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "1cab8c8f23c1498e8ccaea92465d32fa",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/10000 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 1/10000 || Item: 0/85 || Loss: 1.1192790269851685\n",
      "--------------------------------------------------\n",
      "##### Epoch: 1/10000 || Loss: 0.9309695959091187\n",
      "--------------------------------------------------\n",
      "Validation || Epoch: 1 || Loss: 0.9031798947941173 || Accuracy: 0.6225854158401489 || F1-score: 0.25579975579975583\n",
      "Epoch: 101/10000 || Item: 0/85 || Loss: 0.7530666589736938\n",
      "--------------------------------------------------\n",
      "##### Epoch: 101/10000 || Loss: 0.5289303064346313\n",
      "--------------------------------------------------\n",
      "Validation || Epoch: 101 || Loss: 0.8341609022834084 || Accuracy: 0.679049015045166 || F1-score: 0.5430116182079968\n",
      "Early stopping at epoch 135!\n",
      "Accuracy on dataset of size 672: 68.75 %.\n",
      "Average loss: 0.7924448576840487\n",
      "proportion of labels in prediction: [tensor(0.7232), tensor(0.1756), tensor(0.1012)]\n",
      "proportion of labels in data: [tensor(0.6235), tensor(0.2232), tensor(0.1533)]\n",
      "- f1: [0.79558011 0.46268657 0.46783626]\n",
      "- f1 (average): 0.5753676449904527\n",
      "- accuracy: 0.6875\n",
      "\n",
      "********** lstm_hidden_dim: [8, 8] || ffnhidden_dim: [100, 100, 100, 100, 100]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/var/folders/l7/bnn1j6bs3bqfskq2jlq55yh80000gr/T/ipykernel_51169/2493663396.py:31: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  train, valid, test = split_dataset(x_data=torch.tensor(x_data).float(),\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "a9d0e71364f942df91243ffd53f0f5c2",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/10000 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 1/10000 || Item: 0/85 || Loss: 1.1225972175598145\n",
      "--------------------------------------------------\n",
      "##### Epoch: 1/10000 || Loss: 1.020470380783081\n",
      "--------------------------------------------------\n",
      "Validation || Epoch: 1 || Loss: 0.9420102292841132 || Accuracy: 0.6225854158401489 || F1-score: 0.25579975579975583\n",
      "Epoch: 101/10000 || Item: 0/85 || Loss: 0.578769862651825\n",
      "--------------------------------------------------\n",
      "##### Epoch: 101/10000 || Loss: 0.3644253611564636\n",
      "--------------------------------------------------\n",
      "Validation || Epoch: 101 || Loss: 0.7749437364664945 || Accuracy: 0.6924219727516174 || F1-score: 0.5651662690808598\n",
      "Early stopping at epoch 133!\n",
      "Accuracy on dataset of size 672: 71.875 %.\n",
      "Average loss: 0.7509793043136597\n",
      "proportion of labels in prediction: [tensor(0.7173), tensor(0.1845), tensor(0.0982)]\n",
      "proportion of labels in data: [tensor(0.6235), tensor(0.2232), tensor(0.1533)]\n",
      "- f1: [0.82574917 0.52554745 0.46153846]\n",
      "- f1 (average): 0.6042783581285004\n",
      "- accuracy: 0.71875\n",
      "\n",
      "********** lstm_hidden_dim: [12, 12, 8] || ffnhidden_dim: [100, 100]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/var/folders/l7/bnn1j6bs3bqfskq2jlq55yh80000gr/T/ipykernel_51169/2493663396.py:31: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  train, valid, test = split_dataset(x_data=torch.tensor(x_data).float(),\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "68ba4ed1f8c04a2b920e77705148ef68",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/10000 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 1/10000 || Item: 0/85 || Loss: 1.1425316333770752\n",
      "--------------------------------------------------\n",
      "##### Epoch: 1/10000 || Loss: 0.9537950754165649\n",
      "--------------------------------------------------\n",
      "Validation || Epoch: 1 || Loss: 0.885266201062636 || Accuracy: 0.6225854158401489 || F1-score: 0.25579975579975583\n",
      "Epoch: 101/10000 || Item: 0/85 || Loss: 0.6237946152687073\n",
      "--------------------------------------------------\n",
      "##### Epoch: 101/10000 || Loss: 0.1699737012386322\n",
      "--------------------------------------------------\n",
      "Validation || Epoch: 101 || Loss: 0.8081171404231678 || Accuracy: 0.6671619415283203 || F1-score: 0.5278475681152801\n",
      "Early stopping at epoch 125!\n",
      "Accuracy on dataset of size 672: 68.30357360839844 %.\n",
      "Average loss: 0.7727127833799883\n",
      "proportion of labels in prediction: [tensor(0.7336), tensor(0.1786), tensor(0.0878)]\n",
      "proportion of labels in data: [tensor(0.6235), tensor(0.2232), tensor(0.1533)]\n",
      "- f1: [0.79605263 0.45185185 0.43209877]\n",
      "- f1 (average): 0.5600010829542993\n",
      "- accuracy: 0.6830357313156128\n",
      "\n",
      "********** lstm_hidden_dim: [12, 12, 8] || ffnhidden_dim: [100, 100, 100]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/var/folders/l7/bnn1j6bs3bqfskq2jlq55yh80000gr/T/ipykernel_51169/2493663396.py:31: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  train, valid, test = split_dataset(x_data=torch.tensor(x_data).float(),\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "98f95a5ed8694a05bfb39ae3bdbbda35",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/10000 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 1/10000 || Item: 0/85 || Loss: 1.1180133819580078\n",
      "--------------------------------------------------\n",
      "##### Epoch: 1/10000 || Loss: 0.9255759716033936\n",
      "--------------------------------------------------\n",
      "Validation || Epoch: 1 || Loss: 0.9132819771766663 || Accuracy: 0.6225854158401489 || F1-score: 0.25579975579975583\n",
      "Epoch: 101/10000 || Item: 0/85 || Loss: 0.7313652634620667\n",
      "--------------------------------------------------\n",
      "##### Epoch: 101/10000 || Loss: 0.0869215875864029\n",
      "--------------------------------------------------\n",
      "Validation || Epoch: 101 || Loss: 0.8132577646862377 || Accuracy: 0.658246636390686 || F1-score: 0.4984643819573214\n",
      "Early stopping at epoch 123!\n",
      "Accuracy on dataset of size 672: 68.1547622680664 %.\n",
      "Average loss: 0.7469774267890237\n",
      "proportion of labels in prediction: [tensor(0.7173), tensor(0.1875), tensor(0.0952)]\n",
      "proportion of labels in data: [tensor(0.6235), tensor(0.2232), tensor(0.1533)]\n",
      "- f1: [0.80133185 0.44202899 0.43113772]\n",
      "- f1 (average): 0.55816618785142\n",
      "- accuracy: 0.6815476417541504\n",
      "\n",
      "********** lstm_hidden_dim: [12, 12, 8] || ffnhidden_dim: [100, 100, 100, 100]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/var/folders/l7/bnn1j6bs3bqfskq2jlq55yh80000gr/T/ipykernel_51169/2493663396.py:31: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  train, valid, test = split_dataset(x_data=torch.tensor(x_data).float(),\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "9aedb5485dfb45a8acac70472b20f034",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/10000 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 1/10000 || Item: 0/85 || Loss: 1.0959380865097046\n",
      "--------------------------------------------------\n",
      "##### Epoch: 1/10000 || Loss: 0.9692442417144775\n",
      "--------------------------------------------------\n",
      "Validation || Epoch: 1 || Loss: 0.9381837411360308 || Accuracy: 0.6225854158401489 || F1-score: 0.25579975579975583\n",
      "Epoch: 101/10000 || Item: 0/85 || Loss: 0.8282528519630432\n",
      "--------------------------------------------------\n",
      "##### Epoch: 101/10000 || Loss: 0.18298083543777466\n",
      "--------------------------------------------------\n",
      "Validation || Epoch: 101 || Loss: 0.8390961018475619 || Accuracy: 0.6671619415283203 || F1-score: 0.5085976184094277\n",
      "Epoch: 201/10000 || Item: 0/85 || Loss: 0.6801908016204834\n",
      "--------------------------------------------------\n",
      "##### Epoch: 201/10000 || Loss: 0.9419746398925781\n",
      "--------------------------------------------------\n",
      "Validation || Epoch: 201 || Loss: 0.819741119037975 || Accuracy: 0.6671619415283203 || F1-score: 0.5085976184094277\n",
      "Epoch: 301/10000 || Item: 0/85 || Loss: 0.6159858107566833\n",
      "--------------------------------------------------\n",
      "##### Epoch: 301/10000 || Loss: 0.31902554631233215\n",
      "--------------------------------------------------\n",
      "Validation || Epoch: 301 || Loss: 0.8295209841294722 || Accuracy: 0.6671619415283203 || F1-score: 0.5085976184094277\n",
      "Epoch: 401/10000 || Item: 0/85 || Loss: 0.640324592590332\n",
      "--------------------------------------------------\n",
      "##### Epoch: 401/10000 || Loss: 0.429536372423172\n",
      "--------------------------------------------------\n",
      "Validation || Epoch: 401 || Loss: 0.8321171186187051 || Accuracy: 0.6671619415283203 || F1-score: 0.5082723806854882\n",
      "Early stopping at epoch 430!\n",
      "Accuracy on dataset of size 672: 66.81547546386719 %.\n",
      "Average loss: 0.7995375340635126\n",
      "proportion of labels in prediction: [tensor(0.7545), tensor(0.1845), tensor(0.0610)]\n",
      "proportion of labels in data: [tensor(0.6235), tensor(0.2232), tensor(0.1533)]\n",
      "- f1: [0.79913607 0.40875912 0.31944444]\n",
      "- f1 (average): 0.5091132125488355\n",
      "- accuracy: 0.668154776096344\n",
      "\n",
      "********** lstm_hidden_dim: [12, 12, 8] || ffnhidden_dim: [100, 100, 100, 100, 100]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/var/folders/l7/bnn1j6bs3bqfskq2jlq55yh80000gr/T/ipykernel_51169/2493663396.py:31: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  train, valid, test = split_dataset(x_data=torch.tensor(x_data).float(),\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "d54af86de2134622bc074ab8648c7ddd",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/10000 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 1/10000 || Item: 0/85 || Loss: 1.127925157546997\n",
      "--------------------------------------------------\n",
      "##### Epoch: 1/10000 || Loss: 0.9608778953552246\n",
      "--------------------------------------------------\n",
      "Validation || Epoch: 1 || Loss: 0.9378372539173473 || Accuracy: 0.6225854158401489 || F1-score: 0.25579975579975583\n",
      "Epoch: 101/10000 || Item: 0/85 || Loss: 0.8151942491531372\n",
      "--------------------------------------------------\n",
      "##### Epoch: 101/10000 || Loss: 0.7873227000236511\n",
      "--------------------------------------------------\n",
      "Validation || Epoch: 101 || Loss: 0.8786657940257679 || Accuracy: 0.6344724893569946 || F1-score: 0.4162058177243729\n",
      "Early stopping at epoch 139!\n",
      "Accuracy on dataset of size 672: 64.58333587646484 %.\n",
      "Average loss: 0.8206196373159235\n",
      "proportion of labels in prediction: [tensor(0.6935), tensor(0.2902), tensor(0.0164)]\n",
      "proportion of labels in data: [tensor(0.6235), tensor(0.2232), tensor(0.1533)]\n",
      "- f1: [0.79548023 0.44057971 0.10526316]\n",
      "- f1 (average): 0.44710769800945505\n",
      "- accuracy: 0.6458333134651184\n",
      "\n",
      "********** lstm_hidden_dim: [12, 12, 12, 8] || ffnhidden_dim: [100, 100]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/var/folders/l7/bnn1j6bs3bqfskq2jlq55yh80000gr/T/ipykernel_51169/2493663396.py:31: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  train, valid, test = split_dataset(x_data=torch.tensor(x_data).float(),\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "764041501ad4460dbe9118ef79d22062",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/10000 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 1/10000 || Item: 0/85 || Loss: 1.0581080913543701\n",
      "--------------------------------------------------\n",
      "##### Epoch: 1/10000 || Loss: 0.965984046459198\n",
      "--------------------------------------------------\n",
      "Validation || Epoch: 1 || Loss: 0.8825081424279646 || Accuracy: 0.6225854158401489 || F1-score: 0.25579975579975583\n",
      "Epoch: 101/10000 || Item: 0/85 || Loss: 0.7237440943717957\n",
      "--------------------------------------------------\n",
      "##### Epoch: 101/10000 || Loss: 0.2629973292350769\n",
      "--------------------------------------------------\n",
      "Validation || Epoch: 101 || Loss: 0.7669510462067344 || Accuracy: 0.6879643201828003 || F1-score: 0.5468867367093668\n",
      "Epoch: 201/10000 || Item: 0/85 || Loss: 0.8005213737487793\n",
      "--------------------------------------------------\n",
      "##### Epoch: 201/10000 || Loss: 1.259475827217102\n",
      "--------------------------------------------------\n",
      "Validation || Epoch: 201 || Loss: 0.7732626741582697 || Accuracy: 0.6879643201828003 || F1-score: 0.5468867367093668\n",
      "Epoch: 301/10000 || Item: 0/85 || Loss: 0.42048007249832153\n",
      "--------------------------------------------------\n",
      "##### Epoch: 301/10000 || Loss: 0.21239136159420013\n",
      "--------------------------------------------------\n",
      "Validation || Epoch: 301 || Loss: 0.7747988429936495 || Accuracy: 0.6879643201828003 || F1-score: 0.5468867367093668\n",
      "Epoch: 401/10000 || Item: 0/85 || Loss: 0.5766432881355286\n",
      "--------------------------------------------------\n",
      "##### Epoch: 401/10000 || Loss: 0.541541337966919\n",
      "--------------------------------------------------\n",
      "Validation || Epoch: 401 || Loss: 0.7651166157288984 || Accuracy: 0.6879643201828003 || F1-score: 0.5468867367093668\n",
      "Epoch: 501/10000 || Item: 0/85 || Loss: 0.658301830291748\n",
      "--------------------------------------------------\n",
      "##### Epoch: 501/10000 || Loss: 0.7285420298576355\n",
      "--------------------------------------------------\n",
      "Validation || Epoch: 501 || Loss: 0.7795525735074823 || Accuracy: 0.6879643201828003 || F1-score: 0.5468867367093668\n",
      "Epoch: 601/10000 || Item: 0/85 || Loss: 0.68149733543396\n",
      "--------------------------------------------------\n",
      "##### Epoch: 601/10000 || Loss: 0.6151123046875\n",
      "--------------------------------------------------\n",
      "Validation || Epoch: 601 || Loss: 0.7734259529547258 || Accuracy: 0.6879643201828003 || F1-score: 0.5468867367093668\n",
      "Epoch: 701/10000 || Item: 0/85 || Loss: 0.6902033090591431\n",
      "--------------------------------------------------\n",
      "##### Epoch: 701/10000 || Loss: 0.3985026776790619\n",
      "--------------------------------------------------\n",
      "Validation || Epoch: 701 || Loss: 0.7712962627410889 || Accuracy: 0.6879643201828003 || F1-score: 0.5468867367093668\n",
      "Epoch: 801/10000 || Item: 0/85 || Loss: 0.5823967456817627\n",
      "--------------------------------------------------\n",
      "##### Epoch: 801/10000 || Loss: 0.12737691402435303\n",
      "--------------------------------------------------\n",
      "Validation || Epoch: 801 || Loss: 0.7687737616625699 || Accuracy: 0.6879643201828003 || F1-score: 0.5468867367093668\n",
      "Epoch: 901/10000 || Item: 0/85 || Loss: 0.42985910177230835\n",
      "--------------------------------------------------\n",
      "##### Epoch: 901/10000 || Loss: 0.1314137578010559\n",
      "--------------------------------------------------\n",
      "Validation || Epoch: 901 || Loss: 0.7775844118811868 || Accuracy: 0.6879643201828003 || F1-score: 0.5468867367093668\n",
      "Epoch: 1001/10000 || Item: 0/85 || Loss: 0.6875714063644409\n",
      "--------------------------------------------------\n",
      "##### Epoch: 1001/10000 || Loss: 1.353942632675171\n",
      "--------------------------------------------------\n",
      "Validation || Epoch: 1001 || Loss: 0.7829888788136569 || Accuracy: 0.6879643201828003 || F1-score: 0.5468867367093668\n",
      "Epoch: 1101/10000 || Item: 0/85 || Loss: 0.6115439534187317\n",
      "--------------------------------------------------\n",
      "##### Epoch: 1101/10000 || Loss: 0.20275409519672394\n",
      "--------------------------------------------------\n",
      "Validation || Epoch: 1101 || Loss: 0.7878553217107599 || Accuracy: 0.6879643201828003 || F1-score: 0.5468867367093668\n",
      "Epoch: 1201/10000 || Item: 0/85 || Loss: 0.5770443677902222\n",
      "--------------------------------------------------\n",
      "##### Epoch: 1201/10000 || Loss: 0.3964283764362335\n",
      "--------------------------------------------------\n",
      "Validation || Epoch: 1201 || Loss: 0.7741883993148804 || Accuracy: 0.6879643201828003 || F1-score: 0.5468867367093668\n",
      "Epoch: 1301/10000 || Item: 0/85 || Loss: 0.5639873147010803\n",
      "--------------------------------------------------\n",
      "##### Epoch: 1301/10000 || Loss: 0.3784034252166748\n",
      "--------------------------------------------------\n",
      "Validation || Epoch: 1301 || Loss: 0.7857688340273771 || Accuracy: 0.6879643201828003 || F1-score: 0.5468867367093668\n",
      "Epoch: 1401/10000 || Item: 0/85 || Loss: 0.5516438484191895\n",
      "--------------------------------------------------\n",
      "##### Epoch: 1401/10000 || Loss: 1.20610511302948\n",
      "--------------------------------------------------\n",
      "Validation || Epoch: 1401 || Loss: 0.7780289866707542 || Accuracy: 0.6879643201828003 || F1-score: 0.5468867367093668\n",
      "Epoch: 1501/10000 || Item: 0/85 || Loss: 0.50921630859375\n",
      "--------------------------------------------------\n",
      "##### Epoch: 1501/10000 || Loss: 0.3798248767852783\n",
      "--------------------------------------------------\n",
      "Validation || Epoch: 1501 || Loss: 0.7593741444024172 || Accuracy: 0.6879643201828003 || F1-score: 0.5468867367093668\n",
      "Epoch: 1601/10000 || Item: 0/85 || Loss: 0.45807167887687683\n",
      "--------------------------------------------------\n",
      "##### Epoch: 1601/10000 || Loss: 0.5005151629447937\n",
      "--------------------------------------------------\n",
      "Validation || Epoch: 1601 || Loss: 0.7740627310492776 || Accuracy: 0.6879643201828003 || F1-score: 0.5468867367093668\n",
      "Epoch: 1701/10000 || Item: 0/85 || Loss: 0.46439453959465027\n",
      "--------------------------------------------------\n",
      "##### Epoch: 1701/10000 || Loss: 0.6633172035217285\n",
      "--------------------------------------------------\n",
      "Validation || Epoch: 1701 || Loss: 0.7688839327205311 || Accuracy: 0.6879643201828003 || F1-score: 0.5468867367093668\n",
      "Epoch: 1801/10000 || Item: 0/85 || Loss: 0.5186299681663513\n",
      "--------------------------------------------------\n",
      "##### Epoch: 1801/10000 || Loss: 0.5373347401618958\n",
      "--------------------------------------------------\n",
      "Validation || Epoch: 1801 || Loss: 0.7758631760423834 || Accuracy: 0.6864784359931946 || F1-score: 0.5455716586151368\n",
      "Early stopping at epoch 1846!\n",
      "Accuracy on dataset of size 672: 68.75 %.\n",
      "Average loss: 0.7303985844958912\n",
      "proportion of labels in prediction: [tensor(0.7336), tensor(0.1801), tensor(0.0863)]\n",
      "proportion of labels in data: [tensor(0.6235), tensor(0.2232), tensor(0.1533)]\n",
      "- f1: [0.8004386  0.46494465 0.42236025]\n",
      "- f1 (average): 0.5625811647949758\n",
      "- accuracy: 0.6875\n",
      "\n",
      "********** lstm_hidden_dim: [12, 12, 12, 8] || ffnhidden_dim: [100, 100, 100]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/var/folders/l7/bnn1j6bs3bqfskq2jlq55yh80000gr/T/ipykernel_51169/2493663396.py:31: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  train, valid, test = split_dataset(x_data=torch.tensor(x_data).float(),\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "ab45bc6753f146d484d7bf2ed3f75356",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/10000 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 1/10000 || Item: 0/85 || Loss: 1.1116864681243896\n",
      "--------------------------------------------------\n",
      "##### Epoch: 1/10000 || Loss: 0.9596397280693054\n",
      "--------------------------------------------------\n",
      "Validation || Epoch: 1 || Loss: 0.9104283506220038 || Accuracy: 0.6225854158401489 || F1-score: 0.25579975579975583\n",
      "Epoch: 101/10000 || Item: 0/85 || Loss: 0.6912787556648254\n",
      "--------------------------------------------------\n",
      "##### Epoch: 101/10000 || Loss: 0.1996433138847351\n",
      "--------------------------------------------------\n",
      "Validation || Epoch: 101 || Loss: 0.7782505317167803 || Accuracy: 0.6939078569412231 || F1-score: 0.56118227629019\n",
      "Early stopping at epoch 123!\n",
      "Accuracy on dataset of size 672: 68.30357360839844 %.\n",
      "Average loss: 0.7525844194672324\n",
      "proportion of labels in prediction: [tensor(0.7202), tensor(0.1905), tensor(0.0893)]\n",
      "proportion of labels in data: [tensor(0.6235), tensor(0.2232), tensor(0.1533)]\n",
      "- f1: [0.79512735 0.48201439 0.40490798]\n",
      "- f1 (average): 0.5606832390720732\n",
      "- accuracy: 0.6830357313156128\n",
      "\n",
      "********** lstm_hidden_dim: [12, 12, 12, 8] || ffnhidden_dim: [100, 100, 100, 100]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/var/folders/l7/bnn1j6bs3bqfskq2jlq55yh80000gr/T/ipykernel_51169/2493663396.py:31: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  train, valid, test = split_dataset(x_data=torch.tensor(x_data).float(),\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "08938671c05c4807af3e31bd7d807822",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/10000 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 1/10000 || Item: 0/85 || Loss: 1.096859335899353\n",
      "--------------------------------------------------\n",
      "##### Epoch: 1/10000 || Loss: 0.9114543795585632\n",
      "--------------------------------------------------\n",
      "Validation || Epoch: 1 || Loss: 0.907750584862449 || Accuracy: 0.6225854158401489 || F1-score: 0.25579975579975583\n",
      "Epoch: 101/10000 || Item: 0/85 || Loss: 0.8409744501113892\n",
      "--------------------------------------------------\n",
      "##### Epoch: 101/10000 || Loss: 0.5794983506202698\n",
      "--------------------------------------------------\n",
      "Validation || Epoch: 101 || Loss: 0.8129292293028398 || Accuracy: 0.6671619415283203 || F1-score: 0.5217717128873098\n",
      "Early stopping at epoch 129!\n",
      "Accuracy on dataset of size 672: 67.70833587646484 %.\n",
      "Average loss: 0.8091904737732627\n",
      "proportion of labels in prediction: [tensor(0.7455), tensor(0.1652), tensor(0.0893)]\n",
      "proportion of labels in data: [tensor(0.6235), tensor(0.2232), tensor(0.1533)]\n",
      "- f1: [0.79565217 0.45210728 0.36809816]\n",
      "- f1 (average): 0.5386192043719108\n",
      "- accuracy: 0.6770833134651184\n",
      "\n",
      "********** lstm_hidden_dim: [12, 12, 12, 8] || ffnhidden_dim: [100, 100, 100, 100, 100]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/var/folders/l7/bnn1j6bs3bqfskq2jlq55yh80000gr/T/ipykernel_51169/2493663396.py:31: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  train, valid, test = split_dataset(x_data=torch.tensor(x_data).float(),\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "5751116999494cfc87433dfe0cd06474",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/10000 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 1/10000 || Item: 0/85 || Loss: 1.093720555305481\n",
      "--------------------------------------------------\n",
      "##### Epoch: 1/10000 || Loss: 0.9559621214866638\n",
      "--------------------------------------------------\n",
      "Validation || Epoch: 1 || Loss: 0.9292432503266768 || Accuracy: 0.6225854158401489 || F1-score: 0.25579975579975583\n",
      "Epoch: 101/10000 || Item: 0/85 || Loss: 0.6506471633911133\n",
      "--------------------------------------------------\n",
      "##### Epoch: 101/10000 || Loss: 0.7666477560997009\n",
      "--------------------------------------------------\n",
      "Validation || Epoch: 101 || Loss: 0.8619428331201727 || Accuracy: 0.6359583735466003 || F1-score: 0.40043296039233195\n",
      "Early stopping at epoch 120!\n",
      "Accuracy on dataset of size 672: 63.39285659790039 %.\n",
      "Average loss: 0.849154607816176\n",
      "proportion of labels in prediction: [tensor(0.7202), tensor(0.2798), tensor(0.)]\n",
      "proportion of labels in data: [tensor(0.6235), tensor(0.2232), tensor(0.1533)]\n",
      "- f1: [0.78848283 0.41420118 0.        ]\n",
      "- f1 (average): 0.4008946728088052\n",
      "- accuracy: 0.6339285969734192\n"
     ]
    }
   ],
   "source": [
    "x_data, input_channels = obtain_SDSN_input(pooled_cls_pretrained, path_specifics)\n",
    "for lstm_hidden_dim in lstm_hidden_dim_trial:\n",
    "    for ffn_hidden_dim in ffn_hidden_dim_trial:\n",
    "        print(f\"\\n********** lstm_hidden_dim: {lstm_hidden_dim} \"\n",
    "              f\"|| ffnhidden_dim: {ffn_hidden_dim}\")\n",
    "        implement_sdsn(x_data=x_data,\n",
    "                       y_data=y_data,\n",
    "                       sig_depth=sig_depth,\n",
    "                       input_channels=input_channels,\n",
    "                       output_channels=output_channels,\n",
    "                       lstm_hidden_dim=lstm_hidden_dim,\n",
    "                       ffn_hidden_dim=ffn_hidden_dim,\n",
    "                       BiLSTM=BiLSTM,\n",
    "                       learning_rate=learning_rate,\n",
    "                       loss=loss)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "880250b6",
   "metadata": {},
   "source": [
    "## Fine-tuned BERT"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ab058dcb",
   "metadata": {},
   "source": [
    "### Mean pooled"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "199297ac",
   "metadata": {},
   "outputs": [],
   "source": [
    "x_data, input_channels = obtain_SDSN_input(pooled_mean, path_specifics)\n",
    "for lstm_hidden_dim in lstm_hidden_dim_trial:\n",
    "    for ffn_hidden_dim in ffn_hidden_dim_trial:\n",
    "        print(f\"\\n********** lstm_hidden_dim: {lstm_hidden_dim} \"\n",
    "              f\"|| ffnhidden_dim: {ffn_hidden_dim}\")\n",
    "        implement_sdsn(x_data=x_data,\n",
    "                       y_data=y_data,\n",
    "                       sig_depth=sig_depth,\n",
    "                       input_channels=input_channels,\n",
    "                       output_channels=output_channels,\n",
    "                       lstm_hidden_dim=lstm_hidden_dim,\n",
    "                       ffn_hidden_dim=ffn_hidden_dim,\n",
    "                       BiLSTM=BiLSTM,\n",
    "                       learning_rate=learning_rate,\n",
    "                       loss=loss)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6ac088ce",
   "metadata": {},
   "source": [
    "### Max pooled"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "68d0e9d5",
   "metadata": {},
   "outputs": [],
   "source": [
    "x_data, input_channels = obtain_SDSN_input(pooled_max, path_specifics)\n",
    "for lstm_hidden_dim in lstm_hidden_dim_trial:\n",
    "    for ffn_hidden_dim in ffn_hidden_dim_trial:\n",
    "        print(f\"\\n********** lstm_hidden_dim: {lstm_hidden_dim} \"\n",
    "              f\"|| ffnhidden_dim: {ffn_hidden_dim}\")\n",
    "        implement_sdsn(x_data=x_data,\n",
    "                       y_data=y_data,\n",
    "                       sig_depth=sig_depth,\n",
    "                       input_channels=input_channels,\n",
    "                       output_channels=output_channels,\n",
    "                       lstm_hidden_dim=lstm_hidden_dim,\n",
    "                       ffn_hidden_dim=ffn_hidden_dim,\n",
    "                       BiLSTM=BiLSTM,\n",
    "                       learning_rate=learning_rate,\n",
    "                       loss=loss)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b41d89ba",
   "metadata": {},
   "source": [
    "### Sum pooled"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fd6535cc",
   "metadata": {},
   "outputs": [],
   "source": [
    "x_data, input_channels = obtain_SDSN_input(pooled_sum, path_specifics)\n",
    "for lstm_hidden_dim in lstm_hidden_dim_trial:\n",
    "    for ffn_hidden_dim in ffn_hidden_dim_trial:\n",
    "        print(f\"\\n********** lstm_hidden_dim: {lstm_hidden_dim} \"\n",
    "              f\"|| ffnhidden_dim: {ffn_hidden_dim}\")\n",
    "        implement_sdsn(x_data=x_data,\n",
    "                       y_data=y_data,\n",
    "                       sig_depth=sig_depth,\n",
    "                       input_channels=input_channels,\n",
    "                       output_channels=output_channels,\n",
    "                       lstm_hidden_dim=lstm_hidden_dim,\n",
    "                       ffn_hidden_dim=ffn_hidden_dim,\n",
    "                       BiLSTM=BiLSTM,\n",
    "                       learning_rate=learning_rate,\n",
    "                       loss=loss)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d0740751",
   "metadata": {},
   "source": [
    "### CLS"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f8d8f0bf",
   "metadata": {},
   "outputs": [],
   "source": [
    "x_data, input_channels = obtain_SDSN_input(pooled_cls, path_specifics)\n",
    "for lstm_hidden_dim in lstm_hidden_dim_trial:\n",
    "    for ffn_hidden_dim in ffn_hidden_dim_trial:\n",
    "        print(f\"\\n********** lstm_hidden_dim: {lstm_hidden_dim} \"\n",
    "              f\"|| ffnhidden_dim: {ffn_hidden_dim}\")\n",
    "        implement_sdsn(x_data=x_data,\n",
    "                       y_data=y_data,\n",
    "                       sig_depth=sig_depth,\n",
    "                       input_channels=input_channels,\n",
    "                       output_channels=output_channels,\n",
    "                       lstm_hidden_dim=lstm_hidden_dim,\n",
    "                       ffn_hidden_dim=ffn_hidden_dim,\n",
    "                       BiLSTM=BiLSTM,\n",
    "                       learning_rate=learning_rate,\n",
    "                       loss=loss)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b63ffede",
   "metadata": {},
   "source": [
    "Baselines:\n",
    "   - just looking at the sentence embeddings (encodes nothing about the history on the post)\n",
    "       - highlights importance of looking at the sequence\n",
    "   - averaging history\n",
    "   - comparing the cosine similarity between previous post and current post to see if switch\n",
    "   \n",
    "Test for:\n",
    "- How many posts do you need to look back?"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "nlpsig-networks",
   "language": "python",
   "name": "nlpsig-networks"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.16"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
