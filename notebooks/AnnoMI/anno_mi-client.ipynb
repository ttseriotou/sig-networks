{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "a983a5e8",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import torch\n",
    "import transformers\n",
    "import pickle\n",
    "import os\n",
    "\n",
    "import nlpsig\n",
    "import nlpsig_networks\n",
    "\n",
    "from torch.optim.lr_scheduler import ReduceLROnPlateau, StepLR\n",
    "from nlpsig.classification_utils import DataSplits, Folds\n",
    "from nlpsig_networks.pytorch_utils import SaveBestModel, training_pytorch, testing_pytorch, set_seed, KFold_pytorch\n",
    "from nlpsig_networks.focal_loss import FocalLoss\n",
    "from nlpsig_networks.ffn import FeedforwardNeuralNetModel\n",
    "from nlpsig_networks.deepsignet import StackedDeepSigNet\n",
    "\n",
    "from tqdm.notebook import tqdm\n",
    "\n",
    "seed = 2023"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "a38f698f",
   "metadata": {},
   "outputs": [],
   "source": [
    "from nlpsig_networks.scripts.ffn_baseline_functions import (\n",
    "    implement_ffn,\n",
    "    ffn_hyperparameter_search,\n",
    "    obtain_mean_history,\n",
    "    obtain_signatures_history,\n",
    "    histories_baseline_hyperparameter_search\n",
    ")\n",
    "from nlpsig_networks.scripts.sdsn_functions import (\n",
    "    obtain_SDSN_input,\n",
    "    sdsn_hyperparameter_search\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "193d632e",
   "metadata": {},
   "outputs": [],
   "source": [
    "import signatory"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "6cfcd244",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "69904"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "signatory.signature_channels(channels=16, depth=4)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "55314ddf",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "17816"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "signatory.logsignature_channels(in_channels=16, depth=4)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "e98f2a35",
   "metadata": {},
   "outputs": [],
   "source": [
    "output_dir = \"client_talk_type\"\n",
    "if not os.path.isdir(output_dir):\n",
    "    os.makedirs(output_dir)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f7409a03",
   "metadata": {},
   "source": [
    "## AnnoMI"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "f00bb922",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>mi_quality</th>\n",
       "      <th>transcript_id</th>\n",
       "      <th>topic</th>\n",
       "      <th>utterance_id</th>\n",
       "      <th>interlocutor</th>\n",
       "      <th>timestamp</th>\n",
       "      <th>utterance_text</th>\n",
       "      <th>annotator_id</th>\n",
       "      <th>therapist_input_exists</th>\n",
       "      <th>therapist_input_subtype</th>\n",
       "      <th>reflection_exists</th>\n",
       "      <th>reflection_subtype</th>\n",
       "      <th>question_exists</th>\n",
       "      <th>question_subtype</th>\n",
       "      <th>main_therapist_behaviour</th>\n",
       "      <th>client_talk_type</th>\n",
       "      <th>datetime</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>high</td>\n",
       "      <td>0</td>\n",
       "      <td>reducing alcohol consumption</td>\n",
       "      <td>0</td>\n",
       "      <td>therapist</td>\n",
       "      <td>00:00:13</td>\n",
       "      <td>Thanks for filling it out. We give this form t...</td>\n",
       "      <td>3</td>\n",
       "      <td>False</td>\n",
       "      <td>NaN</td>\n",
       "      <td>False</td>\n",
       "      <td>NaN</td>\n",
       "      <td>True</td>\n",
       "      <td>open</td>\n",
       "      <td>question</td>\n",
       "      <td>NaN</td>\n",
       "      <td>2023-06-07 00:00:13</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>high</td>\n",
       "      <td>0</td>\n",
       "      <td>reducing alcohol consumption</td>\n",
       "      <td>1</td>\n",
       "      <td>client</td>\n",
       "      <td>00:00:24</td>\n",
       "      <td>Sure.</td>\n",
       "      <td>3</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>neutral</td>\n",
       "      <td>2023-06-07 00:00:24</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>high</td>\n",
       "      <td>0</td>\n",
       "      <td>reducing alcohol consumption</td>\n",
       "      <td>2</td>\n",
       "      <td>therapist</td>\n",
       "      <td>00:00:25</td>\n",
       "      <td>So, let's see. It looks that you put-- You dri...</td>\n",
       "      <td>3</td>\n",
       "      <td>True</td>\n",
       "      <td>information</td>\n",
       "      <td>False</td>\n",
       "      <td>NaN</td>\n",
       "      <td>False</td>\n",
       "      <td>NaN</td>\n",
       "      <td>therapist_input</td>\n",
       "      <td>NaN</td>\n",
       "      <td>2023-06-07 00:00:25</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>high</td>\n",
       "      <td>0</td>\n",
       "      <td>reducing alcohol consumption</td>\n",
       "      <td>3</td>\n",
       "      <td>client</td>\n",
       "      <td>00:00:34</td>\n",
       "      <td>Mm-hmm.</td>\n",
       "      <td>3</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>neutral</td>\n",
       "      <td>2023-06-07 00:00:34</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>high</td>\n",
       "      <td>0</td>\n",
       "      <td>reducing alcohol consumption</td>\n",
       "      <td>4</td>\n",
       "      <td>therapist</td>\n",
       "      <td>00:00:34</td>\n",
       "      <td>-and you usually have three to four drinks whe...</td>\n",
       "      <td>3</td>\n",
       "      <td>True</td>\n",
       "      <td>information</td>\n",
       "      <td>False</td>\n",
       "      <td>NaN</td>\n",
       "      <td>False</td>\n",
       "      <td>NaN</td>\n",
       "      <td>therapist_input</td>\n",
       "      <td>NaN</td>\n",
       "      <td>2023-06-07 00:00:34</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "  mi_quality  transcript_id                         topic  utterance_id  \\\n",
       "0       high              0  reducing alcohol consumption             0   \n",
       "1       high              0  reducing alcohol consumption             1   \n",
       "2       high              0  reducing alcohol consumption             2   \n",
       "3       high              0  reducing alcohol consumption             3   \n",
       "4       high              0  reducing alcohol consumption             4   \n",
       "\n",
       "  interlocutor timestamp                                     utterance_text  \\\n",
       "0    therapist  00:00:13  Thanks for filling it out. We give this form t...   \n",
       "1       client  00:00:24                                              Sure.   \n",
       "2    therapist  00:00:25  So, let's see. It looks that you put-- You dri...   \n",
       "3       client  00:00:34                                            Mm-hmm.   \n",
       "4    therapist  00:00:34  -and you usually have three to four drinks whe...   \n",
       "\n",
       "   annotator_id therapist_input_exists therapist_input_subtype  \\\n",
       "0             3                  False                     NaN   \n",
       "1             3                    NaN                     NaN   \n",
       "2             3                   True             information   \n",
       "3             3                    NaN                     NaN   \n",
       "4             3                   True             information   \n",
       "\n",
       "  reflection_exists reflection_subtype question_exists question_subtype  \\\n",
       "0             False                NaN            True             open   \n",
       "1               NaN                NaN             NaN              NaN   \n",
       "2             False                NaN           False              NaN   \n",
       "3               NaN                NaN             NaN              NaN   \n",
       "4             False                NaN           False              NaN   \n",
       "\n",
       "  main_therapist_behaviour client_talk_type            datetime  \n",
       "0                 question              NaN 2023-06-07 00:00:13  \n",
       "1                      NaN          neutral 2023-06-07 00:00:24  \n",
       "2          therapist_input              NaN 2023-06-07 00:00:25  \n",
       "3                      NaN          neutral 2023-06-07 00:00:34  \n",
       "4          therapist_input              NaN 2023-06-07 00:00:34  "
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "anno_mi = pd.read_csv(\"AnnoMI-full.csv\")\n",
    "anno_mi[\"datetime\"] = pd.to_datetime(anno_mi[\"timestamp\"])\n",
    "anno_mi = anno_mi.drop(columns=[\"video_title\", \"video_url\"])\n",
    "anno_mi.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "720d820f",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "therapist    6826\n",
       "client       6725\n",
       "Name: interlocutor, dtype: int64"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "anno_mi[\"interlocutor\"].value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "84d5594d",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "other              0.313947\n",
       "question           0.286258\n",
       "reflection         0.251538\n",
       "therapist_input    0.148257\n",
       "Name: main_therapist_behaviour, dtype: float64"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "anno_mi[\"main_therapist_behaviour\"].value_counts() / anno_mi[\"interlocutor\"].value_counts()[\"therapist\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "44217a68",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "neutral    0.627063\n",
       "change     0.248030\n",
       "sustain    0.124907\n",
       "Name: client_talk_type, dtype: float64"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "anno_mi[\"client_talk_type\"].value_counts() / anno_mi[\"interlocutor\"].value_counts()[\"client\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "367137a3",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "therapist    6826\n",
       "client       6725\n",
       "Name: interlocutor, dtype: int64"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "anno_mi[\"interlocutor\"].value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "9a5a319f",
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "reducing alcohol consumption                                                          2326\n",
       "more exercise / increasing activity                                                   2034\n",
       "reducing recidivism                                                                   1303\n",
       "reducing drug use                                                                     1104\n",
       "diabetes management                                                                    948\n",
       "smoking cessation                                                                      923\n",
       "smoking cessation                                                                      541\n",
       "taking medicine / following medical procedure                                          448\n",
       "asthma management                                                                      431\n",
       "avoiding DOI                                                                           394\n",
       "changing approach to disease                                                           315\n",
       "reducing gambling                                                                      297\n",
       "weight loss                                                                            294\n",
       "unidentifiable                                                                         287\n",
       "smoking cessation; reducing alcohol consumption                                        254\n",
       "overcoming issues at school                                                            167\n",
       "compliance with rules                                                                  146\n",
       "supporting client to live in more alignment with her values                            133\n",
       "increasing activity; taking medicine / following medical procedure                     126\n",
       "better oral health                                                                      97\n",
       "managing life                                                                           86\n",
       "anxiety management                                                                      79\n",
       "more exercise / increasing activity; weight loss                                        66\n",
       "Being assertive with flatmate about moving out                                          62\n",
       "reducing drug use; following medical procedure                                          59\n",
       "taking steps towards getting help with day-care                                         57\n",
       "reducing alcohol consumption; safe sex                                                  55\n",
       "reducing self-harm                                                                      54\n",
       "reducing coffee consumption                                                             51\n",
       "increasing self-confidence                                                              50\n",
       "completion of community service                                                         46\n",
       "reducing violence                                                                       41\n",
       "diet; reducing alcohol consumption; diabetes management                                 40\n",
       "weight loss; diet                                                                       36\n",
       "birth control                                                                           36\n",
       "reducing alcohol consumption; compliance with rules                                     31\n",
       "charging battery                                                                        29\n",
       "diagnosis                                                                               21\n",
       "providing information on medicines                                                      19\n",
       "engaging in community activities                                                        17\n",
       "problem recognition                                                                     16\n",
       "opening up                                                                              15\n",
       "recognising success                                                                     11\n",
       "not getting into a car with someone who is under the influence of drugs or alcohol       6\n",
       "Name: topic, dtype: int64"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "anno_mi[\"topic\"].value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "507f8a50",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "133"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(anno_mi[\"transcript_id\"].unique())"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d31003be",
   "metadata": {},
   "source": [
    "## Only considering client for now..."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "a5a752a9",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "6725"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "client_index = [isinstance(x, str) for x in anno_mi[\"client_talk_type\"]]\n",
    "sum(client_index)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "1a84179e",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(6725,)"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y_data = anno_mi[\"client_talk_type\"][client_index]\n",
    "y_data.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "7272095b",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "1     neutral\n",
       "3     neutral\n",
       "5     neutral\n",
       "7     neutral\n",
       "9     neutral\n",
       "11    neutral\n",
       "13    neutral\n",
       "15    neutral\n",
       "17    neutral\n",
       "19    neutral\n",
       "21    neutral\n",
       "23    neutral\n",
       "25    neutral\n",
       "27    neutral\n",
       "29    neutral\n",
       "31    neutral\n",
       "33    neutral\n",
       "35     change\n",
       "37     change\n",
       "39     change\n",
       "Name: client_talk_type, dtype: object"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y_data[0:20]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "7b8bd903",
   "metadata": {},
   "outputs": [],
   "source": [
    "label_to_id = {y_data.unique()[i]: i for i in range(len(y_data.unique()))}\n",
    "id_to_label = {v: k for k, v in label_to_id.items()}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "e478c216",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'neutral': 0, 'change': 1, 'sustain': 2}"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "label_to_id"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "4f716f8e",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{0: 'neutral', 1: 'change', 2: 'sustain'}"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "id_to_label"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "e46018b4",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 1, 1]"
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y_data = [label_to_id[x] for x in y_data]\n",
    "y_data[0:20]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "9342e6a3",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "3"
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "output_dim = len(label_to_id.values())\n",
    "output_dim"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "07a35e43",
   "metadata": {},
   "source": [
    "## Obtaining SBERT Embeddings\n",
    "\n",
    "We can use the `SentenceEncoder` class within `nlpsig` to obtain sentence embeddings from a model. This class uses the [`sentence-transformer`](https://www.sbert.net/docs/package_reference/SentenceTransformer.html) package and here, we have use the pre-trained `all-MiniLM-L12-v2` model by passing this name as a string to the class - alternative models can be found [here](https://www.sbert.net/docs/pretrained_models.html).\n",
    "\n",
    "We can pass our dataframe and the column name which stores the sentences that we wish to encode along with the model name into the constructor of the class to initialise our sentence encoder as follows:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "87e3568e",
   "metadata": {},
   "outputs": [],
   "source": [
    "# initialise the Text Encoder\n",
    "sentence_encoder = nlpsig.SentenceEncoder(df=anno_mi,\n",
    "                                          feature_name=\"utterance_text\",\n",
    "                                          model_name=\"all-MiniLM-L12-v2\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "94d224a7",
   "metadata": {},
   "source": [
    "We used the `.load_pretrained_model()` method to load in the pre-trained model - this may require you to download the model if this is the first time running the notebook."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "ea1150b6",
   "metadata": {},
   "outputs": [],
   "source": [
    "sentence_encoder.load_pretrained_model()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "968f461c",
   "metadata": {},
   "source": [
    "We can then obtain embeddings via the `.obtain_embeddings()` method."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "7e03af88",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[INFO] number of sentences to encode: 13551\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "491b14c56a79414ca6c87f94172984a6",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Batches:   0%|          | 0/212 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "sbert_embeddings = sentence_encoder.obtain_embeddings()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "027a5477",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(13551, 384)"
      ]
     },
     "execution_count": 25,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "sbert_embeddings.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2c0599d7",
   "metadata": {},
   "source": [
    "We can save our embeddings for use later:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "84b34862",
   "metadata": {},
   "outputs": [],
   "source": [
    "np.save(f\"{output_dir}/anno_mi_client_sentence_embeddings_384\",\n",
    "        sbert_embeddings)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "b5f2bbba",
   "metadata": {},
   "outputs": [],
   "source": [
    "sbert_embeddings = np.load(f\"{output_dir}/anno_mi_client_sentence_embeddings_384.npy\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "21be231a",
   "metadata": {},
   "source": [
    "# Baseline: FFN baseline\n",
    "\n",
    "Using the embeddings for the sentences directly in a FFN to predict the client talk type."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0697e221",
   "metadata": {},
   "source": [
    "Going to try out some variations (1 hidden layer, 2 hidden layers and 3 hidden layers - all of size 100)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "bcf70846",
   "metadata": {},
   "outputs": [],
   "source": [
    "num_epochs = 100\n",
    "hidden_dim_sizes = [[100]*i for i in range(1, 4)]\n",
    "dropout_rates = [0.5, 0.2, 0.1]\n",
    "learning_rates = [5e-3, 1e-3, 5e-4, 1e-4, 1e-5]\n",
    "seeds = [0, 1, 12, 123, 1234]\n",
    "loss = \"focal\"\n",
    "gamma = 2\n",
    "validation_metric = \"f1\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "id": "381d7183",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[[100], [100, 100], [100, 100, 100]]"
      ]
     },
     "execution_count": 29,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "hidden_dim_sizes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "id": "c07c9717",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[0.005, 0.001, 0.0005, 0.0001, 1e-05]"
      ]
     },
     "execution_count": 30,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "learning_rates"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3b8798fc",
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "cfd95483de1146aaa2e5416340258851",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/3 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "c43cd483d2a64ad282962e04b3dbe474",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/3 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "c9106ac70e23420c8ca843c51297cd9f",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/5 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "7300534ad8c844399e8180276a448f33",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/5 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "ffn_current, best_ffn_current, best_valid_metric, extra_info = ffn_hyperparameter_search(\n",
    "    num_epochs=num_epochs,\n",
    "    x_data=sbert_embeddings[client_index],\n",
    "    y_data=y_data,\n",
    "    hidden_dim_sizes=hidden_dim_sizes,\n",
    "    output_dim=output_dim,\n",
    "    dropout_rates=dropout_rates,\n",
    "    learning_rates=learning_rates,\n",
    "    seeds=seeds,\n",
    "    loss=loss,\n",
    "    gamma=gamma,\n",
    "    k_fold=False,\n",
    "    validation_metric=validation_metric,\n",
    "    results_output=f\"ffn_current_focal_{gamma}.csv\",\n",
    "    verbose=False\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "49f7c8c6",
   "metadata": {},
   "outputs": [],
   "source": [
    "ffn_current"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a375b54e",
   "metadata": {},
   "outputs": [],
   "source": [
    "best_ffn_current"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "171c2dab",
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "ffn_current_kfold, best_ffn_current_kfold, best_valid_metric, extra_info = ffn_hyperparameter_search(\n",
    "    num_epochs=num_epochs,\n",
    "    x_data=sbert_embeddings[client_index],\n",
    "    y_data=y_data,\n",
    "    hidden_dim_sizes=hidden_dim_sizes,\n",
    "    output_dim=output_dim,\n",
    "    dropout_rates=dropout_rates,\n",
    "    learning_rates=learning_rates,\n",
    "    seeds=seeds,\n",
    "    loss=loss,\n",
    "    gamma=gamma,\n",
    "    k_fold=True,\n",
    "    validation_metric=validation_metric,\n",
    "    results_output=f\"ffn_current_focal_{gamma}_kfold.csv\",\n",
    "    verbose=False\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "13940ae5",
   "metadata": {},
   "outputs": [],
   "source": [
    "ffn_current_kfold"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "74090ed5",
   "metadata": {},
   "outputs": [],
   "source": [
    "best_ffn_current_kfold"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8ad7a7e7",
   "metadata": {},
   "source": [
    "# Baseline 2: Averaging history and use FFN\n",
    "\n",
    "Here, we will use `nlpsig` to construct some paths of embeddings for the last $k$ utterances which we will average and use those in a FFN. We will also concatenate the current utterance embedding to the FFN input - all of this is done in the `obtain_mean_history` function in `nlpsig-networks.scripts.ffn_baseline_functions` which we imported earlier on.\n",
    "\n",
    "Here, we will run the hyperparameter search to implement the FFN with the same parameters as above. For this baseline, we can also see how well the model performance is affected by the size of the history window $k$."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "42bab1b7",
   "metadata": {},
   "outputs": [],
   "source": [
    "window_sizes = [5, 10, 20, 50]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3e746e99",
   "metadata": {},
   "outputs": [],
   "source": [
    "ffn_mean_history, best_valid_metric, extra_info = histories_baseline_hyperparameter_search(\n",
    "    num_epochs=num_epochs,\n",
    "    df=anno_mi,\n",
    "    id_column=\"transcript_id\",\n",
    "    label_column=\"client_talk_type\",\n",
    "    embeddings=sbert_embeddings,\n",
    "    y_data=y_data,\n",
    "    output_dim=output_dim,\n",
    "    window_sizes=window_sizes,\n",
    "    hidden_dim_sizes=hidden_dim_sizes,\n",
    "    dropout_rates=dropout_rates,\n",
    "    learning_rates=learning_rates,\n",
    "    use_signatures=False,\n",
    "    seeds=seeds,\n",
    "    loss=loss,\n",
    "    gamma=gamma,\n",
    "    path_indices=client_index,\n",
    "    k_fold=False,\n",
    "    validation_metric=validation_metric,\n",
    "    results_output=f\"{output_dir}/ffn_mean_history_focal_{gamma}.csv\",\n",
    "    verbose=False\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a408980c",
   "metadata": {},
   "outputs": [],
   "source": [
    "ffn_mean_history_kfold, best_valid_metric, extra_info = histories_baseline_hyperparameter_search(\n",
    "    num_epochs=num_epochs,\n",
    "    df=anno_mi,\n",
    "    id_column=\"transcript_id\",\n",
    "    label_column=\"client_talk_type\",\n",
    "    embeddings=sbert_embeddings,\n",
    "    y_data=y_data,\n",
    "    output_dim=output_dim,\n",
    "    window_sizes=window_sizes,\n",
    "    hidden_dim_sizes=hidden_dim_sizes,\n",
    "    dropout_rates=dropout_rates,\n",
    "    learning_rates=learning_rates,\n",
    "    use_signatures=False,\n",
    "    seeds=seeds,\n",
    "    loss=loss,\n",
    "    gamma=gamma,\n",
    "    path_indices=client_index,\n",
    "    k_fold=True,\n",
    "    validation_metric=validation_metric,\n",
    "    results_output=f\"{output_dir}/ffn_mean_history_focal_{gamma}_kfold.csv\",\n",
    "    verbose=False\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0cf51402",
   "metadata": {},
   "source": [
    "# Baseline 3: FFN using signatures\n",
    "\n",
    "First, we dimension reduce these and then take signatures. We use the path signature as input to the FFN for classification."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 286,
   "id": "aa98763b",
   "metadata": {},
   "outputs": [],
   "source": [
    "dimensions_and_sig_depths = [(30, 2), (10, 3), (5, 4), (4, 5), (3, 6)]\n",
    "dim_reduce_methods = [\"gaussian_random_projection\", \"umap\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 171,
   "id": "c893cdc6",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[30, 900]\n",
      "[10, 100, 1000]\n",
      "[5, 25, 125, 625]\n",
      "[4, 16, 64, 256, 1024]\n",
      "[3, 9, 27, 81, 243, 729]\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "[930, 1110, 780, 1364, 1092]"
      ]
     },
     "execution_count": 171,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "[signatory.signature_channels(channels, depth)\n",
    " for (channels, depth) in dimensions_and_sig_depths]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1bf45117",
   "metadata": {},
   "outputs": [],
   "source": [
    "[signatory.logsignature_channels(channels, depth)\n",
    " for (channels, depth) in dimensions_and_sig_depths]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cca67102",
   "metadata": {},
   "source": [
    "# Baseline: LSTM classification"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f33e2718",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a7a58c0f",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "4c69d8f8",
   "metadata": {},
   "source": [
    "# Baseline: Fine-tune BERT for classification"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b4f6bbba",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "959322e5",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "da4ff92d",
   "metadata": {},
   "source": [
    "# StackedDeepSigNet"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "32ae1a72",
   "metadata": {},
   "source": [
    "## Obtaining path by looking at post history\n",
    "\n",
    "We can obtain a path by looking at the history of each post. Here we look at the last 10 posts (and pad with vectors of zeros if there are less than 10 posts) including the current post.\n",
    "\n",
    "We only want to consider paths that correspond to a client's utterance as we want to model a change in mood at that time. Their history will still contain the therapist's utterances too."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 244,
   "id": "90bfd87c",
   "metadata": {},
   "outputs": [],
   "source": [
    "time_features = [\"time_encoding\", \"timeline_index\"]\n",
    "path_specifics = {\"pad_by\": \"history\",\n",
    "                  \"zero_padding\": True,\n",
    "                  \"method\": \"k_last\",\n",
    "                  \"k\": 10,\n",
    "                  \"time_feature\": time_features,\n",
    "                  \"standardise_method\": [\"minmax\", None],\n",
    "                  \"embeddings\": \"dim_reduced\",\n",
    "                  \"include_current_embedding\": True,\n",
    "                  \"pad_from_below\": False}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 298,
   "id": "9cf4e16c",
   "metadata": {},
   "outputs": [],
   "source": [
    "sig_depths = [2,3]\n",
    "dim_reduce_methods = [\"gaussian_random_projection\", \"umap\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 297,
   "id": "43dbc33f",
   "metadata": {},
   "outputs": [],
   "source": [
    "output_dim = len(label_to_id)\n",
    "lstm_hidden_dims = [[8,8], [12,12,8]]\n",
    "num_time_features = len(time_features)\n",
    "conv_output_channels = [20, 10, 5]\n",
    "learning_rate = 1e-4"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 300,
   "id": "9a9b2b2c",
   "metadata": {},
   "outputs": [],
   "source": [
    "embedding_dim = 384\n",
    "dimensions = [embedding_dim, 100, 50, 30]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a1c2fb49",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b84678e9",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "73a223cf",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "33d6df59",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0a2dd647",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0e70729b",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "189a27c1",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0befdbaf",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "nlpsig-networks",
   "language": "python",
   "name": "nlpsig-networks"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.16"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
