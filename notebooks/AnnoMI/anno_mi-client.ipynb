{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "a983a5e8",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import torch\n",
    "import os\n",
    "import evaluate\n",
    "\n",
    "import nlpsig\n",
    "\n",
    "from nlpsig.classification_utils import DataSplits\n",
    "\n",
    "from sklearn import metrics\n",
    "\n",
    "from tqdm.notebook import tqdm\n",
    "\n",
    "seed = 2023"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "e4e666cc",
   "metadata": {},
   "outputs": [],
   "source": [
    "from nlpsig_networks.scripts.ffn_baseline_functions import (\n",
    "    ffn_hyperparameter_search,\n",
    "    histories_baseline_hyperparameter_search\n",
    ")\n",
    "from nlpsig_networks.scripts.swnu_network_functions import (\n",
    "    swnu_network_hyperparameter_search\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "193d632e",
   "metadata": {},
   "outputs": [],
   "source": [
    "import signatory"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "6e918dde",
   "metadata": {},
   "outputs": [],
   "source": [
    "output_dir = \"client_talk_type\"\n",
    "if not os.path.isdir(output_dir):\n",
    "    os.makedirs(output_dir)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "id": "f7409a03",
   "metadata": {},
   "source": [
    "## AnnoMI"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "f00bb922",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>mi_quality</th>\n",
       "      <th>transcript_id</th>\n",
       "      <th>topic</th>\n",
       "      <th>utterance_id</th>\n",
       "      <th>interlocutor</th>\n",
       "      <th>timestamp</th>\n",
       "      <th>utterance_text</th>\n",
       "      <th>annotator_id</th>\n",
       "      <th>therapist_input_exists</th>\n",
       "      <th>therapist_input_subtype</th>\n",
       "      <th>reflection_exists</th>\n",
       "      <th>reflection_subtype</th>\n",
       "      <th>question_exists</th>\n",
       "      <th>question_subtype</th>\n",
       "      <th>main_therapist_behaviour</th>\n",
       "      <th>client_talk_type</th>\n",
       "      <th>datetime</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>high</td>\n",
       "      <td>0</td>\n",
       "      <td>reducing alcohol consumption</td>\n",
       "      <td>0</td>\n",
       "      <td>therapist</td>\n",
       "      <td>00:00:13</td>\n",
       "      <td>Thanks for filling it out. We give this form t...</td>\n",
       "      <td>3</td>\n",
       "      <td>False</td>\n",
       "      <td>NaN</td>\n",
       "      <td>False</td>\n",
       "      <td>NaN</td>\n",
       "      <td>True</td>\n",
       "      <td>open</td>\n",
       "      <td>question</td>\n",
       "      <td>NaN</td>\n",
       "      <td>2023-06-19 00:00:13</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>high</td>\n",
       "      <td>0</td>\n",
       "      <td>reducing alcohol consumption</td>\n",
       "      <td>1</td>\n",
       "      <td>client</td>\n",
       "      <td>00:00:24</td>\n",
       "      <td>Sure.</td>\n",
       "      <td>3</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>neutral</td>\n",
       "      <td>2023-06-19 00:00:24</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>high</td>\n",
       "      <td>0</td>\n",
       "      <td>reducing alcohol consumption</td>\n",
       "      <td>2</td>\n",
       "      <td>therapist</td>\n",
       "      <td>00:00:25</td>\n",
       "      <td>So, let's see. It looks that you put-- You dri...</td>\n",
       "      <td>3</td>\n",
       "      <td>True</td>\n",
       "      <td>information</td>\n",
       "      <td>False</td>\n",
       "      <td>NaN</td>\n",
       "      <td>False</td>\n",
       "      <td>NaN</td>\n",
       "      <td>therapist_input</td>\n",
       "      <td>NaN</td>\n",
       "      <td>2023-06-19 00:00:25</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>high</td>\n",
       "      <td>0</td>\n",
       "      <td>reducing alcohol consumption</td>\n",
       "      <td>3</td>\n",
       "      <td>client</td>\n",
       "      <td>00:00:34</td>\n",
       "      <td>Mm-hmm.</td>\n",
       "      <td>3</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>neutral</td>\n",
       "      <td>2023-06-19 00:00:34</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>high</td>\n",
       "      <td>0</td>\n",
       "      <td>reducing alcohol consumption</td>\n",
       "      <td>4</td>\n",
       "      <td>therapist</td>\n",
       "      <td>00:00:34</td>\n",
       "      <td>-and you usually have three to four drinks whe...</td>\n",
       "      <td>3</td>\n",
       "      <td>True</td>\n",
       "      <td>information</td>\n",
       "      <td>False</td>\n",
       "      <td>NaN</td>\n",
       "      <td>False</td>\n",
       "      <td>NaN</td>\n",
       "      <td>therapist_input</td>\n",
       "      <td>NaN</td>\n",
       "      <td>2023-06-19 00:00:34</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "  mi_quality  transcript_id                         topic  utterance_id  \\\n",
       "0       high              0  reducing alcohol consumption             0   \n",
       "1       high              0  reducing alcohol consumption             1   \n",
       "2       high              0  reducing alcohol consumption             2   \n",
       "3       high              0  reducing alcohol consumption             3   \n",
       "4       high              0  reducing alcohol consumption             4   \n",
       "\n",
       "  interlocutor timestamp                                     utterance_text  \\\n",
       "0    therapist  00:00:13  Thanks for filling it out. We give this form t...   \n",
       "1       client  00:00:24                                              Sure.   \n",
       "2    therapist  00:00:25  So, let's see. It looks that you put-- You dri...   \n",
       "3       client  00:00:34                                            Mm-hmm.   \n",
       "4    therapist  00:00:34  -and you usually have three to four drinks whe...   \n",
       "\n",
       "   annotator_id therapist_input_exists therapist_input_subtype  \\\n",
       "0             3                  False                     NaN   \n",
       "1             3                    NaN                     NaN   \n",
       "2             3                   True             information   \n",
       "3             3                    NaN                     NaN   \n",
       "4             3                   True             information   \n",
       "\n",
       "  reflection_exists reflection_subtype question_exists question_subtype  \\\n",
       "0             False                NaN            True             open   \n",
       "1               NaN                NaN             NaN              NaN   \n",
       "2             False                NaN           False              NaN   \n",
       "3               NaN                NaN             NaN              NaN   \n",
       "4             False                NaN           False              NaN   \n",
       "\n",
       "  main_therapist_behaviour client_talk_type            datetime  \n",
       "0                 question              NaN 2023-06-19 00:00:13  \n",
       "1                      NaN          neutral 2023-06-19 00:00:24  \n",
       "2          therapist_input              NaN 2023-06-19 00:00:25  \n",
       "3                      NaN          neutral 2023-06-19 00:00:34  \n",
       "4          therapist_input              NaN 2023-06-19 00:00:34  "
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "anno_mi = pd.read_csv(\"AnnoMI-full.csv\")\n",
    "anno_mi[\"datetime\"] = pd.to_datetime(anno_mi[\"timestamp\"])\n",
    "anno_mi = anno_mi.drop(columns=[\"video_title\", \"video_url\"])\n",
    "anno_mi.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "720d820f",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "therapist    6826\n",
       "client       6725\n",
       "Name: interlocutor, dtype: int64"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "anno_mi[\"interlocutor\"].value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "84d5594d",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "other              0.313947\n",
       "question           0.286258\n",
       "reflection         0.251538\n",
       "therapist_input    0.148257\n",
       "Name: main_therapist_behaviour, dtype: float64"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "anno_mi[\"main_therapist_behaviour\"].value_counts() / anno_mi[\"interlocutor\"].value_counts()[\"therapist\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "44217a68",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "neutral    0.627063\n",
       "change     0.248030\n",
       "sustain    0.124907\n",
       "Name: client_talk_type, dtype: float64"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "anno_mi[\"client_talk_type\"].value_counts() / anno_mi[\"interlocutor\"].value_counts()[\"client\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "367137a3",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "therapist    6826\n",
       "client       6725\n",
       "Name: interlocutor, dtype: int64"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "anno_mi[\"interlocutor\"].value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "9a5a319f",
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "reducing alcohol consumption                                                          2326\n",
       "more exercise / increasing activity                                                   2034\n",
       "reducing recidivism                                                                   1303\n",
       "reducing drug use                                                                     1104\n",
       "diabetes management                                                                    948\n",
       "smoking cessation                                                                      923\n",
       "smoking cessation                                                                      541\n",
       "taking medicine / following medical procedure                                          448\n",
       "asthma management                                                                      431\n",
       "avoiding DOI                                                                           394\n",
       "changing approach to disease                                                           315\n",
       "reducing gambling                                                                      297\n",
       "weight loss                                                                            294\n",
       "unidentifiable                                                                         287\n",
       "smoking cessation; reducing alcohol consumption                                        254\n",
       "overcoming issues at school                                                            167\n",
       "compliance with rules                                                                  146\n",
       "supporting client to live in more alignment with her values                            133\n",
       "increasing activity; taking medicine / following medical procedure                     126\n",
       "better oral health                                                                      97\n",
       "managing life                                                                           86\n",
       "anxiety management                                                                      79\n",
       "more exercise / increasing activity; weight loss                                        66\n",
       "Being assertive with flatmate about moving out                                          62\n",
       "reducing drug use; following medical procedure                                          59\n",
       "taking steps towards getting help with day-care                                         57\n",
       "reducing alcohol consumption; safe sex                                                  55\n",
       "reducing self-harm                                                                      54\n",
       "reducing coffee consumption                                                             51\n",
       "increasing self-confidence                                                              50\n",
       "completion of community service                                                         46\n",
       "reducing violence                                                                       41\n",
       "diet; reducing alcohol consumption; diabetes management                                 40\n",
       "weight loss; diet                                                                       36\n",
       "birth control                                                                           36\n",
       "reducing alcohol consumption; compliance with rules                                     31\n",
       "charging battery                                                                        29\n",
       "diagnosis                                                                               21\n",
       "providing information on medicines                                                      19\n",
       "engaging in community activities                                                        17\n",
       "problem recognition                                                                     16\n",
       "opening up                                                                              15\n",
       "recognising success                                                                     11\n",
       "not getting into a car with someone who is under the influence of drugs or alcohol       6\n",
       "Name: topic, dtype: int64"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "anno_mi[\"topic\"].value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "507f8a50",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "133"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(anno_mi[\"transcript_id\"].unique())"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "id": "d31003be",
   "metadata": {},
   "source": [
    "## Only considering client for now..."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "a5a752a9",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "6725"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "client_index = [isinstance(x, str) for x in anno_mi[\"client_talk_type\"]]\n",
    "sum(client_index)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "1a84179e",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(6725,)"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y_data = anno_mi[\"client_talk_type\"][client_index]\n",
    "y_data.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "7272095b",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "1     neutral\n",
       "3     neutral\n",
       "5     neutral\n",
       "7     neutral\n",
       "9     neutral\n",
       "11    neutral\n",
       "13    neutral\n",
       "15    neutral\n",
       "17    neutral\n",
       "19    neutral\n",
       "21    neutral\n",
       "23    neutral\n",
       "25    neutral\n",
       "27    neutral\n",
       "29    neutral\n",
       "31    neutral\n",
       "33    neutral\n",
       "35     change\n",
       "37     change\n",
       "39     change\n",
       "Name: client_talk_type, dtype: object"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y_data[0:20]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "7b8bd903",
   "metadata": {},
   "outputs": [],
   "source": [
    "label_to_id = {y_data.unique()[i]: i for i in range(len(y_data.unique()))}\n",
    "id_to_label = {v: k for k, v in label_to_id.items()}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "e478c216",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'neutral': 0, 'change': 1, 'sustain': 2}"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "label_to_id"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "4f716f8e",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{0: 'neutral', 1: 'change', 2: 'sustain'}"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "id_to_label"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "e46018b4",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 1, 1]"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y_data = [label_to_id[x] for x in y_data]\n",
    "y_data[0:20]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "30c4b24d",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "3"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "output_dim = len(label_to_id.values())\n",
    "output_dim"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "id": "07a35e43",
   "metadata": {},
   "source": [
    "## Obtaining SBERT Embeddings\n",
    "\n",
    "We can use the `SentenceEncoder` class within `nlpsig` to obtain sentence embeddings from a model. This class uses the [`sentence-transformer`](https://www.sbert.net/docs/package_reference/SentenceTransformer.html) package and here, we have use the pre-trained `all-MiniLM-L12-v2` model by passing this name as a string to the class - alternative models can be found [here](https://www.sbert.net/docs/pretrained_models.html).\n",
    "\n",
    "We can pass our dataframe and the column name which stores the sentences that we wish to encode along with the model name into the constructor of the class to initialise our sentence encoder as follows:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "87e3568e",
   "metadata": {},
   "outputs": [],
   "source": [
    "# initialise the Text Encoder\n",
    "sentence_encoder = nlpsig.SentenceEncoder(df=anno_mi,\n",
    "                                          feature_name=\"utterance_text\",\n",
    "                                          model_name=\"all-MiniLM-L12-v2\")"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "id": "7b680def",
   "metadata": {},
   "source": [
    "We used the `.load_pretrained_model()` method to load in the pre-trained model - this may require you to download the model if this is the first time running the notebook."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "d2179853",
   "metadata": {},
   "outputs": [],
   "source": [
    "sentence_encoder.load_pretrained_model()"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "id": "93a0668d",
   "metadata": {},
   "source": [
    "We can then obtain embeddings via the `.obtain_embeddings()` method."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "7e03af88",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[INFO] number of sentences to encode: 13551\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "d7183e19e7a740608ced9bc411918013",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Batches:   0%|          | 0/212 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "sbert_embeddings = sentence_encoder.obtain_embeddings()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "64d868d9",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(13551, 384)"
      ]
     },
     "execution_count": 25,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "sbert_embeddings.shape"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "id": "65921a6d",
   "metadata": {},
   "source": [
    "We can save our embeddings for use later:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "84b34862",
   "metadata": {},
   "outputs": [],
   "source": [
    "np.save(f\"{output_dir}/anno_mi_client_sentence_embeddings_384\",\n",
    "        sbert_embeddings)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "1c672e12",
   "metadata": {},
   "outputs": [],
   "source": [
    "sbert_embeddings = np.load(f\"{output_dir}/anno_mi_client_sentence_embeddings_384.npy\")"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "id": "21be231a",
   "metadata": {},
   "source": [
    "# Baseline: FFN baseline\n",
    "\n",
    "Using the embeddings for the sentences directly in a FFN to predict the client talk type."
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "id": "0697e221",
   "metadata": {},
   "source": [
    "Going to try out some variations (1 hidden layer, 2 hidden layers and 3 hidden layers - all of size 100)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "bcf70846",
   "metadata": {},
   "outputs": [],
   "source": [
    "num_epochs = 100\n",
    "hidden_dim_sizes = [[100]*i for i in range(1, 4)]\n",
    "dropout_rates = [0.5, 0.2, 0.1]\n",
    "learning_rates = [5e-3, 1e-3, 5e-4, 1e-4, 1e-5]\n",
    "seeds = [0, 1, 12, 123, 1234]\n",
    "loss = \"focal\"\n",
    "gamma = 2\n",
    "validation_metric = \"f1\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "cb066ccc",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[[100], [100, 100], [100, 100, 100]]"
      ]
     },
     "execution_count": 22,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "hidden_dim_sizes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "808b1de7",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[0.005, 0.001, 0.0005, 0.0001, 1e-05]"
      ]
     },
     "execution_count": 23,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "learning_rates"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "id": "03228aca",
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "f44327037c094b2fb757ac519d66f2b8",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/3 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "2dadf9d0856c411cbe58322d6fd6dc7d",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/3 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "10bdd4413bf34ea79564f3837a41dbac",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/5 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "10affe8ad4914bbfb9bf600a8a2d1048",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/5 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "f258492939514160a74372bb764d4750",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/5 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "1812fd3fb91342d589921c16eb74c199",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/3 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "aed93f6e7d0643ad971d747748c932fb",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/5 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "3216b9bccd5d45d18b4f9d7cd1745a85",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/5 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "9b2c8189fe6947b789446de8e6d472b2",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/5 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "33afb0e2ed2b4822a252cfedce2abde6",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/3 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "dd073570eb444165a0c262e9fadc2cf8",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/5 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "2cd7e7373df247cda5a035d0341968f7",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/5 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "7dd2fd8bcbc64d52b5c76bdb27b04e24",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/5 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "saving results dataframe to CSV for this hyperparameter search in ffn_current_focal_2.csv\n",
      "saving the best model results dataframe to CSV for this hyperparameter search in ffn_current_focal_2_best_model.csv\n"
     ]
    }
   ],
   "source": [
    "ffn_current, best_ffn_current, _, __ = ffn_hyperparameter_search(\n",
    "    num_epochs=num_epochs,\n",
    "    x_data=sbert_embeddings[client_index],\n",
    "    y_data=y_data,\n",
    "    hidden_dim_sizes=hidden_dim_sizes,\n",
    "    output_dim=output_dim,\n",
    "    dropout_rates=dropout_rates,\n",
    "    learning_rates=learning_rates,\n",
    "    seeds=seeds,\n",
    "    loss=loss,\n",
    "    gamma=gamma,\n",
    "    k_fold=False,\n",
    "    validation_metric=validation_metric,\n",
    "    results_output=f\"{output_dir}/ffn_current_focal_{gamma}.csv\",\n",
    "    verbose=False\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "id": "6e3c1c45",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>loss</th>\n",
       "      <th>accuracy</th>\n",
       "      <th>f1</th>\n",
       "      <th>f1_scores</th>\n",
       "      <th>valid_loss</th>\n",
       "      <th>valid_accuracy</th>\n",
       "      <th>valid_f1</th>\n",
       "      <th>valid_f1_scores</th>\n",
       "      <th>hidden_dim</th>\n",
       "      <th>dropout_rate</th>\n",
       "      <th>learning_rate</th>\n",
       "      <th>seed</th>\n",
       "      <th>gamma</th>\n",
       "      <th>k_fold</th>\n",
       "      <th>model_id</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>focal</td>\n",
       "      <td>0.684015</td>\n",
       "      <td>0.618947</td>\n",
       "      <td>[0.7808471454880296, 0.5281899109792284, 0.547...</td>\n",
       "      <td>0.564228</td>\n",
       "      <td>0.694238</td>\n",
       "      <td>0.607537</td>\n",
       "      <td>[0.7920646583394563, 0.5475285171102662, 0.483...</td>\n",
       "      <td>[100]</td>\n",
       "      <td>0.5</td>\n",
       "      <td>0.00500</td>\n",
       "      <td>0</td>\n",
       "      <td>2</td>\n",
       "      <td>False</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>focal</td>\n",
       "      <td>0.692937</td>\n",
       "      <td>0.605870</td>\n",
       "      <td>[0.7964912280701756, 0.5169628432956381, 0.504...</td>\n",
       "      <td>0.574431</td>\n",
       "      <td>0.726766</td>\n",
       "      <td>0.623467</td>\n",
       "      <td>[0.821629213483146, 0.5737704918032787, 0.475]</td>\n",
       "      <td>[100]</td>\n",
       "      <td>0.5</td>\n",
       "      <td>0.00500</td>\n",
       "      <td>1</td>\n",
       "      <td>2</td>\n",
       "      <td>False</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>focal</td>\n",
       "      <td>0.695911</td>\n",
       "      <td>0.619387</td>\n",
       "      <td>[0.7940652818991099, 0.529032258064516, 0.5350...</td>\n",
       "      <td>0.668241</td>\n",
       "      <td>0.706320</td>\n",
       "      <td>0.613244</td>\n",
       "      <td>[0.804332129963899, 0.5559999999999999, 0.4794...</td>\n",
       "      <td>[100]</td>\n",
       "      <td>0.5</td>\n",
       "      <td>0.00500</td>\n",
       "      <td>12</td>\n",
       "      <td>2</td>\n",
       "      <td>False</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>focal</td>\n",
       "      <td>0.698141</td>\n",
       "      <td>0.611627</td>\n",
       "      <td>[0.79976717112922, 0.5218855218855218, 0.51322...</td>\n",
       "      <td>0.542071</td>\n",
       "      <td>0.713755</td>\n",
       "      <td>0.611268</td>\n",
       "      <td>[0.8147622427253371, 0.5546218487394958, 0.464...</td>\n",
       "      <td>[100]</td>\n",
       "      <td>0.5</td>\n",
       "      <td>0.00500</td>\n",
       "      <td>123</td>\n",
       "      <td>2</td>\n",
       "      <td>False</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>focal</td>\n",
       "      <td>0.696654</td>\n",
       "      <td>0.618950</td>\n",
       "      <td>[0.793575252825699, 0.5481239804241436, 0.5151...</td>\n",
       "      <td>0.681275</td>\n",
       "      <td>0.716543</td>\n",
       "      <td>0.625144</td>\n",
       "      <td>[0.8127259580621836, 0.5720000000000001, 0.490...</td>\n",
       "      <td>[100]</td>\n",
       "      <td>0.5</td>\n",
       "      <td>0.00500</td>\n",
       "      <td>1234</td>\n",
       "      <td>2</td>\n",
       "      <td>False</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>focal</td>\n",
       "      <td>0.645353</td>\n",
       "      <td>0.531895</td>\n",
       "      <td>[0.7853403141361256, 0.3394833948339484, 0.470...</td>\n",
       "      <td>0.592595</td>\n",
       "      <td>0.650558</td>\n",
       "      <td>0.522043</td>\n",
       "      <td>[0.7971530249110321, 0.3333333333333333, 0.435...</td>\n",
       "      <td>[100, 100, 100]</td>\n",
       "      <td>0.1</td>\n",
       "      <td>0.00001</td>\n",
       "      <td>0</td>\n",
       "      <td>2</td>\n",
       "      <td>False</td>\n",
       "      <td>44</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>focal</td>\n",
       "      <td>0.596283</td>\n",
       "      <td>0.387553</td>\n",
       "      <td>[0.7388016288539849, 0.42385786802030456, 0.0]</td>\n",
       "      <td>0.758998</td>\n",
       "      <td>0.602230</td>\n",
       "      <td>0.386229</td>\n",
       "      <td>[0.7382840663302092, 0.4204018547140649, 0.0]</td>\n",
       "      <td>[100, 100, 100]</td>\n",
       "      <td>0.1</td>\n",
       "      <td>0.00001</td>\n",
       "      <td>1</td>\n",
       "      <td>2</td>\n",
       "      <td>False</td>\n",
       "      <td>44</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>focal</td>\n",
       "      <td>0.647584</td>\n",
       "      <td>0.418361</td>\n",
       "      <td>[0.7968036529680366, 0.45827814569536424, 0.0]</td>\n",
       "      <td>0.643662</td>\n",
       "      <td>0.671933</td>\n",
       "      <td>0.431289</td>\n",
       "      <td>[0.8022284122562674, 0.4916387959866221, 0.0]</td>\n",
       "      <td>[100, 100, 100]</td>\n",
       "      <td>0.1</td>\n",
       "      <td>0.00001</td>\n",
       "      <td>12</td>\n",
       "      <td>2</td>\n",
       "      <td>False</td>\n",
       "      <td>44</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>focal</td>\n",
       "      <td>0.645353</td>\n",
       "      <td>0.413831</td>\n",
       "      <td>[0.796149490373726, 0.44534412955465585, 0.0]</td>\n",
       "      <td>0.639678</td>\n",
       "      <td>0.675651</td>\n",
       "      <td>0.429970</td>\n",
       "      <td>[0.8079834824501033, 0.48192771084337344, 0.0]</td>\n",
       "      <td>[100, 100, 100]</td>\n",
       "      <td>0.1</td>\n",
       "      <td>0.00001</td>\n",
       "      <td>123</td>\n",
       "      <td>2</td>\n",
       "      <td>False</td>\n",
       "      <td>44</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>focal</td>\n",
       "      <td>0.657249</td>\n",
       "      <td>0.557803</td>\n",
       "      <td>[0.7898465171192444, 0.3835616438356165, 0.5]</td>\n",
       "      <td>0.584770</td>\n",
       "      <td>0.656134</td>\n",
       "      <td>0.537666</td>\n",
       "      <td>[0.7974044700793078, 0.37656903765690375, 0.43...</td>\n",
       "      <td>[100, 100, 100]</td>\n",
       "      <td>0.1</td>\n",
       "      <td>0.00001</td>\n",
       "      <td>1234</td>\n",
       "      <td>2</td>\n",
       "      <td>False</td>\n",
       "      <td>44</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>225 rows × 15 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "     loss  accuracy        f1  \\\n",
       "0   focal  0.684015  0.618947   \n",
       "0   focal  0.692937  0.605870   \n",
       "0   focal  0.695911  0.619387   \n",
       "0   focal  0.698141  0.611627   \n",
       "0   focal  0.696654  0.618950   \n",
       "..    ...       ...       ...   \n",
       "0   focal  0.645353  0.531895   \n",
       "0   focal  0.596283  0.387553   \n",
       "0   focal  0.647584  0.418361   \n",
       "0   focal  0.645353  0.413831   \n",
       "0   focal  0.657249  0.557803   \n",
       "\n",
       "                                            f1_scores  valid_loss  \\\n",
       "0   [0.7808471454880296, 0.5281899109792284, 0.547...    0.564228   \n",
       "0   [0.7964912280701756, 0.5169628432956381, 0.504...    0.574431   \n",
       "0   [0.7940652818991099, 0.529032258064516, 0.5350...    0.668241   \n",
       "0   [0.79976717112922, 0.5218855218855218, 0.51322...    0.542071   \n",
       "0   [0.793575252825699, 0.5481239804241436, 0.5151...    0.681275   \n",
       "..                                                ...         ...   \n",
       "0   [0.7853403141361256, 0.3394833948339484, 0.470...    0.592595   \n",
       "0      [0.7388016288539849, 0.42385786802030456, 0.0]    0.758998   \n",
       "0      [0.7968036529680366, 0.45827814569536424, 0.0]    0.643662   \n",
       "0       [0.796149490373726, 0.44534412955465585, 0.0]    0.639678   \n",
       "0       [0.7898465171192444, 0.3835616438356165, 0.5]    0.584770   \n",
       "\n",
       "    valid_accuracy  valid_f1  \\\n",
       "0         0.694238  0.607537   \n",
       "0         0.726766  0.623467   \n",
       "0         0.706320  0.613244   \n",
       "0         0.713755  0.611268   \n",
       "0         0.716543  0.625144   \n",
       "..             ...       ...   \n",
       "0         0.650558  0.522043   \n",
       "0         0.602230  0.386229   \n",
       "0         0.671933  0.431289   \n",
       "0         0.675651  0.429970   \n",
       "0         0.656134  0.537666   \n",
       "\n",
       "                                      valid_f1_scores       hidden_dim  \\\n",
       "0   [0.7920646583394563, 0.5475285171102662, 0.483...            [100]   \n",
       "0      [0.821629213483146, 0.5737704918032787, 0.475]            [100]   \n",
       "0   [0.804332129963899, 0.5559999999999999, 0.4794...            [100]   \n",
       "0   [0.8147622427253371, 0.5546218487394958, 0.464...            [100]   \n",
       "0   [0.8127259580621836, 0.5720000000000001, 0.490...            [100]   \n",
       "..                                                ...              ...   \n",
       "0   [0.7971530249110321, 0.3333333333333333, 0.435...  [100, 100, 100]   \n",
       "0       [0.7382840663302092, 0.4204018547140649, 0.0]  [100, 100, 100]   \n",
       "0       [0.8022284122562674, 0.4916387959866221, 0.0]  [100, 100, 100]   \n",
       "0      [0.8079834824501033, 0.48192771084337344, 0.0]  [100, 100, 100]   \n",
       "0   [0.7974044700793078, 0.37656903765690375, 0.43...  [100, 100, 100]   \n",
       "\n",
       "    dropout_rate  learning_rate  seed  gamma  k_fold  model_id  \n",
       "0            0.5        0.00500     0      2   False         0  \n",
       "0            0.5        0.00500     1      2   False         0  \n",
       "0            0.5        0.00500    12      2   False         0  \n",
       "0            0.5        0.00500   123      2   False         0  \n",
       "0            0.5        0.00500  1234      2   False         0  \n",
       "..           ...            ...   ...    ...     ...       ...  \n",
       "0            0.1        0.00001     0      2   False        44  \n",
       "0            0.1        0.00001     1      2   False        44  \n",
       "0            0.1        0.00001    12      2   False        44  \n",
       "0            0.1        0.00001   123      2   False        44  \n",
       "0            0.1        0.00001  1234      2   False        44  \n",
       "\n",
       "[225 rows x 15 columns]"
      ]
     },
     "execution_count": 40,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "ffn_current"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "id": "32e429b4",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>loss</th>\n",
       "      <th>accuracy</th>\n",
       "      <th>f1</th>\n",
       "      <th>f1_scores</th>\n",
       "      <th>valid_loss</th>\n",
       "      <th>valid_accuracy</th>\n",
       "      <th>valid_f1</th>\n",
       "      <th>valid_f1_scores</th>\n",
       "      <th>hidden_dim</th>\n",
       "      <th>dropout_rate</th>\n",
       "      <th>learning_rate</th>\n",
       "      <th>seed</th>\n",
       "      <th>gamma</th>\n",
       "      <th>k_fold</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>focal</td>\n",
       "      <td>0.699628</td>\n",
       "      <td>0.616654</td>\n",
       "      <td>[0.7990654205607477, 0.525963149078727, 0.5249...</td>\n",
       "      <td>0.632668</td>\n",
       "      <td>0.722119</td>\n",
       "      <td>0.627415</td>\n",
       "      <td>[0.8181174805378627, 0.5546218487394958, 0.509...</td>\n",
       "      <td>[100]</td>\n",
       "      <td>0.5</td>\n",
       "      <td>0.001</td>\n",
       "      <td>0</td>\n",
       "      <td>2</td>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>focal</td>\n",
       "      <td>0.704833</td>\n",
       "      <td>0.627111</td>\n",
       "      <td>[0.7983490566037734, 0.5552050473186121, 0.527...</td>\n",
       "      <td>0.681163</td>\n",
       "      <td>0.714684</td>\n",
       "      <td>0.622294</td>\n",
       "      <td>[0.8117394416607016, 0.5490196078431373, 0.506...</td>\n",
       "      <td>[100]</td>\n",
       "      <td>0.5</td>\n",
       "      <td>0.001</td>\n",
       "      <td>1</td>\n",
       "      <td>2</td>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>focal</td>\n",
       "      <td>0.704089</td>\n",
       "      <td>0.625025</td>\n",
       "      <td>[0.8009395184967704, 0.5366666666666666, 0.537...</td>\n",
       "      <td>0.568209</td>\n",
       "      <td>0.726766</td>\n",
       "      <td>0.635061</td>\n",
       "      <td>[0.8222698072805139, 0.5684210526315789, 0.514...</td>\n",
       "      <td>[100]</td>\n",
       "      <td>0.5</td>\n",
       "      <td>0.001</td>\n",
       "      <td>12</td>\n",
       "      <td>2</td>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>focal</td>\n",
       "      <td>0.694424</td>\n",
       "      <td>0.618451</td>\n",
       "      <td>[0.7903130537507383, 0.5288461538461539, 0.536...</td>\n",
       "      <td>0.608452</td>\n",
       "      <td>0.724907</td>\n",
       "      <td>0.633952</td>\n",
       "      <td>[0.8160919540229885, 0.5896414342629483, 0.496...</td>\n",
       "      <td>[100]</td>\n",
       "      <td>0.5</td>\n",
       "      <td>0.001</td>\n",
       "      <td>123</td>\n",
       "      <td>2</td>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>focal</td>\n",
       "      <td>0.698885</td>\n",
       "      <td>0.624533</td>\n",
       "      <td>[0.7961859356376638, 0.5333333333333333, 0.544...</td>\n",
       "      <td>0.541399</td>\n",
       "      <td>0.716543</td>\n",
       "      <td>0.627569</td>\n",
       "      <td>[0.8112798264642083, 0.5714285714285714, 0.5]</td>\n",
       "      <td>[100]</td>\n",
       "      <td>0.5</td>\n",
       "      <td>0.001</td>\n",
       "      <td>1234</td>\n",
       "      <td>2</td>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "    loss  accuracy        f1  \\\n",
       "0  focal  0.699628  0.616654   \n",
       "0  focal  0.704833  0.627111   \n",
       "0  focal  0.704089  0.625025   \n",
       "0  focal  0.694424  0.618451   \n",
       "0  focal  0.698885  0.624533   \n",
       "\n",
       "                                           f1_scores  valid_loss  \\\n",
       "0  [0.7990654205607477, 0.525963149078727, 0.5249...    0.632668   \n",
       "0  [0.7983490566037734, 0.5552050473186121, 0.527...    0.681163   \n",
       "0  [0.8009395184967704, 0.5366666666666666, 0.537...    0.568209   \n",
       "0  [0.7903130537507383, 0.5288461538461539, 0.536...    0.608452   \n",
       "0  [0.7961859356376638, 0.5333333333333333, 0.544...    0.541399   \n",
       "\n",
       "   valid_accuracy  valid_f1  \\\n",
       "0        0.722119  0.627415   \n",
       "0        0.714684  0.622294   \n",
       "0        0.726766  0.635061   \n",
       "0        0.724907  0.633952   \n",
       "0        0.716543  0.627569   \n",
       "\n",
       "                                     valid_f1_scores hidden_dim  dropout_rate  \\\n",
       "0  [0.8181174805378627, 0.5546218487394958, 0.509...      [100]           0.5   \n",
       "0  [0.8117394416607016, 0.5490196078431373, 0.506...      [100]           0.5   \n",
       "0  [0.8222698072805139, 0.5684210526315789, 0.514...      [100]           0.5   \n",
       "0  [0.8160919540229885, 0.5896414342629483, 0.496...      [100]           0.5   \n",
       "0      [0.8112798264642083, 0.5714285714285714, 0.5]      [100]           0.5   \n",
       "\n",
       "   learning_rate  seed  gamma  k_fold  \n",
       "0          0.001     0      2   False  \n",
       "0          0.001     1      2   False  \n",
       "0          0.001    12      2   False  \n",
       "0          0.001   123      2   False  \n",
       "0          0.001  1234      2   False  "
      ]
     },
     "execution_count": 41,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "best_ffn_current"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "id": "c1cd3480",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.6223547220370722"
      ]
     },
     "execution_count": 42,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "best_ffn_current[\"f1\"].mean()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 68,
   "id": "2b1b1e6e",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([0.7969706 , 0.53600287, 0.5340907 ])"
      ]
     },
     "execution_count": 68,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "np.stack(best_ffn_current[\"f1_scores\"]).mean(axis=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "id": "171c2dab",
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "ab4fc91892034fcd9f93f309f35bdbd2",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/3 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "704f45173b6d40d98e6b4779556cb677",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/3 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "5d76b816786545f99e49a58e4585c1f3",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/5 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "17e8207362b64de7b879b210a5105ea7",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/5 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "521f3ee553c14db095397d93c9b1aa7b",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/5 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "0381bea73fab4022a7a2f104a1928cf3",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/3 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "11033981a39a4616995966afdfd6e030",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/5 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "80f6861ffa5c4d9a91aa8d1988f75e5f",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/5 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "a415bc68bdea4f0fa05e337d18489cbe",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/5 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "b417e073eafc44aeb7641afcd7ec5f7d",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/3 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "14f86d3ac6d4422f9ddead9f4785b9ac",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/5 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "e6f9401465864c75be65cc4c7647ba85",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/5 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "65e4cc4d467f424681ef459a4e14505a",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/5 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "saving results dataframe to CSV for this hyperparameter search in ffn_current_focal_2_kfold.csv\n",
      "saving the best model results dataframe to CSV for this hyperparameter search in ffn_current_focal_2_kfold_best_model.csv\n"
     ]
    }
   ],
   "source": [
    "ffn_current_kfold, best_ffn_current_kfold, _, __ = ffn_hyperparameter_search(\n",
    "    num_epochs=num_epochs,\n",
    "    x_data=sbert_embeddings[client_index],\n",
    "    y_data=y_data,\n",
    "    hidden_dim_sizes=hidden_dim_sizes,\n",
    "    output_dim=output_dim,\n",
    "    dropout_rates=dropout_rates,\n",
    "    learning_rates=learning_rates,\n",
    "    seeds=seeds,\n",
    "    loss=loss,\n",
    "    gamma=gamma,\n",
    "    k_fold=True,\n",
    "    validation_metric=validation_metric,\n",
    "    results_output=f\"{output_dir}/ffn_current_focal_{gamma}_kfold.csv\",\n",
    "    verbose=False\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "id": "6f8f21d9",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>loss</th>\n",
       "      <th>accuracy</th>\n",
       "      <th>f1</th>\n",
       "      <th>f1_scores</th>\n",
       "      <th>valid_loss</th>\n",
       "      <th>valid_accuracy</th>\n",
       "      <th>valid_f1</th>\n",
       "      <th>valid_f1_scores</th>\n",
       "      <th>hidden_dim</th>\n",
       "      <th>dropout_rate</th>\n",
       "      <th>learning_rate</th>\n",
       "      <th>seed</th>\n",
       "      <th>gamma</th>\n",
       "      <th>k_fold</th>\n",
       "      <th>model_id</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>focal</td>\n",
       "      <td>0.681784</td>\n",
       "      <td>0.594099</td>\n",
       "      <td>[0.7857559836544076, 0.505226480836237, 0.4913...</td>\n",
       "      <td>0.545414</td>\n",
       "      <td>0.686374</td>\n",
       "      <td>0.583469</td>\n",
       "      <td>[0.7960155911650064, 0.5026455026455026, 0.451...</td>\n",
       "      <td>[100]</td>\n",
       "      <td>0.5</td>\n",
       "      <td>0.00500</td>\n",
       "      <td>0</td>\n",
       "      <td>2</td>\n",
       "      <td>True</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>focal</td>\n",
       "      <td>0.686989</td>\n",
       "      <td>0.582050</td>\n",
       "      <td>[0.7977272727272727, 0.4909747292418772, 0.457...</td>\n",
       "      <td>0.534665</td>\n",
       "      <td>0.692005</td>\n",
       "      <td>0.589859</td>\n",
       "      <td>[0.7959183673469388, 0.49382716049382713, 0.47...</td>\n",
       "      <td>[100]</td>\n",
       "      <td>0.5</td>\n",
       "      <td>0.00500</td>\n",
       "      <td>0</td>\n",
       "      <td>2</td>\n",
       "      <td>True</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>focal</td>\n",
       "      <td>0.682528</td>\n",
       "      <td>0.575796</td>\n",
       "      <td>[0.788538681948424, 0.5342237061769616, 0.4046...</td>\n",
       "      <td>0.552925</td>\n",
       "      <td>0.700450</td>\n",
       "      <td>0.604532</td>\n",
       "      <td>[0.7991323210412147, 0.5532467532467532, 0.461...</td>\n",
       "      <td>[100]</td>\n",
       "      <td>0.5</td>\n",
       "      <td>0.00500</td>\n",
       "      <td>0</td>\n",
       "      <td>2</td>\n",
       "      <td>True</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>focal</td>\n",
       "      <td>0.706320</td>\n",
       "      <td>0.613436</td>\n",
       "      <td>[0.805491990846682, 0.5451263537906137, 0.4896...</td>\n",
       "      <td>0.577055</td>\n",
       "      <td>0.701014</td>\n",
       "      <td>0.605842</td>\n",
       "      <td>[0.800520381613183, 0.5459317585301838, 0.4710...</td>\n",
       "      <td>[100]</td>\n",
       "      <td>0.5</td>\n",
       "      <td>0.00500</td>\n",
       "      <td>0</td>\n",
       "      <td>2</td>\n",
       "      <td>True</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>focal</td>\n",
       "      <td>0.672862</td>\n",
       "      <td>0.596099</td>\n",
       "      <td>[0.7738814993954052, 0.5225225225225226, 0.491...</td>\n",
       "      <td>0.548656</td>\n",
       "      <td>0.679617</td>\n",
       "      <td>0.605924</td>\n",
       "      <td>[0.775735294117647, 0.5420353982300885, 0.5]</td>\n",
       "      <td>[100]</td>\n",
       "      <td>0.5</td>\n",
       "      <td>0.00500</td>\n",
       "      <td>0</td>\n",
       "      <td>2</td>\n",
       "      <td>True</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>focal</td>\n",
       "      <td>0.653532</td>\n",
       "      <td>0.552813</td>\n",
       "      <td>[0.7872340425531915, 0.3870967741935484, 0.484...</td>\n",
       "      <td>0.625054</td>\n",
       "      <td>0.626126</td>\n",
       "      <td>0.505284</td>\n",
       "      <td>[0.7734855136084283, 0.3289817232375979, 0.413...</td>\n",
       "      <td>[100, 100, 100]</td>\n",
       "      <td>0.1</td>\n",
       "      <td>0.00001</td>\n",
       "      <td>1234</td>\n",
       "      <td>2</td>\n",
       "      <td>True</td>\n",
       "      <td>44</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>focal</td>\n",
       "      <td>0.640149</td>\n",
       "      <td>0.521224</td>\n",
       "      <td>[0.7870370370370371, 0.3321917808219178, 0.444...</td>\n",
       "      <td>0.619201</td>\n",
       "      <td>0.636824</td>\n",
       "      <td>0.524574</td>\n",
       "      <td>[0.7733450241122314, 0.37055214723926383, 0.42...</td>\n",
       "      <td>[100, 100, 100]</td>\n",
       "      <td>0.1</td>\n",
       "      <td>0.00001</td>\n",
       "      <td>1234</td>\n",
       "      <td>2</td>\n",
       "      <td>True</td>\n",
       "      <td>44</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>focal</td>\n",
       "      <td>0.626766</td>\n",
       "      <td>0.499733</td>\n",
       "      <td>[0.7731188971855256, 0.34596375617792424, 0.38...</td>\n",
       "      <td>0.617926</td>\n",
       "      <td>0.627815</td>\n",
       "      <td>0.508627</td>\n",
       "      <td>[0.771168041684759, 0.31865284974093266, 0.436...</td>\n",
       "      <td>[100, 100, 100]</td>\n",
       "      <td>0.1</td>\n",
       "      <td>0.00001</td>\n",
       "      <td>1234</td>\n",
       "      <td>2</td>\n",
       "      <td>True</td>\n",
       "      <td>44</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>focal</td>\n",
       "      <td>0.610409</td>\n",
       "      <td>0.487177</td>\n",
       "      <td>[0.7679719462302746, 0.2956810631229236, 0.397...</td>\n",
       "      <td>0.638740</td>\n",
       "      <td>0.630068</td>\n",
       "      <td>0.509474</td>\n",
       "      <td>[0.7740511915269197, 0.3742405832320777, 0.380...</td>\n",
       "      <td>[100, 100, 100]</td>\n",
       "      <td>0.1</td>\n",
       "      <td>0.00001</td>\n",
       "      <td>1234</td>\n",
       "      <td>2</td>\n",
       "      <td>True</td>\n",
       "      <td>44</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>focal</td>\n",
       "      <td>0.616357</td>\n",
       "      <td>0.501398</td>\n",
       "      <td>[0.7639132981839485, 0.32558139534883723, 0.41...</td>\n",
       "      <td>0.627865</td>\n",
       "      <td>0.627252</td>\n",
       "      <td>0.506051</td>\n",
       "      <td>[0.7765118317265557, 0.32323232323232326, 0.41...</td>\n",
       "      <td>[100, 100, 100]</td>\n",
       "      <td>0.1</td>\n",
       "      <td>0.00001</td>\n",
       "      <td>1234</td>\n",
       "      <td>2</td>\n",
       "      <td>True</td>\n",
       "      <td>44</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>1125 rows × 15 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "     loss  accuracy        f1  \\\n",
       "0   focal  0.681784  0.594099   \n",
       "1   focal  0.686989  0.582050   \n",
       "2   focal  0.682528  0.575796   \n",
       "3   focal  0.706320  0.613436   \n",
       "4   focal  0.672862  0.596099   \n",
       "..    ...       ...       ...   \n",
       "0   focal  0.653532  0.552813   \n",
       "1   focal  0.640149  0.521224   \n",
       "2   focal  0.626766  0.499733   \n",
       "3   focal  0.610409  0.487177   \n",
       "4   focal  0.616357  0.501398   \n",
       "\n",
       "                                            f1_scores  valid_loss  \\\n",
       "0   [0.7857559836544076, 0.505226480836237, 0.4913...    0.545414   \n",
       "1   [0.7977272727272727, 0.4909747292418772, 0.457...    0.534665   \n",
       "2   [0.788538681948424, 0.5342237061769616, 0.4046...    0.552925   \n",
       "3   [0.805491990846682, 0.5451263537906137, 0.4896...    0.577055   \n",
       "4   [0.7738814993954052, 0.5225225225225226, 0.491...    0.548656   \n",
       "..                                                ...         ...   \n",
       "0   [0.7872340425531915, 0.3870967741935484, 0.484...    0.625054   \n",
       "1   [0.7870370370370371, 0.3321917808219178, 0.444...    0.619201   \n",
       "2   [0.7731188971855256, 0.34596375617792424, 0.38...    0.617926   \n",
       "3   [0.7679719462302746, 0.2956810631229236, 0.397...    0.638740   \n",
       "4   [0.7639132981839485, 0.32558139534883723, 0.41...    0.627865   \n",
       "\n",
       "    valid_accuracy  valid_f1  \\\n",
       "0         0.686374  0.583469   \n",
       "1         0.692005  0.589859   \n",
       "2         0.700450  0.604532   \n",
       "3         0.701014  0.605842   \n",
       "4         0.679617  0.605924   \n",
       "..             ...       ...   \n",
       "0         0.626126  0.505284   \n",
       "1         0.636824  0.524574   \n",
       "2         0.627815  0.508627   \n",
       "3         0.630068  0.509474   \n",
       "4         0.627252  0.506051   \n",
       "\n",
       "                                      valid_f1_scores       hidden_dim  \\\n",
       "0   [0.7960155911650064, 0.5026455026455026, 0.451...            [100]   \n",
       "1   [0.7959183673469388, 0.49382716049382713, 0.47...            [100]   \n",
       "2   [0.7991323210412147, 0.5532467532467532, 0.461...            [100]   \n",
       "3   [0.800520381613183, 0.5459317585301838, 0.4710...            [100]   \n",
       "4        [0.775735294117647, 0.5420353982300885, 0.5]            [100]   \n",
       "..                                                ...              ...   \n",
       "0   [0.7734855136084283, 0.3289817232375979, 0.413...  [100, 100, 100]   \n",
       "1   [0.7733450241122314, 0.37055214723926383, 0.42...  [100, 100, 100]   \n",
       "2   [0.771168041684759, 0.31865284974093266, 0.436...  [100, 100, 100]   \n",
       "3   [0.7740511915269197, 0.3742405832320777, 0.380...  [100, 100, 100]   \n",
       "4   [0.7765118317265557, 0.32323232323232326, 0.41...  [100, 100, 100]   \n",
       "\n",
       "    dropout_rate  learning_rate  seed  gamma  k_fold  model_id  \n",
       "0            0.5        0.00500     0      2    True         0  \n",
       "1            0.5        0.00500     0      2    True         0  \n",
       "2            0.5        0.00500     0      2    True         0  \n",
       "3            0.5        0.00500     0      2    True         0  \n",
       "4            0.5        0.00500     0      2    True         0  \n",
       "..           ...            ...   ...    ...     ...       ...  \n",
       "0            0.1        0.00001  1234      2    True        44  \n",
       "1            0.1        0.00001  1234      2    True        44  \n",
       "2            0.1        0.00001  1234      2    True        44  \n",
       "3            0.1        0.00001  1234      2    True        44  \n",
       "4            0.1        0.00001  1234      2    True        44  \n",
       "\n",
       "[1125 rows x 15 columns]"
      ]
     },
     "execution_count": 44,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "ffn_current_kfold"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "id": "6af81e06",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>loss</th>\n",
       "      <th>accuracy</th>\n",
       "      <th>f1</th>\n",
       "      <th>f1_scores</th>\n",
       "      <th>valid_loss</th>\n",
       "      <th>valid_accuracy</th>\n",
       "      <th>valid_f1</th>\n",
       "      <th>valid_f1_scores</th>\n",
       "      <th>hidden_dim</th>\n",
       "      <th>dropout_rate</th>\n",
       "      <th>learning_rate</th>\n",
       "      <th>seed</th>\n",
       "      <th>gamma</th>\n",
       "      <th>k_fold</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>focal</td>\n",
       "      <td>0.684758</td>\n",
       "      <td>0.607160</td>\n",
       "      <td>[0.7886815171583383, 0.5196078431372549, 0.513...</td>\n",
       "      <td>0.553060</td>\n",
       "      <td>0.680180</td>\n",
       "      <td>0.593967</td>\n",
       "      <td>[0.7824529991047449, 0.5286236297198538, 0.470...</td>\n",
       "      <td>[100]</td>\n",
       "      <td>0.5</td>\n",
       "      <td>0.0001</td>\n",
       "      <td>0</td>\n",
       "      <td>2</td>\n",
       "      <td>True</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>focal</td>\n",
       "      <td>0.677323</td>\n",
       "      <td>0.586921</td>\n",
       "      <td>[0.7866108786610878, 0.5255023183925811, 0.448...</td>\n",
       "      <td>0.531541</td>\n",
       "      <td>0.688626</td>\n",
       "      <td>0.606592</td>\n",
       "      <td>[0.7841726618705036, 0.5529953917050692, 0.482...</td>\n",
       "      <td>[100]</td>\n",
       "      <td>0.5</td>\n",
       "      <td>0.0001</td>\n",
       "      <td>0</td>\n",
       "      <td>2</td>\n",
       "      <td>True</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>focal</td>\n",
       "      <td>0.685502</td>\n",
       "      <td>0.579362</td>\n",
       "      <td>[0.79133409350057, 0.5272108843537414, 0.41954...</td>\n",
       "      <td>0.550432</td>\n",
       "      <td>0.690315</td>\n",
       "      <td>0.598250</td>\n",
       "      <td>[0.791083916083916, 0.530718954248366, 0.47294...</td>\n",
       "      <td>[100]</td>\n",
       "      <td>0.5</td>\n",
       "      <td>0.0001</td>\n",
       "      <td>0</td>\n",
       "      <td>2</td>\n",
       "      <td>True</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>focal</td>\n",
       "      <td>0.692193</td>\n",
       "      <td>0.602759</td>\n",
       "      <td>[0.7938931297709922, 0.5475409836065575, 0.466...</td>\n",
       "      <td>0.582319</td>\n",
       "      <td>0.683559</td>\n",
       "      <td>0.591700</td>\n",
       "      <td>[0.7836153161175423, 0.5513126491646777, 0.440...</td>\n",
       "      <td>[100]</td>\n",
       "      <td>0.5</td>\n",
       "      <td>0.0001</td>\n",
       "      <td>0</td>\n",
       "      <td>2</td>\n",
       "      <td>True</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>focal</td>\n",
       "      <td>0.665428</td>\n",
       "      <td>0.588839</td>\n",
       "      <td>[0.7696019300361883, 0.4969135802469136, 0.5]</td>\n",
       "      <td>0.547304</td>\n",
       "      <td>0.675113</td>\n",
       "      <td>0.592574</td>\n",
       "      <td>[0.7785356980445657, 0.5266821345707655, 0.472...</td>\n",
       "      <td>[100]</td>\n",
       "      <td>0.5</td>\n",
       "      <td>0.0001</td>\n",
       "      <td>0</td>\n",
       "      <td>2</td>\n",
       "      <td>True</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>focal</td>\n",
       "      <td>0.681784</td>\n",
       "      <td>0.600001</td>\n",
       "      <td>[0.7883124627310675, 0.5033783783783784, 0.508...</td>\n",
       "      <td>0.560043</td>\n",
       "      <td>0.674550</td>\n",
       "      <td>0.580560</td>\n",
       "      <td>[0.7842786958463601, 0.5160493827160494, 0.441...</td>\n",
       "      <td>[100]</td>\n",
       "      <td>0.5</td>\n",
       "      <td>0.0001</td>\n",
       "      <td>1</td>\n",
       "      <td>2</td>\n",
       "      <td>True</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>focal</td>\n",
       "      <td>0.686989</td>\n",
       "      <td>0.596568</td>\n",
       "      <td>[0.7936132465996452, 0.5281250000000001, 0.467...</td>\n",
       "      <td>0.535979</td>\n",
       "      <td>0.694820</td>\n",
       "      <td>0.612573</td>\n",
       "      <td>[0.7891699955614737, 0.5463071512309496, 0.502...</td>\n",
       "      <td>[100]</td>\n",
       "      <td>0.5</td>\n",
       "      <td>0.0001</td>\n",
       "      <td>1</td>\n",
       "      <td>2</td>\n",
       "      <td>True</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>focal</td>\n",
       "      <td>0.680297</td>\n",
       "      <td>0.573057</td>\n",
       "      <td>[0.7853042479908152, 0.5385878489326765, 0.395...</td>\n",
       "      <td>0.552261</td>\n",
       "      <td>0.693131</td>\n",
       "      <td>0.605103</td>\n",
       "      <td>[0.7892888498683055, 0.548469387755102, 0.4775...</td>\n",
       "      <td>[100]</td>\n",
       "      <td>0.5</td>\n",
       "      <td>0.0001</td>\n",
       "      <td>1</td>\n",
       "      <td>2</td>\n",
       "      <td>True</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>focal</td>\n",
       "      <td>0.689963</td>\n",
       "      <td>0.602343</td>\n",
       "      <td>[0.7903699354081034, 0.5454545454545455, 0.471...</td>\n",
       "      <td>0.581351</td>\n",
       "      <td>0.682432</td>\n",
       "      <td>0.587900</td>\n",
       "      <td>[0.7850799289520426, 0.5445783132530121, 0.434...</td>\n",
       "      <td>[100]</td>\n",
       "      <td>0.5</td>\n",
       "      <td>0.0001</td>\n",
       "      <td>1</td>\n",
       "      <td>2</td>\n",
       "      <td>True</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>focal</td>\n",
       "      <td>0.664684</td>\n",
       "      <td>0.587020</td>\n",
       "      <td>[0.7681246255242661, 0.4929356357927786, 0.5]</td>\n",
       "      <td>0.547436</td>\n",
       "      <td>0.685248</td>\n",
       "      <td>0.604926</td>\n",
       "      <td>[0.7860696517412936, 0.5317647058823529, 0.496...</td>\n",
       "      <td>[100]</td>\n",
       "      <td>0.5</td>\n",
       "      <td>0.0001</td>\n",
       "      <td>1</td>\n",
       "      <td>2</td>\n",
       "      <td>True</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>focal</td>\n",
       "      <td>0.688476</td>\n",
       "      <td>0.612616</td>\n",
       "      <td>[0.7875523638539798, 0.5294117647058824, 0.520...</td>\n",
       "      <td>0.554222</td>\n",
       "      <td>0.678491</td>\n",
       "      <td>0.592235</td>\n",
       "      <td>[0.7805096110862763, 0.5263157894736842, 0.469...</td>\n",
       "      <td>[100]</td>\n",
       "      <td>0.5</td>\n",
       "      <td>0.0001</td>\n",
       "      <td>12</td>\n",
       "      <td>2</td>\n",
       "      <td>True</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>focal</td>\n",
       "      <td>0.679554</td>\n",
       "      <td>0.591718</td>\n",
       "      <td>[0.7861822513400835, 0.5232198142414862, 0.465...</td>\n",
       "      <td>0.530573</td>\n",
       "      <td>0.695946</td>\n",
       "      <td>0.617304</td>\n",
       "      <td>[0.787987449574182, 0.5595375722543353, 0.5043...</td>\n",
       "      <td>[100]</td>\n",
       "      <td>0.5</td>\n",
       "      <td>0.0001</td>\n",
       "      <td>12</td>\n",
       "      <td>2</td>\n",
       "      <td>True</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>focal</td>\n",
       "      <td>0.680297</td>\n",
       "      <td>0.576148</td>\n",
       "      <td>[0.7877739331026529, 0.5282392026578072, 0.412...</td>\n",
       "      <td>0.545660</td>\n",
       "      <td>0.684685</td>\n",
       "      <td>0.596718</td>\n",
       "      <td>[0.7852112676056338, 0.5215123859191656, 0.483...</td>\n",
       "      <td>[100]</td>\n",
       "      <td>0.5</td>\n",
       "      <td>0.0001</td>\n",
       "      <td>12</td>\n",
       "      <td>2</td>\n",
       "      <td>True</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>focal</td>\n",
       "      <td>0.679554</td>\n",
       "      <td>0.589501</td>\n",
       "      <td>[0.7852112676056339, 0.5186440677966102, 0.464...</td>\n",
       "      <td>0.578692</td>\n",
       "      <td>0.677928</td>\n",
       "      <td>0.580750</td>\n",
       "      <td>[0.7844178840194777, 0.5295566502463055, 0.428...</td>\n",
       "      <td>[100]</td>\n",
       "      <td>0.5</td>\n",
       "      <td>0.0001</td>\n",
       "      <td>12</td>\n",
       "      <td>2</td>\n",
       "      <td>True</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>focal</td>\n",
       "      <td>0.671375</td>\n",
       "      <td>0.592588</td>\n",
       "      <td>[0.7736526946107785, 0.509375, 0.4947368421052...</td>\n",
       "      <td>0.547014</td>\n",
       "      <td>0.681869</td>\n",
       "      <td>0.600246</td>\n",
       "      <td>[0.7839422643211545, 0.5229681978798587, 0.493...</td>\n",
       "      <td>[100]</td>\n",
       "      <td>0.5</td>\n",
       "      <td>0.0001</td>\n",
       "      <td>12</td>\n",
       "      <td>2</td>\n",
       "      <td>True</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>focal</td>\n",
       "      <td>0.683271</td>\n",
       "      <td>0.604997</td>\n",
       "      <td>[0.7866108786610878, 0.5084745762711864, 0.519...</td>\n",
       "      <td>0.555328</td>\n",
       "      <td>0.678491</td>\n",
       "      <td>0.588698</td>\n",
       "      <td>[0.7846291331546024, 0.5217391304347826, 0.459...</td>\n",
       "      <td>[100]</td>\n",
       "      <td>0.5</td>\n",
       "      <td>0.0001</td>\n",
       "      <td>123</td>\n",
       "      <td>2</td>\n",
       "      <td>True</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>focal</td>\n",
       "      <td>0.684015</td>\n",
       "      <td>0.594493</td>\n",
       "      <td>[0.7909738717339667, 0.5271317829457365, 0.465...</td>\n",
       "      <td>0.536739</td>\n",
       "      <td>0.695946</td>\n",
       "      <td>0.616334</td>\n",
       "      <td>[0.7903657448706513, 0.5452436194895592, 0.513...</td>\n",
       "      <td>[100]</td>\n",
       "      <td>0.5</td>\n",
       "      <td>0.0001</td>\n",
       "      <td>123</td>\n",
       "      <td>2</td>\n",
       "      <td>True</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>focal</td>\n",
       "      <td>0.677323</td>\n",
       "      <td>0.575159</td>\n",
       "      <td>[0.783256880733945, 0.5152542372881356, 0.4269...</td>\n",
       "      <td>0.551897</td>\n",
       "      <td>0.684122</td>\n",
       "      <td>0.593241</td>\n",
       "      <td>[0.7868131868131868, 0.5225464190981433, 0.470...</td>\n",
       "      <td>[100]</td>\n",
       "      <td>0.5</td>\n",
       "      <td>0.0001</td>\n",
       "      <td>123</td>\n",
       "      <td>2</td>\n",
       "      <td>True</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>focal</td>\n",
       "      <td>0.684758</td>\n",
       "      <td>0.595713</td>\n",
       "      <td>[0.7878077373974207, 0.5271828665568369, 0.472...</td>\n",
       "      <td>0.581338</td>\n",
       "      <td>0.684122</td>\n",
       "      <td>0.589917</td>\n",
       "      <td>[0.7856191744340878, 0.5478468899521529, 0.436...</td>\n",
       "      <td>[100]</td>\n",
       "      <td>0.5</td>\n",
       "      <td>0.0001</td>\n",
       "      <td>123</td>\n",
       "      <td>2</td>\n",
       "      <td>True</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>focal</td>\n",
       "      <td>0.667658</td>\n",
       "      <td>0.589309</td>\n",
       "      <td>[0.771531100478469, 0.49374999999999997, 0.502...</td>\n",
       "      <td>0.546651</td>\n",
       "      <td>0.689752</td>\n",
       "      <td>0.610380</td>\n",
       "      <td>[0.7879061371841155, 0.5411764705882353, 0.502...</td>\n",
       "      <td>[100]</td>\n",
       "      <td>0.5</td>\n",
       "      <td>0.0001</td>\n",
       "      <td>123</td>\n",
       "      <td>2</td>\n",
       "      <td>True</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>focal</td>\n",
       "      <td>0.686989</td>\n",
       "      <td>0.611538</td>\n",
       "      <td>[0.7872212176009644, 0.5342019543973942, 0.513...</td>\n",
       "      <td>0.549992</td>\n",
       "      <td>0.681306</td>\n",
       "      <td>0.596595</td>\n",
       "      <td>[0.7828828828828828, 0.5386473429951691, 0.468...</td>\n",
       "      <td>[100]</td>\n",
       "      <td>0.5</td>\n",
       "      <td>0.0001</td>\n",
       "      <td>1234</td>\n",
       "      <td>2</td>\n",
       "      <td>True</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>focal</td>\n",
       "      <td>0.686989</td>\n",
       "      <td>0.596283</td>\n",
       "      <td>[0.7926322043969102, 0.5398773006134969, 0.456...</td>\n",
       "      <td>0.529428</td>\n",
       "      <td>0.697072</td>\n",
       "      <td>0.613762</td>\n",
       "      <td>[0.7924865831842576, 0.5567010309278351, 0.492...</td>\n",
       "      <td>[100]</td>\n",
       "      <td>0.5</td>\n",
       "      <td>0.0001</td>\n",
       "      <td>1234</td>\n",
       "      <td>2</td>\n",
       "      <td>True</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>focal</td>\n",
       "      <td>0.678067</td>\n",
       "      <td>0.569431</td>\n",
       "      <td>[0.7856328392246295, 0.5167785234899329, 0.405...</td>\n",
       "      <td>0.551127</td>\n",
       "      <td>0.690315</td>\n",
       "      <td>0.597966</td>\n",
       "      <td>[0.791083916083916, 0.5295629820051414, 0.4732...</td>\n",
       "      <td>[100]</td>\n",
       "      <td>0.5</td>\n",
       "      <td>0.0001</td>\n",
       "      <td>1234</td>\n",
       "      <td>2</td>\n",
       "      <td>True</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>focal</td>\n",
       "      <td>0.686989</td>\n",
       "      <td>0.598666</td>\n",
       "      <td>[0.7896287566293458, 0.5412541254125413, 0.465...</td>\n",
       "      <td>0.578891</td>\n",
       "      <td>0.685248</td>\n",
       "      <td>0.594553</td>\n",
       "      <td>[0.7845057880676759, 0.5532934131736528, 0.445...</td>\n",
       "      <td>[100]</td>\n",
       "      <td>0.5</td>\n",
       "      <td>0.0001</td>\n",
       "      <td>1234</td>\n",
       "      <td>2</td>\n",
       "      <td>True</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>focal</td>\n",
       "      <td>0.667658</td>\n",
       "      <td>0.587934</td>\n",
       "      <td>[0.7730282962071041, 0.5038639876352395, 0.486...</td>\n",
       "      <td>0.547873</td>\n",
       "      <td>0.678491</td>\n",
       "      <td>0.599874</td>\n",
       "      <td>[0.7814207650273224, 0.519208381839348, 0.4989...</td>\n",
       "      <td>[100]</td>\n",
       "      <td>0.5</td>\n",
       "      <td>0.0001</td>\n",
       "      <td>1234</td>\n",
       "      <td>2</td>\n",
       "      <td>True</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "    loss  accuracy        f1  \\\n",
       "0  focal  0.684758  0.607160   \n",
       "1  focal  0.677323  0.586921   \n",
       "2  focal  0.685502  0.579362   \n",
       "3  focal  0.692193  0.602759   \n",
       "4  focal  0.665428  0.588839   \n",
       "0  focal  0.681784  0.600001   \n",
       "1  focal  0.686989  0.596568   \n",
       "2  focal  0.680297  0.573057   \n",
       "3  focal  0.689963  0.602343   \n",
       "4  focal  0.664684  0.587020   \n",
       "0  focal  0.688476  0.612616   \n",
       "1  focal  0.679554  0.591718   \n",
       "2  focal  0.680297  0.576148   \n",
       "3  focal  0.679554  0.589501   \n",
       "4  focal  0.671375  0.592588   \n",
       "0  focal  0.683271  0.604997   \n",
       "1  focal  0.684015  0.594493   \n",
       "2  focal  0.677323  0.575159   \n",
       "3  focal  0.684758  0.595713   \n",
       "4  focal  0.667658  0.589309   \n",
       "0  focal  0.686989  0.611538   \n",
       "1  focal  0.686989  0.596283   \n",
       "2  focal  0.678067  0.569431   \n",
       "3  focal  0.686989  0.598666   \n",
       "4  focal  0.667658  0.587934   \n",
       "\n",
       "                                           f1_scores  valid_loss  \\\n",
       "0  [0.7886815171583383, 0.5196078431372549, 0.513...    0.553060   \n",
       "1  [0.7866108786610878, 0.5255023183925811, 0.448...    0.531541   \n",
       "2  [0.79133409350057, 0.5272108843537414, 0.41954...    0.550432   \n",
       "3  [0.7938931297709922, 0.5475409836065575, 0.466...    0.582319   \n",
       "4      [0.7696019300361883, 0.4969135802469136, 0.5]    0.547304   \n",
       "0  [0.7883124627310675, 0.5033783783783784, 0.508...    0.560043   \n",
       "1  [0.7936132465996452, 0.5281250000000001, 0.467...    0.535979   \n",
       "2  [0.7853042479908152, 0.5385878489326765, 0.395...    0.552261   \n",
       "3  [0.7903699354081034, 0.5454545454545455, 0.471...    0.581351   \n",
       "4      [0.7681246255242661, 0.4929356357927786, 0.5]    0.547436   \n",
       "0  [0.7875523638539798, 0.5294117647058824, 0.520...    0.554222   \n",
       "1  [0.7861822513400835, 0.5232198142414862, 0.465...    0.530573   \n",
       "2  [0.7877739331026529, 0.5282392026578072, 0.412...    0.545660   \n",
       "3  [0.7852112676056339, 0.5186440677966102, 0.464...    0.578692   \n",
       "4  [0.7736526946107785, 0.509375, 0.4947368421052...    0.547014   \n",
       "0  [0.7866108786610878, 0.5084745762711864, 0.519...    0.555328   \n",
       "1  [0.7909738717339667, 0.5271317829457365, 0.465...    0.536739   \n",
       "2  [0.783256880733945, 0.5152542372881356, 0.4269...    0.551897   \n",
       "3  [0.7878077373974207, 0.5271828665568369, 0.472...    0.581338   \n",
       "4  [0.771531100478469, 0.49374999999999997, 0.502...    0.546651   \n",
       "0  [0.7872212176009644, 0.5342019543973942, 0.513...    0.549992   \n",
       "1  [0.7926322043969102, 0.5398773006134969, 0.456...    0.529428   \n",
       "2  [0.7856328392246295, 0.5167785234899329, 0.405...    0.551127   \n",
       "3  [0.7896287566293458, 0.5412541254125413, 0.465...    0.578891   \n",
       "4  [0.7730282962071041, 0.5038639876352395, 0.486...    0.547873   \n",
       "\n",
       "   valid_accuracy  valid_f1  \\\n",
       "0        0.680180  0.593967   \n",
       "1        0.688626  0.606592   \n",
       "2        0.690315  0.598250   \n",
       "3        0.683559  0.591700   \n",
       "4        0.675113  0.592574   \n",
       "0        0.674550  0.580560   \n",
       "1        0.694820  0.612573   \n",
       "2        0.693131  0.605103   \n",
       "3        0.682432  0.587900   \n",
       "4        0.685248  0.604926   \n",
       "0        0.678491  0.592235   \n",
       "1        0.695946  0.617304   \n",
       "2        0.684685  0.596718   \n",
       "3        0.677928  0.580750   \n",
       "4        0.681869  0.600246   \n",
       "0        0.678491  0.588698   \n",
       "1        0.695946  0.616334   \n",
       "2        0.684122  0.593241   \n",
       "3        0.684122  0.589917   \n",
       "4        0.689752  0.610380   \n",
       "0        0.681306  0.596595   \n",
       "1        0.697072  0.613762   \n",
       "2        0.690315  0.597966   \n",
       "3        0.685248  0.594553   \n",
       "4        0.678491  0.599874   \n",
       "\n",
       "                                     valid_f1_scores hidden_dim  dropout_rate  \\\n",
       "0  [0.7824529991047449, 0.5286236297198538, 0.470...      [100]           0.5   \n",
       "1  [0.7841726618705036, 0.5529953917050692, 0.482...      [100]           0.5   \n",
       "2  [0.791083916083916, 0.530718954248366, 0.47294...      [100]           0.5   \n",
       "3  [0.7836153161175423, 0.5513126491646777, 0.440...      [100]           0.5   \n",
       "4  [0.7785356980445657, 0.5266821345707655, 0.472...      [100]           0.5   \n",
       "0  [0.7842786958463601, 0.5160493827160494, 0.441...      [100]           0.5   \n",
       "1  [0.7891699955614737, 0.5463071512309496, 0.502...      [100]           0.5   \n",
       "2  [0.7892888498683055, 0.548469387755102, 0.4775...      [100]           0.5   \n",
       "3  [0.7850799289520426, 0.5445783132530121, 0.434...      [100]           0.5   \n",
       "4  [0.7860696517412936, 0.5317647058823529, 0.496...      [100]           0.5   \n",
       "0  [0.7805096110862763, 0.5263157894736842, 0.469...      [100]           0.5   \n",
       "1  [0.787987449574182, 0.5595375722543353, 0.5043...      [100]           0.5   \n",
       "2  [0.7852112676056338, 0.5215123859191656, 0.483...      [100]           0.5   \n",
       "3  [0.7844178840194777, 0.5295566502463055, 0.428...      [100]           0.5   \n",
       "4  [0.7839422643211545, 0.5229681978798587, 0.493...      [100]           0.5   \n",
       "0  [0.7846291331546024, 0.5217391304347826, 0.459...      [100]           0.5   \n",
       "1  [0.7903657448706513, 0.5452436194895592, 0.513...      [100]           0.5   \n",
       "2  [0.7868131868131868, 0.5225464190981433, 0.470...      [100]           0.5   \n",
       "3  [0.7856191744340878, 0.5478468899521529, 0.436...      [100]           0.5   \n",
       "4  [0.7879061371841155, 0.5411764705882353, 0.502...      [100]           0.5   \n",
       "0  [0.7828828828828828, 0.5386473429951691, 0.468...      [100]           0.5   \n",
       "1  [0.7924865831842576, 0.5567010309278351, 0.492...      [100]           0.5   \n",
       "2  [0.791083916083916, 0.5295629820051414, 0.4732...      [100]           0.5   \n",
       "3  [0.7845057880676759, 0.5532934131736528, 0.445...      [100]           0.5   \n",
       "4  [0.7814207650273224, 0.519208381839348, 0.4989...      [100]           0.5   \n",
       "\n",
       "   learning_rate  seed  gamma  k_fold  \n",
       "0         0.0001     0      2    True  \n",
       "1         0.0001     0      2    True  \n",
       "2         0.0001     0      2    True  \n",
       "3         0.0001     0      2    True  \n",
       "4         0.0001     0      2    True  \n",
       "0         0.0001     1      2    True  \n",
       "1         0.0001     1      2    True  \n",
       "2         0.0001     1      2    True  \n",
       "3         0.0001     1      2    True  \n",
       "4         0.0001     1      2    True  \n",
       "0         0.0001    12      2    True  \n",
       "1         0.0001    12      2    True  \n",
       "2         0.0001    12      2    True  \n",
       "3         0.0001    12      2    True  \n",
       "4         0.0001    12      2    True  \n",
       "0         0.0001   123      2    True  \n",
       "1         0.0001   123      2    True  \n",
       "2         0.0001   123      2    True  \n",
       "3         0.0001   123      2    True  \n",
       "4         0.0001   123      2    True  \n",
       "0         0.0001  1234      2    True  \n",
       "1         0.0001  1234      2    True  \n",
       "2         0.0001  1234      2    True  \n",
       "3         0.0001  1234      2    True  \n",
       "4         0.0001  1234      2    True  "
      ]
     },
     "execution_count": 45,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "best_ffn_current_kfold"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "id": "55b152d0",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.5924049773807214"
      ]
     },
     "execution_count": 46,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "best_ffn_current_kfold[\"f1\"].mean()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 67,
   "id": "a88880a8",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([0.78498169, 0.52167665, 0.47055659])"
      ]
     },
     "execution_count": 67,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "np.stack(best_ffn_current_kfold[\"f1_scores\"]).mean(axis=0)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "id": "8ad7a7e7",
   "metadata": {},
   "source": [
    "# Baseline: Averaging history and use FFN\n",
    "\n",
    "Here, we will use `nlpsig` to construct some paths of embeddings for the last $k$ utterances which we will average and use those in a FFN. We will also concatenate the current utterance embedding to the FFN input - all of this is done in the `obtain_mean_history` function in `nlpsig-networks.scripts.ffn_baseline_functions` which we imported earlier on.\n",
    "\n",
    "Here, we will run the hyperparameter search to implement the FFN with the same parameters as above. For this baseline, we can also see how well the model performance is affected by the size of the history window $k$."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "a335acd9",
   "metadata": {},
   "outputs": [],
   "source": [
    "window_sizes = [5, 10, 20, 50]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "beab5369",
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "93572fe3a848478d9cce757a230c0a57",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/4 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[INFO] Concatenating the embeddings to the dataframe...\n",
      "[INFO] - columns beginning with 'e' denote the full embddings.\n",
      "[INFO] Adding time feature columns into dataframe in `.df`.\n",
      "[INFO] Adding 'time_encoding' and feature...\n",
      "[INFO] Adding 'time_diff' and feature...\n",
      "[INFO] Adding 'timeline_index' feature...\n",
      "[INFO] Padding ids and storing in `.df_padded` and `.array_padded` attributes.\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "d026bbddd3d24deda5dccd416bd9d16c",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/13551 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "c1642556fdb740c5812020dd42eb0c5c",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/3 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "90ebe58ea3714be0be30ea7f0f91cc05",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/3 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "20b566b08d59492eafda90a83532d2eb",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/5 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "d31b795984644907b5129341e2a5dba5",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/5 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "4bb34c3e751a4dcb9495ca5f1e94e169",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/5 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "13d1adbafb5c4c31bef56ae2a9fb85e7",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/3 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "293d9aa2846b471cb84fe5b4ab918e39",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/5 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "51b82618655d457591a4f1b8dfea7eec",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/5 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "becae07aba4d4b03bfc70b7b03f79076",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/5 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "eb9fbab62e65406093f3bfbe2dc9e0d1",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/3 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "0229334b5a1641ec8d3c21f705d784ef",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/5 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "6f3e49a19ec34af7b4e02dc7cfeb0028",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/5 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "370e4497ebb940b786723984e95b1610",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/5 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[INFO] Concatenating the embeddings to the dataframe...\n",
      "[INFO] - columns beginning with 'e' denote the full embddings.\n",
      "[INFO] Adding time feature columns into dataframe in `.df`.\n",
      "[INFO] Adding 'time_encoding' and feature...\n",
      "[INFO] Adding 'time_diff' and feature...\n",
      "[INFO] Adding 'timeline_index' feature...\n",
      "[INFO] Padding ids and storing in `.df_padded` and `.array_padded` attributes.\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "7a0f98222ffe42c1b245b2f5e69b0f4a",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/13551 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "ce719df9f6e84ae2aa2f32cec2fef5ad",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/3 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "e353d4a0c5ad4929af9b1c6476fea859",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/3 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "49a1684e817e4b119e0c8c381d1b474f",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/5 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "a48647eda8a4487dbcbc7c86d02a1a6b",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/5 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "759d3c6f84564bb58f2796a25e98a3da",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/5 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "e76d5862cc204f2b9d6d47fc6da6cc2a",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/3 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "8574c01f17664fe4b233ddf6d8216f49",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/5 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "a73b8c7cc1a24edeb36799b9561afa35",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/5 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "c2c7125ab8364e20bc8a1045b647b999",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/5 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "19fa2361868f423f85571abd6775f7cc",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/3 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "676714fdcdb240ba9bc3f56955c4e8ac",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/5 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "4d49f67747ee41418f091534e4303fb3",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/5 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "bcc2c3f7d5944e4997022b3c1dd1a0fb",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/5 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[INFO] Concatenating the embeddings to the dataframe...\n",
      "[INFO] - columns beginning with 'e' denote the full embddings.\n",
      "[INFO] Adding time feature columns into dataframe in `.df`.\n",
      "[INFO] Adding 'time_encoding' and feature...\n",
      "[INFO] Adding 'time_diff' and feature...\n",
      "[INFO] Adding 'timeline_index' feature...\n",
      "[INFO] Padding ids and storing in `.df_padded` and `.array_padded` attributes.\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "5ca832fbe68c4be7a5c01a82c14a1fb1",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/13551 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "952fbdd7dede4fdf96d55abebf5c6ee9",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/3 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "266984e99338467d81ab4bb2a3f40169",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/3 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "bfdd76fa69ec4d779fe4f711fe6441df",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/5 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "6bb6d399739b42ee8cbfe6e971eb6355",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/5 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "bd68c90a4ad3484c9a2165b5de9ed290",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/5 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "501737e657cd4685a6621e2bad5b306b",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/3 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "52f8d623061f494e84a8ceafb061a7d9",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/5 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "edb0ca584b3143cba2bde6947668a9d4",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/5 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "2d506197c34446539a74b05e2d5e8716",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/5 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "44b28f3091a149afa8f5e57004cbceed",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/3 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "77732b822149466daa1a1e8b600407e5",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/5 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "6b9438ab26fa458e83fcd0d078c522c2",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/5 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "711277db3a0844f6a374e36382129ac4",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/5 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[INFO] Concatenating the embeddings to the dataframe...\n",
      "[INFO] - columns beginning with 'e' denote the full embddings.\n",
      "[INFO] Adding time feature columns into dataframe in `.df`.\n",
      "[INFO] Adding 'time_encoding' and feature...\n",
      "[INFO] Adding 'time_diff' and feature...\n",
      "[INFO] Adding 'timeline_index' feature...\n",
      "[INFO] Padding ids and storing in `.df_padded` and `.array_padded` attributes.\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "59d7177d23d54c19afffcf0cf75cd672",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/13551 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "2bb3c7ac3f29425c9874054eae7cc3fe",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/3 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "02b488d98df94fa5a6c07ef04f89f731",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/3 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "e5305a28806040c49b82c9f7e7b6497e",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/5 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "8e26c0489e70437cb3772d83cd8f6401",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/5 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "b029e6019cc143b091cf56d6ae4dc00d",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/5 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "c9655d298ba347a9940809531f82d0b6",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/3 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "571e629e495d4153932c71e534c1e87f",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/5 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "c47571c819ec4438ad4be95442e00b79",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/5 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "e550110b08084e318e58e22d175470d5",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/5 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "cef864b45e164908a1e55020e66a8be1",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/3 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "74d9eee741c64039a9d5a41affd72dc1",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/5 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "6f8d6ee1a40048e2870a23418afaa102",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/5 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "71d2f14a3b15426d87330d2eed17bd22",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/5 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[INFO] Concatenating the embeddings to the dataframe...\n",
      "[INFO] - columns beginning with 'e' denote the full embddings.\n",
      "[INFO] Adding time feature columns into dataframe in `.df`.\n",
      "[INFO] Adding 'time_encoding' and feature...\n",
      "[INFO] Adding 'time_diff' and feature...\n",
      "[INFO] Adding 'timeline_index' feature...\n",
      "[INFO] Padding ids and storing in `.df_padded` and `.array_padded` attributes.\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "3a51858ba88849c4b158c87e5014a1bd",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/13551 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "saving results dataframe to CSV for this hyperparameter search in client_talk_type/ffn_mean_history_focal_2.csv\n",
      "saving the best model results dataframe to CSV for this hyperparameter search in client_talk_type/ffn_mean_history_focal_2_best_model.csv\n"
     ]
    }
   ],
   "source": [
    "ffn_mean_history, best_ffn_mean_history, _, __ = histories_baseline_hyperparameter_search(\n",
    "    num_epochs=num_epochs,\n",
    "    df=anno_mi,\n",
    "    id_column=\"transcript_id\",\n",
    "    label_column=\"client_talk_type\",\n",
    "    embeddings=sbert_embeddings,\n",
    "    y_data=y_data,\n",
    "    output_dim=output_dim,\n",
    "    window_sizes=window_sizes,\n",
    "    hidden_dim_sizes=hidden_dim_sizes,\n",
    "    dropout_rates=dropout_rates,\n",
    "    learning_rates=learning_rates,\n",
    "    use_signatures=False,\n",
    "    seeds=seeds,\n",
    "    loss=loss,\n",
    "    gamma=gamma,\n",
    "    path_indices=client_index,\n",
    "    k_fold=False,\n",
    "    validation_metric=validation_metric,\n",
    "    results_output=f\"{output_dir}/ffn_mean_history_focal_{gamma}.csv\",\n",
    "    verbose=False\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "id": "47345579",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>loss</th>\n",
       "      <th>accuracy</th>\n",
       "      <th>f1</th>\n",
       "      <th>f1_scores</th>\n",
       "      <th>valid_loss</th>\n",
       "      <th>valid_accuracy</th>\n",
       "      <th>valid_f1</th>\n",
       "      <th>valid_f1_scores</th>\n",
       "      <th>hidden_dim</th>\n",
       "      <th>dropout_rate</th>\n",
       "      <th>learning_rate</th>\n",
       "      <th>seed</th>\n",
       "      <th>gamma</th>\n",
       "      <th>k_fold</th>\n",
       "      <th>model_id</th>\n",
       "      <th>k</th>\n",
       "      <th>input_dim</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>focal</td>\n",
       "      <td>0.713011</td>\n",
       "      <td>0.614313</td>\n",
       "      <td>[0.8114157806379407, 0.5272727272727272, 0.504...</td>\n",
       "      <td>0.697381</td>\n",
       "      <td>0.725836</td>\n",
       "      <td>0.625205</td>\n",
       "      <td>[0.818368745716244, 0.5365853658536585, 0.5206...</td>\n",
       "      <td>[100]</td>\n",
       "      <td>0.5</td>\n",
       "      <td>0.00500</td>\n",
       "      <td>0</td>\n",
       "      <td>2</td>\n",
       "      <td>False</td>\n",
       "      <td>0.00</td>\n",
       "      <td>5</td>\n",
       "      <td>766</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>focal</td>\n",
       "      <td>0.710037</td>\n",
       "      <td>0.620470</td>\n",
       "      <td>[0.8068181818181818, 0.5251798561151079, 0.529...</td>\n",
       "      <td>0.502735</td>\n",
       "      <td>0.717472</td>\n",
       "      <td>0.611772</td>\n",
       "      <td>[0.8177408177408177, 0.5253863134657837, 0.492...</td>\n",
       "      <td>[100]</td>\n",
       "      <td>0.5</td>\n",
       "      <td>0.00500</td>\n",
       "      <td>1</td>\n",
       "      <td>2</td>\n",
       "      <td>False</td>\n",
       "      <td>0.00</td>\n",
       "      <td>5</td>\n",
       "      <td>766</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>focal</td>\n",
       "      <td>0.667658</td>\n",
       "      <td>0.595767</td>\n",
       "      <td>[0.7693259121830551, 0.5345622119815667, 0.483...</td>\n",
       "      <td>0.602109</td>\n",
       "      <td>0.700743</td>\n",
       "      <td>0.621087</td>\n",
       "      <td>[0.7975921745673438, 0.5708955223880597, 0.494...</td>\n",
       "      <td>[100]</td>\n",
       "      <td>0.5</td>\n",
       "      <td>0.00500</td>\n",
       "      <td>12</td>\n",
       "      <td>2</td>\n",
       "      <td>False</td>\n",
       "      <td>0.00</td>\n",
       "      <td>5</td>\n",
       "      <td>766</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>focal</td>\n",
       "      <td>0.697398</td>\n",
       "      <td>0.627495</td>\n",
       "      <td>[0.7888161808447353, 0.538961038961039, 0.5547...</td>\n",
       "      <td>0.534903</td>\n",
       "      <td>0.716543</td>\n",
       "      <td>0.626636</td>\n",
       "      <td>[0.812545587162655, 0.5786407766990291, 0.4887...</td>\n",
       "      <td>[100]</td>\n",
       "      <td>0.5</td>\n",
       "      <td>0.00500</td>\n",
       "      <td>123</td>\n",
       "      <td>2</td>\n",
       "      <td>False</td>\n",
       "      <td>0.00</td>\n",
       "      <td>5</td>\n",
       "      <td>766</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>focal</td>\n",
       "      <td>0.709294</td>\n",
       "      <td>0.610480</td>\n",
       "      <td>[0.8129251700680273, 0.5212765957446809, 0.497...</td>\n",
       "      <td>0.517703</td>\n",
       "      <td>0.731413</td>\n",
       "      <td>0.629395</td>\n",
       "      <td>[0.8272033310201249, 0.552915766738661, 0.5080...</td>\n",
       "      <td>[100]</td>\n",
       "      <td>0.5</td>\n",
       "      <td>0.00500</td>\n",
       "      <td>1234</td>\n",
       "      <td>2</td>\n",
       "      <td>False</td>\n",
       "      <td>0.00</td>\n",
       "      <td>5</td>\n",
       "      <td>766</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>focal</td>\n",
       "      <td>0.617100</td>\n",
       "      <td>0.265933</td>\n",
       "      <td>[0.7633163501621121, 0.03448275862068966, 0.0]</td>\n",
       "      <td>0.756498</td>\n",
       "      <td>0.640335</td>\n",
       "      <td>0.267512</td>\n",
       "      <td>[0.7808764940239044, 0.021660649819494584, 0.0]</td>\n",
       "      <td>[100, 100, 100]</td>\n",
       "      <td>0.1</td>\n",
       "      <td>0.00001</td>\n",
       "      <td>0</td>\n",
       "      <td>2</td>\n",
       "      <td>False</td>\n",
       "      <td>3.44</td>\n",
       "      <td>50</td>\n",
       "      <td>766</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>focal</td>\n",
       "      <td>0.667658</td>\n",
       "      <td>0.566020</td>\n",
       "      <td>[0.7959905660377359, 0.43717728055077454, 0.46...</td>\n",
       "      <td>0.560264</td>\n",
       "      <td>0.693309</td>\n",
       "      <td>0.585954</td>\n",
       "      <td>[0.8141720896601591, 0.48945147679324896, 0.45...</td>\n",
       "      <td>[100, 100, 100]</td>\n",
       "      <td>0.1</td>\n",
       "      <td>0.00001</td>\n",
       "      <td>1</td>\n",
       "      <td>2</td>\n",
       "      <td>False</td>\n",
       "      <td>3.44</td>\n",
       "      <td>50</td>\n",
       "      <td>766</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>focal</td>\n",
       "      <td>0.617100</td>\n",
       "      <td>0.254406</td>\n",
       "      <td>[0.7632183908045977, 0.0, 0.0]</td>\n",
       "      <td>0.788310</td>\n",
       "      <td>0.639405</td>\n",
       "      <td>0.260163</td>\n",
       "      <td>[0.7804878048780487, 0.0, 0.0]</td>\n",
       "      <td>[100, 100, 100]</td>\n",
       "      <td>0.1</td>\n",
       "      <td>0.00001</td>\n",
       "      <td>12</td>\n",
       "      <td>2</td>\n",
       "      <td>False</td>\n",
       "      <td>3.44</td>\n",
       "      <td>50</td>\n",
       "      <td>766</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>focal</td>\n",
       "      <td>0.683271</td>\n",
       "      <td>0.577781</td>\n",
       "      <td>[0.801648028251913, 0.5021645021645021, 0.4295...</td>\n",
       "      <td>0.594105</td>\n",
       "      <td>0.697955</td>\n",
       "      <td>0.576923</td>\n",
       "      <td>[0.8155619596541788, 0.51520572450805, 0.4]</td>\n",
       "      <td>[100, 100, 100]</td>\n",
       "      <td>0.1</td>\n",
       "      <td>0.00001</td>\n",
       "      <td>123</td>\n",
       "      <td>2</td>\n",
       "      <td>False</td>\n",
       "      <td>3.44</td>\n",
       "      <td>50</td>\n",
       "      <td>766</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>focal</td>\n",
       "      <td>0.679554</td>\n",
       "      <td>0.576449</td>\n",
       "      <td>[0.8037383177570093, 0.4600000000000001, 0.465...</td>\n",
       "      <td>0.567068</td>\n",
       "      <td>0.705390</td>\n",
       "      <td>0.593548</td>\n",
       "      <td>[0.8220946915351506, 0.5149700598802396, 0.443...</td>\n",
       "      <td>[100, 100, 100]</td>\n",
       "      <td>0.1</td>\n",
       "      <td>0.00001</td>\n",
       "      <td>1234</td>\n",
       "      <td>2</td>\n",
       "      <td>False</td>\n",
       "      <td>3.44</td>\n",
       "      <td>50</td>\n",
       "      <td>766</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>900 rows × 17 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "     loss  accuracy        f1  \\\n",
       "0   focal  0.713011  0.614313   \n",
       "0   focal  0.710037  0.620470   \n",
       "0   focal  0.667658  0.595767   \n",
       "0   focal  0.697398  0.627495   \n",
       "0   focal  0.709294  0.610480   \n",
       "..    ...       ...       ...   \n",
       "0   focal  0.617100  0.265933   \n",
       "0   focal  0.667658  0.566020   \n",
       "0   focal  0.617100  0.254406   \n",
       "0   focal  0.683271  0.577781   \n",
       "0   focal  0.679554  0.576449   \n",
       "\n",
       "                                            f1_scores  valid_loss  \\\n",
       "0   [0.8114157806379407, 0.5272727272727272, 0.504...    0.697381   \n",
       "0   [0.8068181818181818, 0.5251798561151079, 0.529...    0.502735   \n",
       "0   [0.7693259121830551, 0.5345622119815667, 0.483...    0.602109   \n",
       "0   [0.7888161808447353, 0.538961038961039, 0.5547...    0.534903   \n",
       "0   [0.8129251700680273, 0.5212765957446809, 0.497...    0.517703   \n",
       "..                                                ...         ...   \n",
       "0      [0.7633163501621121, 0.03448275862068966, 0.0]    0.756498   \n",
       "0   [0.7959905660377359, 0.43717728055077454, 0.46...    0.560264   \n",
       "0                      [0.7632183908045977, 0.0, 0.0]    0.788310   \n",
       "0   [0.801648028251913, 0.5021645021645021, 0.4295...    0.594105   \n",
       "0   [0.8037383177570093, 0.4600000000000001, 0.465...    0.567068   \n",
       "\n",
       "    valid_accuracy  valid_f1  \\\n",
       "0         0.725836  0.625205   \n",
       "0         0.717472  0.611772   \n",
       "0         0.700743  0.621087   \n",
       "0         0.716543  0.626636   \n",
       "0         0.731413  0.629395   \n",
       "..             ...       ...   \n",
       "0         0.640335  0.267512   \n",
       "0         0.693309  0.585954   \n",
       "0         0.639405  0.260163   \n",
       "0         0.697955  0.576923   \n",
       "0         0.705390  0.593548   \n",
       "\n",
       "                                      valid_f1_scores       hidden_dim  \\\n",
       "0   [0.818368745716244, 0.5365853658536585, 0.5206...            [100]   \n",
       "0   [0.8177408177408177, 0.5253863134657837, 0.492...            [100]   \n",
       "0   [0.7975921745673438, 0.5708955223880597, 0.494...            [100]   \n",
       "0   [0.812545587162655, 0.5786407766990291, 0.4887...            [100]   \n",
       "0   [0.8272033310201249, 0.552915766738661, 0.5080...            [100]   \n",
       "..                                                ...              ...   \n",
       "0     [0.7808764940239044, 0.021660649819494584, 0.0]  [100, 100, 100]   \n",
       "0   [0.8141720896601591, 0.48945147679324896, 0.45...  [100, 100, 100]   \n",
       "0                      [0.7804878048780487, 0.0, 0.0]  [100, 100, 100]   \n",
       "0         [0.8155619596541788, 0.51520572450805, 0.4]  [100, 100, 100]   \n",
       "0   [0.8220946915351506, 0.5149700598802396, 0.443...  [100, 100, 100]   \n",
       "\n",
       "    dropout_rate  learning_rate  seed  gamma  k_fold  model_id   k  input_dim  \n",
       "0            0.5        0.00500     0      2   False      0.00   5        766  \n",
       "0            0.5        0.00500     1      2   False      0.00   5        766  \n",
       "0            0.5        0.00500    12      2   False      0.00   5        766  \n",
       "0            0.5        0.00500   123      2   False      0.00   5        766  \n",
       "0            0.5        0.00500  1234      2   False      0.00   5        766  \n",
       "..           ...            ...   ...    ...     ...       ...  ..        ...  \n",
       "0            0.1        0.00001     0      2   False      3.44  50        766  \n",
       "0            0.1        0.00001     1      2   False      3.44  50        766  \n",
       "0            0.1        0.00001    12      2   False      3.44  50        766  \n",
       "0            0.1        0.00001   123      2   False      3.44  50        766  \n",
       "0            0.1        0.00001  1234      2   False      3.44  50        766  \n",
       "\n",
       "[900 rows x 17 columns]"
      ]
     },
     "execution_count": 29,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "ffn_mean_history"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "id": "238f9f59",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>loss</th>\n",
       "      <th>accuracy</th>\n",
       "      <th>f1</th>\n",
       "      <th>f1_scores</th>\n",
       "      <th>valid_loss</th>\n",
       "      <th>valid_accuracy</th>\n",
       "      <th>valid_f1</th>\n",
       "      <th>valid_f1_scores</th>\n",
       "      <th>hidden_dim</th>\n",
       "      <th>dropout_rate</th>\n",
       "      <th>learning_rate</th>\n",
       "      <th>seed</th>\n",
       "      <th>gamma</th>\n",
       "      <th>k_fold</th>\n",
       "      <th>k</th>\n",
       "      <th>input_dim</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>focal</td>\n",
       "      <td>0.707807</td>\n",
       "      <td>0.631739</td>\n",
       "      <td>[0.798329355608592, 0.5847589424572317, 0.5121...</td>\n",
       "      <td>0.718380</td>\n",
       "      <td>0.736989</td>\n",
       "      <td>0.648432</td>\n",
       "      <td>[0.8244719592134013, 0.6247619047619047, 0.496...</td>\n",
       "      <td>[100]</td>\n",
       "      <td>0.5</td>\n",
       "      <td>0.001</td>\n",
       "      <td>0</td>\n",
       "      <td>2</td>\n",
       "      <td>False</td>\n",
       "      <td>50</td>\n",
       "      <td>766</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>focal</td>\n",
       "      <td>0.708550</td>\n",
       "      <td>0.635621</td>\n",
       "      <td>[0.8004807692307692, 0.5795275590551181, 0.526...</td>\n",
       "      <td>0.549926</td>\n",
       "      <td>0.732342</td>\n",
       "      <td>0.639982</td>\n",
       "      <td>[0.8253968253968255, 0.5984251968503937, 0.496...</td>\n",
       "      <td>[100]</td>\n",
       "      <td>0.5</td>\n",
       "      <td>0.001</td>\n",
       "      <td>1</td>\n",
       "      <td>2</td>\n",
       "      <td>False</td>\n",
       "      <td>50</td>\n",
       "      <td>766</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>focal</td>\n",
       "      <td>0.709294</td>\n",
       "      <td>0.633258</td>\n",
       "      <td>[0.7988269794721409, 0.5654281098546042, 0.535...</td>\n",
       "      <td>0.615128</td>\n",
       "      <td>0.732342</td>\n",
       "      <td>0.644632</td>\n",
       "      <td>[0.8202166064981948, 0.6078431372549019, 0.505...</td>\n",
       "      <td>[100]</td>\n",
       "      <td>0.5</td>\n",
       "      <td>0.001</td>\n",
       "      <td>12</td>\n",
       "      <td>2</td>\n",
       "      <td>False</td>\n",
       "      <td>50</td>\n",
       "      <td>766</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>focal</td>\n",
       "      <td>0.710037</td>\n",
       "      <td>0.632813</td>\n",
       "      <td>[0.8046783625730994, 0.5382059800664452, 0.555...</td>\n",
       "      <td>0.541037</td>\n",
       "      <td>0.736989</td>\n",
       "      <td>0.641692</td>\n",
       "      <td>[0.8297567954220315, 0.6012024048096193, 0.494...</td>\n",
       "      <td>[100]</td>\n",
       "      <td>0.5</td>\n",
       "      <td>0.001</td>\n",
       "      <td>123</td>\n",
       "      <td>2</td>\n",
       "      <td>False</td>\n",
       "      <td>50</td>\n",
       "      <td>766</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>focal</td>\n",
       "      <td>0.699628</td>\n",
       "      <td>0.631056</td>\n",
       "      <td>[0.7921760391198045, 0.5714285714285714, 0.529...</td>\n",
       "      <td>0.556330</td>\n",
       "      <td>0.719331</td>\n",
       "      <td>0.640200</td>\n",
       "      <td>[0.8095952023988006, 0.6074074074074074, 0.503...</td>\n",
       "      <td>[100]</td>\n",
       "      <td>0.5</td>\n",
       "      <td>0.001</td>\n",
       "      <td>1234</td>\n",
       "      <td>2</td>\n",
       "      <td>False</td>\n",
       "      <td>50</td>\n",
       "      <td>766</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "    loss  accuracy        f1  \\\n",
       "0  focal  0.707807  0.631739   \n",
       "0  focal  0.708550  0.635621   \n",
       "0  focal  0.709294  0.633258   \n",
       "0  focal  0.710037  0.632813   \n",
       "0  focal  0.699628  0.631056   \n",
       "\n",
       "                                           f1_scores  valid_loss  \\\n",
       "0  [0.798329355608592, 0.5847589424572317, 0.5121...    0.718380   \n",
       "0  [0.8004807692307692, 0.5795275590551181, 0.526...    0.549926   \n",
       "0  [0.7988269794721409, 0.5654281098546042, 0.535...    0.615128   \n",
       "0  [0.8046783625730994, 0.5382059800664452, 0.555...    0.541037   \n",
       "0  [0.7921760391198045, 0.5714285714285714, 0.529...    0.556330   \n",
       "\n",
       "   valid_accuracy  valid_f1  \\\n",
       "0        0.736989  0.648432   \n",
       "0        0.732342  0.639982   \n",
       "0        0.732342  0.644632   \n",
       "0        0.736989  0.641692   \n",
       "0        0.719331  0.640200   \n",
       "\n",
       "                                     valid_f1_scores hidden_dim  dropout_rate  \\\n",
       "0  [0.8244719592134013, 0.6247619047619047, 0.496...      [100]           0.5   \n",
       "0  [0.8253968253968255, 0.5984251968503937, 0.496...      [100]           0.5   \n",
       "0  [0.8202166064981948, 0.6078431372549019, 0.505...      [100]           0.5   \n",
       "0  [0.8297567954220315, 0.6012024048096193, 0.494...      [100]           0.5   \n",
       "0  [0.8095952023988006, 0.6074074074074074, 0.503...      [100]           0.5   \n",
       "\n",
       "   learning_rate  seed  gamma  k_fold   k  input_dim  \n",
       "0          0.001     0      2   False  50        766  \n",
       "0          0.001     1      2   False  50        766  \n",
       "0          0.001    12      2   False  50        766  \n",
       "0          0.001   123      2   False  50        766  \n",
       "0          0.001  1234      2   False  50        766  "
      ]
     },
     "execution_count": 30,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "best_ffn_mean_history"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "id": "b858f4e0",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.6328974621408594"
      ]
     },
     "execution_count": 31,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "best_ffn_mean_history[\"f1\"].mean()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 69,
   "id": "2742581d",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([0.7988983 , 0.56786983, 0.53192425])"
      ]
     },
     "execution_count": 69,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "np.stack(best_ffn_mean_history[\"f1_scores\"]).mean(axis=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "id": "e6e53879",
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "dd1f09d62b7243299a474000a8fabc48",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/4 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[INFO] Concatenating the embeddings to the dataframe...\n",
      "[INFO] - columns beginning with 'e' denote the full embddings.\n",
      "[INFO] Adding time feature columns into dataframe in `.df`.\n",
      "[INFO] Adding 'time_encoding' and feature...\n",
      "[INFO] Adding 'time_diff' and feature...\n",
      "[INFO] Adding 'timeline_index' feature...\n",
      "[INFO] Padding ids and storing in `.df_padded` and `.array_padded` attributes.\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "b10cac71e3b64b42b1657d31ec0edeb4",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/13551 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "e77e756ad70442d5bb9903cf3161b98a",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/3 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "da36ee431e8743f3b9cac122d050f7ea",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/3 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "5ea889817efc47aba8f620c6cbe8fb06",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/5 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "c198838dcb2e4495b0068bb834889f16",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/5 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "2c11d0161f454bca9eb441c59d9e6ffc",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/5 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "c8ffa086f1a14c69856367fe06b73243",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/3 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "7b86dbec2c64466281a39d9f235e6cbd",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/5 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "d75ed1ac76634ea9a16f0cd3aa120021",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/5 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "7f850e4559b64cb88cfb315e4ebc5de5",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/5 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "b200b90e3b2f40738dd92c412aed0259",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/3 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "ee6e1832a545472c8dd80f71f73a1741",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/5 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "62394ea6bc0c4ad7af86dcf695e97f69",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/5 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "e2d62c2233e941fcaa4e20c2472e8049",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/5 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[INFO] Concatenating the embeddings to the dataframe...\n",
      "[INFO] - columns beginning with 'e' denote the full embddings.\n",
      "[INFO] Adding time feature columns into dataframe in `.df`.\n",
      "[INFO] Adding 'time_encoding' and feature...\n",
      "[INFO] Adding 'time_diff' and feature...\n",
      "[INFO] Adding 'timeline_index' feature...\n",
      "[INFO] Padding ids and storing in `.df_padded` and `.array_padded` attributes.\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "adfb80fec79f4e4abf9def4e11ea5e08",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/13551 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "9adc016c4d164881950f5c2514c69554",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/3 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "36ab184c9b0243e489af3ed905958cc6",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/3 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "68493a40d6264c1cbaa7391739936c2f",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/5 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "7263f9488f894bae86526f94737b23a1",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/5 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "97e65b7d240d4c169a72f168ec5cb351",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/5 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "42cae6782b6d4c41b400a4734f289260",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/3 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "eca0cee7fdf143ecb43ecd4eb228b46b",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/5 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "11c18f52d1504a16b134206e7cef41b6",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/5 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "9fd74f583eac42d09f5ba95cbf955fae",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/5 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "5ad16068acf8439497aee438ff598ae1",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/3 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "4ebbfbbc2bb04b2380664cf27f111e90",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/5 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "2dfe82a5a33f4be0ab496aff118acddb",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/5 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "d37956762a9c426c830574ade2f7e3dc",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/5 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[INFO] Concatenating the embeddings to the dataframe...\n",
      "[INFO] - columns beginning with 'e' denote the full embddings.\n",
      "[INFO] Adding time feature columns into dataframe in `.df`.\n",
      "[INFO] Adding 'time_encoding' and feature...\n",
      "[INFO] Adding 'time_diff' and feature...\n",
      "[INFO] Adding 'timeline_index' feature...\n",
      "[INFO] Padding ids and storing in `.df_padded` and `.array_padded` attributes.\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "ce92125130fe479e8408aa881f33563e",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/13551 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "9caabad4ba884ae78aa6661bb4ad6b7d",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/3 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "fefe7ae77bb549449c372373b5a35ad8",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/3 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "708a702469624f78af795eab637dd378",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/5 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "019cf8e3a1fc458e95cf515b4eda1af7",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/5 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "09872f0ba8544e3f9314048b7defc67f",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/5 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "e19b486573b340f5b4a7b817749ec9e5",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/3 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "03e61f9d4b0c40b6bf0d77963436216a",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/5 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "83b50278ddb948848f8aaec4ff68ab7e",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/5 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "98b4ff8860264d1b8b346e10700f1a64",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/5 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "79092dbd4fc647bbaae1d02b9a33c62d",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/3 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "b65ceef6b0b8487da027733c4bbd1ea6",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/5 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "b5dd2904147b40889b5a87cecc8d88a7",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/5 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "2063552c9e52445990097e7fbb0a636c",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/5 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[INFO] Concatenating the embeddings to the dataframe...\n",
      "[INFO] - columns beginning with 'e' denote the full embddings.\n",
      "[INFO] Adding time feature columns into dataframe in `.df`.\n",
      "[INFO] Adding 'time_encoding' and feature...\n",
      "[INFO] Adding 'time_diff' and feature...\n",
      "[INFO] Adding 'timeline_index' feature...\n",
      "[INFO] Padding ids and storing in `.df_padded` and `.array_padded` attributes.\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "13f98d347f6341539fd3153d1703086d",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/13551 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "9b19cae407de49648634fb0630a9d85e",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/3 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "b1a9e2b14a744b298e9aeff5758846ef",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/3 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "32c156520a9341d4bb08f6491dabd4f7",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/5 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "763840f5f327486198054fe7542ad51e",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/5 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "c1294fb3de154aab89eb16c490ac953d",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/5 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "ad1bcfe6f6b9400dae380cdca9027826",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/3 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "223efccd473e4610a896917ca8b6ae8f",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/5 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "4f941667110544f486661b7f1427bead",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/5 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "4d191cdb720f4bb7a7d4b987652b9267",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/5 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "d8cd7d0b9de84bb3af5ef6e08beb0661",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/3 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "37c122d6ef5d4b308775207ad3ede193",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/5 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "827d7c1b3bd4461bb87ff10df3004e05",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/5 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "890c89411f474fff813d6afff941a37c",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/5 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[INFO] Concatenating the embeddings to the dataframe...\n",
      "[INFO] - columns beginning with 'e' denote the full embddings.\n",
      "[INFO] Adding time feature columns into dataframe in `.df`.\n",
      "[INFO] Adding 'time_encoding' and feature...\n",
      "[INFO] Adding 'time_diff' and feature...\n",
      "[INFO] Adding 'timeline_index' feature...\n",
      "[INFO] Padding ids and storing in `.df_padded` and `.array_padded` attributes.\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "6fcf6c67ad6d497faf9dfc183cb3d801",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/13551 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "saving results dataframe to CSV for this hyperparameter search in client_talk_type/ffn_mean_history_focal_2_kfold.csv\n",
      "saving the best model results dataframe to CSV for this hyperparameter search in client_talk_type/ffn_mean_history_focal_2_kfold_best_model.csv\n"
     ]
    }
   ],
   "source": [
    "ffn_mean_history_kfold, best_ffn_mean_history_kfold, _, __ = histories_baseline_hyperparameter_search(\n",
    "    num_epochs=num_epochs,\n",
    "    df=anno_mi,\n",
    "    id_column=\"transcript_id\",\n",
    "    label_column=\"client_talk_type\",\n",
    "    embeddings=sbert_embeddings,\n",
    "    y_data=y_data,\n",
    "    output_dim=output_dim,\n",
    "    window_sizes=window_sizes,\n",
    "    hidden_dim_sizes=hidden_dim_sizes,\n",
    "    dropout_rates=dropout_rates,\n",
    "    learning_rates=learning_rates,\n",
    "    use_signatures=False,\n",
    "    seeds=seeds,\n",
    "    loss=loss,\n",
    "    gamma=gamma,\n",
    "    path_indices=client_index,\n",
    "    k_fold=True,\n",
    "    validation_metric=validation_metric,\n",
    "    results_output=f\"{output_dir}/ffn_mean_history_focal_{gamma}_kfold.csv\",\n",
    "    verbose=False\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "id": "191556f6",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>loss</th>\n",
       "      <th>accuracy</th>\n",
       "      <th>f1</th>\n",
       "      <th>f1_scores</th>\n",
       "      <th>valid_loss</th>\n",
       "      <th>valid_accuracy</th>\n",
       "      <th>valid_f1</th>\n",
       "      <th>valid_f1_scores</th>\n",
       "      <th>hidden_dim</th>\n",
       "      <th>dropout_rate</th>\n",
       "      <th>learning_rate</th>\n",
       "      <th>seed</th>\n",
       "      <th>gamma</th>\n",
       "      <th>k_fold</th>\n",
       "      <th>model_id</th>\n",
       "      <th>k</th>\n",
       "      <th>input_dim</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>focal</td>\n",
       "      <td>0.672862</td>\n",
       "      <td>0.601383</td>\n",
       "      <td>[0.7743119266055046, 0.5278276481149013, 0.502...</td>\n",
       "      <td>0.536458</td>\n",
       "      <td>0.664977</td>\n",
       "      <td>0.581384</td>\n",
       "      <td>[0.772706732941708, 0.4993141289437586, 0.4721...</td>\n",
       "      <td>[100]</td>\n",
       "      <td>0.5</td>\n",
       "      <td>0.00500</td>\n",
       "      <td>0</td>\n",
       "      <td>2</td>\n",
       "      <td>True</td>\n",
       "      <td>0.00</td>\n",
       "      <td>5</td>\n",
       "      <td>766</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>focal</td>\n",
       "      <td>0.689219</td>\n",
       "      <td>0.590228</td>\n",
       "      <td>[0.7997678467788741, 0.5151515151515151, 0.455...</td>\n",
       "      <td>0.528168</td>\n",
       "      <td>0.699887</td>\n",
       "      <td>0.612343</td>\n",
       "      <td>[0.7982456140350876, 0.5367088607594938, 0.502...</td>\n",
       "      <td>[100]</td>\n",
       "      <td>0.5</td>\n",
       "      <td>0.00500</td>\n",
       "      <td>0</td>\n",
       "      <td>2</td>\n",
       "      <td>True</td>\n",
       "      <td>0.00</td>\n",
       "      <td>5</td>\n",
       "      <td>766</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>focal</td>\n",
       "      <td>0.687732</td>\n",
       "      <td>0.565361</td>\n",
       "      <td>[0.791759465478842, 0.5346869712351945, 0.3696...</td>\n",
       "      <td>0.533283</td>\n",
       "      <td>0.695946</td>\n",
       "      <td>0.592782</td>\n",
       "      <td>[0.7955706984667802, 0.5286458333333333, 0.454...</td>\n",
       "      <td>[100]</td>\n",
       "      <td>0.5</td>\n",
       "      <td>0.00500</td>\n",
       "      <td>0</td>\n",
       "      <td>2</td>\n",
       "      <td>True</td>\n",
       "      <td>0.00</td>\n",
       "      <td>5</td>\n",
       "      <td>766</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>focal</td>\n",
       "      <td>0.687732</td>\n",
       "      <td>0.585681</td>\n",
       "      <td>[0.7934537246049661, 0.4970873786407767, 0.466...</td>\n",
       "      <td>0.567295</td>\n",
       "      <td>0.701577</td>\n",
       "      <td>0.594639</td>\n",
       "      <td>[0.8050739957716702, 0.5205091937765206, 0.458...</td>\n",
       "      <td>[100]</td>\n",
       "      <td>0.5</td>\n",
       "      <td>0.00500</td>\n",
       "      <td>0</td>\n",
       "      <td>2</td>\n",
       "      <td>True</td>\n",
       "      <td>0.00</td>\n",
       "      <td>5</td>\n",
       "      <td>766</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>focal</td>\n",
       "      <td>0.661710</td>\n",
       "      <td>0.585731</td>\n",
       "      <td>[0.7608173076923077, 0.5103011093502379, 0.486...</td>\n",
       "      <td>0.545385</td>\n",
       "      <td>0.689752</td>\n",
       "      <td>0.612503</td>\n",
       "      <td>[0.7840858292355833, 0.5374233128834355, 0.516]</td>\n",
       "      <td>[100]</td>\n",
       "      <td>0.5</td>\n",
       "      <td>0.00500</td>\n",
       "      <td>0</td>\n",
       "      <td>2</td>\n",
       "      <td>True</td>\n",
       "      <td>0.00</td>\n",
       "      <td>5</td>\n",
       "      <td>766</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>focal</td>\n",
       "      <td>0.678067</td>\n",
       "      <td>0.581589</td>\n",
       "      <td>[0.7988165680473372, 0.47694753577106525, 0.46...</td>\n",
       "      <td>0.603217</td>\n",
       "      <td>0.668919</td>\n",
       "      <td>0.557512</td>\n",
       "      <td>[0.7909854175872735, 0.48687350835322196, 0.39...</td>\n",
       "      <td>[100, 100, 100]</td>\n",
       "      <td>0.1</td>\n",
       "      <td>0.00001</td>\n",
       "      <td>1234</td>\n",
       "      <td>2</td>\n",
       "      <td>True</td>\n",
       "      <td>3.44</td>\n",
       "      <td>50</td>\n",
       "      <td>766</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>focal</td>\n",
       "      <td>0.673606</td>\n",
       "      <td>0.563899</td>\n",
       "      <td>[0.8027923211169284, 0.4462809917355372, 0.442...</td>\n",
       "      <td>0.598215</td>\n",
       "      <td>0.673423</td>\n",
       "      <td>0.574711</td>\n",
       "      <td>[0.7879592740150508, 0.4847058823529411, 0.451...</td>\n",
       "      <td>[100, 100, 100]</td>\n",
       "      <td>0.1</td>\n",
       "      <td>0.00001</td>\n",
       "      <td>1234</td>\n",
       "      <td>2</td>\n",
       "      <td>True</td>\n",
       "      <td>3.44</td>\n",
       "      <td>50</td>\n",
       "      <td>766</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>focal</td>\n",
       "      <td>0.642379</td>\n",
       "      <td>0.518177</td>\n",
       "      <td>[0.7772020725388602, 0.4147909967845659, 0.362...</td>\n",
       "      <td>0.603113</td>\n",
       "      <td>0.662162</td>\n",
       "      <td>0.542741</td>\n",
       "      <td>[0.7956427015250545, 0.42493638676844786, 0.40...</td>\n",
       "      <td>[100, 100, 100]</td>\n",
       "      <td>0.1</td>\n",
       "      <td>0.00001</td>\n",
       "      <td>1234</td>\n",
       "      <td>2</td>\n",
       "      <td>True</td>\n",
       "      <td>3.44</td>\n",
       "      <td>50</td>\n",
       "      <td>766</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>focal</td>\n",
       "      <td>0.640149</td>\n",
       "      <td>0.538257</td>\n",
       "      <td>[0.7726190476190476, 0.41627543035993736, 0.42...</td>\n",
       "      <td>0.621480</td>\n",
       "      <td>0.650338</td>\n",
       "      <td>0.533928</td>\n",
       "      <td>[0.7822222222222224, 0.4493597206053551, 0.370...</td>\n",
       "      <td>[100, 100, 100]</td>\n",
       "      <td>0.1</td>\n",
       "      <td>0.00001</td>\n",
       "      <td>1234</td>\n",
       "      <td>2</td>\n",
       "      <td>True</td>\n",
       "      <td>3.44</td>\n",
       "      <td>50</td>\n",
       "      <td>766</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>focal</td>\n",
       "      <td>0.659480</td>\n",
       "      <td>0.557107</td>\n",
       "      <td>[0.7857988165680473, 0.4554140127388535, 0.430...</td>\n",
       "      <td>0.610611</td>\n",
       "      <td>0.651464</td>\n",
       "      <td>0.545470</td>\n",
       "      <td>[0.7815684536996013, 0.41816009557945044, 0.43...</td>\n",
       "      <td>[100, 100, 100]</td>\n",
       "      <td>0.1</td>\n",
       "      <td>0.00001</td>\n",
       "      <td>1234</td>\n",
       "      <td>2</td>\n",
       "      <td>True</td>\n",
       "      <td>3.44</td>\n",
       "      <td>50</td>\n",
       "      <td>766</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>4500 rows × 17 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "     loss  accuracy        f1  \\\n",
       "0   focal  0.672862  0.601383   \n",
       "1   focal  0.689219  0.590228   \n",
       "2   focal  0.687732  0.565361   \n",
       "3   focal  0.687732  0.585681   \n",
       "4   focal  0.661710  0.585731   \n",
       "..    ...       ...       ...   \n",
       "0   focal  0.678067  0.581589   \n",
       "1   focal  0.673606  0.563899   \n",
       "2   focal  0.642379  0.518177   \n",
       "3   focal  0.640149  0.538257   \n",
       "4   focal  0.659480  0.557107   \n",
       "\n",
       "                                            f1_scores  valid_loss  \\\n",
       "0   [0.7743119266055046, 0.5278276481149013, 0.502...    0.536458   \n",
       "1   [0.7997678467788741, 0.5151515151515151, 0.455...    0.528168   \n",
       "2   [0.791759465478842, 0.5346869712351945, 0.3696...    0.533283   \n",
       "3   [0.7934537246049661, 0.4970873786407767, 0.466...    0.567295   \n",
       "4   [0.7608173076923077, 0.5103011093502379, 0.486...    0.545385   \n",
       "..                                                ...         ...   \n",
       "0   [0.7988165680473372, 0.47694753577106525, 0.46...    0.603217   \n",
       "1   [0.8027923211169284, 0.4462809917355372, 0.442...    0.598215   \n",
       "2   [0.7772020725388602, 0.4147909967845659, 0.362...    0.603113   \n",
       "3   [0.7726190476190476, 0.41627543035993736, 0.42...    0.621480   \n",
       "4   [0.7857988165680473, 0.4554140127388535, 0.430...    0.610611   \n",
       "\n",
       "    valid_accuracy  valid_f1  \\\n",
       "0         0.664977  0.581384   \n",
       "1         0.699887  0.612343   \n",
       "2         0.695946  0.592782   \n",
       "3         0.701577  0.594639   \n",
       "4         0.689752  0.612503   \n",
       "..             ...       ...   \n",
       "0         0.668919  0.557512   \n",
       "1         0.673423  0.574711   \n",
       "2         0.662162  0.542741   \n",
       "3         0.650338  0.533928   \n",
       "4         0.651464  0.545470   \n",
       "\n",
       "                                      valid_f1_scores       hidden_dim  \\\n",
       "0   [0.772706732941708, 0.4993141289437586, 0.4721...            [100]   \n",
       "1   [0.7982456140350876, 0.5367088607594938, 0.502...            [100]   \n",
       "2   [0.7955706984667802, 0.5286458333333333, 0.454...            [100]   \n",
       "3   [0.8050739957716702, 0.5205091937765206, 0.458...            [100]   \n",
       "4     [0.7840858292355833, 0.5374233128834355, 0.516]            [100]   \n",
       "..                                                ...              ...   \n",
       "0   [0.7909854175872735, 0.48687350835322196, 0.39...  [100, 100, 100]   \n",
       "1   [0.7879592740150508, 0.4847058823529411, 0.451...  [100, 100, 100]   \n",
       "2   [0.7956427015250545, 0.42493638676844786, 0.40...  [100, 100, 100]   \n",
       "3   [0.7822222222222224, 0.4493597206053551, 0.370...  [100, 100, 100]   \n",
       "4   [0.7815684536996013, 0.41816009557945044, 0.43...  [100, 100, 100]   \n",
       "\n",
       "    dropout_rate  learning_rate  seed  gamma  k_fold  model_id   k  input_dim  \n",
       "0            0.5        0.00500     0      2    True      0.00   5        766  \n",
       "1            0.5        0.00500     0      2    True      0.00   5        766  \n",
       "2            0.5        0.00500     0      2    True      0.00   5        766  \n",
       "3            0.5        0.00500     0      2    True      0.00   5        766  \n",
       "4            0.5        0.00500     0      2    True      0.00   5        766  \n",
       "..           ...            ...   ...    ...     ...       ...  ..        ...  \n",
       "0            0.1        0.00001  1234      2    True      3.44  50        766  \n",
       "1            0.1        0.00001  1234      2    True      3.44  50        766  \n",
       "2            0.1        0.00001  1234      2    True      3.44  50        766  \n",
       "3            0.1        0.00001  1234      2    True      3.44  50        766  \n",
       "4            0.1        0.00001  1234      2    True      3.44  50        766  \n",
       "\n",
       "[4500 rows x 17 columns]"
      ]
     },
     "execution_count": 33,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "ffn_mean_history_kfold"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "id": "58d0fd35",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>loss</th>\n",
       "      <th>accuracy</th>\n",
       "      <th>f1</th>\n",
       "      <th>f1_scores</th>\n",
       "      <th>valid_loss</th>\n",
       "      <th>valid_accuracy</th>\n",
       "      <th>valid_f1</th>\n",
       "      <th>valid_f1_scores</th>\n",
       "      <th>hidden_dim</th>\n",
       "      <th>dropout_rate</th>\n",
       "      <th>learning_rate</th>\n",
       "      <th>seed</th>\n",
       "      <th>gamma</th>\n",
       "      <th>k_fold</th>\n",
       "      <th>k</th>\n",
       "      <th>input_dim</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>focal</td>\n",
       "      <td>0.699628</td>\n",
       "      <td>0.629848</td>\n",
       "      <td>[0.7965998785670917, 0.5466034755134281, 0.546...</td>\n",
       "      <td>0.535128</td>\n",
       "      <td>0.685811</td>\n",
       "      <td>0.601814</td>\n",
       "      <td>[0.7854578096947935, 0.543030303030303, 0.4769...</td>\n",
       "      <td>[100]</td>\n",
       "      <td>0.5</td>\n",
       "      <td>0.0001</td>\n",
       "      <td>0</td>\n",
       "      <td>2</td>\n",
       "      <td>True</td>\n",
       "      <td>20</td>\n",
       "      <td>766</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>focal</td>\n",
       "      <td>0.681041</td>\n",
       "      <td>0.596610</td>\n",
       "      <td>[0.7869249394673123, 0.5405405405405405, 0.462...</td>\n",
       "      <td>0.507187</td>\n",
       "      <td>0.696509</td>\n",
       "      <td>0.624477</td>\n",
       "      <td>[0.7877401646843549, 0.5691609977324262, 0.516...</td>\n",
       "      <td>[100]</td>\n",
       "      <td>0.5</td>\n",
       "      <td>0.0001</td>\n",
       "      <td>0</td>\n",
       "      <td>2</td>\n",
       "      <td>True</td>\n",
       "      <td>20</td>\n",
       "      <td>766</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>focal</td>\n",
       "      <td>0.689219</td>\n",
       "      <td>0.591243</td>\n",
       "      <td>[0.789838337182448, 0.5564924114671164, 0.4273...</td>\n",
       "      <td>0.534393</td>\n",
       "      <td>0.692005</td>\n",
       "      <td>0.600451</td>\n",
       "      <td>[0.7948831054256728, 0.537966537966538, 0.4685...</td>\n",
       "      <td>[100]</td>\n",
       "      <td>0.5</td>\n",
       "      <td>0.0001</td>\n",
       "      <td>0</td>\n",
       "      <td>2</td>\n",
       "      <td>True</td>\n",
       "      <td>20</td>\n",
       "      <td>766</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>focal</td>\n",
       "      <td>0.680297</td>\n",
       "      <td>0.601317</td>\n",
       "      <td>[0.7790487658037327, 0.5457364341085271, 0.479...</td>\n",
       "      <td>0.557449</td>\n",
       "      <td>0.685248</td>\n",
       "      <td>0.597495</td>\n",
       "      <td>[0.7831541218637994, 0.5563380281690141, 0.452...</td>\n",
       "      <td>[100]</td>\n",
       "      <td>0.5</td>\n",
       "      <td>0.0001</td>\n",
       "      <td>0</td>\n",
       "      <td>2</td>\n",
       "      <td>True</td>\n",
       "      <td>20</td>\n",
       "      <td>766</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>focal</td>\n",
       "      <td>0.667658</td>\n",
       "      <td>0.600250</td>\n",
       "      <td>[0.7642770352369381, 0.5081723625557206, 0.528...</td>\n",
       "      <td>0.528262</td>\n",
       "      <td>0.681869</td>\n",
       "      <td>0.606892</td>\n",
       "      <td>[0.77910174152154, 0.5415730337078652, 0.5]</td>\n",
       "      <td>[100]</td>\n",
       "      <td>0.5</td>\n",
       "      <td>0.0001</td>\n",
       "      <td>0</td>\n",
       "      <td>2</td>\n",
       "      <td>True</td>\n",
       "      <td>20</td>\n",
       "      <td>766</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>focal</td>\n",
       "      <td>0.689219</td>\n",
       "      <td>0.615304</td>\n",
       "      <td>[0.7893462469733656, 0.5358851674641149, 0.520...</td>\n",
       "      <td>0.531559</td>\n",
       "      <td>0.680743</td>\n",
       "      <td>0.594290</td>\n",
       "      <td>[0.7827260458839406, 0.5410628019323671, 0.459...</td>\n",
       "      <td>[100]</td>\n",
       "      <td>0.5</td>\n",
       "      <td>0.0001</td>\n",
       "      <td>1</td>\n",
       "      <td>2</td>\n",
       "      <td>True</td>\n",
       "      <td>20</td>\n",
       "      <td>766</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>focal</td>\n",
       "      <td>0.680297</td>\n",
       "      <td>0.597075</td>\n",
       "      <td>[0.7845503922751961, 0.5407066052227342, 0.465...</td>\n",
       "      <td>0.509566</td>\n",
       "      <td>0.685811</td>\n",
       "      <td>0.613716</td>\n",
       "      <td>[0.7775239835541344, 0.5565819861431871, 0.507...</td>\n",
       "      <td>[100]</td>\n",
       "      <td>0.5</td>\n",
       "      <td>0.0001</td>\n",
       "      <td>1</td>\n",
       "      <td>2</td>\n",
       "      <td>True</td>\n",
       "      <td>20</td>\n",
       "      <td>766</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>focal</td>\n",
       "      <td>0.675836</td>\n",
       "      <td>0.578892</td>\n",
       "      <td>[0.7780373831775701, 0.5499181669394436, 0.408...</td>\n",
       "      <td>0.530567</td>\n",
       "      <td>0.685811</td>\n",
       "      <td>0.598425</td>\n",
       "      <td>[0.7876344086021505, 0.5445665445665446, 0.463...</td>\n",
       "      <td>[100]</td>\n",
       "      <td>0.5</td>\n",
       "      <td>0.0001</td>\n",
       "      <td>1</td>\n",
       "      <td>2</td>\n",
       "      <td>True</td>\n",
       "      <td>20</td>\n",
       "      <td>766</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>focal</td>\n",
       "      <td>0.684758</td>\n",
       "      <td>0.604041</td>\n",
       "      <td>[0.7838651414810355, 0.5588697017268446, 0.469...</td>\n",
       "      <td>0.553035</td>\n",
       "      <td>0.681306</td>\n",
       "      <td>0.594199</td>\n",
       "      <td>[0.7785778577857785, 0.5623529411764706, 0.441...</td>\n",
       "      <td>[100]</td>\n",
       "      <td>0.5</td>\n",
       "      <td>0.0001</td>\n",
       "      <td>1</td>\n",
       "      <td>2</td>\n",
       "      <td>True</td>\n",
       "      <td>20</td>\n",
       "      <td>766</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>focal</td>\n",
       "      <td>0.667658</td>\n",
       "      <td>0.601386</td>\n",
       "      <td>[0.7639060568603213, 0.5289747399702823, 0.511...</td>\n",
       "      <td>0.529611</td>\n",
       "      <td>0.674550</td>\n",
       "      <td>0.603511</td>\n",
       "      <td>[0.7723880597014926, 0.5430167597765363, 0.495...</td>\n",
       "      <td>[100]</td>\n",
       "      <td>0.5</td>\n",
       "      <td>0.0001</td>\n",
       "      <td>1</td>\n",
       "      <td>2</td>\n",
       "      <td>True</td>\n",
       "      <td>20</td>\n",
       "      <td>766</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>focal</td>\n",
       "      <td>0.692193</td>\n",
       "      <td>0.623333</td>\n",
       "      <td>[0.7906691221608348, 0.5463108320251177, 0.533...</td>\n",
       "      <td>0.539443</td>\n",
       "      <td>0.677365</td>\n",
       "      <td>0.596191</td>\n",
       "      <td>[0.7767166894042746, 0.5454545454545455, 0.466...</td>\n",
       "      <td>[100]</td>\n",
       "      <td>0.5</td>\n",
       "      <td>0.0001</td>\n",
       "      <td>12</td>\n",
       "      <td>2</td>\n",
       "      <td>True</td>\n",
       "      <td>20</td>\n",
       "      <td>766</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>focal</td>\n",
       "      <td>0.681041</td>\n",
       "      <td>0.591809</td>\n",
       "      <td>[0.7891891891891891, 0.541213063763608, 0.4450...</td>\n",
       "      <td>0.513420</td>\n",
       "      <td>0.690878</td>\n",
       "      <td>0.614730</td>\n",
       "      <td>[0.7868852459016394, 0.5532407407407407, 0.504...</td>\n",
       "      <td>[100]</td>\n",
       "      <td>0.5</td>\n",
       "      <td>0.0001</td>\n",
       "      <td>12</td>\n",
       "      <td>2</td>\n",
       "      <td>True</td>\n",
       "      <td>20</td>\n",
       "      <td>766</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>focal</td>\n",
       "      <td>0.689219</td>\n",
       "      <td>0.589982</td>\n",
       "      <td>[0.7906976744186046, 0.5635179153094464, 0.415...</td>\n",
       "      <td>0.536695</td>\n",
       "      <td>0.688063</td>\n",
       "      <td>0.598472</td>\n",
       "      <td>[0.7893569844789357, 0.5404732254047322, 0.465...</td>\n",
       "      <td>[100]</td>\n",
       "      <td>0.5</td>\n",
       "      <td>0.0001</td>\n",
       "      <td>12</td>\n",
       "      <td>2</td>\n",
       "      <td>True</td>\n",
       "      <td>20</td>\n",
       "      <td>766</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>focal</td>\n",
       "      <td>0.686245</td>\n",
       "      <td>0.607651</td>\n",
       "      <td>[0.7825044937088076, 0.558213716108453, 0.4822...</td>\n",
       "      <td>0.556622</td>\n",
       "      <td>0.683559</td>\n",
       "      <td>0.595503</td>\n",
       "      <td>[0.7824529991047449, 0.5569007263922517, 0.447...</td>\n",
       "      <td>[100]</td>\n",
       "      <td>0.5</td>\n",
       "      <td>0.0001</td>\n",
       "      <td>12</td>\n",
       "      <td>2</td>\n",
       "      <td>True</td>\n",
       "      <td>20</td>\n",
       "      <td>766</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>focal</td>\n",
       "      <td>0.663941</td>\n",
       "      <td>0.598446</td>\n",
       "      <td>[0.7590881084411583, 0.5222551928783382, 0.513...</td>\n",
       "      <td>0.530625</td>\n",
       "      <td>0.677928</td>\n",
       "      <td>0.604811</td>\n",
       "      <td>[0.7754158964879853, 0.5429864253393665, 0.496...</td>\n",
       "      <td>[100]</td>\n",
       "      <td>0.5</td>\n",
       "      <td>0.0001</td>\n",
       "      <td>12</td>\n",
       "      <td>2</td>\n",
       "      <td>True</td>\n",
       "      <td>20</td>\n",
       "      <td>766</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>focal</td>\n",
       "      <td>0.695167</td>\n",
       "      <td>0.626583</td>\n",
       "      <td>[0.7919463087248322, 0.5457463884430177, 0.542...</td>\n",
       "      <td>0.535143</td>\n",
       "      <td>0.681306</td>\n",
       "      <td>0.594024</td>\n",
       "      <td>[0.7854578096947935, 0.5326757090012331, 0.463...</td>\n",
       "      <td>[100]</td>\n",
       "      <td>0.5</td>\n",
       "      <td>0.0001</td>\n",
       "      <td>123</td>\n",
       "      <td>2</td>\n",
       "      <td>True</td>\n",
       "      <td>20</td>\n",
       "      <td>766</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>focal</td>\n",
       "      <td>0.684015</td>\n",
       "      <td>0.597483</td>\n",
       "      <td>[0.7903903903903905, 0.5392912172573191, 0.462...</td>\n",
       "      <td>0.506780</td>\n",
       "      <td>0.697635</td>\n",
       "      <td>0.623647</td>\n",
       "      <td>[0.7898320472083522, 0.5635103926096998, 0.517...</td>\n",
       "      <td>[100]</td>\n",
       "      <td>0.5</td>\n",
       "      <td>0.0001</td>\n",
       "      <td>123</td>\n",
       "      <td>2</td>\n",
       "      <td>True</td>\n",
       "      <td>20</td>\n",
       "      <td>766</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>focal</td>\n",
       "      <td>0.696654</td>\n",
       "      <td>0.601403</td>\n",
       "      <td>[0.794901506373117, 0.5709515859766277, 0.4383...</td>\n",
       "      <td>0.533215</td>\n",
       "      <td>0.695946</td>\n",
       "      <td>0.603888</td>\n",
       "      <td>[0.7985865724381626, 0.5494223363286265, 0.463...</td>\n",
       "      <td>[100]</td>\n",
       "      <td>0.5</td>\n",
       "      <td>0.0001</td>\n",
       "      <td>123</td>\n",
       "      <td>2</td>\n",
       "      <td>True</td>\n",
       "      <td>20</td>\n",
       "      <td>766</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>focal</td>\n",
       "      <td>0.683271</td>\n",
       "      <td>0.602752</td>\n",
       "      <td>[0.7829224293445579, 0.5520504731861199, 0.473...</td>\n",
       "      <td>0.551709</td>\n",
       "      <td>0.688063</td>\n",
       "      <td>0.599302</td>\n",
       "      <td>[0.7870619946091646, 0.5650118203309693, 0.445...</td>\n",
       "      <td>[100]</td>\n",
       "      <td>0.5</td>\n",
       "      <td>0.0001</td>\n",
       "      <td>123</td>\n",
       "      <td>2</td>\n",
       "      <td>True</td>\n",
       "      <td>20</td>\n",
       "      <td>766</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>focal</td>\n",
       "      <td>0.664684</td>\n",
       "      <td>0.596425</td>\n",
       "      <td>[0.7611484422724496, 0.5166163141993957, 0.511...</td>\n",
       "      <td>0.528710</td>\n",
       "      <td>0.688626</td>\n",
       "      <td>0.616118</td>\n",
       "      <td>[0.7842056932966024, 0.5513264129181084, 0.512...</td>\n",
       "      <td>[100]</td>\n",
       "      <td>0.5</td>\n",
       "      <td>0.0001</td>\n",
       "      <td>123</td>\n",
       "      <td>2</td>\n",
       "      <td>True</td>\n",
       "      <td>20</td>\n",
       "      <td>766</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>focal</td>\n",
       "      <td>0.692193</td>\n",
       "      <td>0.623270</td>\n",
       "      <td>[0.7897310513447432, 0.5442834138486312, 0.535...</td>\n",
       "      <td>0.530419</td>\n",
       "      <td>0.677928</td>\n",
       "      <td>0.596133</td>\n",
       "      <td>[0.7777274784970576, 0.5432399512789282, 0.467...</td>\n",
       "      <td>[100]</td>\n",
       "      <td>0.5</td>\n",
       "      <td>0.0001</td>\n",
       "      <td>1234</td>\n",
       "      <td>2</td>\n",
       "      <td>True</td>\n",
       "      <td>20</td>\n",
       "      <td>766</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>focal</td>\n",
       "      <td>0.682528</td>\n",
       "      <td>0.597103</td>\n",
       "      <td>[0.7872212176009645, 0.5446293494704992, 0.459...</td>\n",
       "      <td>0.505024</td>\n",
       "      <td>0.690315</td>\n",
       "      <td>0.614962</td>\n",
       "      <td>[0.783363802559415, 0.5646794150731158, 0.4968...</td>\n",
       "      <td>[100]</td>\n",
       "      <td>0.5</td>\n",
       "      <td>0.0001</td>\n",
       "      <td>1234</td>\n",
       "      <td>2</td>\n",
       "      <td>True</td>\n",
       "      <td>20</td>\n",
       "      <td>766</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>focal</td>\n",
       "      <td>0.692193</td>\n",
       "      <td>0.592600</td>\n",
       "      <td>[0.7926054303870596, 0.5638474295190713, 0.421...</td>\n",
       "      <td>0.531270</td>\n",
       "      <td>0.695946</td>\n",
       "      <td>0.604361</td>\n",
       "      <td>[0.7954245490541135, 0.5532994923857869, 0.464...</td>\n",
       "      <td>[100]</td>\n",
       "      <td>0.5</td>\n",
       "      <td>0.0001</td>\n",
       "      <td>1234</td>\n",
       "      <td>2</td>\n",
       "      <td>True</td>\n",
       "      <td>20</td>\n",
       "      <td>766</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>focal</td>\n",
       "      <td>0.674349</td>\n",
       "      <td>0.601641</td>\n",
       "      <td>[0.7705521472392639, 0.558641975308642, 0.4757...</td>\n",
       "      <td>0.550257</td>\n",
       "      <td>0.681869</td>\n",
       "      <td>0.600462</td>\n",
       "      <td>[0.7775752051048314, 0.5714285714285715, 0.452...</td>\n",
       "      <td>[100]</td>\n",
       "      <td>0.5</td>\n",
       "      <td>0.0001</td>\n",
       "      <td>1234</td>\n",
       "      <td>2</td>\n",
       "      <td>True</td>\n",
       "      <td>20</td>\n",
       "      <td>766</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>focal</td>\n",
       "      <td>0.663197</td>\n",
       "      <td>0.594774</td>\n",
       "      <td>[0.7611484422724496, 0.5090361445783133, 0.514...</td>\n",
       "      <td>0.526768</td>\n",
       "      <td>0.685811</td>\n",
       "      <td>0.614584</td>\n",
       "      <td>[0.7800829875518671, 0.5547945205479452, 0.508...</td>\n",
       "      <td>[100]</td>\n",
       "      <td>0.5</td>\n",
       "      <td>0.0001</td>\n",
       "      <td>1234</td>\n",
       "      <td>2</td>\n",
       "      <td>True</td>\n",
       "      <td>20</td>\n",
       "      <td>766</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "    loss  accuracy        f1  \\\n",
       "0  focal  0.699628  0.629848   \n",
       "1  focal  0.681041  0.596610   \n",
       "2  focal  0.689219  0.591243   \n",
       "3  focal  0.680297  0.601317   \n",
       "4  focal  0.667658  0.600250   \n",
       "0  focal  0.689219  0.615304   \n",
       "1  focal  0.680297  0.597075   \n",
       "2  focal  0.675836  0.578892   \n",
       "3  focal  0.684758  0.604041   \n",
       "4  focal  0.667658  0.601386   \n",
       "0  focal  0.692193  0.623333   \n",
       "1  focal  0.681041  0.591809   \n",
       "2  focal  0.689219  0.589982   \n",
       "3  focal  0.686245  0.607651   \n",
       "4  focal  0.663941  0.598446   \n",
       "0  focal  0.695167  0.626583   \n",
       "1  focal  0.684015  0.597483   \n",
       "2  focal  0.696654  0.601403   \n",
       "3  focal  0.683271  0.602752   \n",
       "4  focal  0.664684  0.596425   \n",
       "0  focal  0.692193  0.623270   \n",
       "1  focal  0.682528  0.597103   \n",
       "2  focal  0.692193  0.592600   \n",
       "3  focal  0.674349  0.601641   \n",
       "4  focal  0.663197  0.594774   \n",
       "\n",
       "                                           f1_scores  valid_loss  \\\n",
       "0  [0.7965998785670917, 0.5466034755134281, 0.546...    0.535128   \n",
       "1  [0.7869249394673123, 0.5405405405405405, 0.462...    0.507187   \n",
       "2  [0.789838337182448, 0.5564924114671164, 0.4273...    0.534393   \n",
       "3  [0.7790487658037327, 0.5457364341085271, 0.479...    0.557449   \n",
       "4  [0.7642770352369381, 0.5081723625557206, 0.528...    0.528262   \n",
       "0  [0.7893462469733656, 0.5358851674641149, 0.520...    0.531559   \n",
       "1  [0.7845503922751961, 0.5407066052227342, 0.465...    0.509566   \n",
       "2  [0.7780373831775701, 0.5499181669394436, 0.408...    0.530567   \n",
       "3  [0.7838651414810355, 0.5588697017268446, 0.469...    0.553035   \n",
       "4  [0.7639060568603213, 0.5289747399702823, 0.511...    0.529611   \n",
       "0  [0.7906691221608348, 0.5463108320251177, 0.533...    0.539443   \n",
       "1  [0.7891891891891891, 0.541213063763608, 0.4450...    0.513420   \n",
       "2  [0.7906976744186046, 0.5635179153094464, 0.415...    0.536695   \n",
       "3  [0.7825044937088076, 0.558213716108453, 0.4822...    0.556622   \n",
       "4  [0.7590881084411583, 0.5222551928783382, 0.513...    0.530625   \n",
       "0  [0.7919463087248322, 0.5457463884430177, 0.542...    0.535143   \n",
       "1  [0.7903903903903905, 0.5392912172573191, 0.462...    0.506780   \n",
       "2  [0.794901506373117, 0.5709515859766277, 0.4383...    0.533215   \n",
       "3  [0.7829224293445579, 0.5520504731861199, 0.473...    0.551709   \n",
       "4  [0.7611484422724496, 0.5166163141993957, 0.511...    0.528710   \n",
       "0  [0.7897310513447432, 0.5442834138486312, 0.535...    0.530419   \n",
       "1  [0.7872212176009645, 0.5446293494704992, 0.459...    0.505024   \n",
       "2  [0.7926054303870596, 0.5638474295190713, 0.421...    0.531270   \n",
       "3  [0.7705521472392639, 0.558641975308642, 0.4757...    0.550257   \n",
       "4  [0.7611484422724496, 0.5090361445783133, 0.514...    0.526768   \n",
       "\n",
       "   valid_accuracy  valid_f1  \\\n",
       "0        0.685811  0.601814   \n",
       "1        0.696509  0.624477   \n",
       "2        0.692005  0.600451   \n",
       "3        0.685248  0.597495   \n",
       "4        0.681869  0.606892   \n",
       "0        0.680743  0.594290   \n",
       "1        0.685811  0.613716   \n",
       "2        0.685811  0.598425   \n",
       "3        0.681306  0.594199   \n",
       "4        0.674550  0.603511   \n",
       "0        0.677365  0.596191   \n",
       "1        0.690878  0.614730   \n",
       "2        0.688063  0.598472   \n",
       "3        0.683559  0.595503   \n",
       "4        0.677928  0.604811   \n",
       "0        0.681306  0.594024   \n",
       "1        0.697635  0.623647   \n",
       "2        0.695946  0.603888   \n",
       "3        0.688063  0.599302   \n",
       "4        0.688626  0.616118   \n",
       "0        0.677928  0.596133   \n",
       "1        0.690315  0.614962   \n",
       "2        0.695946  0.604361   \n",
       "3        0.681869  0.600462   \n",
       "4        0.685811  0.614584   \n",
       "\n",
       "                                     valid_f1_scores hidden_dim  dropout_rate  \\\n",
       "0  [0.7854578096947935, 0.543030303030303, 0.4769...      [100]           0.5   \n",
       "1  [0.7877401646843549, 0.5691609977324262, 0.516...      [100]           0.5   \n",
       "2  [0.7948831054256728, 0.537966537966538, 0.4685...      [100]           0.5   \n",
       "3  [0.7831541218637994, 0.5563380281690141, 0.452...      [100]           0.5   \n",
       "4        [0.77910174152154, 0.5415730337078652, 0.5]      [100]           0.5   \n",
       "0  [0.7827260458839406, 0.5410628019323671, 0.459...      [100]           0.5   \n",
       "1  [0.7775239835541344, 0.5565819861431871, 0.507...      [100]           0.5   \n",
       "2  [0.7876344086021505, 0.5445665445665446, 0.463...      [100]           0.5   \n",
       "3  [0.7785778577857785, 0.5623529411764706, 0.441...      [100]           0.5   \n",
       "4  [0.7723880597014926, 0.5430167597765363, 0.495...      [100]           0.5   \n",
       "0  [0.7767166894042746, 0.5454545454545455, 0.466...      [100]           0.5   \n",
       "1  [0.7868852459016394, 0.5532407407407407, 0.504...      [100]           0.5   \n",
       "2  [0.7893569844789357, 0.5404732254047322, 0.465...      [100]           0.5   \n",
       "3  [0.7824529991047449, 0.5569007263922517, 0.447...      [100]           0.5   \n",
       "4  [0.7754158964879853, 0.5429864253393665, 0.496...      [100]           0.5   \n",
       "0  [0.7854578096947935, 0.5326757090012331, 0.463...      [100]           0.5   \n",
       "1  [0.7898320472083522, 0.5635103926096998, 0.517...      [100]           0.5   \n",
       "2  [0.7985865724381626, 0.5494223363286265, 0.463...      [100]           0.5   \n",
       "3  [0.7870619946091646, 0.5650118203309693, 0.445...      [100]           0.5   \n",
       "4  [0.7842056932966024, 0.5513264129181084, 0.512...      [100]           0.5   \n",
       "0  [0.7777274784970576, 0.5432399512789282, 0.467...      [100]           0.5   \n",
       "1  [0.783363802559415, 0.5646794150731158, 0.4968...      [100]           0.5   \n",
       "2  [0.7954245490541135, 0.5532994923857869, 0.464...      [100]           0.5   \n",
       "3  [0.7775752051048314, 0.5714285714285715, 0.452...      [100]           0.5   \n",
       "4  [0.7800829875518671, 0.5547945205479452, 0.508...      [100]           0.5   \n",
       "\n",
       "   learning_rate  seed  gamma  k_fold   k  input_dim  \n",
       "0         0.0001     0      2    True  20        766  \n",
       "1         0.0001     0      2    True  20        766  \n",
       "2         0.0001     0      2    True  20        766  \n",
       "3         0.0001     0      2    True  20        766  \n",
       "4         0.0001     0      2    True  20        766  \n",
       "0         0.0001     1      2    True  20        766  \n",
       "1         0.0001     1      2    True  20        766  \n",
       "2         0.0001     1      2    True  20        766  \n",
       "3         0.0001     1      2    True  20        766  \n",
       "4         0.0001     1      2    True  20        766  \n",
       "0         0.0001    12      2    True  20        766  \n",
       "1         0.0001    12      2    True  20        766  \n",
       "2         0.0001    12      2    True  20        766  \n",
       "3         0.0001    12      2    True  20        766  \n",
       "4         0.0001    12      2    True  20        766  \n",
       "0         0.0001   123      2    True  20        766  \n",
       "1         0.0001   123      2    True  20        766  \n",
       "2         0.0001   123      2    True  20        766  \n",
       "3         0.0001   123      2    True  20        766  \n",
       "4         0.0001   123      2    True  20        766  \n",
       "0         0.0001  1234      2    True  20        766  \n",
       "1         0.0001  1234      2    True  20        766  \n",
       "2         0.0001  1234      2    True  20        766  \n",
       "3         0.0001  1234      2    True  20        766  \n",
       "4         0.0001  1234      2    True  20        766  "
      ]
     },
     "execution_count": 34,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "best_ffn_mean_history_kfold"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "id": "a2e47c41",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.6024489022123928"
      ]
     },
     "execution_count": 35,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "best_ffn_mean_history_kfold[\"f1\"].mean()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 70,
   "id": "b0addfa4",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([0.78204441, 0.54354018, 0.48176212])"
      ]
     },
     "execution_count": 70,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "np.stack(best_ffn_mean_history_kfold[\"f1_scores\"]).mean(axis=0)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "id": "0cf51402",
   "metadata": {},
   "source": [
    "# Baseline: FFN using signatures\n",
    "\n",
    "First, we dimension reduce these and then take signatures. We use the path signature as input to the FFN for classification.\n",
    "\n",
    "We want to choose a dimension and signature depth such that the number of terms in the signature is _roughly_ 384 so that it is comparable to the number of features that we used for the previous baseline where we computed the mean of the history. Again, we are concatenating the features we obtain with the current utterance embedding."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 71,
   "id": "aa98763b",
   "metadata": {},
   "outputs": [],
   "source": [
    "dim_reduce_methods = [\"gaussian_random_projection\", \"umap\"]"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "id": "beea6053",
   "metadata": {},
   "source": [
    "## Using signature"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 131,
   "id": "c893cdc6",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[380, 399, 340, 363]"
      ]
     },
     "execution_count": 131,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "signature_dimensions_and_sig_depths = [(19, 2), (7, 3), (4, 4), (3, 5)]\n",
    "[signatory.signature_channels(channels, depth)\n",
    " for (channels, depth) in signature_dimensions_and_sig_depths]"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "id": "54612d60",
   "metadata": {},
   "source": [
    "### Using UMAP"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "223447a8",
   "metadata": {},
   "outputs": [],
   "source": [
    "ffn_signature_umap, best_ffn_signature_umap, _, __ = histories_baseline_hyperparameter_search(\n",
    "    num_epochs=num_epochs,\n",
    "    df=anno_mi,\n",
    "    id_column=\"transcript_id\",\n",
    "    label_column=\"client_talk_type\",\n",
    "    embeddings=sbert_embeddings,\n",
    "    y_data=y_data,\n",
    "    output_dim=output_dim,\n",
    "    window_sizes=window_sizes,\n",
    "    hidden_dim_sizes=hidden_dim_sizes,\n",
    "    dropout_rates=dropout_rates,\n",
    "    learning_rates=learning_rates,\n",
    "    use_signatures=True,\n",
    "    log_signature=False,\n",
    "    dim_reduce_methods=[\"umap\"],\n",
    "    dimension_and_sig_depths=signature_dimensions_and_sig_depths,\n",
    "    seeds=seeds,\n",
    "    loss=loss,\n",
    "    gamma=gamma,\n",
    "    path_indices=client_index,\n",
    "    k_fold=False,\n",
    "    validation_metric=validation_metric,\n",
    "    results_output=f\"{output_dir}/ffn_signature_umap_focal_{gamma}.csv\",\n",
    "    verbose=False\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5e1d6eae",
   "metadata": {},
   "outputs": [],
   "source": [
    "best_ffn_signature_umap[\"f1\"].mean()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e3d73f7a",
   "metadata": {},
   "outputs": [],
   "source": [
    "np.stack(best_ffn_signature_umap[\"f1_scores\"]).mean(axis=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "37ac1973",
   "metadata": {},
   "outputs": [],
   "source": [
    "ffn_signature_umap_kfold, best_ffn_signature_umap_kfold, _, __ = histories_baseline_hyperparameter_search(\n",
    "    num_epochs=num_epochs,\n",
    "    df=anno_mi,\n",
    "    id_column=\"transcript_id\",\n",
    "    label_column=\"client_talk_type\",\n",
    "    embeddings=sbert_embeddings,\n",
    "    y_data=y_data,\n",
    "    output_dim=output_dim,\n",
    "    window_sizes=window_sizes,\n",
    "    hidden_dim_sizes=hidden_dim_sizes,\n",
    "    dropout_rates=dropout_rates,\n",
    "    learning_rates=learning_rates,\n",
    "    use_signatures=True,\n",
    "    log_signature=False,\n",
    "    dim_reduce_methods=[\"umap\"],\n",
    "    dimension_and_sig_depths=signature_dimensions_and_sig_depths,\n",
    "    seeds=seeds,\n",
    "    loss=loss,\n",
    "    gamma=gamma,\n",
    "    path_indices=client_index,\n",
    "    k_fold=True,\n",
    "    validation_metric=validation_metric,\n",
    "    results_output=f\"{output_dir}/ffn_signature_umap_focal_{gamma}_kfold.csv\",\n",
    "    verbose=False\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3765b7cf",
   "metadata": {},
   "outputs": [],
   "source": [
    "best_ffn_signature_umap_kfold[\"f1\"].mean()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9d06dc20",
   "metadata": {},
   "outputs": [],
   "source": [
    "np.stack(best_ffn_signature_umap_kfold[\"f1_scores\"]).mean(axis=0)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "id": "509cb39e",
   "metadata": {},
   "source": [
    "### Using random projections"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "df97aba2",
   "metadata": {},
   "outputs": [],
   "source": [
    "ffn_signature_grp, best_ffn_signature_grp, _, __ = histories_baseline_hyperparameter_search(\n",
    "    num_epochs=num_epochs,\n",
    "    df=anno_mi,\n",
    "    id_column=\"transcript_id\",\n",
    "    label_column=\"client_talk_type\",\n",
    "    embeddings=sbert_embeddings,\n",
    "    y_data=y_data,\n",
    "    output_dim=output_dim,\n",
    "    window_sizes=window_sizes,\n",
    "    hidden_dim_sizes=hidden_dim_sizes,\n",
    "    dropout_rates=dropout_rates,\n",
    "    learning_rates=learning_rates,\n",
    "    use_signatures=True,\n",
    "    log_signature=False,\n",
    "    dim_reduce_methods=[\"gaussian_random_projection\"],\n",
    "    dimension_and_sig_depths=signature_dimensions_and_sig_depths,\n",
    "    seeds=seeds,\n",
    "    loss=loss,\n",
    "    gamma=gamma,\n",
    "    path_indices=client_index,\n",
    "    k_fold=False,\n",
    "    validation_metric=validation_metric,\n",
    "    results_output=f\"{output_dir}/ffn_signature_grp_focal_{gamma}.csv\",\n",
    "    verbose=False\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "79b2dec2",
   "metadata": {},
   "outputs": [],
   "source": [
    "best_ffn_signature_grp[\"f1\"].mean()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "be59d270",
   "metadata": {},
   "outputs": [],
   "source": [
    "np.stack(best_ffn_signature_grp[\"f1_scores\"]).mean(axis=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5ccba221",
   "metadata": {},
   "outputs": [],
   "source": [
    "ffn_signature_grp_kfold, best_ffn_signature_grp_kfold, _, __ = histories_baseline_hyperparameter_search(\n",
    "    num_epochs=num_epochs,\n",
    "    df=anno_mi,\n",
    "    id_column=\"transcript_id\",\n",
    "    label_column=\"client_talk_type\",\n",
    "    embeddings=sbert_embeddings,\n",
    "    y_data=y_data,\n",
    "    output_dim=output_dim,\n",
    "    window_sizes=window_sizes,\n",
    "    hidden_dim_sizes=hidden_dim_sizes,\n",
    "    dropout_rates=dropout_rates,\n",
    "    learning_rates=learning_rates,\n",
    "    use_signatures=True,\n",
    "    log_signature=False,\n",
    "    dim_reduce_methods=[\"gaussian_random_projection\"],\n",
    "    dimension_and_sig_depths=signature_dimensions_and_sig_depths,\n",
    "    seeds=seeds,\n",
    "    loss=loss,\n",
    "    gamma=gamma,\n",
    "    path_indices=client_index,\n",
    "    k_fold=True,\n",
    "    validation_metric=validation_metric,\n",
    "    results_output=f\"{output_dir}/ffn_signature_grp_focal_{gamma}_kfold.csv\",\n",
    "    verbose=False\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "15da00d0",
   "metadata": {},
   "outputs": [],
   "source": [
    "best_ffn_signature_grp_kfold[\"f1\"].mean()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "dc9770e7",
   "metadata": {},
   "outputs": [],
   "source": [
    "np.stack(best_ffn_signature_grp_kfold[\"f1_scores\"]).mean(axis=0)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "id": "871fe909",
   "metadata": {},
   "source": [
    "## Using log signature"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 125,
   "id": "08de59af",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[406, 385, 406, 294]"
      ]
     },
     "execution_count": 125,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "log_signature_dimensions_and_sig_depths = [(28, 2), (10, 3), (6, 4), (4, 5)]\n",
    "[signatory.logsignature_channels(channels, depth)\n",
    " for (channels, depth) in log_signature_dimensions_and_sig_depths]"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "id": "c94885e5",
   "metadata": {},
   "source": [
    "### Using UMAP"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d461f89e",
   "metadata": {},
   "outputs": [],
   "source": [
    "ffn_logsignature_umap, best_ffn_logsignature_umap, _, __ = histories_baseline_hyperparameter_search(\n",
    "    num_epochs=num_epochs,\n",
    "    df=anno_mi,\n",
    "    id_column=\"transcript_id\",\n",
    "    label_column=\"client_talk_type\",\n",
    "    embeddings=sbert_embeddings,\n",
    "    y_data=y_data,\n",
    "    output_dim=output_dim,\n",
    "    window_sizes=window_sizes,\n",
    "    hidden_dim_sizes=hidden_dim_sizes,\n",
    "    dropout_rates=dropout_rates,\n",
    "    learning_rates=learning_rates,\n",
    "    use_signatures=True,\n",
    "    log_signature=True,\n",
    "    dim_reduce_methods=[\"umap\"],\n",
    "    dimension_and_sig_depths=signature_dimensions_and_sig_depths,\n",
    "    seeds=seeds,\n",
    "    loss=loss,\n",
    "    gamma=gamma,\n",
    "    path_indices=client_index,\n",
    "    k_fold=False,\n",
    "    validation_metric=validation_metric,\n",
    "    results_output=f\"{output_dir}/ffn_logsignature_umap_focal_{gamma}.csv\",\n",
    "    verbose=False\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8f26bdfb",
   "metadata": {},
   "outputs": [],
   "source": [
    "best_ffn_logsignature_umap[\"f1\"].mean()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b9edcb84",
   "metadata": {},
   "outputs": [],
   "source": [
    "np.stack(best_ffn_logsignature_umap[\"f1_scores\"]).mean(axis=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b9cd8cf0",
   "metadata": {},
   "outputs": [],
   "source": [
    "ffn_logsignature_umap_kfold, best_ffn_logsignature_umap_kfold, _, __ = histories_baseline_hyperparameter_search(\n",
    "    num_epochs=num_epochs,\n",
    "    df=anno_mi,\n",
    "    id_column=\"transcript_id\",\n",
    "    label_column=\"client_talk_type\",\n",
    "    embeddings=sbert_embeddings,\n",
    "    y_data=y_data,\n",
    "    output_dim=output_dim,\n",
    "    window_sizes=window_sizes,\n",
    "    hidden_dim_sizes=hidden_dim_sizes,\n",
    "    dropout_rates=dropout_rates,\n",
    "    learning_rates=learning_rates,\n",
    "    use_signatures=True,\n",
    "    log_signature=True,\n",
    "    dim_reduce_methods=[\"umap\"],\n",
    "    dimension_and_sig_depths=signature_dimensions_and_sig_depths,\n",
    "    seeds=seeds,\n",
    "    loss=loss,\n",
    "    gamma=gamma,\n",
    "    path_indices=client_index,\n",
    "    k_fold=True,\n",
    "    validation_metric=validation_metric,\n",
    "    results_output=f\"{output_dir}/ffn_logsignature_umap_focal_{gamma}_kfold.csv\",\n",
    "    verbose=False\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "db662960",
   "metadata": {},
   "outputs": [],
   "source": [
    "best_ffn_logsignature_umap_kfold[\"f1\"].mean()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f9d8a18b",
   "metadata": {},
   "outputs": [],
   "source": [
    "np.stack(best_ffn_logsignature_umap_kfold[\"f1_scores\"]).mean(axis=0)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "id": "0de6f338",
   "metadata": {},
   "source": [
    "### Using random projections"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "295de19d",
   "metadata": {},
   "outputs": [],
   "source": [
    "ffn_logsignature_grp, best_ffn_logsignature_grp, _, __ = histories_baseline_hyperparameter_search(\n",
    "    num_epochs=num_epochs,\n",
    "    df=anno_mi,\n",
    "    id_column=\"transcript_id\",\n",
    "    label_column=\"client_talk_type\",\n",
    "    embeddings=sbert_embeddings,\n",
    "    y_data=y_data,\n",
    "    output_dim=output_dim,\n",
    "    window_sizes=window_sizes,\n",
    "    hidden_dim_sizes=hidden_dim_sizes,\n",
    "    dropout_rates=dropout_rates,\n",
    "    learning_rates=learning_rates,\n",
    "    use_signatures=True,\n",
    "    log_signature=True,\n",
    "    dim_reduce_methods=[\"gaussian_random_projection\"],\n",
    "    dimension_and_sig_depths=signature_dimensions_and_sig_depths,\n",
    "    seeds=seeds,\n",
    "    loss=loss,\n",
    "    gamma=gamma,\n",
    "    path_indices=client_index,\n",
    "    k_fold=False,\n",
    "    validation_metric=validation_metric,\n",
    "    results_output=f\"{output_dir}/ffn_logsignature_grp_focal_{gamma}.csv\",\n",
    "    verbose=False\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "89e97c9c",
   "metadata": {},
   "outputs": [],
   "source": [
    "best_ffn_logsignature_grp[\"f1\"].mean()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "82a3db6d",
   "metadata": {},
   "outputs": [],
   "source": [
    "np.stack(best_ffn_logsignature_grp[\"f1_scores\"]).mean(axis=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bcf5003d",
   "metadata": {},
   "outputs": [],
   "source": [
    "ffn_logsignature_grp_kfold, best_ffn_logsignature_grp_kfold, _, __ = histories_baseline_hyperparameter_search(\n",
    "    num_epochs=num_epochs,\n",
    "    df=anno_mi,\n",
    "    id_column=\"transcript_id\",\n",
    "    label_column=\"client_talk_type\",\n",
    "    embeddings=sbert_embeddings,\n",
    "    y_data=y_data,\n",
    "    output_dim=output_dim,\n",
    "    window_sizes=window_sizes,\n",
    "    hidden_dim_sizes=hidden_dim_sizes,\n",
    "    dropout_rates=dropout_rates,\n",
    "    learning_rates=learning_rates,\n",
    "    use_signatures=True,\n",
    "    log_signature=True,\n",
    "    dim_reduce_methods=[\"gaussian_random_projection\"],\n",
    "    dimension_and_sig_depths=signature_dimensions_and_sig_depths,\n",
    "    seeds=seeds,\n",
    "    loss=loss,\n",
    "    gamma=gamma,\n",
    "    path_indices=client_index,\n",
    "    k_fold=True,\n",
    "    validation_metric=validation_metric,\n",
    "    results_output=f\"{output_dir}/ffn_logsignature_grp_focal_{gamma}_kfold.csv\",\n",
    "    verbose=False\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0ff79def",
   "metadata": {},
   "outputs": [],
   "source": [
    "best_ffn_logsignature_grp_kfold[\"f1\"].mean()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7d4bd7ed",
   "metadata": {},
   "outputs": [],
   "source": [
    "np.stack(best_ffn_logsignature_grp_kfold[\"f1_scores\"]).mean(axis=0)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "id": "3a710eb3",
   "metadata": {},
   "source": [
    "# Baseline: LSTM classification"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "38d81c7c",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3ed43d57",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "id": "5910ca89",
   "metadata": {},
   "source": [
    "# Baseline: Fine-tune BERT for classification"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "a59ec481",
   "metadata": {},
   "outputs": [],
   "source": [
    "from transformers import (\n",
    "    AutoModelForSequenceClassification,\n",
    "    AutoTokenizer,\n",
    "    DataCollatorWithPadding\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "8cf96317",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of the model checkpoint at bert-base-uncased were not used when initializing BertForSequenceClassification: ['cls.predictions.bias', 'cls.predictions.transform.LayerNorm.bias', 'cls.seq_relationship.weight', 'cls.predictions.transform.LayerNorm.weight', 'cls.seq_relationship.bias', 'cls.predictions.decoder.weight', 'cls.predictions.transform.dense.weight', 'cls.predictions.transform.dense.bias']\n",
      "- This IS expected if you are initializing BertForSequenceClassification from the checkpoint of a model trained on another task or with another architecture (e.g. initializing a BertForSequenceClassification model from a BertForPreTraining model).\n",
      "- This IS NOT expected if you are initializing BertForSequenceClassification from the checkpoint of a model that you expect to be exactly identical (initializing a BertForSequenceClassification model from a BertForSequenceClassification model).\n",
      "Some weights of BertForSequenceClassification were not initialized from the model checkpoint at bert-base-uncased and are newly initialized: ['classifier.weight', 'classifier.bias']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"
     ]
    }
   ],
   "source": [
    "pretrained_model = \"bert-base-uncased\"\n",
    "model = AutoModelForSequenceClassification.from_pretrained(\n",
    "    pretrained_model,\n",
    "    num_labels=output_dim,\n",
    "    id2label=id_to_label,\n",
    "    label2id=label_to_id\n",
    ")\n",
    "tokenizer = AutoTokenizer.from_pretrained(pretrained_model)\n",
    "data_collator = DataCollatorWithPadding(tokenizer=tokenizer)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "id": "729e9df3",
   "metadata": {},
   "source": [
    "We need to make a column in `anno_mi` called `label`:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "e10927ea",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>mi_quality</th>\n",
       "      <th>transcript_id</th>\n",
       "      <th>topic</th>\n",
       "      <th>utterance_id</th>\n",
       "      <th>interlocutor</th>\n",
       "      <th>timestamp</th>\n",
       "      <th>utterance_text</th>\n",
       "      <th>annotator_id</th>\n",
       "      <th>therapist_input_exists</th>\n",
       "      <th>therapist_input_subtype</th>\n",
       "      <th>reflection_exists</th>\n",
       "      <th>reflection_subtype</th>\n",
       "      <th>question_exists</th>\n",
       "      <th>question_subtype</th>\n",
       "      <th>main_therapist_behaviour</th>\n",
       "      <th>client_talk_type</th>\n",
       "      <th>datetime</th>\n",
       "      <th>label</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>high</td>\n",
       "      <td>0</td>\n",
       "      <td>reducing alcohol consumption</td>\n",
       "      <td>1</td>\n",
       "      <td>client</td>\n",
       "      <td>00:00:24</td>\n",
       "      <td>Sure.</td>\n",
       "      <td>3</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>neutral</td>\n",
       "      <td>2023-06-09 00:00:24</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>high</td>\n",
       "      <td>0</td>\n",
       "      <td>reducing alcohol consumption</td>\n",
       "      <td>3</td>\n",
       "      <td>client</td>\n",
       "      <td>00:00:34</td>\n",
       "      <td>Mm-hmm.</td>\n",
       "      <td>3</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>neutral</td>\n",
       "      <td>2023-06-09 00:00:34</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>high</td>\n",
       "      <td>0</td>\n",
       "      <td>reducing alcohol consumption</td>\n",
       "      <td>5</td>\n",
       "      <td>client</td>\n",
       "      <td>00:00:39</td>\n",
       "      <td>Usually three drinks and glasses of wine.</td>\n",
       "      <td>3</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>neutral</td>\n",
       "      <td>2023-06-09 00:00:39</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>high</td>\n",
       "      <td>0</td>\n",
       "      <td>reducing alcohol consumption</td>\n",
       "      <td>7</td>\n",
       "      <td>client</td>\n",
       "      <td>00:00:46</td>\n",
       "      <td>Something like that.</td>\n",
       "      <td>3</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>neutral</td>\n",
       "      <td>2023-06-09 00:00:46</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>high</td>\n",
       "      <td>0</td>\n",
       "      <td>reducing alcohol consumption</td>\n",
       "      <td>9</td>\n",
       "      <td>client</td>\n",
       "      <td>00:01:03</td>\n",
       "      <td>Okay.</td>\n",
       "      <td>3</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>neutral</td>\n",
       "      <td>2023-06-09 00:01:03</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "  mi_quality  transcript_id                         topic  utterance_id  \\\n",
       "0       high              0  reducing alcohol consumption             1   \n",
       "1       high              0  reducing alcohol consumption             3   \n",
       "2       high              0  reducing alcohol consumption             5   \n",
       "3       high              0  reducing alcohol consumption             7   \n",
       "4       high              0  reducing alcohol consumption             9   \n",
       "\n",
       "  interlocutor timestamp                             utterance_text  \\\n",
       "0       client  00:00:24                                      Sure.   \n",
       "1       client  00:00:34                                    Mm-hmm.   \n",
       "2       client  00:00:39  Usually three drinks and glasses of wine.   \n",
       "3       client  00:00:46                       Something like that.   \n",
       "4       client  00:01:03                                      Okay.   \n",
       "\n",
       "   annotator_id therapist_input_exists therapist_input_subtype  \\\n",
       "0             3                    NaN                     NaN   \n",
       "1             3                    NaN                     NaN   \n",
       "2             3                    NaN                     NaN   \n",
       "3             3                    NaN                     NaN   \n",
       "4             3                    NaN                     NaN   \n",
       "\n",
       "  reflection_exists reflection_subtype question_exists question_subtype  \\\n",
       "0               NaN                NaN             NaN              NaN   \n",
       "1               NaN                NaN             NaN              NaN   \n",
       "2               NaN                NaN             NaN              NaN   \n",
       "3               NaN                NaN             NaN              NaN   \n",
       "4               NaN                NaN             NaN              NaN   \n",
       "\n",
       "  main_therapist_behaviour client_talk_type            datetime  label  \n",
       "0                      NaN          neutral 2023-06-09 00:00:24      0  \n",
       "1                      NaN          neutral 2023-06-09 00:00:34      0  \n",
       "2                      NaN          neutral 2023-06-09 00:00:39      0  \n",
       "3                      NaN          neutral 2023-06-09 00:00:46      0  \n",
       "4                      NaN          neutral 2023-06-09 00:01:03      0  "
      ]
     },
     "execution_count": 23,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df = anno_mi[client_index].reset_index(drop=True)\n",
    "df[\"label\"] = df[\"client_talk_type\"].apply(lambda x: label_to_id[x])\n",
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "b194af23",
   "metadata": {},
   "outputs": [],
   "source": [
    "fine_tune_bert = nlpsig.TextEncoder(df=df,\n",
    "                                    feature_name=\"utterance_text\",\n",
    "                                    model=model,\n",
    "                                    tokenizer=tokenizer,\n",
    "                                    data_collator=data_collator)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "5a0c222c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[INFO] Setting return_special_tokens_mask=True\n",
      "[INFO] Tokenizing the dataset...\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Map:   0%|          | 0/6725 [00:00<?, ? examples/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[INFO] Saving the tokenized text for each sentence into `.df['tokens']`...\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Map:   0%|          | 0/6725 [00:00<?, ? examples/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[INFO] Creating tokenized dataframe and setting in `.tokenized_df` attribute...\n",
      "[INFO] Note: 'text_id' is the column name for denoting the corresponding text id\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "Dataset({\n",
       "    features: ['mi_quality', 'transcript_id', 'topic', 'utterance_id', 'interlocutor', 'timestamp', 'utterance_text', 'annotator_id', 'therapist_input_exists', 'therapist_input_subtype', 'reflection_exists', 'reflection_subtype', 'question_exists', 'question_subtype', 'main_therapist_behaviour', 'client_talk_type', 'datetime', 'label', 'input_ids', 'token_type_ids', 'attention_mask', 'special_tokens_mask', 'tokens'],\n",
       "    num_rows: 6725\n",
       "})"
      ]
     },
     "execution_count": 25,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "fine_tune_bert.tokenize_text()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "50a61a8e",
   "metadata": {},
   "outputs": [],
   "source": [
    "splits = DataSplits(x_data=sbert_embeddings[client_index],\n",
    "                    y_data=torch.tensor(y_data))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "b30d7b88",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tuple"
      ]
     },
     "execution_count": 27,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "type(splits.indices)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "af956a07",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "3"
      ]
     },
     "execution_count": 28,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(splits.indices)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "id": "8f476516",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "dict_keys(['neutral', 'change', 'sustain'])"
      ]
     },
     "execution_count": 29,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "label_to_id.keys()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "id": "4fa328f5",
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "DatasetDict({\n",
       "    train: Dataset({\n",
       "        features: ['mi_quality', 'transcript_id', 'topic', 'utterance_id', 'interlocutor', 'timestamp', 'utterance_text', 'annotator_id', 'therapist_input_exists', 'therapist_input_subtype', 'reflection_exists', 'reflection_subtype', 'question_exists', 'question_subtype', 'main_therapist_behaviour', 'client_talk_type', 'datetime', 'label', 'input_ids', 'token_type_ids', 'attention_mask', 'special_tokens_mask', 'tokens'],\n",
       "        num_rows: 3604\n",
       "    })\n",
       "    test: Dataset({\n",
       "        features: ['mi_quality', 'transcript_id', 'topic', 'utterance_id', 'interlocutor', 'timestamp', 'utterance_text', 'annotator_id', 'therapist_input_exists', 'therapist_input_subtype', 'reflection_exists', 'reflection_subtype', 'question_exists', 'question_subtype', 'main_therapist_behaviour', 'client_talk_type', 'datetime', 'label', 'input_ids', 'token_type_ids', 'attention_mask', 'special_tokens_mask', 'tokens'],\n",
       "        num_rows: 1345\n",
       "    })\n",
       "    validation: Dataset({\n",
       "        features: ['mi_quality', 'transcript_id', 'topic', 'utterance_id', 'interlocutor', 'timestamp', 'utterance_text', 'annotator_id', 'therapist_input_exists', 'therapist_input_subtype', 'reflection_exists', 'reflection_subtype', 'question_exists', 'question_subtype', 'main_therapist_behaviour', 'client_talk_type', 'datetime', 'label', 'input_ids', 'token_type_ids', 'attention_mask', 'special_tokens_mask', 'tokens'],\n",
       "        num_rows: 1776\n",
       "    })\n",
       "})"
      ]
     },
     "execution_count": 30,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "fine_tune_bert.split_dataset(indices=splits.indices)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "id": "629e4352",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Dataset({\n",
       "    features: ['mi_quality', 'transcript_id', 'topic', 'utterance_id', 'interlocutor', 'timestamp', 'utterance_text', 'annotator_id', 'therapist_input_exists', 'therapist_input_subtype', 'reflection_exists', 'reflection_subtype', 'question_exists', 'question_subtype', 'main_therapist_behaviour', 'client_talk_type', 'datetime', 'label', 'input_ids', 'token_type_ids', 'attention_mask', 'special_tokens_mask', 'tokens'],\n",
       "    num_rows: 3604\n",
       "})"
      ]
     },
     "execution_count": 31,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "fine_tune_bert.dataset_split[\"train\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "id": "b52c7e50",
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[INFO] Setting up TrainingArguments object and saving to `.training_args`.\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "TrainingArguments(\n",
       "_n_gpu=0,\n",
       "adafactor=False,\n",
       "adam_beta1=0.9,\n",
       "adam_beta2=0.999,\n",
       "adam_epsilon=1e-08,\n",
       "auto_find_batch_size=False,\n",
       "bf16=False,\n",
       "bf16_full_eval=False,\n",
       "data_seed=None,\n",
       "dataloader_drop_last=False,\n",
       "dataloader_num_workers=0,\n",
       "dataloader_pin_memory=True,\n",
       "ddp_bucket_cap_mb=None,\n",
       "ddp_find_unused_parameters=None,\n",
       "ddp_timeout=1800,\n",
       "debug=[],\n",
       "deepspeed=None,\n",
       "disable_tqdm=False,\n",
       "do_eval=True,\n",
       "do_predict=False,\n",
       "do_train=False,\n",
       "eval_accumulation_steps=None,\n",
       "eval_delay=0,\n",
       "eval_steps=None,\n",
       "evaluation_strategy=epoch,\n",
       "fp16=False,\n",
       "fp16_backend=auto,\n",
       "fp16_full_eval=False,\n",
       "fp16_opt_level=O1,\n",
       "fsdp=[],\n",
       "fsdp_config={'fsdp_min_num_params': 0, 'xla': False, 'xla_fsdp_grad_ckpt': False},\n",
       "fsdp_min_num_params=0,\n",
       "fsdp_transformer_layer_cls_to_wrap=None,\n",
       "full_determinism=False,\n",
       "gradient_accumulation_steps=1,\n",
       "gradient_checkpointing=False,\n",
       "greater_is_better=None,\n",
       "group_by_length=False,\n",
       "half_precision_backend=auto,\n",
       "hub_model_id=None,\n",
       "hub_private_repo=False,\n",
       "hub_strategy=every_save,\n",
       "hub_token=<HUB_TOKEN>,\n",
       "ignore_data_skip=False,\n",
       "include_inputs_for_metrics=False,\n",
       "jit_mode_eval=False,\n",
       "label_names=None,\n",
       "label_smoothing_factor=0.0,\n",
       "learning_rate=5e-05,\n",
       "length_column_name=length,\n",
       "load_best_model_at_end=False,\n",
       "local_rank=-1,\n",
       "log_level=passive,\n",
       "log_level_replica=warning,\n",
       "log_on_each_node=True,\n",
       "logging_dir=fine-tuned-bert-anno-mi-client/runs/Jun09_14-45-33_519-G7X1JTJFD4,\n",
       "logging_first_step=False,\n",
       "logging_nan_inf_filter=True,\n",
       "logging_steps=500,\n",
       "logging_strategy=steps,\n",
       "lr_scheduler_type=linear,\n",
       "max_grad_norm=1.0,\n",
       "max_steps=-1,\n",
       "metric_for_best_model=None,\n",
       "mp_parameters=,\n",
       "no_cuda=False,\n",
       "num_train_epochs=600,\n",
       "optim=adamw_hf,\n",
       "optim_args=None,\n",
       "output_dir=fine-tuned-bert-anno-mi-client,\n",
       "overwrite_output_dir=False,\n",
       "past_index=-1,\n",
       "per_device_eval_batch_size=8,\n",
       "per_device_train_batch_size=128,\n",
       "prediction_loss_only=False,\n",
       "push_to_hub=False,\n",
       "push_to_hub_model_id=None,\n",
       "push_to_hub_organization=None,\n",
       "push_to_hub_token=<PUSH_TO_HUB_TOKEN>,\n",
       "ray_scope=last,\n",
       "remove_unused_columns=True,\n",
       "report_to=[],\n",
       "resume_from_checkpoint=None,\n",
       "run_name=fine-tuned-bert-anno-mi-client,\n",
       "save_on_each_node=False,\n",
       "save_steps=10000,\n",
       "save_strategy=steps,\n",
       "save_total_limit=None,\n",
       "seed=2023,\n",
       "sharded_ddp=[],\n",
       "skip_memory_metrics=True,\n",
       "tf32=None,\n",
       "torch_compile=False,\n",
       "torch_compile_backend=None,\n",
       "torch_compile_mode=None,\n",
       "torchdynamo=None,\n",
       "tpu_metrics_debug=False,\n",
       "tpu_num_cores=None,\n",
       "use_ipex=False,\n",
       "use_legacy_prediction_loop=False,\n",
       "use_mps_device=False,\n",
       "warmup_ratio=0.0,\n",
       "warmup_steps=0,\n",
       "weight_decay=0.0,\n",
       "xpu_backend=None,\n",
       ")"
      ]
     },
     "execution_count": 32,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model_name = \"fine-tuned-bert-anno-mi-client\"\n",
    "fine_tune_bert.set_up_training_args(output_dir=model_name,\n",
    "                                    num_train_epochs=600,\n",
    "                                    per_device_train_batch_size=128,\n",
    "                                    disable_tqdm=False,\n",
    "                                    save_strategy=\"steps\",\n",
    "                                    save_steps=10000,\n",
    "                                    seed=seed)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "id": "021f2ce6",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "def compute_metrics(eval_pred):\n",
    "    accuracy = evaluate.load(\"accuracy\")\n",
    "    f1 = evaluate.load(\"f1\")\n",
    "    predictions = np.argmax(eval_pred.predictions, axis=1)\n",
    "    accuracy = accuracy.compute(predictions=predictions, references=eval_pred.label_ids)['accuracy']\n",
    "    f1 = f1.compute(predictions=predictions, references=eval_pred.label_ids)['f1']\n",
    "    return {\"accuracy\": accuracy, \"f1\": f1}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "id": "543e6c3d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[INFO] Setting up Trainer object, and saving to `.trainer`.\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<transformers.trainer.Trainer at 0x2d6c3dbb0>"
      ]
     },
     "execution_count": 34,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "fine_tune_bert.set_up_trainer(data_collator=data_collator,\n",
    "                              compute_metrics=compute_metrics)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3d16afe1",
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "fine_tune_bert.fit_transformer_with_trainer_api()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "id": "ccced630",
   "metadata": {},
   "outputs": [],
   "source": [
    "def compute_classification_accuracy(model,\n",
    "                                    test_dataset,\n",
    "                                    feature_name):\n",
    "    # loop through test set and make prediction from model\n",
    "    predicted = [None for i in range(len(test_dataset))]\n",
    "    for i in tqdm(range(len(test_dataset))):\n",
    "        inputs = tokenizer(test_dataset[feature_name][i],\n",
    "                           return_tensors=\"pt\")\n",
    "        with torch.no_grad():\n",
    "            logits = model(**inputs).logits\n",
    "        predicted[i] = logits.argmax().item()\n",
    "\n",
    "    # convert to torch tensor\n",
    "    predicted = torch.tensor(predicted)\n",
    "    labels = torch.tensor(test_dataset[\"label\"])\n",
    "    \n",
    "    # compute accuracy\n",
    "    accuracy = ((predicted == labels).sum() / len(labels)).item()\n",
    "    # compute F1\n",
    "    f1_scores = metrics.f1_score(labels, predicted, average=None)\n",
    "    f1 = sum(f1_scores)/len(f1_scores)\n",
    "    \n",
    "    # print evaluation metrics\n",
    "    print(\n",
    "        f\"Accuracy on dataset of size {len(labels)}: \"\n",
    "        f\"{100 * accuracy} %.\"\n",
    "    )\n",
    "    print(f\"- f1: {f1_scores}\")\n",
    "    print(f\"- f1 (macro): {f1}\")\n",
    "        \n",
    "    return {\"accuracy\": accuracy,\n",
    "            \"f1\": f1,\n",
    "            \"f1_scores\": f1_scores}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "id": "7ba70327",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "2cc41adda289412f984a638822248800",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/1345 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy on dataset of size 1345: 33.382898569107056 %.\n",
      "- f1: [0.37770898 0.35405872 0.        ]\n",
      "- f1 (macro): 0.24392256675418103\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "{'accuracy': 0.33382898569107056,\n",
       " 'f1': 0.24392256675418103,\n",
       " 'f1_scores': array([0.37770898, 0.35405872, 0.        ])}"
      ]
     },
     "execution_count": 46,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "compute_classification_accuracy(model=fine_tune_bert.model,\n",
    "                                test_dataset=fine_tune_bert.dataset_split[\"test\"],\n",
    "                                feature_name=\"utterance_text\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 148,
   "id": "cb91d408",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'neutral'"
      ]
     },
     "execution_count": 148,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 145,
   "id": "e2f341dc",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['neutral',\n",
       " 'neutral',\n",
       " 'neutral',\n",
       " 'neutral',\n",
       " 'neutral',\n",
       " 'neutral',\n",
       " 'change',\n",
       " 'neutral',\n",
       " 'neutral',\n",
       " 'neutral',\n",
       " 'neutral',\n",
       " 'neutral',\n",
       " 'neutral',\n",
       " 'neutral',\n",
       " 'neutral',\n",
       " 'neutral',\n",
       " 'neutral',\n",
       " 'neutral',\n",
       " 'neutral',\n",
       " 'neutral',\n",
       " 'neutral',\n",
       " 'neutral',\n",
       " 'change',\n",
       " 'change',\n",
       " 'neutral',\n",
       " 'change',\n",
       " 'change',\n",
       " 'change',\n",
       " 'neutral',\n",
       " 'neutral',\n",
       " 'neutral',\n",
       " 'neutral',\n",
       " 'change',\n",
       " 'neutral',\n",
       " 'neutral',\n",
       " 'neutral',\n",
       " 'neutral',\n",
       " 'change',\n",
       " 'change',\n",
       " 'change',\n",
       " 'change',\n",
       " 'change',\n",
       " 'change',\n",
       " 'change',\n",
       " 'change',\n",
       " 'change',\n",
       " 'change',\n",
       " 'change',\n",
       " 'change',\n",
       " 'change',\n",
       " 'change',\n",
       " 'neutral',\n",
       " 'neutral',\n",
       " 'change',\n",
       " 'neutral',\n",
       " 'change',\n",
       " 'neutral',\n",
       " 'neutral',\n",
       " 'sustain',\n",
       " 'neutral',\n",
       " 'sustain',\n",
       " 'change',\n",
       " 'neutral',\n",
       " 'change',\n",
       " 'neutral',\n",
       " 'change',\n",
       " 'neutral',\n",
       " 'neutral',\n",
       " 'change',\n",
       " 'change',\n",
       " 'change',\n",
       " 'neutral',\n",
       " 'neutral',\n",
       " 'change',\n",
       " 'neutral',\n",
       " 'sustain',\n",
       " 'neutral',\n",
       " 'change',\n",
       " 'change',\n",
       " 'change',\n",
       " 'change',\n",
       " 'neutral',\n",
       " 'neutral',\n",
       " 'change',\n",
       " 'neutral',\n",
       " 'neutral',\n",
       " 'neutral',\n",
       " 'change',\n",
       " 'neutral',\n",
       " 'change',\n",
       " 'neutral',\n",
       " 'change',\n",
       " 'change',\n",
       " 'neutral',\n",
       " 'neutral',\n",
       " 'change',\n",
       " 'sustain',\n",
       " 'neutral',\n",
       " 'sustain',\n",
       " 'change',\n",
       " 'sustain',\n",
       " 'change',\n",
       " 'change',\n",
       " 'change',\n",
       " 'change',\n",
       " 'change',\n",
       " 'change',\n",
       " 'neutral',\n",
       " 'change',\n",
       " 'neutral',\n",
       " 'neutral',\n",
       " 'neutral',\n",
       " 'neutral',\n",
       " 'neutral',\n",
       " 'neutral',\n",
       " 'neutral',\n",
       " 'sustain',\n",
       " 'sustain',\n",
       " 'sustain',\n",
       " 'sustain',\n",
       " 'sustain',\n",
       " 'neutral',\n",
       " 'neutral',\n",
       " 'neutral',\n",
       " 'neutral',\n",
       " 'neutral',\n",
       " 'neutral',\n",
       " 'sustain',\n",
       " 'neutral',\n",
       " 'neutral',\n",
       " 'neutral',\n",
       " 'neutral',\n",
       " 'sustain',\n",
       " 'sustain',\n",
       " 'neutral',\n",
       " 'neutral',\n",
       " 'neutral',\n",
       " 'neutral',\n",
       " 'neutral',\n",
       " 'sustain',\n",
       " 'neutral',\n",
       " 'sustain',\n",
       " 'sustain',\n",
       " 'sustain',\n",
       " 'sustain',\n",
       " 'neutral',\n",
       " 'neutral',\n",
       " 'sustain',\n",
       " 'neutral',\n",
       " 'neutral',\n",
       " 'neutral',\n",
       " 'neutral',\n",
       " 'neutral',\n",
       " 'neutral',\n",
       " 'neutral',\n",
       " 'neutral',\n",
       " 'neutral',\n",
       " 'neutral',\n",
       " 'neutral',\n",
       " 'neutral',\n",
       " 'neutral',\n",
       " 'neutral',\n",
       " 'neutral',\n",
       " 'neutral',\n",
       " 'neutral',\n",
       " 'neutral',\n",
       " 'change',\n",
       " 'neutral',\n",
       " 'neutral',\n",
       " 'neutral',\n",
       " 'neutral',\n",
       " 'neutral',\n",
       " 'neutral',\n",
       " 'neutral',\n",
       " 'neutral',\n",
       " 'neutral',\n",
       " 'sustain',\n",
       " 'neutral',\n",
       " 'neutral',\n",
       " 'neutral',\n",
       " 'neutral',\n",
       " 'neutral',\n",
       " 'neutral',\n",
       " 'neutral',\n",
       " 'neutral',\n",
       " 'neutral',\n",
       " 'neutral',\n",
       " 'neutral',\n",
       " 'neutral',\n",
       " 'neutral',\n",
       " 'neutral',\n",
       " 'neutral',\n",
       " 'neutral',\n",
       " 'neutral',\n",
       " 'neutral',\n",
       " 'neutral',\n",
       " 'neutral',\n",
       " 'neutral',\n",
       " 'neutral',\n",
       " 'neutral',\n",
       " 'neutral',\n",
       " 'neutral',\n",
       " 'neutral',\n",
       " 'neutral',\n",
       " 'change',\n",
       " 'change',\n",
       " 'change',\n",
       " 'change',\n",
       " 'neutral',\n",
       " 'sustain',\n",
       " 'neutral',\n",
       " 'neutral',\n",
       " 'neutral',\n",
       " 'neutral',\n",
       " 'neutral',\n",
       " 'neutral',\n",
       " 'sustain',\n",
       " 'neutral',\n",
       " 'neutral',\n",
       " 'neutral',\n",
       " 'neutral',\n",
       " 'neutral',\n",
       " 'neutral',\n",
       " 'sustain',\n",
       " 'neutral',\n",
       " 'neutral',\n",
       " 'neutral',\n",
       " 'neutral',\n",
       " 'neutral',\n",
       " 'neutral',\n",
       " 'neutral',\n",
       " 'neutral',\n",
       " 'neutral',\n",
       " 'neutral',\n",
       " 'change',\n",
       " 'neutral',\n",
       " 'neutral',\n",
       " 'neutral',\n",
       " 'neutral',\n",
       " 'neutral',\n",
       " 'sustain',\n",
       " 'neutral',\n",
       " 'neutral',\n",
       " 'sustain',\n",
       " 'neutral',\n",
       " 'neutral',\n",
       " 'neutral',\n",
       " 'neutral',\n",
       " 'neutral',\n",
       " 'change',\n",
       " 'change',\n",
       " 'sustain',\n",
       " 'sustain',\n",
       " 'neutral',\n",
       " 'neutral',\n",
       " 'neutral',\n",
       " 'neutral',\n",
       " 'change',\n",
       " 'sustain',\n",
       " 'neutral',\n",
       " 'change',\n",
       " 'neutral',\n",
       " 'sustain',\n",
       " 'sustain',\n",
       " 'neutral',\n",
       " 'neutral',\n",
       " 'change',\n",
       " 'sustain',\n",
       " 'sustain',\n",
       " 'change',\n",
       " 'sustain',\n",
       " 'neutral',\n",
       " 'change',\n",
       " 'change',\n",
       " 'neutral',\n",
       " 'neutral',\n",
       " 'change',\n",
       " 'neutral',\n",
       " 'change',\n",
       " 'neutral',\n",
       " 'neutral',\n",
       " 'neutral',\n",
       " 'neutral',\n",
       " 'neutral',\n",
       " 'sustain',\n",
       " 'neutral',\n",
       " 'sustain',\n",
       " 'sustain',\n",
       " 'sustain',\n",
       " 'sustain',\n",
       " 'sustain',\n",
       " 'neutral',\n",
       " 'neutral',\n",
       " 'change',\n",
       " 'change',\n",
       " 'neutral',\n",
       " 'change',\n",
       " 'sustain',\n",
       " 'change',\n",
       " 'change',\n",
       " 'change',\n",
       " 'change',\n",
       " 'change',\n",
       " 'neutral',\n",
       " 'neutral',\n",
       " 'neutral',\n",
       " 'change',\n",
       " 'change',\n",
       " 'change',\n",
       " 'neutral',\n",
       " 'change',\n",
       " 'neutral',\n",
       " 'sustain',\n",
       " 'change',\n",
       " 'change',\n",
       " 'sustain',\n",
       " 'change',\n",
       " 'change',\n",
       " 'neutral',\n",
       " 'neutral',\n",
       " 'sustain',\n",
       " 'neutral',\n",
       " 'change',\n",
       " 'neutral',\n",
       " 'neutral',\n",
       " 'change',\n",
       " 'neutral',\n",
       " 'change',\n",
       " 'change',\n",
       " 'change',\n",
       " 'change',\n",
       " 'change',\n",
       " 'change',\n",
       " 'change',\n",
       " 'change',\n",
       " 'change',\n",
       " 'change',\n",
       " 'change',\n",
       " 'change',\n",
       " 'change',\n",
       " 'neutral',\n",
       " 'neutral',\n",
       " 'change',\n",
       " 'change',\n",
       " 'neutral',\n",
       " 'change',\n",
       " 'change',\n",
       " 'change',\n",
       " 'change',\n",
       " 'change',\n",
       " 'change',\n",
       " 'change',\n",
       " 'neutral',\n",
       " 'neutral',\n",
       " 'neutral',\n",
       " 'change',\n",
       " 'change',\n",
       " 'change',\n",
       " 'change',\n",
       " 'change',\n",
       " 'change',\n",
       " 'change',\n",
       " 'neutral',\n",
       " 'neutral',\n",
       " 'change',\n",
       " 'neutral',\n",
       " 'neutral',\n",
       " 'neutral',\n",
       " 'change',\n",
       " 'neutral',\n",
       " 'neutral',\n",
       " 'neutral',\n",
       " 'neutral',\n",
       " 'neutral',\n",
       " 'change',\n",
       " 'change',\n",
       " 'change',\n",
       " 'change',\n",
       " 'change',\n",
       " 'change',\n",
       " 'change',\n",
       " 'change',\n",
       " 'change',\n",
       " 'change',\n",
       " 'neutral',\n",
       " 'sustain',\n",
       " 'neutral',\n",
       " 'change',\n",
       " 'change',\n",
       " 'change',\n",
       " 'change',\n",
       " 'change',\n",
       " 'change',\n",
       " 'neutral',\n",
       " 'sustain',\n",
       " 'change',\n",
       " 'change',\n",
       " 'change',\n",
       " 'change',\n",
       " 'neutral',\n",
       " 'change',\n",
       " 'neutral',\n",
       " 'change',\n",
       " 'change',\n",
       " 'change',\n",
       " 'change',\n",
       " 'change',\n",
       " 'change',\n",
       " 'sustain',\n",
       " 'sustain',\n",
       " 'neutral',\n",
       " 'neutral',\n",
       " 'sustain',\n",
       " 'neutral',\n",
       " 'neutral',\n",
       " 'neutral',\n",
       " 'neutral',\n",
       " 'neutral',\n",
       " 'sustain',\n",
       " 'neutral',\n",
       " 'neutral',\n",
       " 'change',\n",
       " 'change',\n",
       " 'neutral',\n",
       " 'neutral',\n",
       " 'sustain',\n",
       " 'neutral',\n",
       " 'neutral',\n",
       " 'neutral',\n",
       " 'change',\n",
       " 'change',\n",
       " 'neutral',\n",
       " 'neutral',\n",
       " 'neutral',\n",
       " 'change',\n",
       " 'neutral',\n",
       " 'change',\n",
       " 'change',\n",
       " 'change',\n",
       " 'change',\n",
       " 'change',\n",
       " 'change',\n",
       " 'change',\n",
       " 'change',\n",
       " 'change',\n",
       " 'change',\n",
       " 'change',\n",
       " 'change',\n",
       " 'neutral',\n",
       " 'neutral',\n",
       " 'neutral',\n",
       " 'neutral',\n",
       " 'neutral',\n",
       " 'neutral',\n",
       " 'neutral',\n",
       " 'change',\n",
       " 'neutral',\n",
       " 'neutral',\n",
       " 'neutral',\n",
       " 'neutral',\n",
       " 'neutral',\n",
       " 'neutral',\n",
       " 'neutral',\n",
       " 'neutral',\n",
       " 'change',\n",
       " 'neutral',\n",
       " 'neutral',\n",
       " 'neutral',\n",
       " 'sustain',\n",
       " 'neutral',\n",
       " 'neutral',\n",
       " 'neutral',\n",
       " 'neutral',\n",
       " 'sustain',\n",
       " 'neutral',\n",
       " 'neutral',\n",
       " 'neutral',\n",
       " 'neutral',\n",
       " 'neutral',\n",
       " 'sustain',\n",
       " 'neutral',\n",
       " 'neutral',\n",
       " 'neutral',\n",
       " 'neutral',\n",
       " 'neutral',\n",
       " 'neutral',\n",
       " 'neutral',\n",
       " 'neutral',\n",
       " 'neutral',\n",
       " 'neutral',\n",
       " 'neutral',\n",
       " 'sustain',\n",
       " 'neutral',\n",
       " 'neutral',\n",
       " 'neutral',\n",
       " 'neutral',\n",
       " 'change',\n",
       " 'change',\n",
       " 'change',\n",
       " 'change',\n",
       " 'neutral',\n",
       " 'neutral',\n",
       " 'neutral',\n",
       " 'neutral',\n",
       " 'neutral',\n",
       " 'neutral',\n",
       " 'neutral',\n",
       " 'neutral',\n",
       " 'sustain',\n",
       " 'sustain',\n",
       " 'sustain',\n",
       " 'neutral',\n",
       " 'neutral',\n",
       " 'sustain',\n",
       " 'sustain',\n",
       " 'sustain',\n",
       " 'neutral',\n",
       " 'neutral',\n",
       " 'sustain',\n",
       " 'neutral',\n",
       " 'neutral',\n",
       " 'change',\n",
       " 'change',\n",
       " 'neutral',\n",
       " 'sustain',\n",
       " 'neutral',\n",
       " 'change',\n",
       " 'change',\n",
       " 'change',\n",
       " 'change',\n",
       " 'change',\n",
       " 'change',\n",
       " 'change',\n",
       " 'change',\n",
       " 'change',\n",
       " 'change',\n",
       " 'neutral',\n",
       " 'neutral',\n",
       " 'neutral',\n",
       " 'neutral',\n",
       " 'sustain',\n",
       " 'sustain',\n",
       " 'neutral',\n",
       " 'sustain',\n",
       " 'sustain',\n",
       " 'sustain',\n",
       " 'sustain',\n",
       " 'sustain',\n",
       " 'change',\n",
       " 'sustain',\n",
       " 'change',\n",
       " 'sustain',\n",
       " 'sustain',\n",
       " 'sustain',\n",
       " 'neutral',\n",
       " 'change',\n",
       " 'change',\n",
       " 'neutral',\n",
       " 'change',\n",
       " 'change',\n",
       " 'change',\n",
       " 'neutral',\n",
       " 'change',\n",
       " 'neutral',\n",
       " 'neutral',\n",
       " 'neutral',\n",
       " 'neutral',\n",
       " 'neutral',\n",
       " 'change',\n",
       " 'change',\n",
       " 'change',\n",
       " 'change',\n",
       " 'neutral',\n",
       " 'change',\n",
       " 'change',\n",
       " 'change',\n",
       " 'change',\n",
       " 'neutral',\n",
       " 'change',\n",
       " 'change',\n",
       " 'change',\n",
       " 'change',\n",
       " 'change',\n",
       " 'neutral',\n",
       " 'neutral',\n",
       " 'change',\n",
       " 'neutral',\n",
       " 'neutral',\n",
       " 'change',\n",
       " 'change',\n",
       " 'change',\n",
       " 'change',\n",
       " 'neutral',\n",
       " 'neutral',\n",
       " 'neutral',\n",
       " 'change',\n",
       " 'change',\n",
       " 'neutral',\n",
       " 'neutral',\n",
       " 'change',\n",
       " 'neutral',\n",
       " 'neutral',\n",
       " 'neutral',\n",
       " 'neutral',\n",
       " 'neutral',\n",
       " 'neutral',\n",
       " 'change',\n",
       " 'change',\n",
       " 'change',\n",
       " 'neutral',\n",
       " 'neutral',\n",
       " 'change',\n",
       " 'sustain',\n",
       " 'sustain',\n",
       " 'neutral',\n",
       " 'neutral',\n",
       " 'change',\n",
       " 'sustain',\n",
       " 'neutral',\n",
       " 'sustain',\n",
       " 'change',\n",
       " 'neutral',\n",
       " 'change',\n",
       " 'neutral',\n",
       " 'sustain',\n",
       " 'sustain',\n",
       " 'sustain',\n",
       " 'neutral',\n",
       " 'change',\n",
       " 'neutral',\n",
       " 'neutral',\n",
       " 'change',\n",
       " 'neutral',\n",
       " 'neutral',\n",
       " 'neutral',\n",
       " 'change',\n",
       " 'neutral',\n",
       " 'neutral',\n",
       " 'change',\n",
       " 'change',\n",
       " 'sustain',\n",
       " 'change',\n",
       " 'sustain',\n",
       " 'sustain',\n",
       " 'sustain',\n",
       " 'neutral',\n",
       " 'neutral',\n",
       " 'change',\n",
       " 'sustain',\n",
       " 'neutral',\n",
       " 'sustain',\n",
       " 'change',\n",
       " 'change',\n",
       " 'neutral',\n",
       " 'sustain',\n",
       " 'sustain',\n",
       " 'sustain',\n",
       " 'change',\n",
       " 'sustain',\n",
       " 'change',\n",
       " 'change',\n",
       " 'neutral',\n",
       " 'neutral',\n",
       " 'change',\n",
       " 'change',\n",
       " 'neutral',\n",
       " 'neutral',\n",
       " 'change',\n",
       " 'change',\n",
       " 'change',\n",
       " 'neutral',\n",
       " 'neutral',\n",
       " 'neutral',\n",
       " 'neutral',\n",
       " 'sustain',\n",
       " 'sustain',\n",
       " 'sustain',\n",
       " 'sustain',\n",
       " 'neutral',\n",
       " 'sustain',\n",
       " 'sustain',\n",
       " 'neutral',\n",
       " 'change',\n",
       " 'neutral',\n",
       " 'neutral',\n",
       " 'change',\n",
       " 'neutral',\n",
       " 'sustain',\n",
       " 'neutral',\n",
       " 'neutral',\n",
       " 'change',\n",
       " 'neutral',\n",
       " 'change',\n",
       " 'neutral',\n",
       " 'neutral',\n",
       " 'neutral',\n",
       " 'neutral',\n",
       " 'neutral',\n",
       " 'neutral',\n",
       " 'neutral',\n",
       " 'change',\n",
       " 'change',\n",
       " 'change',\n",
       " 'change',\n",
       " 'change',\n",
       " 'neutral',\n",
       " 'neutral',\n",
       " 'change',\n",
       " 'change',\n",
       " 'change',\n",
       " 'change',\n",
       " 'change',\n",
       " 'neutral',\n",
       " 'change',\n",
       " 'neutral',\n",
       " 'change',\n",
       " 'change',\n",
       " 'neutral',\n",
       " 'neutral',\n",
       " 'change',\n",
       " 'neutral',\n",
       " 'change',\n",
       " 'change',\n",
       " 'change',\n",
       " 'change',\n",
       " 'change',\n",
       " 'change',\n",
       " 'change',\n",
       " 'neutral',\n",
       " 'neutral',\n",
       " 'neutral',\n",
       " 'neutral',\n",
       " 'neutral',\n",
       " 'neutral',\n",
       " 'neutral',\n",
       " 'change',\n",
       " 'neutral',\n",
       " 'neutral',\n",
       " 'neutral',\n",
       " 'change',\n",
       " 'neutral',\n",
       " 'neutral',\n",
       " 'neutral',\n",
       " 'neutral',\n",
       " 'neutral',\n",
       " 'neutral',\n",
       " 'neutral',\n",
       " 'sustain',\n",
       " 'change',\n",
       " 'sustain',\n",
       " 'neutral',\n",
       " 'neutral',\n",
       " 'sustain',\n",
       " 'sustain',\n",
       " 'neutral',\n",
       " 'neutral',\n",
       " 'neutral',\n",
       " 'neutral',\n",
       " 'neutral',\n",
       " 'neutral',\n",
       " 'neutral',\n",
       " 'neutral',\n",
       " 'sustain',\n",
       " 'neutral',\n",
       " 'neutral',\n",
       " 'sustain',\n",
       " 'sustain',\n",
       " 'sustain',\n",
       " 'neutral',\n",
       " 'sustain',\n",
       " 'neutral',\n",
       " 'neutral',\n",
       " 'change',\n",
       " 'neutral',\n",
       " 'neutral',\n",
       " 'change',\n",
       " 'sustain',\n",
       " 'neutral',\n",
       " 'neutral',\n",
       " 'sustain',\n",
       " 'neutral',\n",
       " 'neutral',\n",
       " 'neutral',\n",
       " 'sustain',\n",
       " 'neutral',\n",
       " 'neutral',\n",
       " 'sustain',\n",
       " 'sustain',\n",
       " 'neutral',\n",
       " 'sustain',\n",
       " 'neutral',\n",
       " 'neutral',\n",
       " 'neutral',\n",
       " 'neutral',\n",
       " 'neutral',\n",
       " 'neutral',\n",
       " 'sustain',\n",
       " 'neutral',\n",
       " 'neutral',\n",
       " 'sustain',\n",
       " 'neutral',\n",
       " 'neutral',\n",
       " 'change',\n",
       " 'neutral',\n",
       " 'neutral',\n",
       " 'neutral',\n",
       " 'sustain',\n",
       " 'neutral',\n",
       " 'neutral',\n",
       " 'sustain',\n",
       " 'change',\n",
       " 'neutral',\n",
       " 'neutral',\n",
       " 'neutral',\n",
       " 'neutral',\n",
       " 'neutral',\n",
       " 'neutral',\n",
       " 'neutral',\n",
       " 'neutral',\n",
       " 'neutral',\n",
       " 'neutral',\n",
       " 'neutral',\n",
       " 'neutral',\n",
       " 'neutral',\n",
       " 'neutral',\n",
       " 'neutral',\n",
       " 'neutral',\n",
       " 'neutral',\n",
       " 'neutral',\n",
       " 'neutral',\n",
       " 'neutral',\n",
       " 'neutral',\n",
       " 'change',\n",
       " 'neutral',\n",
       " 'change',\n",
       " 'neutral',\n",
       " 'neutral',\n",
       " 'neutral',\n",
       " 'neutral',\n",
       " 'neutral',\n",
       " 'neutral',\n",
       " 'neutral',\n",
       " 'sustain',\n",
       " 'sustain',\n",
       " 'sustain',\n",
       " 'sustain',\n",
       " 'sustain',\n",
       " 'sustain',\n",
       " 'sustain',\n",
       " 'sustain',\n",
       " 'sustain',\n",
       " 'sustain',\n",
       " 'sustain',\n",
       " 'sustain',\n",
       " 'sustain',\n",
       " 'sustain',\n",
       " 'sustain',\n",
       " 'sustain',\n",
       " 'sustain',\n",
       " 'sustain',\n",
       " 'sustain',\n",
       " 'sustain',\n",
       " 'sustain',\n",
       " 'sustain',\n",
       " 'sustain',\n",
       " 'sustain',\n",
       " 'sustain',\n",
       " 'sustain',\n",
       " 'sustain',\n",
       " 'sustain',\n",
       " 'sustain',\n",
       " 'sustain',\n",
       " 'sustain',\n",
       " 'sustain',\n",
       " 'sustain',\n",
       " 'sustain',\n",
       " 'sustain',\n",
       " 'sustain',\n",
       " 'sustain',\n",
       " 'sustain',\n",
       " 'sustain',\n",
       " 'sustain',\n",
       " 'neutral',\n",
       " 'sustain',\n",
       " 'sustain',\n",
       " 'sustain',\n",
       " 'change',\n",
       " 'neutral',\n",
       " 'neutral',\n",
       " 'neutral',\n",
       " 'neutral',\n",
       " 'neutral',\n",
       " 'neutral',\n",
       " 'neutral',\n",
       " 'neutral',\n",
       " 'neutral',\n",
       " 'neutral',\n",
       " 'neutral',\n",
       " 'neutral',\n",
       " 'neutral',\n",
       " 'neutral',\n",
       " 'neutral',\n",
       " 'neutral',\n",
       " 'neutral',\n",
       " 'neutral',\n",
       " 'neutral',\n",
       " 'neutral',\n",
       " 'neutral',\n",
       " 'neutral',\n",
       " 'neutral',\n",
       " 'neutral',\n",
       " 'neutral',\n",
       " 'neutral',\n",
       " 'neutral',\n",
       " 'neutral',\n",
       " 'neutral',\n",
       " 'neutral',\n",
       " 'neutral',\n",
       " 'neutral',\n",
       " 'neutral',\n",
       " 'neutral',\n",
       " 'neutral',\n",
       " 'neutral',\n",
       " 'neutral',\n",
       " 'neutral',\n",
       " 'neutral',\n",
       " 'neutral',\n",
       " 'neutral',\n",
       " 'neutral',\n",
       " 'neutral',\n",
       " 'neutral',\n",
       " 'neutral',\n",
       " 'neutral',\n",
       " 'neutral',\n",
       " 'neutral',\n",
       " 'neutral',\n",
       " 'neutral',\n",
       " 'neutral',\n",
       " 'change',\n",
       " 'neutral',\n",
       " 'change',\n",
       " 'change',\n",
       " 'change',\n",
       " 'neutral',\n",
       " 'sustain',\n",
       " 'neutral',\n",
       " 'neutral',\n",
       " 'neutral',\n",
       " 'neutral',\n",
       " 'neutral',\n",
       " 'change',\n",
       " 'change',\n",
       " 'change',\n",
       " 'change',\n",
       " 'change',\n",
       " 'neutral',\n",
       " 'neutral',\n",
       " 'neutral',\n",
       " 'neutral',\n",
       " 'neutral',\n",
       " 'change',\n",
       " 'change',\n",
       " 'change',\n",
       " 'change',\n",
       " 'change',\n",
       " 'change',\n",
       " 'neutral',\n",
       " 'change',\n",
       " 'change',\n",
       " 'change',\n",
       " 'neutral',\n",
       " 'neutral',\n",
       " 'change',\n",
       " 'change',\n",
       " 'neutral',\n",
       " 'neutral',\n",
       " 'neutral',\n",
       " 'neutral',\n",
       " 'neutral',\n",
       " 'neutral',\n",
       " 'neutral',\n",
       " 'neutral',\n",
       " 'neutral',\n",
       " 'neutral',\n",
       " 'neutral',\n",
       " 'neutral',\n",
       " 'neutral',\n",
       " 'neutral',\n",
       " 'neutral',\n",
       " 'neutral',\n",
       " 'neutral',\n",
       " 'neutral',\n",
       " 'neutral',\n",
       " 'neutral',\n",
       " 'neutral',\n",
       " 'neutral',\n",
       " 'neutral',\n",
       " 'neutral',\n",
       " 'neutral',\n",
       " 'neutral',\n",
       " ...]"
      ]
     },
     "execution_count": 145,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "fine_tune_bert.dataset_split[\"test\"][\"client_talk_type\"]"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "id": "da4ff92d",
   "metadata": {},
   "source": [
    "# SWNU Network"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "id": "32ae1a72",
   "metadata": {},
   "source": [
    "## Obtaining path by looking at post history\n",
    "\n",
    "We can obtain a path by looking at the history of each post. Here we look at the last 10 posts (and pad with vectors of zeros if there are less than 10 posts) including the current post.\n",
    "\n",
    "We only want to consider paths that correspond to a client's utterance as we want to model a change in mood at that time. Their history will still contain the therapist's utterances too."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "id": "90bfd87c",
   "metadata": {},
   "outputs": [],
   "source": [
    "time_features = [\"time_encoding\", \"timeline_index\"]\n",
    "standardise_method = [\"minmax\", None]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "9cf4e16c",
   "metadata": {},
   "outputs": [],
   "source": [
    "sig_depths = [2,3]\n",
    "dim_reduce_methods = [\"gaussian_random_projection\", \"umap\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "43dbc33f",
   "metadata": {},
   "outputs": [],
   "source": [
    "output_dim = len(label_to_id)\n",
    "lstm_hidden_dims = [[8,8], [12,12,8]]\n",
    "num_time_features = len(time_features)\n",
    "conv_output_channels = [20, 10, 5]\n",
    "learning_rate = 1e-4"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "9a9b2b2c",
   "metadata": {},
   "outputs": [],
   "source": [
    "embedding_dim = 384\n",
    "dimensions = [embedding_dim, 100, 50, 30]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "id": "902bca70",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "110"
      ]
     },
     "execution_count": 29,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "signatory.signature_channels(10, 2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "id": "c60459fb",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "650"
      ]
     },
     "execution_count": 30,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "signatory.logsignature_channels(12, 3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "id": "4c47bcb3",
   "metadata": {},
   "outputs": [],
   "source": [
    "import math\n",
    "signature_dimensions_and_sig_depths = [(math.ceil(19/2), 2), (math.ceil(7/2), 3)]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "id": "a1785d16",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[(10, 2), (4, 3)]"
      ]
     },
     "execution_count": 32,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "signature_dimensions_and_sig_depths"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "id": "7b5652fc",
   "metadata": {},
   "outputs": [],
   "source": [
    "log_signature_dimensions_and_sig_depths = [(28, 2), (10, 3), (6, 4)]\n",
    "bilstm_log_signature_dimensions_and_sig_depths = [(int(28/2), 2), (int(10/2), 3), (int(6/2), 4)]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7d472e69",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "id": "37f1fc01",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[(28, 2), (10, 3), (6, 4)]"
      ]
     },
     "execution_count": 34,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "log_signature_dimensions_and_sig_depths"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "id": "deef95e4",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[(14, 2), (5, 3), (3, 4)]"
      ]
     },
     "execution_count": 35,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "bilstm_log_signature_dimensions_and_sig_depths"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "id": "ab9d6409",
   "metadata": {},
   "outputs": [],
   "source": [
    "from __future__ import annotations\n",
    "\n",
    "import nlpsig\n",
    "from nlpsig.classification_utils import DataSplits, Folds\n",
    "from nlpsig_networks.pytorch_utils import SaveBestModel, training_pytorch, testing_pytorch, set_seed, KFold_pytorch\n",
    "from nlpsig_networks.snwu_network import SWNUNetwork\n",
    "from nlpsig_networks.focal_loss import FocalLoss\n",
    "import torch\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "from tqdm.auto import tqdm\n",
    "import os\n",
    "\n",
    "\n",
    "def obtain_SWNUNetwork_input(\n",
    "    method: str,\n",
    "    dimension: int,\n",
    "    df: pd.DataFrame,\n",
    "    id_column: str,\n",
    "    label_column: str,\n",
    "    embeddings: np.array,\n",
    "    k: int,\n",
    "    time_feature: list[str] | str | None = None,\n",
    "    standardise_method: list[str] | str | None = None,\n",
    "    seed: int = 42,\n",
    "    path_indices: np.array | None = None\n",
    ") -> tuple[torch.tensor, int]:\n",
    "    # use nlpsig to construct the path as a numpy array\n",
    "    # first define how we construct the path\n",
    "    path_specifics = {\"pad_by\": \"history\",\n",
    "                      \"zero_padding\": True,\n",
    "                      \"method\": \"k_last\",\n",
    "                      \"k\": k,\n",
    "                      \"time_feature\": time_feature,\n",
    "                      \"standardise_method\": standardise_method,\n",
    "                      \"embeddings\": \"dim_reduced\",\n",
    "                      \"include_current_embedding\": True}\n",
    "    \n",
    "    # first perform dimension reduction on embeddings\n",
    "    if dimension == embeddings.shape[1]:\n",
    "        # no need to perform dimensionality reduction\n",
    "        embeddings_reduced = embeddings\n",
    "    else:\n",
    "        reduction = nlpsig.DimReduce(method=method,\n",
    "                                     n_components=dimension)\n",
    "        embeddings_reduced = reduction.fit_transform(embeddings,\n",
    "                                                     random_state=seed)\n",
    "    \n",
    "    # obtain path by using PrepareData class and .pad method\n",
    "    paths = nlpsig.PrepareData(df,\n",
    "                               id_column=id_column,\n",
    "                               label_column=label_column,\n",
    "                               embeddings=embeddings,\n",
    "                               embeddings_reduced=embeddings_reduced)\n",
    "    paths.pad(**path_specifics)\n",
    "    \n",
    "    # slice the path in specified way\n",
    "    if path_indices is not None:\n",
    "        paths.array_padded = paths.array_padded[path_indices]\n",
    "        paths.embeddings = paths.embeddings[path_indices]\n",
    "        paths.embeddings_reduced = paths.embeddings_reduced[path_indices]\n",
    "    \n",
    "    return paths.get_torch_path_for_SWNUNetwork(\n",
    "        include_time_features_in_path=True,\n",
    "        include_time_features_in_input=True,\n",
    "        include_embedding_in_input=True,\n",
    "        reduced_embeddings=False\n",
    "    )\n",
    "    \n",
    "def implement_swnu_network(\n",
    "    num_epochs: int,\n",
    "    x_data: torch.tensor | np.array,\n",
    "    y_data: torch.tensor | np.array,\n",
    "    input_channels: int,\n",
    "    output_channels: int,\n",
    "    num_time_features: int,\n",
    "    embedding_dim: int,\n",
    "    log_signature: bool,\n",
    "    sig_depth: int,\n",
    "    lstm_hidden_dim: list[int] | int,\n",
    "    ffn_hidden_dim: list[int] | int,\n",
    "    output_dim: int,\n",
    "    BiLSTM: bool,\n",
    "    dropout_rate: float,\n",
    "    learning_rate: float,\n",
    "    seed: int,\n",
    "    loss: str,\n",
    "    gamma: float = 0.0,\n",
    "    augmentation_type: str = \"Conv1d\",\n",
    "    comb_method: str = \"concatenation\",\n",
    "    data_split_seed: int = 0,\n",
    "    k_fold: bool = False,\n",
    "    n_splits: int = 5,\n",
    "    verbose_training: bool = True,\n",
    "    verbose_results: bool = True,\n",
    "    verbose_model: bool = False,\n",
    ") -> tuple[SWNUNetwork, pd.DataFrame]:\n",
    "    # set seed\n",
    "    set_seed(seed)\n",
    "    \n",
    "    # initialise SWNUNetwork\n",
    "    SWNUNetwork_args = {\n",
    "        \"input_channels\": input_channels,\n",
    "        \"output_channels\": output_channels,\n",
    "        \"num_time_features\": num_time_features,\n",
    "        \"embedding_dim\": embedding_dim,\n",
    "        \"log_signature\": log_signature,\n",
    "        \"sig_depth\": sig_depth,\n",
    "        \"hidden_dim_swnu\": lstm_hidden_dim,\n",
    "        \"hidden_dim_ffn\": ffn_hidden_dim,\n",
    "        \"output_dim\": output_dim,\n",
    "        \"dropout_rate\": dropout_rate,\n",
    "        \"augmentation_type\": augmentation_type,\n",
    "        \"BiLSTM\": BiLSTM,\n",
    "        \"comb_method\": comb_method\n",
    "    }\n",
    "    swnu_network_model = SWNUNetwork(**SWNUNetwork_args)\n",
    "    \n",
    "    if verbose_model:\n",
    "        print(swnu_network_model)\n",
    "    \n",
    "    # convert data to torch tensors\n",
    "    if not isinstance(x_data, torch.Tensor):\n",
    "        x_data = torch.tensor(x_data)\n",
    "    if not isinstance(y_data, torch.Tensor):\n",
    "        y_data = torch.tensor(y_data)\n",
    "    x_data = x_data.float()\n",
    "    \n",
    "    # set some variables for training\n",
    "    save_best = True\n",
    "    early_stopping = True\n",
    "    model_output = \"best_model.pkl\"\n",
    "    validation_metric = \"f1\"\n",
    "    patience = 10\n",
    "    \n",
    "    if k_fold:\n",
    "        # perform KFold evaluation and return the performance on validation and test sets\n",
    "        # split dataset\n",
    "        folds = Folds(x_data=x_data,\n",
    "                      y_data=y_data,\n",
    "                      n_splits=n_splits,\n",
    "                      shuffle=True,\n",
    "                      random_state=data_split_seed)\n",
    "        \n",
    "         # define loss\n",
    "        if loss == \"focal\":\n",
    "            criterion = FocalLoss(gamma = gamma)\n",
    "        elif loss == \"cross_entropy\":\n",
    "            criterion = torch.nn.CrossEntropyLoss()\n",
    "        else:\n",
    "            raise ValueError(\"criterion must be either 'focal' or 'cross_entropy'\")\n",
    "\n",
    "        # define optimizer\n",
    "        optimizer = torch.optim.Adam(swnu_network_model.parameters(), lr=learning_rate)\n",
    "        \n",
    "        # perform k-fold evaluation which returns a dataframe with columns for the\n",
    "        # loss, accuracy, f1 (macro) and individual f1-scores for each fold\n",
    "        # (for both validation and test set)\n",
    "        results = KFold_pytorch(folds=folds,\n",
    "                                model=swnu_network_model,\n",
    "                                criterion=criterion,\n",
    "                                optimizer=optimizer,\n",
    "                                num_epochs=num_epochs,\n",
    "                                seed=seed,\n",
    "                                save_best=save_best,\n",
    "                                early_stopping=early_stopping,\n",
    "                                validation_metric=validation_metric,\n",
    "                                patience=patience,\n",
    "                                verbose=verbose_training)\n",
    "    else:\n",
    "        # split dataset\n",
    "        split_data = DataSplits(x_data=x_data,\n",
    "                                y_data=y_data,\n",
    "                                train_size=0.8,\n",
    "                                valid_size=0.2,\n",
    "                                shuffle=True,\n",
    "                                random_state=data_split_seed)\n",
    "        train, valid, test = split_data.get_splits(as_DataLoader=True)\n",
    "\n",
    "        # define loss\n",
    "        if loss == \"focal\":\n",
    "            criterion = FocalLoss(gamma = gamma)\n",
    "            y_train = split_data.get_splits(as_DataLoader=False)[1]\n",
    "            criterion.set_alpha_from_y(y=y_train)\n",
    "        elif loss == \"cross_entropy\":\n",
    "            criterion = torch.nn.CrossEntropyLoss()\n",
    "        else:\n",
    "            raise ValueError(\"criterion must be either 'focal' or 'cross_entropy'\")\n",
    "\n",
    "        # define optimizer\n",
    "        optimizer = torch.optim.Adam(swnu_network_model.parameters(), lr=learning_rate)\n",
    "        \n",
    "        # train FFN\n",
    "        swnu_network_model = training_pytorch(model=swnu_network_model,\n",
    "                                      train_loader=train,\n",
    "                                      criterion=criterion,\n",
    "                                      optimizer=optimizer,\n",
    "                                      num_epochs=num_epochs,\n",
    "                                      valid_loader=valid,\n",
    "                                      seed=seed,\n",
    "                                      save_best=save_best,\n",
    "                                      output=model_output,\n",
    "                                      early_stopping=early_stopping,\n",
    "                                      validation_metric=validation_metric,\n",
    "                                      patience=patience,\n",
    "                                      verbose=verbose_training)\n",
    "        \n",
    "        # evaluate on validation\n",
    "        test_results = testing_pytorch(model=swnu_network_model,\n",
    "                                       test_loader=test,\n",
    "                                       criterion=criterion,\n",
    "                                       verbose=False)\n",
    "        \n",
    "        # evaluate on test\n",
    "        valid_results = testing_pytorch(model=swnu_network_model,\n",
    "                                        test_loader=valid,\n",
    "                                        criterion=criterion)\n",
    "        \n",
    "        results = pd.DataFrame({\"loss\": test_results[\"loss\"],\n",
    "                                \"accuracy\": test_results[\"accuracy\"], \n",
    "                                \"f1\": test_results[\"f1\"],\n",
    "                                \"f1_scores\": test_results[\"f1_scores\"],\n",
    "                                \"valid_loss\": valid_results[\"loss\"],\n",
    "                                \"valid_accuracy\": valid_results[\"accuracy\"], \n",
    "                                \"valid_f1\": valid_results[\"f1\"],\n",
    "                                \"valid_f1_scores\": valid_results[\"f1_scores\"]})\n",
    "\n",
    "    if verbose_results:\n",
    "        with pd.option_context('display.precision', 3):\n",
    "            print(results)\n",
    "            \n",
    "    # remove any models that have been saved\n",
    "    if os.path.exists(model_output):\n",
    "        os.remove(model_output)\n",
    "        \n",
    "    return swnu_network_model, results\n",
    "\n",
    "\n",
    "def swnu_network_hyperparameter_search(\n",
    "    num_epochs: int,\n",
    "    df: pd.DataFrame,\n",
    "    id_column: str,\n",
    "    label_column: str,\n",
    "    embeddings: np.array,\n",
    "    y_data: np.array,\n",
    "    embedding_dim: int,\n",
    "    output_dim: int,\n",
    "    window_sizes: list[int],\n",
    "    dim_reduce_methods: list[str],\n",
    "    dimensions: list[int],\n",
    "    sig_depths: list[int],\n",
    "    log_signature: bool,\n",
    "    conv_output_channels: list[int],\n",
    "    swnu_hidden_dim_sizes: list[int] | list[list[int]],\n",
    "    ffn_hidden_dim_sizes: list[int] | list[list[int]],\n",
    "    dropout_rates: list[float],\n",
    "    learning_rates: list[float],\n",
    "    BiLSTM,\n",
    "    seeds : list[int],\n",
    "    loss: str,\n",
    "    gamma: float = 0.0,\n",
    "    time_feature: list[str] | str | None = None,\n",
    "    standardise_method: list[str] | str | None = None,\n",
    "    augmentation_type: str = \"Conv1d\",\n",
    "    comb_method: str = \"concatenation\",\n",
    "    path_indices: np.array | None = None,\n",
    "    data_split_seed: int = 0,\n",
    "    k_fold: bool = False,\n",
    "    n_splits: int = 5,\n",
    "    validation_metric: str = \"f1\",\n",
    "    results_output: str | None = None,\n",
    "    verbose: bool = True\n",
    "):\n",
    "    if validation_metric not in [\"loss\", \"accuracy\", \"f1\"]:\n",
    "        raise ValueError(\"validation_metric must be either 'loss', 'accuracy' or 'f1'\")\n",
    "    \n",
    "    # initialise SaveBestModel class\n",
    "    model_output = \"best_swnu_network_model.pkl\",\n",
    "    save_best_model = SaveBestModel(metric=validation_metric,\n",
    "                                    output=model_output,\n",
    "                                    verbose=verbose)\n",
    "    \n",
    "    results_df = pd.DataFrame()\n",
    "    model_id = 0\n",
    "    \n",
    "    for k in tqdm(window_sizes):\n",
    "        if verbose:\n",
    "            print(\"\\n\" + \"-\" * 50)\n",
    "            print(f\"k: {k}\")\n",
    "        for dimension in tqdm(dimensions):\n",
    "            for method in tqdm(dim_reduce_methods):\n",
    "                print(\"\\n\" + \"#\" * 50)\n",
    "                print(f\"dimension: {dimension} | \"\n",
    "                      f\"method: {method}\")\n",
    "                x_data, input_channels = obtain_SWNUNetwork_input(\n",
    "                    method=method,\n",
    "                    dimension=dimension,\n",
    "                    df=df,\n",
    "                    id_column=id_column,\n",
    "                    label_column=label_column,\n",
    "                    embeddings=embeddings,\n",
    "                    k=k,\n",
    "                    time_feature=time_feature,\n",
    "                    standardise_method=standardise_method,\n",
    "                    path_indices=path_indices\n",
    "                )\n",
    "        \n",
    "                for lstm_hidden_dim in tqdm(swnu_hidden_dim_sizes):\n",
    "                    for ffn_hidden_dim in tqdm(ffn_hidden_dim_sizes):\n",
    "                        for sig_depth in sig_depths:\n",
    "                            for output_channels in tqdm(conv_output_channels):\n",
    "                                for dropout in tqdm(dropout_rates):\n",
    "                                    for lr in tqdm(learning_rates):\n",
    "                                        if verbose:\n",
    "                                            print(\"\\n\" + \"!\" * 50)\n",
    "                                            print(f\"lstm_hidden_dim: {lstm_hidden_dim} | \"\n",
    "                                                  f\"ffn_hidden_dim: {ffn_hidden_dim} | \"\n",
    "                                                  f\"sig_depth: {sig_depth} | \"\n",
    "                                                  f\"output_channels: {output_channels} | \"\n",
    "                                                  f\"dropout: {dropout} | \"\n",
    "                                                  f\"learning_rate: {lr}\")\n",
    "                                        scores = []\n",
    "                                        verbose_model = verbose\n",
    "                                        for seed in seeds:\n",
    "                                            _, results = implement_swnu_network(\n",
    "                                                num_epochs=num_epochs,\n",
    "                                                x_data=x_data,\n",
    "                                                y_data=y_data,\n",
    "                                                input_channels=input_channels,\n",
    "                                                output_channels=output_channels,\n",
    "                                                num_time_features=len(time_feature),\n",
    "                                                embedding_dim=embedding_dim,\n",
    "                                                log_signature=log_signature,\n",
    "                                                sig_depth=sig_depth,\n",
    "                                                lstm_hidden_dim=lstm_hidden_dim,\n",
    "                                                ffn_hidden_dim=ffn_hidden_dim,\n",
    "                                                output_dim=output_dim,\n",
    "                                                BiLSTM=BiLSTM,\n",
    "                                                dropout_rate=dropout,\n",
    "                                                learning_rate=lr,\n",
    "                                                seed=seed,\n",
    "                                                loss=loss,\n",
    "                                                gamma=gamma,\n",
    "                                                augmentation_type=augmentation_type,\n",
    "                                                comb_method=comb_method,\n",
    "                                                data_split_seed=data_split_seed,\n",
    "                                                k_fold=k_fold,\n",
    "                                                n_splits=n_splits,\n",
    "                                                verbose_training=False,\n",
    "                                                verbose_results=verbose,\n",
    "                                                verbose_model=verbose_model\n",
    "                                            )\n",
    "                                            # save metric that we want to validate on\n",
    "                                            # taking the mean over the performance on the folds for the seed\n",
    "                                            # if k_fold=False, .mean() just returns the performance for the seed\n",
    "                                            scores.append(results[f\"valid_{validation_metric}\"].mean())\n",
    "                                            \n",
    "                                            # concatenate to results dataframe\n",
    "                                            results[\"k\"] = k\n",
    "                                            results[\"dimensions\"] = dimension\n",
    "                                            results[\"sig_depth\"] = sig_depth\n",
    "                                            results[\"method\"] = method\n",
    "                                            results[\"input_channels\"] = input_channels\n",
    "                                            results[\"output_channels\"] = output_channels\n",
    "                                            results[\"num_time_features\"] = num_time_features\n",
    "                                            results[\"embedding_dim\"] = embedding_dim\n",
    "                                            results[\"log_signature\"] = log_signature\n",
    "                                            results[\"lstm_hidden_dim\"] = [lstm_hidden_dim for _ in range(len(results.index))]\n",
    "                                            results[\"ffn_hidden_dim\"] = [ffn_hidden_dim for _ in range(len(results.index))]\n",
    "                                            results[\"dropout_rate\"] = dropout\n",
    "                                            results[\"learning_rate\"] = lr\n",
    "                                            results[\"seed\"] = seed\n",
    "                                            results[\"BiLSTM\"] = BiLSTM\n",
    "                                            results[\"loss\"] = loss\n",
    "                                            results[\"gamma\"] = gamma\n",
    "                                            results[\"k_fold\"] = k_fold\n",
    "                                            results[\"augmentation_type\"] = augmentation_type\n",
    "                                            results[\"comb_method\"] = comb_method\n",
    "                                            results[\"model_id\"] = model_id\n",
    "                                            results_df = pd.concat([results_df, results])\n",
    "                                            \n",
    "                                            # don't continue printing out the model\n",
    "                                            verbose_model = False\n",
    "\n",
    "                                        model_id += 1\n",
    "                                        scores_mean = sum(scores)/len(scores)\n",
    "                                        \n",
    "                                        print(f\"- average{' (kfold)' if k_fold else ''} \"\n",
    "                                              f\"(validation) metric score: {scores_mean}\")\n",
    "                                        print(f\"scores for the different seeds: {scores}\")\n",
    "                                        # save best model according to averaged metric over the different seeds\n",
    "                                        save_best_model(current_valid_metric=scores_mean,\n",
    "                                                        extra_info={\n",
    "                                                            \"k\": k,\n",
    "                                                            \"dimensions\": dimension,\n",
    "                                                            \"sig_depth\": sig_depth,\n",
    "                                                            \"method\": method,\n",
    "                                                            \"input_channels\": input_channels,\n",
    "                                                            \"output_channels\": output_channels,\n",
    "                                                            \"num_time_features\": num_time_features,\n",
    "                                                            \"embedding_dim\": embedding_dim,\n",
    "                                                            \"log_signature\": log_signature,\n",
    "                                                            \"lstm_hidden_dim\": lstm_hidden_dim,\n",
    "                                                            \"ffn_hidden_dim\": ffn_hidden_dim,\n",
    "                                                            \"dropout_rate\": dropout,\n",
    "                                                            \"learning_rate\": lr,\n",
    "                                                            \"BiLSTM\": BiLSTM,\n",
    "                                                            \"loss\": loss,\n",
    "                                                            \"gamma\": gamma,\n",
    "                                                            \"augmentation_type\": augmentation_type,\n",
    "                                                            \"comb_method\": comb_method\n",
    "                                                        })\n",
    "\n",
    "    checkpoint = torch.load(f=model_output)\n",
    "    if verbose:\n",
    "        print(\"*\" * 50)\n",
    "        print(\"The best model had the following parameters:\")\n",
    "        print(checkpoint[\"extra_info\"])\n",
    "\n",
    "    x_data, input_channels = obtain_SWNUNetwork_input(method=checkpoint[\"extra_info\"][\"method\"],\n",
    "                                               dimension=checkpoint[\"extra_info\"][\"k\"],\n",
    "                                               df=df,\n",
    "                                               id_column=id_column,\n",
    "                                               label_column=label_column,\n",
    "                                               embeddings=embeddings,\n",
    "                                               k=checkpoint[\"extra_info\"][\"k\"],\n",
    "                                               path_indices=path_indices)\n",
    "\n",
    "    test_scores = []\n",
    "    test_results_df = pd.DataFrame()\n",
    "    for seed in seeds:\n",
    "        _, test_results = implement_swnu_network(\n",
    "            num_epochs=num_epochs,\n",
    "            x_data=x_data,\n",
    "            y_data=y_data,\n",
    "            sig_depth=checkpoint[\"extra_info\"][\"sig_depth\"],\n",
    "            input_channels=checkpoint[\"extra_info\"][\"input_channels\"],\n",
    "            output_channels=checkpoint[\"extra_info\"][\"output_channels\"],\n",
    "            num_time_features=len(time_feature),\n",
    "            embedding_dim=embedding_dim,\n",
    "            log_signature=checkpoint[\"extra_info\"][\"log_signature\"],\n",
    "            output_dim=output_dim,\n",
    "            lstm_hidden_dim=checkpoint[\"extra_info\"][\"lstm_hidden_dim\"],\n",
    "            ffn_hidden_dim=checkpoint[\"extra_info\"][\"ffn_hidden_dim\"],\n",
    "            BiLSTM=checkpoint[\"extra_info\"][\"BiLSTM\"],\n",
    "            dropout_rate=checkpoint[\"extra_info\"][\"dropout_rate\"],\n",
    "            learning_rate=checkpoint[\"extra_info\"][\"learning_rate\"],\n",
    "            seed=seed,\n",
    "            loss=checkpoint[\"extra_info\"][\"loss\"],\n",
    "            gamma=checkpoint[\"extra_info\"][\"gamma\"],\n",
    "            augmentation_type=checkpoint[\"extra_info\"][\"augmentation_type\"],\n",
    "            comb_method=checkpoint[\"extra_info\"][\"comb_method\"],\n",
    "            data_split_seed=data_split_seed,\n",
    "            k_fold=k_fold,\n",
    "            n_splits=n_splits,\n",
    "            verbose_training=False,\n",
    "            verbose_results=False,\n",
    "            verbose_model=False\n",
    "        )\n",
    "\n",
    "        # save metric that we want to validate on\n",
    "        # taking the mean over the performance on the folds for the seed\n",
    "        # if k_fold=False, .mean() just returns the performance for the seed\n",
    "        test_scores.append(test_results[validation_metric].mean())\n",
    "        \n",
    "        # concatenate to results dataframe\n",
    "        test_results[\"k\"] = checkpoint[\"extra_info\"][\"k\"]\n",
    "        test_results[\"dimensions\"] = checkpoint[\"extra_info\"][\"dimensions\"]\n",
    "        test_results[\"sig_depth\"] = checkpoint[\"extra_info\"][\"sig_depth\"]\n",
    "        test_results[\"method\"] = checkpoint[\"extra_info\"][\"method\"]\n",
    "        test_results[\"input_channels\"] = checkpoint[\"extra_info\"][\"input_channels\"]\n",
    "        test_results[\"output_channels\"] = checkpoint[\"extra_info\"][\"output_channels\"]\n",
    "        test_results[\"num_time_features\"] = len(time_feature)\n",
    "        test_results[\"embedding_dim\"] = embedding_dim\n",
    "        test_results[\"log_signature\"] = checkpoint[\"extra_info\"][\"log_signature\"]\n",
    "        test_results[\"lstm_hidden_dim\"] = [checkpoint[\"extra_info\"][\"lstm_hidden_dim\"]\n",
    "                                           for _ in range(len(test_results.index))]\n",
    "        test_results[\"ffn_hidden_dim\"] = [checkpoint[\"extra_info\"][\"ffn_hidden_dim\"]\n",
    "                                          for _ in range(len(test_results.index))]\n",
    "        test_results[\"dropout_rate\"] = checkpoint[\"extra_info\"][\"dropout_rate\"]\n",
    "        test_results[\"learning_rate\"] = checkpoint[\"extra_info\"][\"learning_rate\"]\n",
    "        test_results[\"seed\"] = seed\n",
    "        test_results[\"BiLSTM\"] = checkpoint[\"extra_info\"][\"BiLSTM\"]\n",
    "        test_results[\"loss\"] = checkpoint[\"extra_info\"][\"loss\"]\n",
    "        test_results[\"gamma\"] = checkpoint[\"extra_info\"][\"gamma\"]\n",
    "        test_results[\"k_fold\"] = k_fold\n",
    "        test_results[\"augmentation_type\"] = checkpoint[\"extra_info\"][\"augmentation_type\"]\n",
    "        test_results[\"comb_method\"] = checkpoint[\"extra_info\"][\"comb_method\"]\n",
    "        test_results_df = pd.concat([test_results_df, test_results])\n",
    "        \n",
    "    test_scores_mean = sum(test_scores)/len(test_scores)\n",
    "    if verbose:\n",
    "        print(f\"best validation score: {save_best_model.best_valid_metric}\")\n",
    "        print(f\"- Best model: average (test) metric score: {test_scores_mean}\")\n",
    "        print(f\"scores for the different seeds: {test_scores}\")\n",
    "        \n",
    "    if results_output is not None:\n",
    "        print(\"saving results dataframe to CSV for this \"\n",
    "            f\"hyperparameter search in {results_output}\")\n",
    "        results_df.to_csv(results_output)\n",
    "    \n",
    "    # remove any models that have been saved\n",
    "    if os.path.exists(model_output):\n",
    "        os.remove(model_output)\n",
    "    \n",
    "    return results_df, test_results_df, save_best_model.best_valid_metric, checkpoint[\"extra_info\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "id": "4dbd01f5",
   "metadata": {},
   "outputs": [],
   "source": [
    "from __future__ import annotations\n",
    "import signatory\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "from nlpsig_networks.swnu import SWNU\n",
    "\n",
    "\n",
    "class SWNUNetwork(nn.Module):\n",
    "    \"\"\"\n",
    "    Stacked Deep Signature Neural Network for classification.\n",
    "    \"\"\"\n",
    "\n",
    "    def __init__(\n",
    "        self,\n",
    "        input_channels: int,\n",
    "        output_channels: int,\n",
    "        num_time_features: int,\n",
    "        embedding_dim: int,\n",
    "        log_signature: bool,\n",
    "        sig_depth: int,\n",
    "        hidden_dim_swnu: list[int] | int,\n",
    "        hidden_dim_ffn: list[int] | int,\n",
    "        output_dim: int,\n",
    "        dropout_rate: float,\n",
    "        augmentation_type: str = \"Conv1d\",\n",
    "        augmentation_args: dict | None = None,\n",
    "        hidden_dim_aug: list[int] | int | None = None,\n",
    "        BiLSTM: bool = False,\n",
    "        comb_method: str = \"gated_addition\",\n",
    "    ):\n",
    "        \"\"\"\n",
    "        SWNU network for classification.\n",
    "\n",
    "        Parameters\n",
    "        ----------\n",
    "        input_channels : int\n",
    "            Dimension of the embeddings that will be passed in.\n",
    "        output_channels : int\n",
    "            Requested dimension of the embeddings after convolution layer.\n",
    "        num_time_features : int\n",
    "            Number of time features to add to FFN input. If none, set to zero.\n",
    "        embedding_dim : int\n",
    "            Dimension of embedding to add to FFN input. If none, set to zero.\n",
    "        log_signature : bool\n",
    "            Whether or not to use the log signature or standard signature.\n",
    "        sig_depth : int\n",
    "            The depth to truncate the path signature at.\n",
    "        hidden_dim_swnu : list[int] | int\n",
    "            Dimensions of the hidden layers in the SNWU blocks.\n",
    "        hidden_dim_ffn : list[int] | int\n",
    "            Dimension of the hidden layers in the FFN.\n",
    "        output_dim : int\n",
    "            Dimension of the output layer in the FFN.\n",
    "        dropout_rate : float\n",
    "            Dropout rate in the FFN.\n",
    "        augmentation_type : str, optional\n",
    "            Method of augmenting the path, by default \"Conv1d\".\n",
    "            Options are:\n",
    "            - \"Conv1d\": passes path through 1D convolution layer.\n",
    "            - \"signatory\": passes path through `Augment` layer from `signatory` package.\n",
    "        augmentation_args : dict | None, optional\n",
    "            Arguments to pass into `torch.Conv1d` or `signatory.Augment`, by default None.\n",
    "            If None, by default will set `kernel_size=3`, `stride=1`, `padding=0`.\n",
    "        hidden_dim_aug : list[int] | int | None\n",
    "            Dimensions of the hidden layers in the augmentation layer.\n",
    "            Passed into `Augment` class from `signatory` package if\n",
    "            `augmentation_type='signatory'`, by default None.\n",
    "        BiLSTM : bool, optional\n",
    "            Whether or not a birectional LSTM is used,\n",
    "            by default False (unidirectional LSTM is used in this case).\n",
    "        comb_method : str, optional\n",
    "            Determines how to combine the path signature and embeddings,\n",
    "            by default \"gated_addition\".\n",
    "            Options are:\n",
    "            - concatenation: concatenation of path signature and embedding vector\n",
    "            - gated_addition: element-wise addition of path signature and embedding vector\n",
    "        \"\"\"\n",
    "        super(SWNUNetwork, self).__init__()\n",
    "        \n",
    "        # dimensionality reduction on the input prior to SWNU\n",
    "        self.input_channels = input_channels\n",
    "        self.augmentation_type = augmentation_type\n",
    "        if isinstance(hidden_dim_aug, int):\n",
    "            hidden_dim_aug = [hidden_dim_aug]\n",
    "        elif hidden_dim_aug is None:\n",
    "            hidden_dim_aug = []\n",
    "        self.hidden_dim_aug = hidden_dim_aug\n",
    "        if augmentation_args is None:\n",
    "            augmentation_args = {\"kernel_size\": 3,\n",
    "                                 \"stride\": 1,\n",
    "                                 \"padding\": 1}\n",
    "        # convolution\n",
    "        self.conv = nn.Conv1d(\n",
    "            in_channels=input_channels,\n",
    "            out_channels=output_channels,\n",
    "            **augmentation_args,\n",
    "        )\n",
    "        # alternative to convolution: using Augment from signatory \n",
    "        self.augment = signatory.Augment(\n",
    "            in_channels=input_channels,\n",
    "            layer_sizes=self.hidden_dim_aug + [output_channels],\n",
    "            include_original=False,\n",
    "            include_time=False,\n",
    "            **augmentation_args,\n",
    "        )\n",
    "        # non-linearity\n",
    "        self.tanh1 = nn.Tanh()\n",
    "        \n",
    "        # signature window network unit to obtain feature set for FFN\n",
    "        if isinstance(hidden_dim_swnu, int):\n",
    "            hidden_dim_swnu = [hidden_dim_swnu]\n",
    "\n",
    "        self.swnu = SWNU(input_size=output_channels,\n",
    "                         hidden_dim=hidden_dim_swnu,\n",
    "                         log_signature=log_signature,\n",
    "                         sig_depth=sig_depth,\n",
    "                         BiLSTM=BiLSTM)\n",
    "        \n",
    "        # signature without lift (for passing into FFN)\n",
    "        mult = 2 if BiLSTM else 1\n",
    "        if log_signature:\n",
    "            signature_output_channels = signatory.logsignature_channels(\n",
    "                in_channels=mult * hidden_dim_swnu[-1], depth=sig_depth\n",
    "            )\n",
    "        else:\n",
    "            signature_output_channels = signatory.signature_channels(\n",
    "                channels=mult * hidden_dim_swnu[-1], depth=sig_depth\n",
    "            )\n",
    "        \n",
    "        # determining how to concatenate features to the SWNU features\n",
    "        self.embedding_dim = embedding_dim\n",
    "        self.num_time_features = num_time_features\n",
    "        if comb_method not in [\"concatenation\", \"gated_addition\"]:\n",
    "            raise ValueError(\n",
    "                \"`comb_method` must be either 'concatenation' or 'gated_addition'.\"\n",
    "            )\n",
    "        self.comb_method = comb_method\n",
    "        if augmentation_type not in [\"Conv1d\", \"signatory\"]:\n",
    "            raise ValueError(\"`augmentation_type` must be 'Conv1d' or 'signatory'.\")\n",
    "        \n",
    "        # find dimension of features to pass through FFN\n",
    "        if self.comb_method == \"concatenation\":\n",
    "            input_dim = (\n",
    "                signature_output_channels\n",
    "                + self.num_time_features\n",
    "                + self.embedding_dim\n",
    "            )\n",
    "        elif self.comb_method == \"gated_addition\":\n",
    "            input_dim = self.embedding_dim\n",
    "            input_gated_linear = (\n",
    "                signature_output_channels\n",
    "                + self.num_time_features\n",
    "            )\n",
    "            if self.embedding_dim > 0:\n",
    "                self.fc_scale = nn.Linear(input_gated_linear, self.embedding_dim)\n",
    "                self.scaler = torch.nn.Parameter(torch.zeros(1, self.embedding_dim))\n",
    "            else:\n",
    "                self.fc_scale = nn.Linear(input_gated_linear, input_gated_linear)\n",
    "                self.scaler = torch.nn.Parameter(torch.zeros(1, input_gated_linear))\n",
    "            # non-linearity\n",
    "            self.tanh2 = nn.Tanh()\n",
    "\n",
    "        # FFN for classification\n",
    "        if isinstance(hidden_dim_ffn, int):\n",
    "            hidden_dim_ffn = [hidden_dim_ffn]\n",
    "        self.hidden_dim_ffn = hidden_dim_ffn\n",
    "        \n",
    "        # FFN: input layer\n",
    "        self.ffn_input_layer = nn.Linear(input_dim, self.hidden_dim_ffn[0])\n",
    "        self.relu = nn.ReLU()\n",
    "        self.dropout = nn.Dropout(dropout_rate)\n",
    "        input_dim = self.hidden_dim_ffn[0]\n",
    "        \n",
    "        # FFN: hidden layers\n",
    "        self.ffn_linear_layers = []\n",
    "        self.ffn_non_linear_layers = []\n",
    "        self.dropout_layers = []\n",
    "        for l in range(len(self.hidden_dim_ffn)):\n",
    "            self.ffn_linear_layers.append(nn.Linear(input_dim, self.hidden_dim_ffn[l]))\n",
    "            self.ffn_non_linear_layers.append(nn.ReLU())\n",
    "            self.dropout_layers.append(nn.Dropout(dropout_rate))\n",
    "            input_dim = self.hidden_dim_ffn[l]\n",
    "        \n",
    "        self.ffn_linear_layers = nn.ModuleList(self.ffn_linear_layers)\n",
    "        self.ffn_non_linear_layers = nn.ModuleList(self.ffn_non_linear_layers)\n",
    "        self.dropout_layers = nn.ModuleList(self.dropout_layers)\n",
    "        \n",
    "        # FFN: readout\n",
    "        self.ffn_final_layer = nn.Linear(input_dim, output_dim)\n",
    "\n",
    "    def forward(self, x: torch.Tensor):\n",
    "        # x has dimensions [batch, length of signal, channels]\n",
    "\n",
    "        # convolution\n",
    "        if self.augmentation_type == \"Conv1d\":\n",
    "            # input has dimensions [batch, length of signal, channels]\n",
    "            # swap dimensions to get [batch, channels, length of signal]\n",
    "            # (nn.Conv1d expects this)\n",
    "            out = torch.transpose(x, 1, 2)\n",
    "            # get only the path information\n",
    "            out = self.conv(out[:, : self.input_channels, :])\n",
    "            out = self.tanh1(out)\n",
    "            # make output have dimensions [batch, length of signal, channels]\n",
    "            out = torch.transpose(out, 1, 2)\n",
    "        elif self.augmentation_type == \"signatory\":\n",
    "            # input has dimensions [batch, length of signal, channels]\n",
    "            # (signatory.Augment expects this)\n",
    "            # and get only the path information\n",
    "            # output has dimensions [batch, length of signal, channels]\n",
    "            out = self.augment(x[:, :, : self.input_channels])\n",
    "\n",
    "        # use SWNU to obtain feature set\n",
    "        out = self.swnu(out)\n",
    "\n",
    "        # combine last post embedding\n",
    "        if x.shape[2] > self.input_channels:\n",
    "            # we have things to concatenate to the path\n",
    "            if self.comb_method == \"concatenation\":\n",
    "                if self.num_time_features > 0:\n",
    "                    # concatenate any time features\n",
    "                    # take the maximum for the latest time\n",
    "                    out = torch.cat(\n",
    "                        (\n",
    "                            out,\n",
    "                            x[\n",
    "                                :,\n",
    "                                :,\n",
    "                                self.input_channels : (\n",
    "                                    self.input_channels + self.num_time_features\n",
    "                                ),\n",
    "                            ].max(1)[0],\n",
    "                        ),\n",
    "                        dim=1,\n",
    "                    )\n",
    "                if x.shape[2] > self.input_channels + self.num_time_features:\n",
    "                    # concatenate current post embedding if provided\n",
    "                    out = torch.cat(\n",
    "                        (\n",
    "                            out,\n",
    "                            x[:, 0, (self.input_channels + self.num_time_features) :],\n",
    "                        ),\n",
    "                        dim=1,\n",
    "                    )\n",
    "            elif self.comb_method == \"gated_addition\":\n",
    "                if self.num_time_features > 0:\n",
    "                    # concatenate any time features\n",
    "                    out_gated = torch.cat(\n",
    "                        (\n",
    "                            out,\n",
    "                            x[\n",
    "                                :,\n",
    "                                :,\n",
    "                                self.input_channels : (\n",
    "                                    self.input_channels + self.num_time_features\n",
    "                                ),\n",
    "                            ].max(1)[0],\n",
    "                        ),\n",
    "                        dim=1,\n",
    "                    )\n",
    "                else:\n",
    "                    out_gated = out\n",
    "                out_gated = self.fc_scale(out_gated.float())\n",
    "                out_gated = self.tanh2(out_gated)\n",
    "                out_gated = torch.mul(self.scaler, out_gated)\n",
    "                if x.shape[2] > self.input_channels + self.num_time_features:\n",
    "                    # concatenate current post embedding if provided\n",
    "                    out = (\n",
    "                        out_gated\n",
    "                        + x[:, 0, (self.input_channels + self.num_time_features) :],\n",
    "                    )\n",
    "                else:\n",
    "                    out = out_gated\n",
    "\n",
    "        # FFN: input layer\n",
    "        out = self.ffn_input_layer(out)\n",
    "        out = self.relu(out)\n",
    "        out = self.dropout(out)\n",
    "        \n",
    "        # FFN: hidden layers    \n",
    "        for l in range(len(self.hidden_dim_ffn)):\n",
    "            out = self.ffn_linear_layers[l](out)\n",
    "            out = self.ffn_non_linear_layers[l](out)\n",
    "            out = self.dropout_layers[l](out)\n",
    "\n",
    "        # FFN: readout\n",
    "        out = self.ffn_final_layer(out)\n",
    "\n",
    "        return out\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "id": "5ba505df",
   "metadata": {},
   "outputs": [],
   "source": [
    "from __future__ import annotations\n",
    "from signatory import Signature, LogSignature, signature_channels, logsignature_channels\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "\n",
    "\n",
    "class SWNU(nn.Module):\n",
    "    \"\"\"\n",
    "    Signature Window Network Unit.\n",
    "    \"\"\"\n",
    "    \n",
    "    def __init__(\n",
    "        self,\n",
    "        input_size: int,\n",
    "        log_signature: bool,\n",
    "        sig_depth: int,\n",
    "        hidden_dim: list[int] | int,\n",
    "        BiLSTM: bool = False,\n",
    "    ):\n",
    "        \"\"\"\n",
    "        Applies a multi-layer Signature Window Network Unit (SWNU) to\n",
    "        an input sequence.\n",
    "\n",
    "        Parameters\n",
    "        ----------\n",
    "        input_size : int\n",
    "            The number of expected features in the input x.\n",
    "        log_signature : bool\n",
    "            Whether or not to use the log signature or standard signature.\n",
    "        sig_depth : int\n",
    "            The depth to truncate the path signature at.\n",
    "        hidden_dim : list[int] | int\n",
    "            Dimensions of the hidden layers in the LSTM blocks in the SWNU.\n",
    "        BiLSTM : bool, optional\n",
    "            Whether or not a birectional LSTM is used for the final SWNU block,\n",
    "            by default False (unidirectional LSTM is used in this case).\n",
    "        \"\"\"\n",
    "        super(SWNU, self).__init__()\n",
    "        \n",
    "        # logging inputs to the class\n",
    "        self.input_size = input_size\n",
    "        self.log_signature = log_signature\n",
    "        if isinstance(hidden_dim, int):\n",
    "            hidden_dim = [hidden_dim]\n",
    "        self.hidden_dim = hidden_dim\n",
    "        self.BiLSTM = BiLSTM\n",
    "        \n",
    "        # creating expanding window signature layers and corresponding LSTM layers\n",
    "        self.signature_layers = []\n",
    "        self.lstm_layers = []\n",
    "        for l in range(len(self.hidden_dim)):\n",
    "            # create expanding window signature layer and compute the input dimension to LSTM\n",
    "            if self.log_signature:    \n",
    "                self.signature_layers.append(LogSignature(depth=sig_depth, stream=True))\n",
    "                if l == 0:\n",
    "                    input_dim_lstm = logsignature_channels(in_channels=input_size,\n",
    "                                                           depth=sig_depth)\n",
    "                else:\n",
    "                    input_dim_lstm = logsignature_channels(in_channels=self.hidden_dim[l-1],\n",
    "                                                           depth=sig_depth)\n",
    "            else:\n",
    "                self.signature_layers.append(Signature(depth=sig_depth, stream=True))\n",
    "                if l == 0:\n",
    "                    input_dim_lstm = signature_channels(channels=input_size,\n",
    "                                                        depth=sig_depth)\n",
    "                else:\n",
    "                    input_dim_lstm = signature_channels(channels=self.hidden_dim[l-1],\n",
    "                                                        depth=sig_depth)\n",
    "            \n",
    "            # create LSTM layer (if last layer, this can be a BiLSTM)\n",
    "            self.lstm_layers.append(nn.LSTM(\n",
    "                input_size=input_dim_lstm,\n",
    "                hidden_size=self.hidden_dim[l],\n",
    "                num_layers=1,\n",
    "                batch_first=True,\n",
    "                bidirectional=False if l!=(len(self.hidden_dim)-1) else self.BiLSTM,\n",
    "            ))\n",
    "        \n",
    "        # make a ModuleList from the signatures and LSTM layers\n",
    "        self.signature_layers = nn.ModuleList(self.signature_layers)\n",
    "        self.lstm_layers = nn.ModuleList(self.lstm_layers)\n",
    "\n",
    "        # final signature without lift (i.e. no expanding windows)\n",
    "        if self.log_signature:\n",
    "            self.signature2 = LogSignature(depth=sig_depth, stream=False)\n",
    "        else:\n",
    "            self.signature2 = Signature(depth=sig_depth, stream=False)\n",
    "            \n",
    "    def forward(self, x: torch.Tensor):\n",
    "        # x has dimensions [batch, length of signal, channels]\n",
    "        \n",
    "        # take signature lifts and lstm\n",
    "        for l in range(len(self.hidden_dim)):\n",
    "            x = self.signature_layers[l](x)\n",
    "            x, _ = self.lstm_layers[l](x)\n",
    "        \n",
    "        # take final signature\n",
    "        out = self.signature2(x)\n",
    "        \n",
    "        return out"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "id": "979215bf",
   "metadata": {},
   "outputs": [],
   "source": [
    "from __future__ import annotations\n",
    "\n",
    "import os\n",
    "import random\n",
    "\n",
    "import torch\n",
    "from sklearn.model_selection import (\n",
    "    GroupKFold,\n",
    "    GroupShuffleSplit,\n",
    "    KFold,\n",
    "    train_test_split,\n",
    ")\n",
    "from torch.utils.data import TensorDataset\n",
    "from torch.utils.data.dataloader import DataLoader\n",
    "\n",
    "\n",
    "class DataSplits:\n",
    "    \"\"\"\n",
    "    Class to split the data into train, validation and test sets.\n",
    "    \"\"\"\n",
    "\n",
    "    def __init__(\n",
    "        self,\n",
    "        x_data: torch.Tensor,\n",
    "        y_data: torch.Tensor,\n",
    "        train_size: float = 0.8,\n",
    "        valid_size: float | None = 0.33,\n",
    "        shuffle: bool = False,\n",
    "        random_state: int = 42,\n",
    "    ):\n",
    "        \"\"\"\n",
    "        Class to split the data into train, validation and test sets.\n",
    "\n",
    "        Parameters\n",
    "        ----------\n",
    "        x_data : torch.Tensor\n",
    "            Features for prediction.\n",
    "        y_data : torch.Tensor\n",
    "            Variable to predict.\n",
    "        train_size : float, optional\n",
    "            Proportion of data to use as training data, by default 0.8.\n",
    "        valid_size : float | None, optional\n",
    "            Proportion of training data to use as validation data, by default 0.33.\n",
    "            If None, will not create a validation set.\n",
    "        shuffle : bool, optional\n",
    "            Whether or not to shuffle the dataset, by default False.\n",
    "        random_state : int, optional\n",
    "            Seed number, by default 42.\n",
    "        \"\"\"\n",
    "        if x_data.shape[0] != y_data.shape[0]:\n",
    "            msg = (\n",
    "                \"x_data and y_data do not have compatible shapes \"\n",
    "                \"(need to have same number of samples)\"\n",
    "            )\n",
    "            raise ValueError(msg)\n",
    "        if (train_size < 0) or (train_size > 1):\n",
    "            msg = \"train_size must be between 0 and 1\"\n",
    "            raise ValueError(msg)\n",
    "        if valid_size is not None and ((valid_size < 0) or (valid_size > 1)):\n",
    "            msg = \"valid_size must be between 0 and 1\"\n",
    "            raise ValueError(msg)\n",
    "\n",
    "        self.x_data = x_data\n",
    "        self.y_data = y_data\n",
    "        self.shuffle = shuffle\n",
    "        if self.shuffle:\n",
    "            self.random_state = random_state\n",
    "        else:\n",
    "            self.random_state = None\n",
    "\n",
    "        # first split data into train set, test/valid set\n",
    "        train_index, test_index = train_test_split(\n",
    "            range(len(self.y_data)),\n",
    "            test_size=(1 - train_size),\n",
    "            shuffle=self.shuffle,\n",
    "            random_state=self.random_state,\n",
    "        )\n",
    "\n",
    "        if valid_size is not None:\n",
    "            # further split the train set into a train, valid set\n",
    "            train_index, valid_index = train_test_split(\n",
    "                train_index,\n",
    "                test_size=valid_size,\n",
    "                shuffle=self.shuffle,\n",
    "                random_state=self.random_state,\n",
    "            )\n",
    "        else:\n",
    "            valid_index = None\n",
    "\n",
    "        # store indices\n",
    "        self.indices = (train_index, valid_index, test_index)\n",
    "\n",
    "    def get_splits(\n",
    "        self, as_DataLoader: bool = False, data_loader_args: dict | None = None\n",
    "    ):\n",
    "        \"\"\"\n",
    "        Returns train, validation and test set.\n",
    "\n",
    "        Parameters\n",
    "        ----------\n",
    "        as_DataLoader : bool, optional\n",
    "            Whether or not to return as `torch.utils.data.dataloader.DataLoader` objects\n",
    "            ready to be passed into PyTorch model, by default False.\n",
    "        data_loader_args : dict | None, optional\n",
    "            Any keywords to be passed in obtaining the\n",
    "            `torch.utils.data.dataloader.DataLoader` object,\n",
    "            by default {\"batch_size\": 64, \"shuffle\": True}.\n",
    "\n",
    "        Returns\n",
    "        -------\n",
    "        - If `as_DataLoader` is True, return tuple of\n",
    "        `torch.utils.data.dataloader.DataLoader` objects:\n",
    "          - First element is training dataset\n",
    "          - Second element is validation dataset\n",
    "          - Third element is testing dataset\n",
    "        - If `as_DataLoader` is False, returns tuple of `torch.Tensors`:\n",
    "          - First element is features for training dataset\n",
    "          - Second element is labels for training dataset\n",
    "          - First element is features for validation dataset\n",
    "          - Second element is labels for validation dataset\n",
    "          - First element is features for testing dataset\n",
    "          - Second element is labels for testing dataset\n",
    "        \"\"\"\n",
    "        if data_loader_args is None:\n",
    "            data_loader_args = {\"batch_size\": 64, \"shuffle\": True}\n",
    "\n",
    "        # obtain validation set\n",
    "        if self.indices[1] is not None:\n",
    "            x_valid = self.x_data[self.indices[1]]\n",
    "            y_valid = self.y_data[self.indices[1]]\n",
    "        else:\n",
    "            x_valid = None\n",
    "            y_valid = None\n",
    "\n",
    "        # obtain training set\n",
    "        x_train = self.x_data[self.indices[0]]\n",
    "        y_train = self.y_data[self.indices[0]]\n",
    "\n",
    "        # obtain test set\n",
    "        x_test = self.x_data[self.indices[2]]\n",
    "        y_test = self.y_data[self.indices[2]]\n",
    "\n",
    "        if as_DataLoader:\n",
    "            # return datasets as DataLoader objects if requested\n",
    "            if x_valid is not None:\n",
    "                valid = TensorDataset(x_valid, y_valid)\n",
    "                valid_loader = DataLoader(dataset=valid, **data_loader_args)\n",
    "            else:\n",
    "                valid_loader = None\n",
    "\n",
    "            train = TensorDataset(x_train, y_train)\n",
    "            test = TensorDataset(x_test, y_test)\n",
    "            train_loader = DataLoader(dataset=train, **data_loader_args)\n",
    "            test_loader = DataLoader(dataset=test, **data_loader_args)\n",
    "\n",
    "            return train_loader, valid_loader, test_loader\n",
    "\n",
    "        return (\n",
    "            x_train,\n",
    "            y_train,\n",
    "            x_valid,\n",
    "            y_valid,\n",
    "            x_test,\n",
    "            y_test,\n",
    "        )\n",
    "\n",
    "\n",
    "class Folds:\n",
    "    \"\"\"\n",
    "    Class to split the data into different folds based on groups.\n",
    "    \"\"\"\n",
    "\n",
    "    def __init__(\n",
    "        self,\n",
    "        x_data: torch.Tensor,\n",
    "        y_data: torch.Tensor,\n",
    "        groups: torch.Tensor | None = None,\n",
    "        n_splits: int = 5,\n",
    "        valid_size: float | None = 0.33,\n",
    "        shuffle: bool = False,\n",
    "        random_state: int = 42,\n",
    "    ):\n",
    "        \"\"\"\n",
    "        Class to split the data into different folds based on groups\n",
    "\n",
    "        Parameters\n",
    "        ----------\n",
    "        x_data : torch.Tensor\n",
    "            Features for prediction.\n",
    "        y_data : torch.Tensor\n",
    "            Variable to predict.\n",
    "        groups : torch.Tensor | None, optional\n",
    "            Groups to split by, default None. If None is passed, then does standard KFold,\n",
    "            otherwise implements GroupShuffleSplit (if shuffle is True),\n",
    "            or GroupKFold (if shuffle is False).\n",
    "        n_splits : int, optional\n",
    "            Number of splits / folds, by default 5.\n",
    "        valid_size : float | None, optional\n",
    "            Proportion of training data to use as validation data, by default 0.33.\n",
    "            If None, will not create a validation set.\n",
    "        shuffle : bool, optional\n",
    "            Whether or not to shuffle the dataset, by default False.\n",
    "        random_state : int, optional\n",
    "            Seed number, by default 42.\n",
    "\n",
    "        Raises\n",
    "        ------\n",
    "        ValueError\n",
    "            if `n_splits` < 2.\n",
    "        ValueError\n",
    "            if `x_data` and `y_data` do not have the same number of records\n",
    "            (number of rows in `x_data` should equal the length of `y_data`).\n",
    "        ValueError\n",
    "            if `x_data` and `groups` do not have the same number of records\n",
    "            (number of rows in `x_data` should equal the length of `groups`).\n",
    "        \"\"\"\n",
    "        if n_splits < 2:\n",
    "            msg = \"n_splits should be at least 2\"\n",
    "            raise ValueError(msg)\n",
    "        if x_data.shape[0] != y_data.shape[0]:\n",
    "            msg = (\n",
    "                \"x_data and y_data do not have compatible shapes \"\n",
    "                \"(need to have same number of samples)\"\n",
    "            )\n",
    "            raise ValueError(msg)\n",
    "        if groups is not None and x_data.shape[0] != groups.shape[0]:\n",
    "            msg = (\n",
    "                \"x_data and groups do not have compatible shapes \"\n",
    "                \"(need to have same number of samples)\"\n",
    "            )\n",
    "            raise ValueError(msg)\n",
    "        if valid_size is not None and ((valid_size < 0) or (valid_size > 1)):\n",
    "            msg = \"valid_size must be between 0 and 1\"\n",
    "            raise ValueError(msg)\n",
    "\n",
    "        self.x_data = x_data\n",
    "        self.y_data = y_data\n",
    "        self.groups = groups\n",
    "        self.n_splits = n_splits\n",
    "        self.shuffle = shuffle\n",
    "        if self.shuffle:\n",
    "            self.random_state = random_state\n",
    "        else:\n",
    "            self.random_state = None\n",
    "\n",
    "        if self.groups is not None:\n",
    "            if self.shuffle:\n",
    "                # GroupShuffleSplit does not guarantee that every group is in a test group\n",
    "                self.fold = GroupShuffleSplit(\n",
    "                    n_splits=self.n_splits, random_state=self.random_state\n",
    "                )\n",
    "            else:\n",
    "                # GroupKFold guarantees that every group is in a test group once\n",
    "                self.fold = GroupKFold(n_splits=self.n_splits)\n",
    "        else:\n",
    "            self.fold = KFold(\n",
    "                n_splits=self.n_splits,\n",
    "                shuffle=self.shuffle,\n",
    "                random_state=self.random_state,\n",
    "            )\n",
    "\n",
    "        # obtain fold indices\n",
    "        self.fold_indices = list(self.fold.split(X=self.x_data, groups=self.groups))\n",
    "\n",
    "        # make the validation sets within the indices\n",
    "        for k in range(self.n_splits):\n",
    "            train_index = self.fold_indices[k][0].tolist()\n",
    "            test_index = self.fold_indices[k][1].tolist()\n",
    "\n",
    "            if valid_size is not None:\n",
    "                # further split the train set into a train, valid set\n",
    "                train_index, valid_index = train_test_split(\n",
    "                    train_index,\n",
    "                    test_size=valid_size,\n",
    "                    shuffle=self.shuffle,\n",
    "                    random_state=self.random_state,\n",
    "                )\n",
    "            else:\n",
    "                valid_index = None\n",
    "\n",
    "            # store indices\n",
    "            self.fold_indices[k] = (train_index, valid_index, test_index)\n",
    "\n",
    "    def get_splits(\n",
    "        self,\n",
    "        fold_index: int,\n",
    "        as_DataLoader: bool = False,\n",
    "        data_loader_args: dict | None = None,\n",
    "    ) -> (\n",
    "        tuple[DataLoader, DataLoader, DataLoader]\n",
    "        | tuple[\n",
    "            torch.Tensor,\n",
    "            torch.Tensor,\n",
    "            torch.Tensor,\n",
    "            torch.Tensor,\n",
    "            torch.Tensor,\n",
    "            torch.Tensor,\n",
    "        ]\n",
    "    ):\n",
    "        \"\"\"\n",
    "        Obtains the data from a particular fold\n",
    "\n",
    "        Parameters\n",
    "        ----------\n",
    "        fold_index : int\n",
    "            Which fold to obtain data for\n",
    "        as_DataLoader : bool, optional\n",
    "            Whether or not to return as `torch.utils.data.dataloader.DataLoader` objects\n",
    "            ready to be passed into PyTorch model, by default False.\n",
    "        data_loader_args : dict | None, optional\n",
    "            Any keywords to be passed in obtaining the\n",
    "            `torch.utils.data.dataloader.DataLoader` object,\n",
    "            by default {\"batch_size\": 64, \"shuffle\": True}.\n",
    "\n",
    "        Returns\n",
    "        -------\n",
    "        - If `as_DataLoader` is True, return tuple of\n",
    "        `torch.utils.data.dataloader.DataLoader` objects:\n",
    "          - First element is training dataset\n",
    "          - Second element is validation dataset\n",
    "          - Third element is testing dataset\n",
    "        - If `as_DataLoader` is False, returns tuple of `torch.Tensors`:\n",
    "          - First element is features for training dataset\n",
    "          - Second element is labels for training dataset\n",
    "          - First element is features for validation dataset\n",
    "          - Second element is labels for validation dataset\n",
    "          - First element is features for testing dataset\n",
    "          - Second element is labels for testing dataset\n",
    "\n",
    "        Raises\n",
    "        ------\n",
    "        ValueError\n",
    "            if the requested `fold_index` is not valid (out of range).\n",
    "        \"\"\"\n",
    "        if data_loader_args is None:\n",
    "            data_loader_args = {\"batch_size\": 64, \"shuffle\": True}\n",
    "        if fold_index not in list(range(self.n_splits)):\n",
    "            msg = (\n",
    "                f\"There are {self.n_splits} folds, so \"\n",
    "                f\"fold_index must be in {list(range(self.n_splits))}\"\n",
    "            )\n",
    "            raise ValueError(msg)\n",
    "\n",
    "        # obtain train and test indices for provided fold_index\n",
    "        train_index = self.fold_indices[fold_index][0]\n",
    "        valid_index = self.fold_indices[fold_index][1]\n",
    "        test_index = self.fold_indices[fold_index][2]\n",
    "\n",
    "        # obtain validation set\n",
    "        if valid_index is not None:\n",
    "            x_valid = self.x_data[valid_index]\n",
    "            y_valid = self.y_data[valid_index]\n",
    "        else:\n",
    "            x_valid = None\n",
    "            y_valid = None\n",
    "\n",
    "        # obtain training set\n",
    "        x_train = self.x_data[train_index]\n",
    "        y_train = self.y_data[train_index]\n",
    "\n",
    "        # obtain test set\n",
    "        x_test = self.x_data[test_index]\n",
    "        y_test = self.y_data[test_index]\n",
    "\n",
    "        if as_DataLoader:\n",
    "            # return datasets as DataLoader objects if requested\n",
    "            if valid_index is not None:\n",
    "                valid = TensorDataset(x_valid, y_valid)\n",
    "                valid_loader = DataLoader(dataset=valid, **data_loader_args)\n",
    "            else:\n",
    "                valid_loader = None\n",
    "\n",
    "            train = TensorDataset(x_train, y_train)\n",
    "            test = TensorDataset(x_test, y_test)\n",
    "            train_loader = DataLoader(dataset=train, **data_loader_args)\n",
    "            test_loader = DataLoader(dataset=test, **data_loader_args)\n",
    "\n",
    "            return train_loader, valid_loader, test_loader\n",
    "\n",
    "        return (\n",
    "            x_train,\n",
    "            y_train,\n",
    "            x_valid,\n",
    "            y_valid,\n",
    "            x_test,\n",
    "            y_test,\n",
    "        )\n",
    "\n",
    "\n",
    "def set_seed(seed: int) -> None:\n",
    "    \"\"\"\n",
    "    Helper function for reproducible behavior to set the seed in\n",
    "    `random`, `torch`.\n",
    "\n",
    "    Parameters\n",
    "    ----------\n",
    "    seed : int\n",
    "        Seed number.\n",
    "    \"\"\"\n",
    "    random.seed(seed)\n",
    "    os.environ[\"PYTHONHASHSEED\"] = str(seed)\n",
    "    # np.random.seed(seed)  # not needed with numpy generators\n",
    "    torch.manual_seed(seed)\n",
    "    torch.cuda.manual_seed(seed)\n",
    "    torch.backends.cudnn.deterministic = True\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "id": "13a67a66",
   "metadata": {},
   "outputs": [
    {
     "ename": "TypeError",
     "evalue": "swnu_network_hyperparameter_search() got an unexpected keyword argument 'num_time_features'",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mTypeError\u001b[0m                                 Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[56], line 1\u001b[0m\n\u001b[0;32m----> 1\u001b[0m swnu_network_log_signature, best_swnu_network_log_signature, _, __ \u001b[39m=\u001b[39m swnu_network_hyperparameter_search(\n\u001b[1;32m      2\u001b[0m     num_epochs\u001b[39m=\u001b[39;49mnum_epochs,\n\u001b[1;32m      3\u001b[0m     df\u001b[39m=\u001b[39;49manno_mi,\n\u001b[1;32m      4\u001b[0m     id_column\u001b[39m=\u001b[39;49m\u001b[39m\"\u001b[39;49m\u001b[39mtranscript_id\u001b[39;49m\u001b[39m\"\u001b[39;49m,\n\u001b[1;32m      5\u001b[0m     label_column\u001b[39m=\u001b[39;49m\u001b[39m\"\u001b[39;49m\u001b[39mclient_talk_type\u001b[39;49m\u001b[39m\"\u001b[39;49m,\n\u001b[1;32m      6\u001b[0m     embeddings\u001b[39m=\u001b[39;49msbert_embeddings,\n\u001b[1;32m      7\u001b[0m     y_data\u001b[39m=\u001b[39;49my_data,\n\u001b[1;32m      8\u001b[0m     num_time_features\u001b[39m=\u001b[39;49mnum_time_features,\n\u001b[1;32m      9\u001b[0m     embedding_dim\u001b[39m=\u001b[39;49membedding_dim,\n\u001b[1;32m     10\u001b[0m     output_dim\u001b[39m=\u001b[39;49moutput_dim,\n\u001b[1;32m     11\u001b[0m     window_sizes\u001b[39m=\u001b[39;49mwindow_sizes,\n\u001b[1;32m     12\u001b[0m     dim_reduce_methods\u001b[39m=\u001b[39;49m[\u001b[39m\"\u001b[39;49m\u001b[39mgaussian_random_projection\u001b[39;49m\u001b[39m\"\u001b[39;49m],\n\u001b[1;32m     13\u001b[0m     dimensions\u001b[39m=\u001b[39;49mdimensions,\n\u001b[1;32m     14\u001b[0m     sig_depths\u001b[39m=\u001b[39;49m[x[\u001b[39m1\u001b[39;49m] \u001b[39mfor\u001b[39;49;00m x \u001b[39min\u001b[39;49;00m log_signature_dimensions_and_sig_depths],\n\u001b[1;32m     15\u001b[0m     log_signature\u001b[39m=\u001b[39;49m\u001b[39mTrue\u001b[39;49;00m,\n\u001b[1;32m     16\u001b[0m     conv_output_channels\u001b[39m=\u001b[39;49mconv_output_channels,\n\u001b[1;32m     17\u001b[0m     swnu_hidden_dim_sizes\u001b[39m=\u001b[39;49m[x[\u001b[39m0\u001b[39;49m] \u001b[39mfor\u001b[39;49;00m x \u001b[39min\u001b[39;49;00m log_signature_dimensions_and_sig_depths],\n\u001b[1;32m     18\u001b[0m     ffn_hidden_dim_sizes\u001b[39m=\u001b[39;49mhidden_dim_sizes,\n\u001b[1;32m     19\u001b[0m     dropout_rates\u001b[39m=\u001b[39;49mdropout_rates,\n\u001b[1;32m     20\u001b[0m     learning_rates\u001b[39m=\u001b[39;49mlearning_rates,\n\u001b[1;32m     21\u001b[0m     BiLSTM\u001b[39m=\u001b[39;49m\u001b[39mFalse\u001b[39;49;00m,\n\u001b[1;32m     22\u001b[0m     seeds\u001b[39m=\u001b[39;49mseeds,\n\u001b[1;32m     23\u001b[0m     loss\u001b[39m=\u001b[39;49mloss,\n\u001b[1;32m     24\u001b[0m     gamma\u001b[39m=\u001b[39;49mgamma,\n\u001b[1;32m     25\u001b[0m     time_feature\u001b[39m=\u001b[39;49mtime_features,\n\u001b[1;32m     26\u001b[0m     standardise_method\u001b[39m=\u001b[39;49mstandardise_method,\n\u001b[1;32m     27\u001b[0m     path_indices\u001b[39m=\u001b[39;49mclient_index,\n\u001b[1;32m     28\u001b[0m     k_fold\u001b[39m=\u001b[39;49m\u001b[39mFalse\u001b[39;49;00m,\n\u001b[1;32m     29\u001b[0m     validation_metric\u001b[39m=\u001b[39;49mvalidation_metric,\n\u001b[1;32m     30\u001b[0m     results_output\u001b[39m=\u001b[39;49m\u001b[39mf\u001b[39;49m\u001b[39m\"\u001b[39;49m\u001b[39m{\u001b[39;49;00moutput_dir\u001b[39m}\u001b[39;49;00m\u001b[39m/ffn_logsignature_grp_focal_\u001b[39;49m\u001b[39m{\u001b[39;49;00mgamma\u001b[39m}\u001b[39;49;00m\u001b[39m.csv\u001b[39;49m\u001b[39m\"\u001b[39;49m,\n\u001b[1;32m     31\u001b[0m     verbose\u001b[39m=\u001b[39;49m\u001b[39mFalse\u001b[39;49;00m\n\u001b[1;32m     32\u001b[0m )\n",
      "\u001b[0;31mTypeError\u001b[0m: swnu_network_hyperparameter_search() got an unexpected keyword argument 'num_time_features'"
     ]
    }
   ],
   "source": [
    "swnu_network_log_signature, best_swnu_network_log_signature, _, __ = swnu_network_hyperparameter_search(\n",
    "    num_epochs=num_epochs,\n",
    "    df=anno_mi,\n",
    "    id_column=\"transcript_id\",\n",
    "    label_column=\"client_talk_type\",\n",
    "    embeddings=sbert_embeddings,\n",
    "    y_data=y_data,\n",
    "    embedding_dim=embedding_dim,\n",
    "    output_dim=output_dim,\n",
    "    window_sizes=window_sizes,\n",
    "    dim_reduce_methods=[\"gaussian_random_projection\"],\n",
    "    dimensions=dimensions,\n",
    "    sig_depths=[x[1] for x in log_signature_dimensions_and_sig_depths],\n",
    "    log_signature=True,\n",
    "    conv_output_channels=conv_output_channels,\n",
    "    swnu_hidden_dim_sizes=[x[0] for x in log_signature_dimensions_and_sig_depths],\n",
    "    ffn_hidden_dim_sizes=hidden_dim_sizes,\n",
    "    dropout_rates=dropout_rates,\n",
    "    learning_rates=learning_rates,\n",
    "    BiLSTM=False,\n",
    "    seeds=seeds,\n",
    "    loss=loss,\n",
    "    gamma=gamma,\n",
    "    time_feature=time_features,\n",
    "    standardise_method=standardise_method,\n",
    "    path_indices=client_index,\n",
    "    k_fold=False,\n",
    "    validation_metric=validation_metric,\n",
    "    results_output=f\"{output_dir}/ffn_logsignature_grp_focal_{gamma}.csv\",\n",
    "    verbose=False\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d6d7bd37",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4daab8de",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "nlpsig-networks",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.16"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
