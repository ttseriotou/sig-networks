{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "a983a5e8",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pickle\n",
    "import os\n",
    "\n",
    "seed = 2023"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "a33739cf-6dc7-4e09-affc-e5b54aca0ca0",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'cpu'"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import torch\n",
    "\n",
    "# set device\n",
    "device = \"cpu\"\n",
    "device"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "f43b86fb-e926-4cdb-9be0-d20129c58d73",
   "metadata": {},
   "outputs": [],
   "source": [
    "import transformers\n",
    "\n",
    "# set to only report critical errors to avoid excessing logging\n",
    "transformers.utils.logging.set_verbosity(50)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "e4e666cc",
   "metadata": {},
   "outputs": [],
   "source": [
    "from nlpsig_networks.scripts.fine_tune_bert_classification import (\n",
    "    fine_tune_transformer_average_seed,\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "6e918dde",
   "metadata": {},
   "outputs": [],
   "source": [
    "output_dir = \"client_talk_type_output\"\n",
    "if not os.path.isdir(output_dir):\n",
    "    os.makedirs(output_dir)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f7409a03",
   "metadata": {},
   "source": [
    "## AnnoMI"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "f00bb922",
   "metadata": {},
   "outputs": [],
   "source": [
    "%run ../load_anno_mi.py"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "720d820f",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>mi_quality</th>\n",
       "      <th>transcript_id</th>\n",
       "      <th>topic</th>\n",
       "      <th>utterance_id</th>\n",
       "      <th>interlocutor</th>\n",
       "      <th>timestamp</th>\n",
       "      <th>utterance_text</th>\n",
       "      <th>annotator_id</th>\n",
       "      <th>therapist_input_exists</th>\n",
       "      <th>therapist_input_subtype</th>\n",
       "      <th>reflection_exists</th>\n",
       "      <th>reflection_subtype</th>\n",
       "      <th>question_exists</th>\n",
       "      <th>question_subtype</th>\n",
       "      <th>main_therapist_behaviour</th>\n",
       "      <th>client_talk_type</th>\n",
       "      <th>datetime</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>high</td>\n",
       "      <td>0</td>\n",
       "      <td>reducing alcohol consumption</td>\n",
       "      <td>0</td>\n",
       "      <td>therapist</td>\n",
       "      <td>00:00:13</td>\n",
       "      <td>Thanks for filling it out. We give this form t...</td>\n",
       "      <td>3</td>\n",
       "      <td>False</td>\n",
       "      <td>NaN</td>\n",
       "      <td>False</td>\n",
       "      <td>NaN</td>\n",
       "      <td>True</td>\n",
       "      <td>open</td>\n",
       "      <td>question</td>\n",
       "      <td>NaN</td>\n",
       "      <td>2023-08-17 00:00:13</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>high</td>\n",
       "      <td>0</td>\n",
       "      <td>reducing alcohol consumption</td>\n",
       "      <td>1</td>\n",
       "      <td>client</td>\n",
       "      <td>00:00:24</td>\n",
       "      <td>Sure.</td>\n",
       "      <td>3</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>neutral</td>\n",
       "      <td>2023-08-17 00:00:24</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>high</td>\n",
       "      <td>0</td>\n",
       "      <td>reducing alcohol consumption</td>\n",
       "      <td>2</td>\n",
       "      <td>therapist</td>\n",
       "      <td>00:00:25</td>\n",
       "      <td>So, let's see. It looks that you put-- You dri...</td>\n",
       "      <td>3</td>\n",
       "      <td>True</td>\n",
       "      <td>information</td>\n",
       "      <td>False</td>\n",
       "      <td>NaN</td>\n",
       "      <td>False</td>\n",
       "      <td>NaN</td>\n",
       "      <td>therapist_input</td>\n",
       "      <td>NaN</td>\n",
       "      <td>2023-08-17 00:00:25</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>high</td>\n",
       "      <td>0</td>\n",
       "      <td>reducing alcohol consumption</td>\n",
       "      <td>3</td>\n",
       "      <td>client</td>\n",
       "      <td>00:00:34</td>\n",
       "      <td>Mm-hmm.</td>\n",
       "      <td>3</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>neutral</td>\n",
       "      <td>2023-08-17 00:00:34</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>high</td>\n",
       "      <td>0</td>\n",
       "      <td>reducing alcohol consumption</td>\n",
       "      <td>4</td>\n",
       "      <td>therapist</td>\n",
       "      <td>00:00:34</td>\n",
       "      <td>-and you usually have three to four drinks whe...</td>\n",
       "      <td>3</td>\n",
       "      <td>True</td>\n",
       "      <td>information</td>\n",
       "      <td>False</td>\n",
       "      <td>NaN</td>\n",
       "      <td>False</td>\n",
       "      <td>NaN</td>\n",
       "      <td>therapist_input</td>\n",
       "      <td>NaN</td>\n",
       "      <td>2023-08-17 00:00:34</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "  mi_quality  transcript_id                         topic  utterance_id  \\\n",
       "0       high              0  reducing alcohol consumption             0   \n",
       "1       high              0  reducing alcohol consumption             1   \n",
       "2       high              0  reducing alcohol consumption             2   \n",
       "3       high              0  reducing alcohol consumption             3   \n",
       "4       high              0  reducing alcohol consumption             4   \n",
       "\n",
       "  interlocutor timestamp                                     utterance_text  \\\n",
       "0    therapist  00:00:13  Thanks for filling it out. We give this form t...   \n",
       "1       client  00:00:24                                              Sure.   \n",
       "2    therapist  00:00:25  So, let's see. It looks that you put-- You dri...   \n",
       "3       client  00:00:34                                            Mm-hmm.   \n",
       "4    therapist  00:00:34  -and you usually have three to four drinks whe...   \n",
       "\n",
       "   annotator_id therapist_input_exists therapist_input_subtype  \\\n",
       "0             3                  False                     NaN   \n",
       "1             3                    NaN                     NaN   \n",
       "2             3                   True             information   \n",
       "3             3                    NaN                     NaN   \n",
       "4             3                   True             information   \n",
       "\n",
       "  reflection_exists reflection_subtype question_exists question_subtype  \\\n",
       "0             False                NaN            True             open   \n",
       "1               NaN                NaN             NaN              NaN   \n",
       "2             False                NaN           False              NaN   \n",
       "3               NaN                NaN             NaN              NaN   \n",
       "4             False                NaN           False              NaN   \n",
       "\n",
       "  main_therapist_behaviour client_talk_type            datetime  \n",
       "0                 question              NaN 2023-08-17 00:00:13  \n",
       "1                      NaN          neutral 2023-08-17 00:00:24  \n",
       "2          therapist_input              NaN 2023-08-17 00:00:25  \n",
       "3                      NaN          neutral 2023-08-17 00:00:34  \n",
       "4          therapist_input              NaN 2023-08-17 00:00:34  "
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "anno_mi.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "84d5594d",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(9699, 384)"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "with open(\"../anno_mi_sbert.pkl\", \"rb\") as f:\n",
    "    sbert_embeddings = pickle.load(f)\n",
    "    \n",
    "sbert_embeddings.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5910ca89",
   "metadata": {},
   "source": [
    "# Baseline: Fine-tune BERT for classification"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "30aa9a08",
   "metadata": {},
   "outputs": [],
   "source": [
    "num_epochs = 10\n",
    "seeds = [0, 1, 12, 123, 1234]\n",
    "loss = \"focal\"\n",
    "gamma = 2\n",
    "validation_metric = \"f1\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "eaee33a9",
   "metadata": {},
   "outputs": [],
   "source": [
    "df = anno_mi\n",
    "path_indices = client_index\n",
    "if path_indices is not None:\n",
    "    df = df.iloc[path_indices].reset_index(drop=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "3a959fee",
   "metadata": {},
   "outputs": [],
   "source": [
    "y_data = df[\"client_talk_type\"]\n",
    "label_to_id = {y_data.unique()[i]: i for i in range(len(y_data.unique()))}\n",
    "id_to_label = {v: k for k, v in label_to_id.items()}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "323c35c5",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([0, 0, 0,  ..., 0, 0, 0])"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "torch.tensor(y_data.apply(lambda x: label_to_id[x]).values)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4c9b014a",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "a59ec481",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[INFO] Setting return_special_tokens_mask=True\n",
      "[INFO] Tokenizing the dataset...\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "f69fb5d280c94877b20400f33d13c3f4",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Map:   0%|          | 0/4817 [00:00<?, ? examples/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[INFO] Saving the tokenized text for each sentence into `.df['tokens']`...\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "4e47740064a44f459fcd71fa99597a79",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Map:   0%|          | 0/4817 [00:00<?, ? examples/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[INFO] Creating tokenized dataframe and setting in `.tokenized_df` attribute...\n",
      "[INFO] Note: 'text_id' is the column name for denoting the corresponding text id\n",
      "[INFO] Setting up TrainingArguments object and saving to `.training_args`.\n",
      "[INFO] Setting up Trainer object, and saving to `.trainer`.\n",
      "[INFO] Training model with 109484547 parameters...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/rchan/opt/miniconda3/envs/nlpsig-networks/lib/python3.8/site-packages/transformers/optimization.py:411: FutureWarning: This implementation of AdamW is deprecated and will be removed in a future version. Use the PyTorch implementation torch.optim.AdamW instead, or set `no_deprecation_warning=True` to disable this warning\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "c02f86aa8e6d4c86b300730eebefa775",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/410 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[13], line 1\u001b[0m\n\u001b[0;32m----> 1\u001b[0m bert_classifier \u001b[39m=\u001b[39m fine_tune_transformer_average_seed(num_epochs\u001b[39m=\u001b[39;49mnum_epochs,\n\u001b[1;32m      2\u001b[0m                                                      pretrained_model_name\u001b[39m=\u001b[39;49m\u001b[39m\"\u001b[39;49m\u001b[39mbert-base-uncased\u001b[39;49m\u001b[39m\"\u001b[39;49m,\n\u001b[1;32m      3\u001b[0m                                                      df\u001b[39m=\u001b[39;49manno_mi,\n\u001b[1;32m      4\u001b[0m                                                      feature_name\u001b[39m=\u001b[39;49m\u001b[39m\"\u001b[39;49m\u001b[39mutterance_text\u001b[39;49m\u001b[39m\"\u001b[39;49m,\n\u001b[1;32m      5\u001b[0m                                                      label_column\u001b[39m=\u001b[39;49m\u001b[39m\"\u001b[39;49m\u001b[39mclient_talk_type\u001b[39;49m\u001b[39m\"\u001b[39;49m,\n\u001b[1;32m      6\u001b[0m                                                      seeds\u001b[39m=\u001b[39;49mseeds,\n\u001b[1;32m      7\u001b[0m                                                      loss\u001b[39m=\u001b[39;49mloss,\n\u001b[1;32m      8\u001b[0m                                                      gamma\u001b[39m=\u001b[39;49mgamma,\n\u001b[1;32m      9\u001b[0m                                                      path_indices\u001b[39m=\u001b[39;49mclient_index,\n\u001b[1;32m     10\u001b[0m                                                      k_fold\u001b[39m=\u001b[39;49m\u001b[39mTrue\u001b[39;49;00m,\n\u001b[1;32m     11\u001b[0m                                                      validation_metric\u001b[39m=\u001b[39;49mvalidation_metric,\n\u001b[1;32m     12\u001b[0m                                                      results_output\u001b[39m=\u001b[39;49m\u001b[39mf\u001b[39;49m\u001b[39m\"\u001b[39;49m\u001b[39m{\u001b[39;49;00moutput_dir\u001b[39m}\u001b[39;49;00m\u001b[39m/bert_classifier.csv\u001b[39;49m\u001b[39m\"\u001b[39;49m,\n\u001b[1;32m     13\u001b[0m                                                      device\u001b[39m=\u001b[39;49mdevice,\n\u001b[1;32m     14\u001b[0m                                                      verbose\u001b[39m=\u001b[39;49m\u001b[39mFalse\u001b[39;49;00m)\n",
      "File \u001b[0;32m~/Library/CloudStorage/OneDrive-TheAlanTuringInstitute/rough_paths/nlpsig-networks/nlpsig_networks/scripts/fine_tune_bert_classification.py:417\u001b[0m, in \u001b[0;36mfine_tune_transformer_average_seed\u001b[0;34m(num_epochs, pretrained_model_name, df, feature_name, label_column, seeds, loss, gamma, path_indices, data_split_seed, split_ids, split_indices, k_fold, n_splits, validation_metric, return_metric_for_each_fold, results_output, device, verbose)\u001b[0m\n\u001b[1;32m    415\u001b[0m test_results_df \u001b[39m=\u001b[39m pd\u001b[39m.\u001b[39mDataFrame()\n\u001b[1;32m    416\u001b[0m \u001b[39mfor\u001b[39;00m seed \u001b[39min\u001b[39;00m seeds:\n\u001b[0;32m--> 417\u001b[0m     test_results \u001b[39m=\u001b[39m fine_tune_transformer_for_classification(\n\u001b[1;32m    418\u001b[0m         num_epochs\u001b[39m=\u001b[39;49mnum_epochs,\n\u001b[1;32m    419\u001b[0m         pretrained_model_name\u001b[39m=\u001b[39;49mpretrained_model_name,\n\u001b[1;32m    420\u001b[0m         df\u001b[39m=\u001b[39;49mdf,\n\u001b[1;32m    421\u001b[0m         feature_name\u001b[39m=\u001b[39;49mfeature_name,\n\u001b[1;32m    422\u001b[0m         label_column\u001b[39m=\u001b[39;49mlabel_column,\n\u001b[1;32m    423\u001b[0m         seed\u001b[39m=\u001b[39;49mseed,\n\u001b[1;32m    424\u001b[0m         loss\u001b[39m=\u001b[39;49mloss,\n\u001b[1;32m    425\u001b[0m         gamma\u001b[39m=\u001b[39;49mgamma,\n\u001b[1;32m    426\u001b[0m         path_indices\u001b[39m=\u001b[39;49mpath_indices,\n\u001b[1;32m    427\u001b[0m         data_split_seed\u001b[39m=\u001b[39;49mdata_split_seed,\n\u001b[1;32m    428\u001b[0m         k_fold\u001b[39m=\u001b[39;49mk_fold,\n\u001b[1;32m    429\u001b[0m         n_splits\u001b[39m=\u001b[39;49mn_splits,\n\u001b[1;32m    430\u001b[0m         split_ids\u001b[39m=\u001b[39;49msplit_ids,\n\u001b[1;32m    431\u001b[0m         split_indices\u001b[39m=\u001b[39;49msplit_indices,\n\u001b[1;32m    432\u001b[0m         return_metric_for_each_fold\u001b[39m=\u001b[39;49mreturn_metric_for_each_fold,\n\u001b[1;32m    433\u001b[0m         device\u001b[39m=\u001b[39;49mdevice,\n\u001b[1;32m    434\u001b[0m         verbose\u001b[39m=\u001b[39;49mverbose,\n\u001b[1;32m    435\u001b[0m     )\n\u001b[1;32m    437\u001b[0m     test_results[\u001b[39m\"\u001b[39m\u001b[39mseed\u001b[39m\u001b[39m\"\u001b[39m] \u001b[39m=\u001b[39m seed\n\u001b[1;32m    438\u001b[0m     test_results[\u001b[39m\"\u001b[39m\u001b[39mloss\u001b[39m\u001b[39m\"\u001b[39m] \u001b[39m=\u001b[39m loss\n",
      "File \u001b[0;32m~/Library/CloudStorage/OneDrive-TheAlanTuringInstitute/rough_paths/nlpsig-networks/nlpsig_networks/scripts/fine_tune_bert_classification.py:293\u001b[0m, in \u001b[0;36mfine_tune_transformer_for_classification\u001b[0;34m(num_epochs, pretrained_model_name, df, feature_name, label_column, seed, loss, gamma, path_indices, data_split_seed, split_ids, split_indices, k_fold, n_splits, return_metric_for_each_fold, device, verbose)\u001b[0m\n\u001b[1;32m    290\u001b[0m predicted \u001b[39m=\u001b[39m torch\u001b[39m.\u001b[39mempty((\u001b[39m0\u001b[39m))\n\u001b[1;32m    291\u001b[0m \u001b[39mfor\u001b[39;00m k \u001b[39min\u001b[39;00m \u001b[39mrange\u001b[39m(n_splits):\n\u001b[1;32m    292\u001b[0m     \u001b[39m# compute how well the model performs on this fold\u001b[39;00m\n\u001b[0;32m--> 293\u001b[0m     results_for_fold \u001b[39m=\u001b[39m _fine_tune_transformer_for_data_split(\n\u001b[1;32m    294\u001b[0m         num_epochs\u001b[39m=\u001b[39;49mnum_epochs,\n\u001b[1;32m    295\u001b[0m         pretrained_model_name\u001b[39m=\u001b[39;49mpretrained_model_name,\n\u001b[1;32m    296\u001b[0m         df\u001b[39m=\u001b[39;49mdf,\n\u001b[1;32m    297\u001b[0m         feature_name\u001b[39m=\u001b[39;49mfeature_name,\n\u001b[1;32m    298\u001b[0m         label_column\u001b[39m=\u001b[39;49mlabel_column,\n\u001b[1;32m    299\u001b[0m         path_indices\u001b[39m=\u001b[39;49mpath_indices,\n\u001b[1;32m    300\u001b[0m         split_indices\u001b[39m=\u001b[39;49mfolds\u001b[39m.\u001b[39;49mfold_indices[k],\n\u001b[1;32m    301\u001b[0m         seed\u001b[39m=\u001b[39;49mseed,\n\u001b[1;32m    302\u001b[0m         loss\u001b[39m=\u001b[39;49mloss,\n\u001b[1;32m    303\u001b[0m         gamma\u001b[39m=\u001b[39;49mgamma,\n\u001b[1;32m    304\u001b[0m         save_model\u001b[39m=\u001b[39;49m\u001b[39mFalse\u001b[39;49;00m,\n\u001b[1;32m    305\u001b[0m         device\u001b[39m=\u001b[39;49mdevice,\n\u001b[1;32m    306\u001b[0m         verbose\u001b[39m=\u001b[39;49mverbose,\n\u001b[1;32m    307\u001b[0m     )\n\u001b[1;32m    309\u001b[0m     \u001b[39m# store the true labels and predicted labels for this fold\u001b[39;00m\n\u001b[1;32m    310\u001b[0m     labels \u001b[39m=\u001b[39m torch\u001b[39m.\u001b[39mcat([labels, results_for_fold[\u001b[39m\"\u001b[39m\u001b[39mlabels\u001b[39m\u001b[39m\"\u001b[39m]])\n",
      "File \u001b[0;32m~/Library/CloudStorage/OneDrive-TheAlanTuringInstitute/rough_paths/nlpsig-networks/nlpsig_networks/scripts/fine_tune_bert_classification.py:215\u001b[0m, in \u001b[0;36m_fine_tune_transformer_for_data_split\u001b[0;34m(num_epochs, pretrained_model_name, df, feature_name, label_column, seed, loss, gamma, batch_size, path_indices, split_indices, save_model, output_dir, device, verbose)\u001b[0m\n\u001b[1;32m    207\u001b[0m text_encoder\u001b[39m.\u001b[39mset_up_trainer(data_collator\u001b[39m=\u001b[39mdata_collator,\n\u001b[1;32m    208\u001b[0m                             compute_metrics\u001b[39m=\u001b[39m_compute_metrics,\n\u001b[1;32m    209\u001b[0m                             optimizers\u001b[39m=\u001b[39m(AdamW(params\u001b[39m=\u001b[39mmodel\u001b[39m.\u001b[39mparameters(),\n\u001b[1;32m    210\u001b[0m                                               weight_decay\u001b[39m=\u001b[39m\u001b[39m0.0001\u001b[39m),\n\u001b[1;32m    211\u001b[0m                                         \u001b[39mNone\u001b[39;00m),\n\u001b[1;32m    212\u001b[0m                             custom_loss\u001b[39m=\u001b[39mcriterion\u001b[39m.\u001b[39mforward)\n\u001b[1;32m    214\u001b[0m \u001b[39m# train model\u001b[39;00m\n\u001b[0;32m--> 215\u001b[0m text_encoder\u001b[39m.\u001b[39;49mfit_transformer_with_trainer_api()\n\u001b[1;32m    217\u001b[0m \u001b[39m# evaluate \u001b[39;00m\n\u001b[1;32m    218\u001b[0m test_performance \u001b[39m=\u001b[39m testing_transformer(\n\u001b[1;32m    219\u001b[0m     model\u001b[39m=\u001b[39mtext_encoder\u001b[39m.\u001b[39mmodel,\n\u001b[1;32m    220\u001b[0m     tokenizer\u001b[39m=\u001b[39mtext_encoder\u001b[39m.\u001b[39mtokenizer,\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m    224\u001b[0m     verbose\u001b[39m=\u001b[39mverbose,\n\u001b[1;32m    225\u001b[0m )\n",
      "File \u001b[0;32m~/Library/CloudStorage/OneDrive-TheAlanTuringInstitute/rough_paths/nlpsig/src/nlpsig/encode_text.py:1362\u001b[0m, in \u001b[0;36mTextEncoder.fit_transformer_with_trainer_api\u001b[0;34m(self, output_dir, data_collator, compute_metrics, training_args, trainer_args)\u001b[0m\n\u001b[1;32m   1357\u001b[0m     \u001b[39mprint\u001b[39m(\n\u001b[1;32m   1358\u001b[0m         \u001b[39mf\u001b[39m\u001b[39m\"\u001b[39m\u001b[39m[INFO] Training model with \u001b[39m\u001b[39m{\u001b[39;00m\u001b[39mself\u001b[39m\u001b[39m.\u001b[39mmodel\u001b[39m.\u001b[39mnum_parameters()\u001b[39m}\u001b[39;00m\u001b[39m parameters...\u001b[39m\u001b[39m\"\u001b[39m\n\u001b[1;32m   1359\u001b[0m     )\n\u001b[1;32m   1361\u001b[0m \u001b[39m# train model\u001b[39;00m\n\u001b[0;32m-> 1362\u001b[0m \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49mtrainer\u001b[39m.\u001b[39;49mtrain()\n\u001b[1;32m   1364\u001b[0m \u001b[39mif\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mverbose:\n\u001b[1;32m   1365\u001b[0m     \u001b[39mprint\u001b[39m(\u001b[39m\"\u001b[39m\u001b[39m[INFO] Training completed!\u001b[39m\u001b[39m\"\u001b[39m)\n",
      "File \u001b[0;32m~/opt/miniconda3/envs/nlpsig-networks/lib/python3.8/site-packages/transformers/trainer.py:1645\u001b[0m, in \u001b[0;36mTrainer.train\u001b[0;34m(self, resume_from_checkpoint, trial, ignore_keys_for_eval, **kwargs)\u001b[0m\n\u001b[1;32m   1640\u001b[0m     \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mmodel_wrapped \u001b[39m=\u001b[39m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mmodel\n\u001b[1;32m   1642\u001b[0m inner_training_loop \u001b[39m=\u001b[39m find_executable_batch_size(\n\u001b[1;32m   1643\u001b[0m     \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_inner_training_loop, \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_train_batch_size, args\u001b[39m.\u001b[39mauto_find_batch_size\n\u001b[1;32m   1644\u001b[0m )\n\u001b[0;32m-> 1645\u001b[0m \u001b[39mreturn\u001b[39;00m inner_training_loop(\n\u001b[1;32m   1646\u001b[0m     args\u001b[39m=\u001b[39;49margs,\n\u001b[1;32m   1647\u001b[0m     resume_from_checkpoint\u001b[39m=\u001b[39;49mresume_from_checkpoint,\n\u001b[1;32m   1648\u001b[0m     trial\u001b[39m=\u001b[39;49mtrial,\n\u001b[1;32m   1649\u001b[0m     ignore_keys_for_eval\u001b[39m=\u001b[39;49mignore_keys_for_eval,\n\u001b[1;32m   1650\u001b[0m )\n",
      "File \u001b[0;32m~/opt/miniconda3/envs/nlpsig-networks/lib/python3.8/site-packages/transformers/trainer.py:1938\u001b[0m, in \u001b[0;36mTrainer._inner_training_loop\u001b[0;34m(self, batch_size, args, resume_from_checkpoint, trial, ignore_keys_for_eval)\u001b[0m\n\u001b[1;32m   1935\u001b[0m     \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mcontrol \u001b[39m=\u001b[39m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mcallback_handler\u001b[39m.\u001b[39mon_step_begin(args, \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mstate, \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mcontrol)\n\u001b[1;32m   1937\u001b[0m \u001b[39mwith\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39maccelerator\u001b[39m.\u001b[39maccumulate(model):\n\u001b[0;32m-> 1938\u001b[0m     tr_loss_step \u001b[39m=\u001b[39m \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49mtraining_step(model, inputs)\n\u001b[1;32m   1940\u001b[0m \u001b[39mif\u001b[39;00m (\n\u001b[1;32m   1941\u001b[0m     args\u001b[39m.\u001b[39mlogging_nan_inf_filter\n\u001b[1;32m   1942\u001b[0m     \u001b[39mand\u001b[39;00m \u001b[39mnot\u001b[39;00m is_torch_tpu_available()\n\u001b[1;32m   1943\u001b[0m     \u001b[39mand\u001b[39;00m (torch\u001b[39m.\u001b[39misnan(tr_loss_step) \u001b[39mor\u001b[39;00m torch\u001b[39m.\u001b[39misinf(tr_loss_step))\n\u001b[1;32m   1944\u001b[0m ):\n\u001b[1;32m   1945\u001b[0m     \u001b[39m# if loss is nan or inf simply add the average of previous logged losses\u001b[39;00m\n\u001b[1;32m   1946\u001b[0m     tr_loss \u001b[39m+\u001b[39m\u001b[39m=\u001b[39m tr_loss \u001b[39m/\u001b[39m (\u001b[39m1\u001b[39m \u001b[39m+\u001b[39m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mstate\u001b[39m.\u001b[39mglobal_step \u001b[39m-\u001b[39m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_globalstep_last_logged)\n",
      "File \u001b[0;32m~/opt/miniconda3/envs/nlpsig-networks/lib/python3.8/site-packages/transformers/trainer.py:2770\u001b[0m, in \u001b[0;36mTrainer.training_step\u001b[0;34m(self, model, inputs)\u001b[0m\n\u001b[1;32m   2768\u001b[0m         scaled_loss\u001b[39m.\u001b[39mbackward()\n\u001b[1;32m   2769\u001b[0m \u001b[39melse\u001b[39;00m:\n\u001b[0;32m-> 2770\u001b[0m     \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49maccelerator\u001b[39m.\u001b[39;49mbackward(loss)\n\u001b[1;32m   2772\u001b[0m \u001b[39mreturn\u001b[39;00m loss\u001b[39m.\u001b[39mdetach() \u001b[39m/\u001b[39m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39margs\u001b[39m.\u001b[39mgradient_accumulation_steps\n",
      "File \u001b[0;32m~/opt/miniconda3/envs/nlpsig-networks/lib/python3.8/site-packages/accelerate/accelerator.py:1820\u001b[0m, in \u001b[0;36mAccelerator.backward\u001b[0;34m(self, loss, **kwargs)\u001b[0m\n\u001b[1;32m   1818\u001b[0m     \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mscaler\u001b[39m.\u001b[39mscale(loss)\u001b[39m.\u001b[39mbackward(\u001b[39m*\u001b[39m\u001b[39m*\u001b[39mkwargs)\n\u001b[1;32m   1819\u001b[0m \u001b[39melse\u001b[39;00m:\n\u001b[0;32m-> 1820\u001b[0m     loss\u001b[39m.\u001b[39;49mbackward(\u001b[39m*\u001b[39;49m\u001b[39m*\u001b[39;49mkwargs)\n",
      "File \u001b[0;32m~/opt/miniconda3/envs/nlpsig-networks/lib/python3.8/site-packages/torch/_tensor.py:255\u001b[0m, in \u001b[0;36mTensor.backward\u001b[0;34m(self, gradient, retain_graph, create_graph, inputs)\u001b[0m\n\u001b[1;32m    246\u001b[0m \u001b[39mif\u001b[39;00m has_torch_function_unary(\u001b[39mself\u001b[39m):\n\u001b[1;32m    247\u001b[0m     \u001b[39mreturn\u001b[39;00m handle_torch_function(\n\u001b[1;32m    248\u001b[0m         Tensor\u001b[39m.\u001b[39mbackward,\n\u001b[1;32m    249\u001b[0m         (\u001b[39mself\u001b[39m,),\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m    253\u001b[0m         create_graph\u001b[39m=\u001b[39mcreate_graph,\n\u001b[1;32m    254\u001b[0m         inputs\u001b[39m=\u001b[39minputs)\n\u001b[0;32m--> 255\u001b[0m torch\u001b[39m.\u001b[39;49mautograd\u001b[39m.\u001b[39;49mbackward(\u001b[39mself\u001b[39;49m, gradient, retain_graph, create_graph, inputs\u001b[39m=\u001b[39;49minputs)\n",
      "File \u001b[0;32m~/opt/miniconda3/envs/nlpsig-networks/lib/python3.8/site-packages/torch/autograd/__init__.py:147\u001b[0m, in \u001b[0;36mbackward\u001b[0;34m(tensors, grad_tensors, retain_graph, create_graph, grad_variables, inputs)\u001b[0m\n\u001b[1;32m    144\u001b[0m \u001b[39mif\u001b[39;00m retain_graph \u001b[39mis\u001b[39;00m \u001b[39mNone\u001b[39;00m:\n\u001b[1;32m    145\u001b[0m     retain_graph \u001b[39m=\u001b[39m create_graph\n\u001b[0;32m--> 147\u001b[0m Variable\u001b[39m.\u001b[39;49m_execution_engine\u001b[39m.\u001b[39;49mrun_backward(\n\u001b[1;32m    148\u001b[0m     tensors, grad_tensors_, retain_graph, create_graph, inputs,\n\u001b[1;32m    149\u001b[0m     allow_unreachable\u001b[39m=\u001b[39;49m\u001b[39mTrue\u001b[39;49;00m, accumulate_grad\u001b[39m=\u001b[39;49m\u001b[39mTrue\u001b[39;49;00m)\n",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "bert_classifier = fine_tune_transformer_average_seed(num_epochs=num_epochs,\n",
    "                                                     pretrained_model_name=\"bert-base-uncased\",\n",
    "                                                     df=anno_mi,\n",
    "                                                     feature_name=\"utterance_text\",\n",
    "                                                     label_column=\"client_talk_type\",\n",
    "                                                     seeds=seeds,\n",
    "                                                     loss=loss,\n",
    "                                                     gamma=gamma,\n",
    "                                                     path_indices=client_index,\n",
    "                                                     k_fold=True,\n",
    "                                                     validation_metric=validation_metric,\n",
    "                                                     results_output=f\"{output_dir}/bert_classifier.csv\",\n",
    "                                                     device=device,\n",
    "                                                     verbose=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "36a270fb-b4ff-4adb-9dcb-ebb4ceb3e690",
   "metadata": {},
   "outputs": [],
   "source": [
    "bert_classifier"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6d75fded-cc50-4c02-a1a9-46a8f258d150",
   "metadata": {},
   "outputs": [],
   "source": [
    "bert_classifier[\"f1\"].mean()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d753b05e-1a15-4266-81ff-7581ccb74693",
   "metadata": {},
   "outputs": [],
   "source": [
    "bert_classifier[\"precision\"].mean()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "520a0f78-4a95-45e8-ab2b-2560f6b43c06",
   "metadata": {},
   "outputs": [],
   "source": [
    "bert_classifier[\"recall\"].mean()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a9b00245-8e4c-401d-bb51-ea10b4646389",
   "metadata": {},
   "outputs": [],
   "source": [
    "np.stack(bert_classifier[\"f1_scores\"]).mean(axis=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a01e7508-807f-48d4-844e-502be70d68a5",
   "metadata": {},
   "outputs": [],
   "source": [
    "np.stack(bert_classifier[\"precision_scores\"]).mean(axis=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ed127b9d-d88d-431a-a93f-39088382007f",
   "metadata": {},
   "outputs": [],
   "source": [
    "np.stack(bert_classifier[\"recall_scores\"]).mean(axis=0)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "nlpsig-networks",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.16"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
