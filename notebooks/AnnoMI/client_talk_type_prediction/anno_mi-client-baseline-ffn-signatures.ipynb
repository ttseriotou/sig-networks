{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 30,
   "id": "a983a5e8",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pickle\n",
    "import os\n",
    "\n",
    "seed = 2023"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "e4e666cc",
   "metadata": {},
   "outputs": [],
   "source": [
    "from nlpsig_networks.scripts.ffn_baseline_functions import (\n",
    "    histories_baseline_hyperparameter_search\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "6e918dde",
   "metadata": {},
   "outputs": [],
   "source": [
    "output_dir = \"client_talk_type_output\"\n",
    "if not os.path.isdir(output_dir):\n",
    "    os.makedirs(output_dir)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f7409a03",
   "metadata": {},
   "source": [
    "## AnnoMI"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "f00bb922",
   "metadata": {},
   "outputs": [],
   "source": [
    "%run ../load_anno_mi.py"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "720d820f",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>mi_quality</th>\n",
       "      <th>transcript_id</th>\n",
       "      <th>topic</th>\n",
       "      <th>utterance_id</th>\n",
       "      <th>interlocutor</th>\n",
       "      <th>timestamp</th>\n",
       "      <th>utterance_text</th>\n",
       "      <th>annotator_id</th>\n",
       "      <th>therapist_input_exists</th>\n",
       "      <th>therapist_input_subtype</th>\n",
       "      <th>reflection_exists</th>\n",
       "      <th>reflection_subtype</th>\n",
       "      <th>question_exists</th>\n",
       "      <th>question_subtype</th>\n",
       "      <th>main_therapist_behaviour</th>\n",
       "      <th>client_talk_type</th>\n",
       "      <th>datetime</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>high</td>\n",
       "      <td>0</td>\n",
       "      <td>reducing alcohol consumption</td>\n",
       "      <td>0</td>\n",
       "      <td>therapist</td>\n",
       "      <td>00:00:13</td>\n",
       "      <td>Thanks for filling it out. We give this form t...</td>\n",
       "      <td>3</td>\n",
       "      <td>False</td>\n",
       "      <td>NaN</td>\n",
       "      <td>False</td>\n",
       "      <td>NaN</td>\n",
       "      <td>True</td>\n",
       "      <td>open</td>\n",
       "      <td>question</td>\n",
       "      <td>NaN</td>\n",
       "      <td>2023-07-25 00:00:13</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>high</td>\n",
       "      <td>0</td>\n",
       "      <td>reducing alcohol consumption</td>\n",
       "      <td>1</td>\n",
       "      <td>client</td>\n",
       "      <td>00:00:24</td>\n",
       "      <td>Sure.</td>\n",
       "      <td>3</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>neutral</td>\n",
       "      <td>2023-07-25 00:00:24</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>high</td>\n",
       "      <td>0</td>\n",
       "      <td>reducing alcohol consumption</td>\n",
       "      <td>2</td>\n",
       "      <td>therapist</td>\n",
       "      <td>00:00:25</td>\n",
       "      <td>So, let's see. It looks that you put-- You dri...</td>\n",
       "      <td>3</td>\n",
       "      <td>True</td>\n",
       "      <td>information</td>\n",
       "      <td>False</td>\n",
       "      <td>NaN</td>\n",
       "      <td>False</td>\n",
       "      <td>NaN</td>\n",
       "      <td>therapist_input</td>\n",
       "      <td>NaN</td>\n",
       "      <td>2023-07-25 00:00:25</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>high</td>\n",
       "      <td>0</td>\n",
       "      <td>reducing alcohol consumption</td>\n",
       "      <td>3</td>\n",
       "      <td>client</td>\n",
       "      <td>00:00:34</td>\n",
       "      <td>Mm-hmm.</td>\n",
       "      <td>3</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>neutral</td>\n",
       "      <td>2023-07-25 00:00:34</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>high</td>\n",
       "      <td>0</td>\n",
       "      <td>reducing alcohol consumption</td>\n",
       "      <td>4</td>\n",
       "      <td>therapist</td>\n",
       "      <td>00:00:34</td>\n",
       "      <td>-and you usually have three to four drinks whe...</td>\n",
       "      <td>3</td>\n",
       "      <td>True</td>\n",
       "      <td>information</td>\n",
       "      <td>False</td>\n",
       "      <td>NaN</td>\n",
       "      <td>False</td>\n",
       "      <td>NaN</td>\n",
       "      <td>therapist_input</td>\n",
       "      <td>NaN</td>\n",
       "      <td>2023-07-25 00:00:34</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "  mi_quality  transcript_id                         topic  utterance_id  \\\n",
       "0       high              0  reducing alcohol consumption             0   \n",
       "1       high              0  reducing alcohol consumption             1   \n",
       "2       high              0  reducing alcohol consumption             2   \n",
       "3       high              0  reducing alcohol consumption             3   \n",
       "4       high              0  reducing alcohol consumption             4   \n",
       "\n",
       "  interlocutor timestamp                                     utterance_text  \\\n",
       "0    therapist  00:00:13  Thanks for filling it out. We give this form t...   \n",
       "1       client  00:00:24                                              Sure.   \n",
       "2    therapist  00:00:25  So, let's see. It looks that you put-- You dri...   \n",
       "3       client  00:00:34                                            Mm-hmm.   \n",
       "4    therapist  00:00:34  -and you usually have three to four drinks whe...   \n",
       "\n",
       "   annotator_id therapist_input_exists therapist_input_subtype  \\\n",
       "0             3                  False                     NaN   \n",
       "1             3                    NaN                     NaN   \n",
       "2             3                   True             information   \n",
       "3             3                    NaN                     NaN   \n",
       "4             3                   True             information   \n",
       "\n",
       "  reflection_exists reflection_subtype question_exists question_subtype  \\\n",
       "0             False                NaN            True             open   \n",
       "1               NaN                NaN             NaN              NaN   \n",
       "2             False                NaN           False              NaN   \n",
       "3               NaN                NaN             NaN              NaN   \n",
       "4             False                NaN           False              NaN   \n",
       "\n",
       "  main_therapist_behaviour client_talk_type            datetime  \n",
       "0                 question              NaN 2023-07-25 00:00:13  \n",
       "1                      NaN          neutral 2023-07-25 00:00:24  \n",
       "2          therapist_input              NaN 2023-07-25 00:00:25  \n",
       "3                      NaN          neutral 2023-07-25 00:00:34  \n",
       "4          therapist_input              NaN 2023-07-25 00:00:34  "
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "anno_mi.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "84d5594d",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(13551, 384)"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "with open(\"../anno_mi_sbert.pkl\", \"rb\") as f:\n",
    "    sbert_embeddings = pickle.load(f)\n",
    "    \n",
    "sbert_embeddings.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "cb4dff32",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[False,\n",
       " True,\n",
       " False,\n",
       " True,\n",
       " False,\n",
       " True,\n",
       " False,\n",
       " True,\n",
       " False,\n",
       " True,\n",
       " False,\n",
       " True,\n",
       " False,\n",
       " True,\n",
       " False,\n",
       " True,\n",
       " False,\n",
       " True,\n",
       " False,\n",
       " True,\n",
       " False,\n",
       " True,\n",
       " False,\n",
       " True,\n",
       " False,\n",
       " True,\n",
       " False,\n",
       " True,\n",
       " False,\n",
       " True,\n",
       " False,\n",
       " True,\n",
       " False,\n",
       " True,\n",
       " False,\n",
       " True,\n",
       " False,\n",
       " True,\n",
       " False,\n",
       " True,\n",
       " False,\n",
       " True,\n",
       " False,\n",
       " True,\n",
       " False,\n",
       " True,\n",
       " False,\n",
       " True,\n",
       " False,\n",
       " True,\n",
       " False,\n",
       " True,\n",
       " False,\n",
       " True,\n",
       " False,\n",
       " True,\n",
       " False,\n",
       " True,\n",
       " False,\n",
       " True,\n",
       " False,\n",
       " True,\n",
       " False,\n",
       " True,\n",
       " False,\n",
       " True,\n",
       " False,\n",
       " True,\n",
       " False,\n",
       " True,\n",
       " False,\n",
       " True,\n",
       " False,\n",
       " True,\n",
       " False,\n",
       " True,\n",
       " False,\n",
       " True,\n",
       " False,\n",
       " True,\n",
       " False,\n",
       " True,\n",
       " False,\n",
       " True,\n",
       " False,\n",
       " True,\n",
       " False,\n",
       " True,\n",
       " False,\n",
       " True,\n",
       " False,\n",
       " False,\n",
       " True,\n",
       " False,\n",
       " True,\n",
       " False,\n",
       " True,\n",
       " False,\n",
       " True,\n",
       " False,\n",
       " True,\n",
       " False,\n",
       " True,\n",
       " False,\n",
       " True,\n",
       " False,\n",
       " True,\n",
       " False,\n",
       " True,\n",
       " False,\n",
       " True,\n",
       " False,\n",
       " True,\n",
       " False,\n",
       " True,\n",
       " False,\n",
       " True,\n",
       " False,\n",
       " True,\n",
       " False,\n",
       " True,\n",
       " False,\n",
       " True,\n",
       " False,\n",
       " True,\n",
       " False,\n",
       " True,\n",
       " True,\n",
       " False,\n",
       " True,\n",
       " False,\n",
       " True,\n",
       " False,\n",
       " True,\n",
       " False,\n",
       " True,\n",
       " False,\n",
       " True,\n",
       " False,\n",
       " True,\n",
       " False,\n",
       " True,\n",
       " False,\n",
       " False,\n",
       " True,\n",
       " False,\n",
       " True,\n",
       " False,\n",
       " True,\n",
       " False,\n",
       " True,\n",
       " False,\n",
       " True,\n",
       " False,\n",
       " True,\n",
       " False,\n",
       " True,\n",
       " False,\n",
       " True,\n",
       " False,\n",
       " True,\n",
       " False,\n",
       " True,\n",
       " False,\n",
       " True,\n",
       " False,\n",
       " True,\n",
       " False,\n",
       " True,\n",
       " False,\n",
       " True,\n",
       " False,\n",
       " True,\n",
       " False,\n",
       " True,\n",
       " False,\n",
       " True,\n",
       " False,\n",
       " True,\n",
       " False,\n",
       " True,\n",
       " False,\n",
       " True,\n",
       " False,\n",
       " True,\n",
       " False,\n",
       " True,\n",
       " False,\n",
       " True,\n",
       " False,\n",
       " True,\n",
       " False,\n",
       " True,\n",
       " False,\n",
       " True,\n",
       " False,\n",
       " True,\n",
       " False,\n",
       " True,\n",
       " False,\n",
       " True,\n",
       " False,\n",
       " False,\n",
       " True,\n",
       " False,\n",
       " True,\n",
       " False,\n",
       " True,\n",
       " False,\n",
       " True,\n",
       " False,\n",
       " True,\n",
       " False,\n",
       " True,\n",
       " False,\n",
       " True,\n",
       " False,\n",
       " True,\n",
       " False,\n",
       " True,\n",
       " False,\n",
       " True,\n",
       " False,\n",
       " True,\n",
       " False,\n",
       " True,\n",
       " False,\n",
       " True,\n",
       " False,\n",
       " True,\n",
       " False,\n",
       " True,\n",
       " False,\n",
       " True,\n",
       " False,\n",
       " True,\n",
       " False,\n",
       " True,\n",
       " False,\n",
       " True,\n",
       " False,\n",
       " True,\n",
       " False,\n",
       " True,\n",
       " False,\n",
       " True,\n",
       " False,\n",
       " True,\n",
       " False,\n",
       " True,\n",
       " False,\n",
       " True,\n",
       " False,\n",
       " True,\n",
       " False,\n",
       " True,\n",
       " False,\n",
       " True,\n",
       " False,\n",
       " True,\n",
       " False,\n",
       " True,\n",
       " False,\n",
       " True,\n",
       " False,\n",
       " True,\n",
       " False,\n",
       " True,\n",
       " False,\n",
       " True,\n",
       " False,\n",
       " True,\n",
       " False,\n",
       " True,\n",
       " False,\n",
       " True,\n",
       " False,\n",
       " True,\n",
       " False,\n",
       " True,\n",
       " False,\n",
       " True,\n",
       " False,\n",
       " True,\n",
       " False,\n",
       " True,\n",
       " False,\n",
       " True,\n",
       " False,\n",
       " True,\n",
       " False,\n",
       " True,\n",
       " False,\n",
       " True,\n",
       " False,\n",
       " True,\n",
       " False,\n",
       " True,\n",
       " False,\n",
       " True,\n",
       " False,\n",
       " True,\n",
       " False,\n",
       " True,\n",
       " False,\n",
       " True,\n",
       " False,\n",
       " True,\n",
       " False,\n",
       " True,\n",
       " False,\n",
       " True,\n",
       " False,\n",
       " True,\n",
       " False,\n",
       " True,\n",
       " False,\n",
       " True,\n",
       " False,\n",
       " True,\n",
       " False,\n",
       " True,\n",
       " False,\n",
       " True,\n",
       " False,\n",
       " True,\n",
       " False,\n",
       " True,\n",
       " False,\n",
       " True,\n",
       " False,\n",
       " True,\n",
       " False,\n",
       " True,\n",
       " False,\n",
       " True,\n",
       " False,\n",
       " True,\n",
       " False,\n",
       " True,\n",
       " False,\n",
       " True,\n",
       " False,\n",
       " True,\n",
       " False,\n",
       " True,\n",
       " False,\n",
       " True,\n",
       " False,\n",
       " True,\n",
       " False,\n",
       " True,\n",
       " False,\n",
       " True,\n",
       " False,\n",
       " True,\n",
       " False,\n",
       " True,\n",
       " False,\n",
       " True,\n",
       " False,\n",
       " True,\n",
       " False,\n",
       " True,\n",
       " False,\n",
       " True,\n",
       " False,\n",
       " True,\n",
       " False,\n",
       " True,\n",
       " False,\n",
       " True,\n",
       " False,\n",
       " True,\n",
       " False,\n",
       " True,\n",
       " False,\n",
       " True,\n",
       " False,\n",
       " True,\n",
       " False,\n",
       " True,\n",
       " False,\n",
       " True,\n",
       " False,\n",
       " True,\n",
       " False,\n",
       " True,\n",
       " False,\n",
       " True,\n",
       " False,\n",
       " True,\n",
       " False,\n",
       " True,\n",
       " False,\n",
       " True,\n",
       " False,\n",
       " True,\n",
       " False,\n",
       " True,\n",
       " False,\n",
       " True,\n",
       " False,\n",
       " True,\n",
       " False,\n",
       " False,\n",
       " True,\n",
       " False,\n",
       " True,\n",
       " False,\n",
       " True,\n",
       " False,\n",
       " True,\n",
       " False,\n",
       " True,\n",
       " False,\n",
       " True,\n",
       " False,\n",
       " True,\n",
       " False,\n",
       " True,\n",
       " False,\n",
       " True,\n",
       " False,\n",
       " True,\n",
       " False,\n",
       " True,\n",
       " False,\n",
       " True,\n",
       " False,\n",
       " True,\n",
       " False,\n",
       " True,\n",
       " False,\n",
       " True,\n",
       " False,\n",
       " True,\n",
       " False,\n",
       " True,\n",
       " False,\n",
       " True,\n",
       " False,\n",
       " True,\n",
       " False,\n",
       " True,\n",
       " False,\n",
       " True,\n",
       " False,\n",
       " True,\n",
       " False,\n",
       " True,\n",
       " False,\n",
       " True,\n",
       " False,\n",
       " True,\n",
       " False,\n",
       " True,\n",
       " False,\n",
       " False,\n",
       " False,\n",
       " False,\n",
       " False,\n",
       " False,\n",
       " False,\n",
       " False,\n",
       " False,\n",
       " False,\n",
       " False,\n",
       " True,\n",
       " True,\n",
       " True,\n",
       " True,\n",
       " True,\n",
       " True,\n",
       " True,\n",
       " True,\n",
       " True,\n",
       " True,\n",
       " False,\n",
       " False,\n",
       " False,\n",
       " False,\n",
       " False,\n",
       " False,\n",
       " False,\n",
       " False,\n",
       " False,\n",
       " False,\n",
       " True,\n",
       " True,\n",
       " True,\n",
       " True,\n",
       " True,\n",
       " True,\n",
       " True,\n",
       " True,\n",
       " True,\n",
       " True,\n",
       " False,\n",
       " False,\n",
       " False,\n",
       " False,\n",
       " False,\n",
       " False,\n",
       " False,\n",
       " False,\n",
       " False,\n",
       " False,\n",
       " True,\n",
       " True,\n",
       " True,\n",
       " True,\n",
       " True,\n",
       " True,\n",
       " True,\n",
       " True,\n",
       " True,\n",
       " True,\n",
       " False,\n",
       " False,\n",
       " False,\n",
       " False,\n",
       " False,\n",
       " False,\n",
       " False,\n",
       " False,\n",
       " False,\n",
       " False,\n",
       " True,\n",
       " True,\n",
       " True,\n",
       " True,\n",
       " True,\n",
       " True,\n",
       " True,\n",
       " True,\n",
       " True,\n",
       " True,\n",
       " False,\n",
       " False,\n",
       " False,\n",
       " False,\n",
       " False,\n",
       " False,\n",
       " False,\n",
       " False,\n",
       " False,\n",
       " False,\n",
       " True,\n",
       " True,\n",
       " True,\n",
       " True,\n",
       " True,\n",
       " True,\n",
       " True,\n",
       " True,\n",
       " True,\n",
       " True,\n",
       " False,\n",
       " False,\n",
       " False,\n",
       " False,\n",
       " False,\n",
       " False,\n",
       " False,\n",
       " False,\n",
       " False,\n",
       " False,\n",
       " True,\n",
       " True,\n",
       " True,\n",
       " True,\n",
       " True,\n",
       " True,\n",
       " True,\n",
       " True,\n",
       " True,\n",
       " True,\n",
       " False,\n",
       " False,\n",
       " False,\n",
       " False,\n",
       " False,\n",
       " False,\n",
       " False,\n",
       " False,\n",
       " False,\n",
       " False,\n",
       " True,\n",
       " True,\n",
       " True,\n",
       " True,\n",
       " True,\n",
       " True,\n",
       " True,\n",
       " True,\n",
       " True,\n",
       " True,\n",
       " False,\n",
       " False,\n",
       " False,\n",
       " False,\n",
       " False,\n",
       " False,\n",
       " False,\n",
       " False,\n",
       " False,\n",
       " False,\n",
       " True,\n",
       " True,\n",
       " True,\n",
       " True,\n",
       " True,\n",
       " True,\n",
       " True,\n",
       " True,\n",
       " True,\n",
       " True,\n",
       " False,\n",
       " False,\n",
       " False,\n",
       " False,\n",
       " False,\n",
       " False,\n",
       " False,\n",
       " False,\n",
       " False,\n",
       " False,\n",
       " True,\n",
       " True,\n",
       " True,\n",
       " True,\n",
       " True,\n",
       " True,\n",
       " True,\n",
       " True,\n",
       " True,\n",
       " True,\n",
       " False,\n",
       " False,\n",
       " False,\n",
       " False,\n",
       " False,\n",
       " False,\n",
       " False,\n",
       " False,\n",
       " False,\n",
       " False,\n",
       " True,\n",
       " True,\n",
       " True,\n",
       " True,\n",
       " True,\n",
       " True,\n",
       " True,\n",
       " True,\n",
       " True,\n",
       " True,\n",
       " False,\n",
       " False,\n",
       " False,\n",
       " False,\n",
       " False,\n",
       " False,\n",
       " False,\n",
       " False,\n",
       " False,\n",
       " False,\n",
       " True,\n",
       " True,\n",
       " True,\n",
       " True,\n",
       " True,\n",
       " True,\n",
       " True,\n",
       " True,\n",
       " True,\n",
       " True,\n",
       " False,\n",
       " False,\n",
       " False,\n",
       " False,\n",
       " False,\n",
       " False,\n",
       " False,\n",
       " False,\n",
       " False,\n",
       " False,\n",
       " True,\n",
       " True,\n",
       " True,\n",
       " True,\n",
       " True,\n",
       " True,\n",
       " True,\n",
       " True,\n",
       " True,\n",
       " True,\n",
       " False,\n",
       " False,\n",
       " False,\n",
       " False,\n",
       " False,\n",
       " False,\n",
       " False,\n",
       " False,\n",
       " False,\n",
       " False,\n",
       " True,\n",
       " True,\n",
       " True,\n",
       " True,\n",
       " True,\n",
       " True,\n",
       " True,\n",
       " True,\n",
       " True,\n",
       " True,\n",
       " False,\n",
       " False,\n",
       " False,\n",
       " False,\n",
       " False,\n",
       " False,\n",
       " False,\n",
       " False,\n",
       " False,\n",
       " False,\n",
       " True,\n",
       " True,\n",
       " True,\n",
       " True,\n",
       " True,\n",
       " True,\n",
       " True,\n",
       " True,\n",
       " True,\n",
       " True,\n",
       " False,\n",
       " False,\n",
       " False,\n",
       " False,\n",
       " False,\n",
       " False,\n",
       " False,\n",
       " False,\n",
       " False,\n",
       " False,\n",
       " True,\n",
       " True,\n",
       " True,\n",
       " True,\n",
       " True,\n",
       " True,\n",
       " True,\n",
       " True,\n",
       " True,\n",
       " True,\n",
       " False,\n",
       " False,\n",
       " False,\n",
       " False,\n",
       " False,\n",
       " False,\n",
       " False,\n",
       " False,\n",
       " False,\n",
       " False,\n",
       " True,\n",
       " True,\n",
       " True,\n",
       " True,\n",
       " True,\n",
       " True,\n",
       " True,\n",
       " True,\n",
       " True,\n",
       " True,\n",
       " False,\n",
       " False,\n",
       " False,\n",
       " False,\n",
       " False,\n",
       " False,\n",
       " False,\n",
       " False,\n",
       " False,\n",
       " False,\n",
       " True,\n",
       " True,\n",
       " True,\n",
       " True,\n",
       " True,\n",
       " True,\n",
       " True,\n",
       " True,\n",
       " True,\n",
       " True,\n",
       " False,\n",
       " False,\n",
       " False,\n",
       " False,\n",
       " False,\n",
       " False,\n",
       " False,\n",
       " False,\n",
       " False,\n",
       " False,\n",
       " True,\n",
       " True,\n",
       " True,\n",
       " True,\n",
       " True,\n",
       " True,\n",
       " True,\n",
       " True,\n",
       " True,\n",
       " True,\n",
       " False,\n",
       " False,\n",
       " False,\n",
       " False,\n",
       " False,\n",
       " False,\n",
       " False,\n",
       " False,\n",
       " False,\n",
       " False,\n",
       " True,\n",
       " True,\n",
       " True,\n",
       " True,\n",
       " True,\n",
       " True,\n",
       " True,\n",
       " True,\n",
       " True,\n",
       " True,\n",
       " False,\n",
       " False,\n",
       " False,\n",
       " False,\n",
       " False,\n",
       " False,\n",
       " False,\n",
       " False,\n",
       " False,\n",
       " False,\n",
       " True,\n",
       " True,\n",
       " True,\n",
       " True,\n",
       " True,\n",
       " True,\n",
       " True,\n",
       " True,\n",
       " True,\n",
       " True,\n",
       " False,\n",
       " False,\n",
       " False,\n",
       " False,\n",
       " False,\n",
       " False,\n",
       " False,\n",
       " False,\n",
       " False,\n",
       " False,\n",
       " True,\n",
       " True,\n",
       " True,\n",
       " True,\n",
       " True,\n",
       " True,\n",
       " True,\n",
       " True,\n",
       " True,\n",
       " True,\n",
       " False,\n",
       " False,\n",
       " False,\n",
       " False,\n",
       " False,\n",
       " False,\n",
       " False,\n",
       " False,\n",
       " False,\n",
       " False,\n",
       " True,\n",
       " True,\n",
       " True,\n",
       " True,\n",
       " True,\n",
       " True,\n",
       " True,\n",
       " True,\n",
       " True,\n",
       " True,\n",
       " False,\n",
       " False,\n",
       " False,\n",
       " False,\n",
       " False,\n",
       " False,\n",
       " False,\n",
       " False,\n",
       " False,\n",
       " False,\n",
       " True,\n",
       " True,\n",
       " True,\n",
       " True,\n",
       " True,\n",
       " True,\n",
       " True,\n",
       " True,\n",
       " True,\n",
       " True,\n",
       " False,\n",
       " False,\n",
       " False,\n",
       " False,\n",
       " False,\n",
       " False,\n",
       " False,\n",
       " False,\n",
       " False,\n",
       " False,\n",
       " True,\n",
       " True,\n",
       " True,\n",
       " True,\n",
       " True,\n",
       " True,\n",
       " True,\n",
       " True,\n",
       " True,\n",
       " True,\n",
       " False,\n",
       " False,\n",
       " False,\n",
       " False,\n",
       " False,\n",
       " False,\n",
       " False,\n",
       " False,\n",
       " False,\n",
       " False,\n",
       " True,\n",
       " True,\n",
       " True,\n",
       " True,\n",
       " True,\n",
       " True,\n",
       " True,\n",
       " True,\n",
       " True,\n",
       " True,\n",
       " False,\n",
       " False,\n",
       " False,\n",
       " False,\n",
       " False,\n",
       " False,\n",
       " False,\n",
       " False,\n",
       " False,\n",
       " False,\n",
       " True,\n",
       " True,\n",
       " True,\n",
       " True,\n",
       " True,\n",
       " True,\n",
       " True,\n",
       " True,\n",
       " True,\n",
       " True,\n",
       " False,\n",
       " False,\n",
       " False,\n",
       " False,\n",
       " False,\n",
       " False,\n",
       " False,\n",
       " False,\n",
       " False,\n",
       " False,\n",
       " True,\n",
       " True,\n",
       " True,\n",
       " True,\n",
       " True,\n",
       " True,\n",
       " True,\n",
       " True,\n",
       " True,\n",
       " True,\n",
       " False,\n",
       " False,\n",
       " ...]"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "client_index"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "ce04f676",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([  0,   0,   0,  ..., 131, 131, 131])"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "client_transcript_id"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0cf51402",
   "metadata": {},
   "source": [
    "# Baseline: FFN using signatures\n",
    "\n",
    "First, we dimension reduce these and then take signatures. We use the path signature as input to the FFN for classification.\n",
    "\n",
    "We want to choose a dimension and signature depth such that the number of terms in the signature is _roughly_ 384 so that it is comparable to the number of features that we used for the previous baseline where we computed the mean of the history. Again, we are concatenating the features we obtain with the current utterance embedding."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "f691b640",
   "metadata": {},
   "outputs": [],
   "source": [
    "num_epochs = 100\n",
    "hidden_dim_sizes = [[128,128],[256,256],[512,512]]\n",
    "dropout_rates = [0.5, 0.2, 0.1]\n",
    "learning_rates = [1e-3, 1e-4, 5e-4]\n",
    "seeds = [0, 1, 12, 123, 1234]\n",
    "loss = \"focal\"\n",
    "gamma = 2\n",
    "validation_metric = \"f1\"\n",
    "patience = 5"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "871fe909",
   "metadata": {},
   "source": [
    "## Using log signature"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "08de59af",
   "metadata": {},
   "outputs": [],
   "source": [
    "log_signature_dimensions_and_sig_depths = [(28, 2), (10, 3), (6, 4)]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "b5480b5f",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[406, 385, 406]"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import signatory\n",
    "\n",
    "[signatory.logsignature_channels(channels, depth)\n",
    " for (channels, depth) in log_signature_dimensions_and_sig_depths]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9ae2ba07",
   "metadata": {},
   "source": [
    "### Using UMAP"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "b9cd8cf0",
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "0fdab6daa90e4a7f85211e054a05b781",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/3 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "a0c589c6a3d24f5b89e8b038388f3940",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/1 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[INFO] Concatenating the embeddings to the dataframe...\n",
      "[INFO] - columns beginning with 'e' denote the full embddings.\n",
      "[INFO] - columns beginning with 'd' denote the dimension reduced embeddings.\n",
      "[INFO] Adding time feature columns into dataframe in `.df`.\n",
      "[INFO] Adding 'time_encoding' and feature...\n",
      "[INFO] Adding 'time_diff' and feature...\n",
      "[INFO] Adding 'timeline_index' feature...\n",
      "[INFO] Padding ids and storing in `.df_padded` and `.array_padded` attributes.\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "0deb747fe6d3480e836340b385b87570",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/13551 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "2a80c97a59b8449c8b10320523e80354",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/3 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "2c7bae7f57b34ccfa728b700a1e09076",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/3 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "adb91b57859547ecb2eb5aee646d98d9",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/3 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "23c266574aec4e29bbfab53e8ab67b3e",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/3 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "c363c7386fc14c159d456d5fbcf768b0",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/3 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "b126e4ee17404b95ab9282a9e3d56d54",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/3 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "33fff3ec06fe408890dcb7e3b50606b4",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/3 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "baf4630ba6e4427d9c3214e72f65a411",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/3 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "63c20ac267264e02b70dbd217487c696",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/3 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "e0c29297dbe4438f982bfec403c1c515",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/3 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "ef482b75afbf4b6296f4ea2311dd7446",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/3 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "7ae52bdfe1f6450f97901927500bb57e",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/3 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "3c62e7a7848341119d6285b5c9194020",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/3 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "745534b81de54460b07b8f9a2af59668",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/1 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[INFO] Concatenating the embeddings to the dataframe...\n",
      "[INFO] - columns beginning with 'e' denote the full embddings.\n",
      "[INFO] - columns beginning with 'd' denote the dimension reduced embeddings.\n",
      "[INFO] Adding time feature columns into dataframe in `.df`.\n",
      "[INFO] Adding 'time_encoding' and feature...\n",
      "[INFO] Adding 'time_diff' and feature...\n",
      "[INFO] Adding 'timeline_index' feature...\n",
      "[INFO] Padding ids and storing in `.df_padded` and `.array_padded` attributes.\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "54abd5641b9548eba2c5ecf1db6c1766",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/13551 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "ceee8fb13e1e43979b1b2ef6ad99ae8a",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/3 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "07a965df282c414eac54d772f43e792f",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/3 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "00bed84aa5ea48379fa70f31254f1149",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/3 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "9e7bd9f327504acdb3bb7966ab867e18",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/3 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "fcf3272fab9942e1b548b5aeafb6057e",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/3 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "411210da244f4fed967ee009b24fde4c",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/3 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "16d4bd92066d42a9932abb9ff43ca0b5",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/3 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "868fb6dc47dd4d57b9cfe4d00818f454",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/3 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "24650513be06486189111b1dd0ca9b6c",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/3 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "179262ce8f7a4ef68a8ce20138ae2407",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/3 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "aabb444233fc47fa911714b6f7ad9a27",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/3 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "52a5eb1abba4431393a3b0f2631689f7",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/3 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "d18fd5a8e5cf4c889359492602ad4a83",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/3 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "827645ca2fae43e886a2dfd84ba6464a",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/1 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[INFO] Concatenating the embeddings to the dataframe...\n",
      "[INFO] - columns beginning with 'e' denote the full embddings.\n",
      "[INFO] - columns beginning with 'd' denote the dimension reduced embeddings.\n",
      "[INFO] Adding time feature columns into dataframe in `.df`.\n",
      "[INFO] Adding 'time_encoding' and feature...\n",
      "[INFO] Adding 'time_diff' and feature...\n",
      "[INFO] Adding 'timeline_index' feature...\n",
      "[INFO] Padding ids and storing in `.df_padded` and `.array_padded` attributes.\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "8ff62fdfadf642dea0cbf7e9afe57bed",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/13551 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "f3a8dccbbe464c71818716b897168170",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/3 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "ebaf984365bd40c7b11a2f1b67c9293a",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/3 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "208d2cf4a5274fddb5ca9cdb41d00b3b",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/3 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "a4f745f4a37a4621969aa6ff182630a7",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/3 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "3be5a69cab0f487b855db92a7160401a",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/3 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "527e2051787b4f05bdf1cecf4658ba23",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/3 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "0b0f42cdd7f648a7995806289dd989ec",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/3 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "44ef9674445747ada404c8d5097237c6",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/3 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "bf83954a81d74e1b85b317bfb768c430",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/3 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "c48ebf1737bb4501b649660a861da91d",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/3 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "fcb000537b394b32adabd6a681657bba",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/3 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "57353842532549d4ace380827e298ae8",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/3 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "0dca1cfc0dc04f9689279141e9c699c2",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/3 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[INFO] Concatenating the embeddings to the dataframe...\n",
      "[INFO] - columns beginning with 'e' denote the full embddings.\n",
      "[INFO] - columns beginning with 'd' denote the dimension reduced embeddings.\n",
      "[INFO] Adding time feature columns into dataframe in `.df`.\n",
      "[INFO] Adding 'time_encoding' and feature...\n",
      "[INFO] Adding 'time_diff' and feature...\n",
      "[INFO] Adding 'timeline_index' feature...\n",
      "[INFO] Padding ids and storing in `.df_padded` and `.array_padded` attributes.\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "00a169f38c9140758cbe694a0246c80f",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/13551 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "saving results dataframe to CSV for this hyperparameter search in client_talk_type_output/ffn_logsignature_umap_focal_2_kfold.csv\n",
      "saving the best model results dataframe to CSV for this hyperparameter search in client_talk_type_output/ffn_logsignature_umap_focal_2_kfold_best_model.csv\n"
     ]
    }
   ],
   "source": [
    "ffn_logsignature_umap_kfold, best_ffn_logsignature_umap_kfold, _, __ = histories_baseline_hyperparameter_search(\n",
    "    num_epochs=num_epochs,\n",
    "    df=anno_mi,\n",
    "    id_column=\"transcript_id\",\n",
    "    label_column=\"client_talk_type\",\n",
    "    embeddings=sbert_embeddings,\n",
    "    y_data=y_data_client,\n",
    "    output_dim=output_dim_client,\n",
    "    hidden_dim_sizes=hidden_dim_sizes,\n",
    "    dropout_rates=dropout_rates,\n",
    "    learning_rates=learning_rates,\n",
    "    use_signatures=True,\n",
    "    seeds=seeds,\n",
    "    loss=loss,\n",
    "    gamma=gamma,\n",
    "    log_signature=True,\n",
    "    dim_reduce_methods=[\"umap\"],\n",
    "    dimension_and_sig_depths=log_signature_dimensions_and_sig_depths,\n",
    "    path_indices=client_index,\n",
    "    split_ids=client_transcript_id,\n",
    "    k_fold=True,\n",
    "    patience=patience,\n",
    "    validation_metric=validation_metric,\n",
    "    results_output=f\"{output_dir}/ffn_logsignature_umap_focal_{gamma}_kfold.csv\",\n",
    "    verbose=False\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "f8b363bd",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/var/folders/l7/bnn1j6bs3bqfskq2jlq55yh80000gr/T/ipykernel_18434/3138393360.py:1: FutureWarning: The default value of numeric_only in DataFrameGroupBy.mean is deprecated. In a future version, numeric_only will default to False. Either specify numeric_only or select only columns which should be valid for the function.\n",
      "  ffn_logsignature_umap_kfold.groupby([\"dimension\", \"sig_depth\", \"hidden_dim\", \"dropout_rate\", \"learning_rate\"]).mean()\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th>accuracy</th>\n",
       "      <th>f1</th>\n",
       "      <th>precision</th>\n",
       "      <th>recall</th>\n",
       "      <th>valid_accuracy</th>\n",
       "      <th>valid_f1</th>\n",
       "      <th>valid_precision</th>\n",
       "      <th>valid_recall</th>\n",
       "      <th>seed</th>\n",
       "      <th>gamma</th>\n",
       "      <th>k_fold</th>\n",
       "      <th>n_splits</th>\n",
       "      <th>batch_size</th>\n",
       "      <th>model_id</th>\n",
       "      <th>input_dim</th>\n",
       "      <th>log_signature</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>dimension</th>\n",
       "      <th>sig_depth</th>\n",
       "      <th>hidden_dim</th>\n",
       "      <th>dropout_rate</th>\n",
       "      <th>learning_rate</th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th rowspan=\"5\" valign=\"top\">6</th>\n",
       "      <th rowspan=\"5\" valign=\"top\">4</th>\n",
       "      <th rowspan=\"5\" valign=\"top\">(128, 128)</th>\n",
       "      <th rowspan=\"3\" valign=\"top\">0.1</th>\n",
       "      <th>0.0001</th>\n",
       "      <td>0.507727</td>\n",
       "      <td>0.360960</td>\n",
       "      <td>0.361479</td>\n",
       "      <td>0.361194</td>\n",
       "      <td>0.674561</td>\n",
       "      <td>0.605467</td>\n",
       "      <td>0.598644</td>\n",
       "      <td>0.615130</td>\n",
       "      <td>274.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>5.0</td>\n",
       "      <td>64.0</td>\n",
       "      <td>2.70</td>\n",
       "      <td>790.0</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>0.0005</th>\n",
       "      <td>0.521780</td>\n",
       "      <td>0.353246</td>\n",
       "      <td>0.356971</td>\n",
       "      <td>0.353992</td>\n",
       "      <td>0.677583</td>\n",
       "      <td>0.603045</td>\n",
       "      <td>0.601896</td>\n",
       "      <td>0.605461</td>\n",
       "      <td>274.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>5.0</td>\n",
       "      <td>64.0</td>\n",
       "      <td>2.80</td>\n",
       "      <td>790.0</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>0.0010</th>\n",
       "      <td>0.533547</td>\n",
       "      <td>0.351780</td>\n",
       "      <td>0.356994</td>\n",
       "      <td>0.353643</td>\n",
       "      <td>0.671964</td>\n",
       "      <td>0.590930</td>\n",
       "      <td>0.596559</td>\n",
       "      <td>0.588186</td>\n",
       "      <td>274.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>5.0</td>\n",
       "      <td>64.0</td>\n",
       "      <td>2.60</td>\n",
       "      <td>790.0</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th rowspan=\"2\" valign=\"top\">0.2</th>\n",
       "      <th>0.0001</th>\n",
       "      <td>0.510837</td>\n",
       "      <td>0.350623</td>\n",
       "      <td>0.353179</td>\n",
       "      <td>0.351986</td>\n",
       "      <td>0.667085</td>\n",
       "      <td>0.593311</td>\n",
       "      <td>0.590125</td>\n",
       "      <td>0.600733</td>\n",
       "      <td>274.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>5.0</td>\n",
       "      <td>64.0</td>\n",
       "      <td>2.40</td>\n",
       "      <td>790.0</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>0.0005</th>\n",
       "      <td>0.535985</td>\n",
       "      <td>0.351374</td>\n",
       "      <td>0.357155</td>\n",
       "      <td>0.353632</td>\n",
       "      <td>0.669950</td>\n",
       "      <td>0.579355</td>\n",
       "      <td>0.593786</td>\n",
       "      <td>0.570571</td>\n",
       "      <td>274.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>5.0</td>\n",
       "      <td>64.0</td>\n",
       "      <td>2.50</td>\n",
       "      <td>790.0</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <th>...</th>\n",
       "      <th>...</th>\n",
       "      <th>...</th>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th rowspan=\"5\" valign=\"top\">28</th>\n",
       "      <th rowspan=\"5\" valign=\"top\">2</th>\n",
       "      <th rowspan=\"5\" valign=\"top\">(512, 512)</th>\n",
       "      <th rowspan=\"2\" valign=\"top\">0.2</th>\n",
       "      <th>0.0005</th>\n",
       "      <td>0.558482</td>\n",
       "      <td>0.421841</td>\n",
       "      <td>0.424717</td>\n",
       "      <td>0.422468</td>\n",
       "      <td>0.691214</td>\n",
       "      <td>0.622049</td>\n",
       "      <td>0.613301</td>\n",
       "      <td>0.635576</td>\n",
       "      <td>274.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>5.0</td>\n",
       "      <td>64.0</td>\n",
       "      <td>0.23</td>\n",
       "      <td>790.0</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>0.0010</th>\n",
       "      <td>0.552446</td>\n",
       "      <td>0.418218</td>\n",
       "      <td>0.419986</td>\n",
       "      <td>0.418650</td>\n",
       "      <td>0.684947</td>\n",
       "      <td>0.607931</td>\n",
       "      <td>0.603000</td>\n",
       "      <td>0.615136</td>\n",
       "      <td>274.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>5.0</td>\n",
       "      <td>64.0</td>\n",
       "      <td>0.21</td>\n",
       "      <td>790.0</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th rowspan=\"3\" valign=\"top\">0.5</th>\n",
       "      <th>0.0001</th>\n",
       "      <td>0.571651</td>\n",
       "      <td>0.424104</td>\n",
       "      <td>0.437790</td>\n",
       "      <td>0.418329</td>\n",
       "      <td>0.700727</td>\n",
       "      <td>0.632929</td>\n",
       "      <td>0.625617</td>\n",
       "      <td>0.642152</td>\n",
       "      <td>274.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>5.0</td>\n",
       "      <td>64.0</td>\n",
       "      <td>0.19</td>\n",
       "      <td>790.0</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>0.0005</th>\n",
       "      <td>0.569212</td>\n",
       "      <td>0.425719</td>\n",
       "      <td>0.432750</td>\n",
       "      <td>0.422995</td>\n",
       "      <td>0.698041</td>\n",
       "      <td>0.622801</td>\n",
       "      <td>0.619750</td>\n",
       "      <td>0.627353</td>\n",
       "      <td>274.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>5.0</td>\n",
       "      <td>64.0</td>\n",
       "      <td>0.20</td>\n",
       "      <td>790.0</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>0.0010</th>\n",
       "      <td>0.569182</td>\n",
       "      <td>0.416608</td>\n",
       "      <td>0.425096</td>\n",
       "      <td>0.414033</td>\n",
       "      <td>0.685842</td>\n",
       "      <td>0.601332</td>\n",
       "      <td>0.604227</td>\n",
       "      <td>0.600183</td>\n",
       "      <td>274.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>5.0</td>\n",
       "      <td>64.0</td>\n",
       "      <td>0.18</td>\n",
       "      <td>790.0</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>81 rows  16 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                                                           accuracy        f1  \\\n",
       "dimension sig_depth hidden_dim dropout_rate learning_rate                       \n",
       "6         4         (128, 128) 0.1          0.0001         0.507727  0.360960   \n",
       "                                            0.0005         0.521780  0.353246   \n",
       "                                            0.0010         0.533547  0.351780   \n",
       "                               0.2          0.0001         0.510837  0.350623   \n",
       "                                            0.0005         0.535985  0.351374   \n",
       "...                                                             ...       ...   \n",
       "28        2         (512, 512) 0.2          0.0005         0.558482  0.421841   \n",
       "                                            0.0010         0.552446  0.418218   \n",
       "                               0.5          0.0001         0.571651  0.424104   \n",
       "                                            0.0005         0.569212  0.425719   \n",
       "                                            0.0010         0.569182  0.416608   \n",
       "\n",
       "                                                           precision  \\\n",
       "dimension sig_depth hidden_dim dropout_rate learning_rate              \n",
       "6         4         (128, 128) 0.1          0.0001          0.361479   \n",
       "                                            0.0005          0.356971   \n",
       "                                            0.0010          0.356994   \n",
       "                               0.2          0.0001          0.353179   \n",
       "                                            0.0005          0.357155   \n",
       "...                                                              ...   \n",
       "28        2         (512, 512) 0.2          0.0005          0.424717   \n",
       "                                            0.0010          0.419986   \n",
       "                               0.5          0.0001          0.437790   \n",
       "                                            0.0005          0.432750   \n",
       "                                            0.0010          0.425096   \n",
       "\n",
       "                                                             recall  \\\n",
       "dimension sig_depth hidden_dim dropout_rate learning_rate             \n",
       "6         4         (128, 128) 0.1          0.0001         0.361194   \n",
       "                                            0.0005         0.353992   \n",
       "                                            0.0010         0.353643   \n",
       "                               0.2          0.0001         0.351986   \n",
       "                                            0.0005         0.353632   \n",
       "...                                                             ...   \n",
       "28        2         (512, 512) 0.2          0.0005         0.422468   \n",
       "                                            0.0010         0.418650   \n",
       "                               0.5          0.0001         0.418329   \n",
       "                                            0.0005         0.422995   \n",
       "                                            0.0010         0.414033   \n",
       "\n",
       "                                                           valid_accuracy  \\\n",
       "dimension sig_depth hidden_dim dropout_rate learning_rate                   \n",
       "6         4         (128, 128) 0.1          0.0001               0.674561   \n",
       "                                            0.0005               0.677583   \n",
       "                                            0.0010               0.671964   \n",
       "                               0.2          0.0001               0.667085   \n",
       "                                            0.0005               0.669950   \n",
       "...                                                                   ...   \n",
       "28        2         (512, 512) 0.2          0.0005               0.691214   \n",
       "                                            0.0010               0.684947   \n",
       "                               0.5          0.0001               0.700727   \n",
       "                                            0.0005               0.698041   \n",
       "                                            0.0010               0.685842   \n",
       "\n",
       "                                                           valid_f1  \\\n",
       "dimension sig_depth hidden_dim dropout_rate learning_rate             \n",
       "6         4         (128, 128) 0.1          0.0001         0.605467   \n",
       "                                            0.0005         0.603045   \n",
       "                                            0.0010         0.590930   \n",
       "                               0.2          0.0001         0.593311   \n",
       "                                            0.0005         0.579355   \n",
       "...                                                             ...   \n",
       "28        2         (512, 512) 0.2          0.0005         0.622049   \n",
       "                                            0.0010         0.607931   \n",
       "                               0.5          0.0001         0.632929   \n",
       "                                            0.0005         0.622801   \n",
       "                                            0.0010         0.601332   \n",
       "\n",
       "                                                           valid_precision  \\\n",
       "dimension sig_depth hidden_dim dropout_rate learning_rate                    \n",
       "6         4         (128, 128) 0.1          0.0001                0.598644   \n",
       "                                            0.0005                0.601896   \n",
       "                                            0.0010                0.596559   \n",
       "                               0.2          0.0001                0.590125   \n",
       "                                            0.0005                0.593786   \n",
       "...                                                                    ...   \n",
       "28        2         (512, 512) 0.2          0.0005                0.613301   \n",
       "                                            0.0010                0.603000   \n",
       "                               0.5          0.0001                0.625617   \n",
       "                                            0.0005                0.619750   \n",
       "                                            0.0010                0.604227   \n",
       "\n",
       "                                                           valid_recall  \\\n",
       "dimension sig_depth hidden_dim dropout_rate learning_rate                 \n",
       "6         4         (128, 128) 0.1          0.0001             0.615130   \n",
       "                                            0.0005             0.605461   \n",
       "                                            0.0010             0.588186   \n",
       "                               0.2          0.0001             0.600733   \n",
       "                                            0.0005             0.570571   \n",
       "...                                                                 ...   \n",
       "28        2         (512, 512) 0.2          0.0005             0.635576   \n",
       "                                            0.0010             0.615136   \n",
       "                               0.5          0.0001             0.642152   \n",
       "                                            0.0005             0.627353   \n",
       "                                            0.0010             0.600183   \n",
       "\n",
       "                                                            seed  gamma  \\\n",
       "dimension sig_depth hidden_dim dropout_rate learning_rate                 \n",
       "6         4         (128, 128) 0.1          0.0001         274.0    2.0   \n",
       "                                            0.0005         274.0    2.0   \n",
       "                                            0.0010         274.0    2.0   \n",
       "                               0.2          0.0001         274.0    2.0   \n",
       "                                            0.0005         274.0    2.0   \n",
       "...                                                          ...    ...   \n",
       "28        2         (512, 512) 0.2          0.0005         274.0    2.0   \n",
       "                                            0.0010         274.0    2.0   \n",
       "                               0.5          0.0001         274.0    2.0   \n",
       "                                            0.0005         274.0    2.0   \n",
       "                                            0.0010         274.0    2.0   \n",
       "\n",
       "                                                           k_fold  n_splits  \\\n",
       "dimension sig_depth hidden_dim dropout_rate learning_rate                     \n",
       "6         4         (128, 128) 0.1          0.0001            1.0       5.0   \n",
       "                                            0.0005            1.0       5.0   \n",
       "                                            0.0010            1.0       5.0   \n",
       "                               0.2          0.0001            1.0       5.0   \n",
       "                                            0.0005            1.0       5.0   \n",
       "...                                                           ...       ...   \n",
       "28        2         (512, 512) 0.2          0.0005            1.0       5.0   \n",
       "                                            0.0010            1.0       5.0   \n",
       "                               0.5          0.0001            1.0       5.0   \n",
       "                                            0.0005            1.0       5.0   \n",
       "                                            0.0010            1.0       5.0   \n",
       "\n",
       "                                                           batch_size  \\\n",
       "dimension sig_depth hidden_dim dropout_rate learning_rate               \n",
       "6         4         (128, 128) 0.1          0.0001               64.0   \n",
       "                                            0.0005               64.0   \n",
       "                                            0.0010               64.0   \n",
       "                               0.2          0.0001               64.0   \n",
       "                                            0.0005               64.0   \n",
       "...                                                               ...   \n",
       "28        2         (512, 512) 0.2          0.0005               64.0   \n",
       "                                            0.0010               64.0   \n",
       "                               0.5          0.0001               64.0   \n",
       "                                            0.0005               64.0   \n",
       "                                            0.0010               64.0   \n",
       "\n",
       "                                                           model_id  \\\n",
       "dimension sig_depth hidden_dim dropout_rate learning_rate             \n",
       "6         4         (128, 128) 0.1          0.0001             2.70   \n",
       "                                            0.0005             2.80   \n",
       "                                            0.0010             2.60   \n",
       "                               0.2          0.0001             2.40   \n",
       "                                            0.0005             2.50   \n",
       "...                                                             ...   \n",
       "28        2         (512, 512) 0.2          0.0005             0.23   \n",
       "                                            0.0010             0.21   \n",
       "                               0.5          0.0001             0.19   \n",
       "                                            0.0005             0.20   \n",
       "                                            0.0010             0.18   \n",
       "\n",
       "                                                           input_dim  \\\n",
       "dimension sig_depth hidden_dim dropout_rate learning_rate              \n",
       "6         4         (128, 128) 0.1          0.0001             790.0   \n",
       "                                            0.0005             790.0   \n",
       "                                            0.0010             790.0   \n",
       "                               0.2          0.0001             790.0   \n",
       "                                            0.0005             790.0   \n",
       "...                                                              ...   \n",
       "28        2         (512, 512) 0.2          0.0005             790.0   \n",
       "                                            0.0010             790.0   \n",
       "                               0.5          0.0001             790.0   \n",
       "                                            0.0005             790.0   \n",
       "                                            0.0010             790.0   \n",
       "\n",
       "                                                           log_signature  \n",
       "dimension sig_depth hidden_dim dropout_rate learning_rate                 \n",
       "6         4         (128, 128) 0.1          0.0001                   1.0  \n",
       "                                            0.0005                   1.0  \n",
       "                                            0.0010                   1.0  \n",
       "                               0.2          0.0001                   1.0  \n",
       "                                            0.0005                   1.0  \n",
       "...                                                                  ...  \n",
       "28        2         (512, 512) 0.2          0.0005                   1.0  \n",
       "                                            0.0010                   1.0  \n",
       "                               0.5          0.0001                   1.0  \n",
       "                                            0.0005                   1.0  \n",
       "                                            0.0010                   1.0  \n",
       "\n",
       "[81 rows x 16 columns]"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "ffn_logsignature_umap_kfold.groupby([\"dimension\", \"sig_depth\", \"hidden_dim\", \"dropout_rate\", \"learning_rate\"]).mean()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "d1ea8817",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>loss</th>\n",
       "      <th>accuracy</th>\n",
       "      <th>f1</th>\n",
       "      <th>f1_scores</th>\n",
       "      <th>precision</th>\n",
       "      <th>precision_scores</th>\n",
       "      <th>recall</th>\n",
       "      <th>recall_scores</th>\n",
       "      <th>valid_loss</th>\n",
       "      <th>valid_accuracy</th>\n",
       "      <th>...</th>\n",
       "      <th>loss_function</th>\n",
       "      <th>gamma</th>\n",
       "      <th>k_fold</th>\n",
       "      <th>n_splits</th>\n",
       "      <th>batch_size</th>\n",
       "      <th>input_dim</th>\n",
       "      <th>dimension</th>\n",
       "      <th>sig_depth</th>\n",
       "      <th>method</th>\n",
       "      <th>log_signature</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>None</td>\n",
       "      <td>0.554031</td>\n",
       "      <td>0.419155</td>\n",
       "      <td>[0.7003303445021235, 0.30224470439456214, 0.25...</td>\n",
       "      <td>0.423570</td>\n",
       "      <td>[0.6856086856086856, 0.3087855297157623, 0.276...</td>\n",
       "      <td>0.416073</td>\n",
       "      <td>[0.7156980950084398, 0.2959752321981424, 0.236...</td>\n",
       "      <td>None</td>\n",
       "      <td>0.710241</td>\n",
       "      <td>...</td>\n",
       "      <td>focal</td>\n",
       "      <td>2</td>\n",
       "      <td>True</td>\n",
       "      <td>5</td>\n",
       "      <td>64</td>\n",
       "      <td>790</td>\n",
       "      <td>28</td>\n",
       "      <td>2</td>\n",
       "      <td>umap</td>\n",
       "      <td>True</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>None</td>\n",
       "      <td>0.557994</td>\n",
       "      <td>0.420992</td>\n",
       "      <td>[0.7042889390519187, 0.32575521644347555, 0.23...</td>\n",
       "      <td>0.424066</td>\n",
       "      <td>[0.6941451990632318, 0.3276942355889724, 0.250...</td>\n",
       "      <td>0.418782</td>\n",
       "      <td>[0.7147335423197492, 0.3238390092879257, 0.217...</td>\n",
       "      <td>None</td>\n",
       "      <td>0.707219</td>\n",
       "      <td>...</td>\n",
       "      <td>focal</td>\n",
       "      <td>2</td>\n",
       "      <td>True</td>\n",
       "      <td>5</td>\n",
       "      <td>64</td>\n",
       "      <td>790</td>\n",
       "      <td>28</td>\n",
       "      <td>2</td>\n",
       "      <td>umap</td>\n",
       "      <td>True</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>None</td>\n",
       "      <td>0.567139</td>\n",
       "      <td>0.437518</td>\n",
       "      <td>[0.7096165191740413, 0.3223418573351279, 0.280...</td>\n",
       "      <td>0.438676</td>\n",
       "      <td>[0.6947781885397413, 0.35298452468680913, 0.26...</td>\n",
       "      <td>0.438605</td>\n",
       "      <td>[0.7251024837231734, 0.29659442724458207, 0.29...</td>\n",
       "      <td>None</td>\n",
       "      <td>0.709121</td>\n",
       "      <td>...</td>\n",
       "      <td>focal</td>\n",
       "      <td>2</td>\n",
       "      <td>True</td>\n",
       "      <td>5</td>\n",
       "      <td>64</td>\n",
       "      <td>790</td>\n",
       "      <td>28</td>\n",
       "      <td>2</td>\n",
       "      <td>umap</td>\n",
       "      <td>True</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>None</td>\n",
       "      <td>0.586344</td>\n",
       "      <td>0.448983</td>\n",
       "      <td>[0.7226557949912639, 0.3574440480051898, 0.266...</td>\n",
       "      <td>0.456829</td>\n",
       "      <td>[0.6989634970707526, 0.3753405994550409, 0.296...</td>\n",
       "      <td>0.443997</td>\n",
       "      <td>[0.7480106100795756, 0.3411764705882353, 0.242...</td>\n",
       "      <td>None</td>\n",
       "      <td>0.706659</td>\n",
       "      <td>...</td>\n",
       "      <td>focal</td>\n",
       "      <td>2</td>\n",
       "      <td>True</td>\n",
       "      <td>5</td>\n",
       "      <td>64</td>\n",
       "      <td>790</td>\n",
       "      <td>28</td>\n",
       "      <td>2</td>\n",
       "      <td>umap</td>\n",
       "      <td>True</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>None</td>\n",
       "      <td>0.589392</td>\n",
       "      <td>0.433413</td>\n",
       "      <td>[0.7356192194901872, 0.2915430267062315, 0.273...</td>\n",
       "      <td>0.444828</td>\n",
       "      <td>[0.6910362364907819, 0.3635522664199815, 0.279...</td>\n",
       "      <td>0.432093</td>\n",
       "      <td>[0.7863515794550278, 0.243343653250774, 0.2665...</td>\n",
       "      <td>None</td>\n",
       "      <td>0.706995</td>\n",
       "      <td>...</td>\n",
       "      <td>focal</td>\n",
       "      <td>2</td>\n",
       "      <td>True</td>\n",
       "      <td>5</td>\n",
       "      <td>64</td>\n",
       "      <td>790</td>\n",
       "      <td>28</td>\n",
       "      <td>2</td>\n",
       "      <td>umap</td>\n",
       "      <td>True</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows  30 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "   loss  accuracy        f1  \\\n",
       "0  None  0.554031  0.419155   \n",
       "0  None  0.557994  0.420992   \n",
       "0  None  0.567139  0.437518   \n",
       "0  None  0.586344  0.448983   \n",
       "0  None  0.589392  0.433413   \n",
       "\n",
       "                                           f1_scores  precision  \\\n",
       "0  [0.7003303445021235, 0.30224470439456214, 0.25...   0.423570   \n",
       "0  [0.7042889390519187, 0.32575521644347555, 0.23...   0.424066   \n",
       "0  [0.7096165191740413, 0.3223418573351279, 0.280...   0.438676   \n",
       "0  [0.7226557949912639, 0.3574440480051898, 0.266...   0.456829   \n",
       "0  [0.7356192194901872, 0.2915430267062315, 0.273...   0.444828   \n",
       "\n",
       "                                    precision_scores    recall  \\\n",
       "0  [0.6856086856086856, 0.3087855297157623, 0.276...  0.416073   \n",
       "0  [0.6941451990632318, 0.3276942355889724, 0.250...  0.418782   \n",
       "0  [0.6947781885397413, 0.35298452468680913, 0.26...  0.438605   \n",
       "0  [0.6989634970707526, 0.3753405994550409, 0.296...  0.443997   \n",
       "0  [0.6910362364907819, 0.3635522664199815, 0.279...  0.432093   \n",
       "\n",
       "                                       recall_scores valid_loss  \\\n",
       "0  [0.7156980950084398, 0.2959752321981424, 0.236...       None   \n",
       "0  [0.7147335423197492, 0.3238390092879257, 0.217...       None   \n",
       "0  [0.7251024837231734, 0.29659442724458207, 0.29...       None   \n",
       "0  [0.7480106100795756, 0.3411764705882353, 0.242...       None   \n",
       "0  [0.7863515794550278, 0.243343653250774, 0.2665...       None   \n",
       "\n",
       "   valid_accuracy  ...  loss_function gamma  k_fold n_splits  batch_size  \\\n",
       "0        0.710241  ...          focal     2    True        5          64   \n",
       "0        0.707219  ...          focal     2    True        5          64   \n",
       "0        0.709121  ...          focal     2    True        5          64   \n",
       "0        0.706659  ...          focal     2    True        5          64   \n",
       "0        0.706995  ...          focal     2    True        5          64   \n",
       "\n",
       "  input_dim dimension  sig_depth  method  log_signature  \n",
       "0       790        28          2    umap           True  \n",
       "0       790        28          2    umap           True  \n",
       "0       790        28          2    umap           True  \n",
       "0       790        28          2    umap           True  \n",
       "0       790        28          2    umap           True  \n",
       "\n",
       "[5 rows x 30 columns]"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "best_ffn_logsignature_umap_kfold"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "db662960",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.4320122761881547"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "best_ffn_logsignature_umap_kfold[\"f1\"].mean()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "266373f0",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.4375938257198291"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "best_ffn_logsignature_umap_kfold[\"precision\"].mean()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "11064150",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.4299098254001956"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "best_ffn_logsignature_umap_kfold[\"recall\"].mean()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "f9d8a18b",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([0.71450216, 0.31986577, 0.26166889])"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "np.stack(best_ffn_logsignature_umap_kfold[\"f1_scores\"]).mean(axis=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "28d6b708",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([0.69290636, 0.34567143, 0.27420368])"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "np.stack(best_ffn_logsignature_umap_kfold[\"precision_scores\"]).mean(axis=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "4f57cc89",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([0.73797926, 0.30018576, 0.25156446])"
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "np.stack(best_ffn_logsignature_umap_kfold[\"recall_scores\"]).mean(axis=0)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0de6f338",
   "metadata": {},
   "source": [
    "### Using random projections"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "bcf5003d",
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "364acc0489fe4f418c7f8f264419834c",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/3 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "fde03cb85d614d01856b0f63cf310c47",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/1 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[INFO] Concatenating the embeddings to the dataframe...\n",
      "[INFO] - columns beginning with 'e' denote the full embddings.\n",
      "[INFO] - columns beginning with 'd' denote the dimension reduced embeddings.\n",
      "[INFO] Adding time feature columns into dataframe in `.df`.\n",
      "[INFO] Adding 'time_encoding' and feature...\n",
      "[INFO] Adding 'time_diff' and feature...\n",
      "[INFO] Adding 'timeline_index' feature...\n",
      "[INFO] Padding ids and storing in `.df_padded` and `.array_padded` attributes.\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "e3b785600732456dba29ae8262b5932e",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/13551 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "03cacc76fd0e4467bf22236a7080eb5d",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/3 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "d2b928453397468789bcbb293a530753",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/3 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "7d171114655b4807a0ceb90e0822ed86",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/3 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "c21e636d99164da1b7a10f1981fc2d20",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/3 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "0c1700f86a0043f8a4e8423930728b90",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/3 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "5023a4de497d4d54b4373d8bfe204195",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/3 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "5e032531907b410f9774e535699ba29c",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/3 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "44b489c8d53440d48bfd6bc29cb354ea",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/3 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "4335fc03b0ea47da9c8f83b7af1f1b36",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/3 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "f2ef83ea35bf430c9090a98d27c2b466",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/3 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "119e253b7df744318b014f4dbd03124a",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/3 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "bb0612519f474395a67c45c30638eb38",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/3 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "17f3d35796f445ccb8a0f728f1fad615",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/3 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "5052f4370a554cf3b31d225f1d103090",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/1 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[INFO] Concatenating the embeddings to the dataframe...\n",
      "[INFO] - columns beginning with 'e' denote the full embddings.\n",
      "[INFO] - columns beginning with 'd' denote the dimension reduced embeddings.\n",
      "[INFO] Adding time feature columns into dataframe in `.df`.\n",
      "[INFO] Adding 'time_encoding' and feature...\n",
      "[INFO] Adding 'time_diff' and feature...\n",
      "[INFO] Adding 'timeline_index' feature...\n",
      "[INFO] Padding ids and storing in `.df_padded` and `.array_padded` attributes.\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "b6e4f74fddb14f2dbbcc228f6a0474cc",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/13551 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "43f87f7114ac4bc58ee95e4c2cff978b",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/3 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "4a798f4761154d46ae64d82078ab8b24",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/3 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "0d625b993e184dcbad023c16de35352a",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/3 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "6acd5d6b78e24cc29b9e5bcd9d80b07e",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/3 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "f23699abcc4246918c000f227172bf9c",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/3 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "8fcc74a77deb4b378e6ab03f19cf8339",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/3 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "5ee7c97c9eef455db7bdf56c3ea97c9e",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/3 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "2cfdbf9ae5824c318fd28d453b9d725e",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/3 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "d50bd2abbe2f4fb1a09823490419a017",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/3 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "1ac3ddfc71d54dc39c53ca158828d6dd",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/3 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "0f31412a6ab5430daa2921cafadd7157",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/3 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "1e01b2a90c4d42729cc9ea383dc44853",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/3 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "2c1344e70702438a851aa6c83cb4322c",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/3 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "d1f8d4ceef0e4c30b6db6982813a15e2",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/1 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[INFO] Concatenating the embeddings to the dataframe...\n",
      "[INFO] - columns beginning with 'e' denote the full embddings.\n",
      "[INFO] - columns beginning with 'd' denote the dimension reduced embeddings.\n",
      "[INFO] Adding time feature columns into dataframe in `.df`.\n",
      "[INFO] Adding 'time_encoding' and feature...\n",
      "[INFO] Adding 'time_diff' and feature...\n",
      "[INFO] Adding 'timeline_index' feature...\n",
      "[INFO] Padding ids and storing in `.df_padded` and `.array_padded` attributes.\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "e271fe56859d477d80fe189d61eeccf1",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/13551 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "e89f352ba64e46b49af30e40fe8d7e56",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/3 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "3f8ce6e0de0146a897f54f013dfdca99",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/3 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "5d8cc0ab85ae49c595625b99bc4dab0b",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/3 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "8ab2a146c52b4dc889976c029fec7348",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/3 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "13be0b80e3864970b941fdc73af45dd7",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/3 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "7a50a03b5f82429e99136c9fc1ea6928",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/3 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "04c3c58da14e44628aa97a2ee2beeced",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/3 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "4db10826349f4ea48cbf3fe6ddf9ca02",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/3 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "4a3445779dc6488981a53121d753f235",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/3 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "e443e83398ae4e7fa2b0c65fb74d4453",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/3 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "62bcf93bc7624b07a51902fed707194b",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/3 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "e8921447809649f0bf7d16373ac72536",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/3 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "1e8d4a8831704149bd15e1b9cb808f78",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/3 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[INFO] Concatenating the embeddings to the dataframe...\n",
      "[INFO] - columns beginning with 'e' denote the full embddings.\n",
      "[INFO] - columns beginning with 'd' denote the dimension reduced embeddings.\n",
      "[INFO] Adding time feature columns into dataframe in `.df`.\n",
      "[INFO] Adding 'time_encoding' and feature...\n",
      "[INFO] Adding 'time_diff' and feature...\n",
      "[INFO] Adding 'timeline_index' feature...\n",
      "[INFO] Padding ids and storing in `.df_padded` and `.array_padded` attributes.\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "4421aa966bad4860a0620f26a5010b5f",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/13551 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "saving results dataframe to CSV for this hyperparameter search in client_talk_type_output/ffn_logsignature_grp_focal_2_kfold.csv\n",
      "saving the best model results dataframe to CSV for this hyperparameter search in client_talk_type_output/ffn_logsignature_grp_focal_2_kfold_best_model.csv\n"
     ]
    }
   ],
   "source": [
    "ffn_logsignature_grp_kfold, best_ffn_logsignature_grp_kfold, _, __ = histories_baseline_hyperparameter_search(\n",
    "    num_epochs=num_epochs,\n",
    "    df=anno_mi,\n",
    "    id_column=\"transcript_id\",\n",
    "    label_column=\"client_talk_type\",\n",
    "    embeddings=sbert_embeddings,\n",
    "    y_data=y_data_client,\n",
    "    output_dim=output_dim_client,\n",
    "    hidden_dim_sizes=hidden_dim_sizes,\n",
    "    dropout_rates=dropout_rates,\n",
    "    learning_rates=learning_rates,\n",
    "    use_signatures=True,\n",
    "    seeds=seeds,\n",
    "    loss=loss,\n",
    "    gamma=gamma,\n",
    "    log_signature=True,\n",
    "    dim_reduce_methods=[\"gaussian_random_projection\"],\n",
    "    dimension_and_sig_depths=log_signature_dimensions_and_sig_depths,\n",
    "    path_indices=client_index,\n",
    "    split_ids=client_transcript_id,\n",
    "    k_fold=True,\n",
    "    patience=patience,\n",
    "    validation_metric=validation_metric,\n",
    "    results_output=f\"{output_dir}/ffn_logsignature_grp_focal_{gamma}_kfold.csv\",\n",
    "    verbose=False\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "9c137d34",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/var/folders/l7/bnn1j6bs3bqfskq2jlq55yh80000gr/T/ipykernel_18434/2536377135.py:1: FutureWarning: The default value of numeric_only in DataFrameGroupBy.mean is deprecated. In a future version, numeric_only will default to False. Either specify numeric_only or select only columns which should be valid for the function.\n",
      "  ffn_logsignature_grp_kfold.groupby([\"dimension\", \"sig_depth\", \"hidden_dim\", \"dropout_rate\", \"learning_rate\"]).mean()\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th>accuracy</th>\n",
       "      <th>f1</th>\n",
       "      <th>precision</th>\n",
       "      <th>recall</th>\n",
       "      <th>valid_accuracy</th>\n",
       "      <th>valid_f1</th>\n",
       "      <th>valid_precision</th>\n",
       "      <th>valid_recall</th>\n",
       "      <th>seed</th>\n",
       "      <th>gamma</th>\n",
       "      <th>k_fold</th>\n",
       "      <th>n_splits</th>\n",
       "      <th>batch_size</th>\n",
       "      <th>model_id</th>\n",
       "      <th>input_dim</th>\n",
       "      <th>log_signature</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>dimension</th>\n",
       "      <th>sig_depth</th>\n",
       "      <th>hidden_dim</th>\n",
       "      <th>dropout_rate</th>\n",
       "      <th>learning_rate</th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th rowspan=\"5\" valign=\"top\">6</th>\n",
       "      <th rowspan=\"5\" valign=\"top\">4</th>\n",
       "      <th rowspan=\"5\" valign=\"top\">(128, 128)</th>\n",
       "      <th rowspan=\"3\" valign=\"top\">0.1</th>\n",
       "      <th>0.0001</th>\n",
       "      <td>0.596738</td>\n",
       "      <td>0.497316</td>\n",
       "      <td>0.492549</td>\n",
       "      <td>0.504843</td>\n",
       "      <td>0.726782</td>\n",
       "      <td>0.666325</td>\n",
       "      <td>0.656439</td>\n",
       "      <td>0.680714</td>\n",
       "      <td>274.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>5.0</td>\n",
       "      <td>64.0</td>\n",
       "      <td>2.70</td>\n",
       "      <td>790.0</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>0.0005</th>\n",
       "      <td>0.590520</td>\n",
       "      <td>0.492322</td>\n",
       "      <td>0.487288</td>\n",
       "      <td>0.502508</td>\n",
       "      <td>0.722171</td>\n",
       "      <td>0.664517</td>\n",
       "      <td>0.652301</td>\n",
       "      <td>0.683179</td>\n",
       "      <td>274.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>5.0</td>\n",
       "      <td>64.0</td>\n",
       "      <td>2.80</td>\n",
       "      <td>790.0</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>0.0010</th>\n",
       "      <td>0.583783</td>\n",
       "      <td>0.487006</td>\n",
       "      <td>0.482385</td>\n",
       "      <td>0.499384</td>\n",
       "      <td>0.720739</td>\n",
       "      <td>0.664204</td>\n",
       "      <td>0.651099</td>\n",
       "      <td>0.684598</td>\n",
       "      <td>274.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>5.0</td>\n",
       "      <td>64.0</td>\n",
       "      <td>2.60</td>\n",
       "      <td>790.0</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th rowspan=\"2\" valign=\"top\">0.2</th>\n",
       "      <th>0.0001</th>\n",
       "      <td>0.599726</td>\n",
       "      <td>0.498823</td>\n",
       "      <td>0.494740</td>\n",
       "      <td>0.505544</td>\n",
       "      <td>0.729200</td>\n",
       "      <td>0.667892</td>\n",
       "      <td>0.659051</td>\n",
       "      <td>0.680876</td>\n",
       "      <td>274.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>5.0</td>\n",
       "      <td>64.0</td>\n",
       "      <td>2.40</td>\n",
       "      <td>790.0</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>0.0005</th>\n",
       "      <td>0.590642</td>\n",
       "      <td>0.494794</td>\n",
       "      <td>0.489605</td>\n",
       "      <td>0.507964</td>\n",
       "      <td>0.721500</td>\n",
       "      <td>0.664249</td>\n",
       "      <td>0.651206</td>\n",
       "      <td>0.684439</td>\n",
       "      <td>274.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>5.0</td>\n",
       "      <td>64.0</td>\n",
       "      <td>2.50</td>\n",
       "      <td>790.0</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <th>...</th>\n",
       "      <th>...</th>\n",
       "      <th>...</th>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th rowspan=\"5\" valign=\"top\">28</th>\n",
       "      <th rowspan=\"5\" valign=\"top\">2</th>\n",
       "      <th rowspan=\"5\" valign=\"top\">(512, 512)</th>\n",
       "      <th rowspan=\"2\" valign=\"top\">0.2</th>\n",
       "      <th>0.0005</th>\n",
       "      <td>0.602683</td>\n",
       "      <td>0.497789</td>\n",
       "      <td>0.495270</td>\n",
       "      <td>0.502661</td>\n",
       "      <td>0.736363</td>\n",
       "      <td>0.678770</td>\n",
       "      <td>0.668547</td>\n",
       "      <td>0.694509</td>\n",
       "      <td>274.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>5.0</td>\n",
       "      <td>64.0</td>\n",
       "      <td>0.23</td>\n",
       "      <td>790.0</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>0.0010</th>\n",
       "      <td>0.590764</td>\n",
       "      <td>0.492928</td>\n",
       "      <td>0.487598</td>\n",
       "      <td>0.506012</td>\n",
       "      <td>0.728774</td>\n",
       "      <td>0.672048</td>\n",
       "      <td>0.659378</td>\n",
       "      <td>0.692117</td>\n",
       "      <td>274.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>5.0</td>\n",
       "      <td>64.0</td>\n",
       "      <td>0.21</td>\n",
       "      <td>790.0</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th rowspan=\"3\" valign=\"top\">0.5</th>\n",
       "      <th>0.0001</th>\n",
       "      <td>0.612498</td>\n",
       "      <td>0.496083</td>\n",
       "      <td>0.499469</td>\n",
       "      <td>0.493388</td>\n",
       "      <td>0.742899</td>\n",
       "      <td>0.685333</td>\n",
       "      <td>0.675236</td>\n",
       "      <td>0.698494</td>\n",
       "      <td>274.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>5.0</td>\n",
       "      <td>64.0</td>\n",
       "      <td>0.19</td>\n",
       "      <td>790.0</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>0.0005</th>\n",
       "      <td>0.600671</td>\n",
       "      <td>0.501886</td>\n",
       "      <td>0.497436</td>\n",
       "      <td>0.508291</td>\n",
       "      <td>0.740168</td>\n",
       "      <td>0.684544</td>\n",
       "      <td>0.672763</td>\n",
       "      <td>0.700381</td>\n",
       "      <td>274.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>5.0</td>\n",
       "      <td>64.0</td>\n",
       "      <td>0.20</td>\n",
       "      <td>790.0</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>0.0010</th>\n",
       "      <td>0.589727</td>\n",
       "      <td>0.495327</td>\n",
       "      <td>0.488539</td>\n",
       "      <td>0.508501</td>\n",
       "      <td>0.735937</td>\n",
       "      <td>0.679724</td>\n",
       "      <td>0.668294</td>\n",
       "      <td>0.695331</td>\n",
       "      <td>274.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>5.0</td>\n",
       "      <td>64.0</td>\n",
       "      <td>0.18</td>\n",
       "      <td>790.0</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>81 rows  16 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                                                           accuracy        f1  \\\n",
       "dimension sig_depth hidden_dim dropout_rate learning_rate                       \n",
       "6         4         (128, 128) 0.1          0.0001         0.596738  0.497316   \n",
       "                                            0.0005         0.590520  0.492322   \n",
       "                                            0.0010         0.583783  0.487006   \n",
       "                               0.2          0.0001         0.599726  0.498823   \n",
       "                                            0.0005         0.590642  0.494794   \n",
       "...                                                             ...       ...   \n",
       "28        2         (512, 512) 0.2          0.0005         0.602683  0.497789   \n",
       "                                            0.0010         0.590764  0.492928   \n",
       "                               0.5          0.0001         0.612498  0.496083   \n",
       "                                            0.0005         0.600671  0.501886   \n",
       "                                            0.0010         0.589727  0.495327   \n",
       "\n",
       "                                                           precision  \\\n",
       "dimension sig_depth hidden_dim dropout_rate learning_rate              \n",
       "6         4         (128, 128) 0.1          0.0001          0.492549   \n",
       "                                            0.0005          0.487288   \n",
       "                                            0.0010          0.482385   \n",
       "                               0.2          0.0001          0.494740   \n",
       "                                            0.0005          0.489605   \n",
       "...                                                              ...   \n",
       "28        2         (512, 512) 0.2          0.0005          0.495270   \n",
       "                                            0.0010          0.487598   \n",
       "                               0.5          0.0001          0.499469   \n",
       "                                            0.0005          0.497436   \n",
       "                                            0.0010          0.488539   \n",
       "\n",
       "                                                             recall  \\\n",
       "dimension sig_depth hidden_dim dropout_rate learning_rate             \n",
       "6         4         (128, 128) 0.1          0.0001         0.504843   \n",
       "                                            0.0005         0.502508   \n",
       "                                            0.0010         0.499384   \n",
       "                               0.2          0.0001         0.505544   \n",
       "                                            0.0005         0.507964   \n",
       "...                                                             ...   \n",
       "28        2         (512, 512) 0.2          0.0005         0.502661   \n",
       "                                            0.0010         0.506012   \n",
       "                               0.5          0.0001         0.493388   \n",
       "                                            0.0005         0.508291   \n",
       "                                            0.0010         0.508501   \n",
       "\n",
       "                                                           valid_accuracy  \\\n",
       "dimension sig_depth hidden_dim dropout_rate learning_rate                   \n",
       "6         4         (128, 128) 0.1          0.0001               0.726782   \n",
       "                                            0.0005               0.722171   \n",
       "                                            0.0010               0.720739   \n",
       "                               0.2          0.0001               0.729200   \n",
       "                                            0.0005               0.721500   \n",
       "...                                                                   ...   \n",
       "28        2         (512, 512) 0.2          0.0005               0.736363   \n",
       "                                            0.0010               0.728774   \n",
       "                               0.5          0.0001               0.742899   \n",
       "                                            0.0005               0.740168   \n",
       "                                            0.0010               0.735937   \n",
       "\n",
       "                                                           valid_f1  \\\n",
       "dimension sig_depth hidden_dim dropout_rate learning_rate             \n",
       "6         4         (128, 128) 0.1          0.0001         0.666325   \n",
       "                                            0.0005         0.664517   \n",
       "                                            0.0010         0.664204   \n",
       "                               0.2          0.0001         0.667892   \n",
       "                                            0.0005         0.664249   \n",
       "...                                                             ...   \n",
       "28        2         (512, 512) 0.2          0.0005         0.678770   \n",
       "                                            0.0010         0.672048   \n",
       "                               0.5          0.0001         0.685333   \n",
       "                                            0.0005         0.684544   \n",
       "                                            0.0010         0.679724   \n",
       "\n",
       "                                                           valid_precision  \\\n",
       "dimension sig_depth hidden_dim dropout_rate learning_rate                    \n",
       "6         4         (128, 128) 0.1          0.0001                0.656439   \n",
       "                                            0.0005                0.652301   \n",
       "                                            0.0010                0.651099   \n",
       "                               0.2          0.0001                0.659051   \n",
       "                                            0.0005                0.651206   \n",
       "...                                                                    ...   \n",
       "28        2         (512, 512) 0.2          0.0005                0.668547   \n",
       "                                            0.0010                0.659378   \n",
       "                               0.5          0.0001                0.675236   \n",
       "                                            0.0005                0.672763   \n",
       "                                            0.0010                0.668294   \n",
       "\n",
       "                                                           valid_recall  \\\n",
       "dimension sig_depth hidden_dim dropout_rate learning_rate                 \n",
       "6         4         (128, 128) 0.1          0.0001             0.680714   \n",
       "                                            0.0005             0.683179   \n",
       "                                            0.0010             0.684598   \n",
       "                               0.2          0.0001             0.680876   \n",
       "                                            0.0005             0.684439   \n",
       "...                                                                 ...   \n",
       "28        2         (512, 512) 0.2          0.0005             0.694509   \n",
       "                                            0.0010             0.692117   \n",
       "                               0.5          0.0001             0.698494   \n",
       "                                            0.0005             0.700381   \n",
       "                                            0.0010             0.695331   \n",
       "\n",
       "                                                            seed  gamma  \\\n",
       "dimension sig_depth hidden_dim dropout_rate learning_rate                 \n",
       "6         4         (128, 128) 0.1          0.0001         274.0    2.0   \n",
       "                                            0.0005         274.0    2.0   \n",
       "                                            0.0010         274.0    2.0   \n",
       "                               0.2          0.0001         274.0    2.0   \n",
       "                                            0.0005         274.0    2.0   \n",
       "...                                                          ...    ...   \n",
       "28        2         (512, 512) 0.2          0.0005         274.0    2.0   \n",
       "                                            0.0010         274.0    2.0   \n",
       "                               0.5          0.0001         274.0    2.0   \n",
       "                                            0.0005         274.0    2.0   \n",
       "                                            0.0010         274.0    2.0   \n",
       "\n",
       "                                                           k_fold  n_splits  \\\n",
       "dimension sig_depth hidden_dim dropout_rate learning_rate                     \n",
       "6         4         (128, 128) 0.1          0.0001            1.0       5.0   \n",
       "                                            0.0005            1.0       5.0   \n",
       "                                            0.0010            1.0       5.0   \n",
       "                               0.2          0.0001            1.0       5.0   \n",
       "                                            0.0005            1.0       5.0   \n",
       "...                                                           ...       ...   \n",
       "28        2         (512, 512) 0.2          0.0005            1.0       5.0   \n",
       "                                            0.0010            1.0       5.0   \n",
       "                               0.5          0.0001            1.0       5.0   \n",
       "                                            0.0005            1.0       5.0   \n",
       "                                            0.0010            1.0       5.0   \n",
       "\n",
       "                                                           batch_size  \\\n",
       "dimension sig_depth hidden_dim dropout_rate learning_rate               \n",
       "6         4         (128, 128) 0.1          0.0001               64.0   \n",
       "                                            0.0005               64.0   \n",
       "                                            0.0010               64.0   \n",
       "                               0.2          0.0001               64.0   \n",
       "                                            0.0005               64.0   \n",
       "...                                                               ...   \n",
       "28        2         (512, 512) 0.2          0.0005               64.0   \n",
       "                                            0.0010               64.0   \n",
       "                               0.5          0.0001               64.0   \n",
       "                                            0.0005               64.0   \n",
       "                                            0.0010               64.0   \n",
       "\n",
       "                                                           model_id  \\\n",
       "dimension sig_depth hidden_dim dropout_rate learning_rate             \n",
       "6         4         (128, 128) 0.1          0.0001             2.70   \n",
       "                                            0.0005             2.80   \n",
       "                                            0.0010             2.60   \n",
       "                               0.2          0.0001             2.40   \n",
       "                                            0.0005             2.50   \n",
       "...                                                             ...   \n",
       "28        2         (512, 512) 0.2          0.0005             0.23   \n",
       "                                            0.0010             0.21   \n",
       "                               0.5          0.0001             0.19   \n",
       "                                            0.0005             0.20   \n",
       "                                            0.0010             0.18   \n",
       "\n",
       "                                                           input_dim  \\\n",
       "dimension sig_depth hidden_dim dropout_rate learning_rate              \n",
       "6         4         (128, 128) 0.1          0.0001             790.0   \n",
       "                                            0.0005             790.0   \n",
       "                                            0.0010             790.0   \n",
       "                               0.2          0.0001             790.0   \n",
       "                                            0.0005             790.0   \n",
       "...                                                              ...   \n",
       "28        2         (512, 512) 0.2          0.0005             790.0   \n",
       "                                            0.0010             790.0   \n",
       "                               0.5          0.0001             790.0   \n",
       "                                            0.0005             790.0   \n",
       "                                            0.0010             790.0   \n",
       "\n",
       "                                                           log_signature  \n",
       "dimension sig_depth hidden_dim dropout_rate learning_rate                 \n",
       "6         4         (128, 128) 0.1          0.0001                   1.0  \n",
       "                                            0.0005                   1.0  \n",
       "                                            0.0010                   1.0  \n",
       "                               0.2          0.0001                   1.0  \n",
       "                                            0.0005                   1.0  \n",
       "...                                                                  ...  \n",
       "28        2         (512, 512) 0.2          0.0005                   1.0  \n",
       "                                            0.0010                   1.0  \n",
       "                               0.5          0.0001                   1.0  \n",
       "                                            0.0005                   1.0  \n",
       "                                            0.0010                   1.0  \n",
       "\n",
       "[81 rows x 16 columns]"
      ]
     },
     "execution_count": 22,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "ffn_logsignature_grp_kfold.groupby([\"dimension\", \"sig_depth\", \"hidden_dim\", \"dropout_rate\", \"learning_rate\"]).mean()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "3fc8b08d",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>loss</th>\n",
       "      <th>accuracy</th>\n",
       "      <th>f1</th>\n",
       "      <th>f1_scores</th>\n",
       "      <th>precision</th>\n",
       "      <th>precision_scores</th>\n",
       "      <th>recall</th>\n",
       "      <th>recall_scores</th>\n",
       "      <th>valid_loss</th>\n",
       "      <th>valid_accuracy</th>\n",
       "      <th>...</th>\n",
       "      <th>loss_function</th>\n",
       "      <th>gamma</th>\n",
       "      <th>k_fold</th>\n",
       "      <th>n_splits</th>\n",
       "      <th>batch_size</th>\n",
       "      <th>input_dim</th>\n",
       "      <th>dimension</th>\n",
       "      <th>sig_depth</th>\n",
       "      <th>method</th>\n",
       "      <th>log_signature</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>None</td>\n",
       "      <td>0.607682</td>\n",
       "      <td>0.487769</td>\n",
       "      <td>[0.7375328083989501, 0.4107657801986543, 0.315...</td>\n",
       "      <td>0.488826</td>\n",
       "      <td>[0.7298701298701299, 0.4256308100929615, 0.310...</td>\n",
       "      <td>0.487137</td>\n",
       "      <td>[0.7453580901856764, 0.39690402476780184, 0.31...</td>\n",
       "      <td>None</td>\n",
       "      <td>0.745495</td>\n",
       "      <td>...</td>\n",
       "      <td>focal</td>\n",
       "      <td>2</td>\n",
       "      <td>True</td>\n",
       "      <td>5</td>\n",
       "      <td>64</td>\n",
       "      <td>790</td>\n",
       "      <td>28</td>\n",
       "      <td>2</td>\n",
       "      <td>gaussian_random_projection</td>\n",
       "      <td>True</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>None</td>\n",
       "      <td>0.613931</td>\n",
       "      <td>0.499005</td>\n",
       "      <td>[0.7391977145577906, 0.4161073825503355, 0.341...</td>\n",
       "      <td>0.500963</td>\n",
       "      <td>[0.729901269393512, 0.4299867899603699, 0.3430...</td>\n",
       "      <td>0.497419</td>\n",
       "      <td>[0.7487340245960936, 0.40309597523219814, 0.34...</td>\n",
       "      <td>None</td>\n",
       "      <td>0.745831</td>\n",
       "      <td>...</td>\n",
       "      <td>focal</td>\n",
       "      <td>2</td>\n",
       "      <td>True</td>\n",
       "      <td>5</td>\n",
       "      <td>64</td>\n",
       "      <td>790</td>\n",
       "      <td>28</td>\n",
       "      <td>2</td>\n",
       "      <td>gaussian_random_projection</td>\n",
       "      <td>True</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>None</td>\n",
       "      <td>0.612102</td>\n",
       "      <td>0.503115</td>\n",
       "      <td>[0.73437876960193, 0.4318957493018926, 0.34307...</td>\n",
       "      <td>0.502770</td>\n",
       "      <td>[0.7347332850591359, 0.43283582089552236, 0.34...</td>\n",
       "      <td>0.503472</td>\n",
       "      <td>[0.7340245960935616, 0.4309597523219814, 0.345...</td>\n",
       "      <td>None</td>\n",
       "      <td>0.743928</td>\n",
       "      <td>...</td>\n",
       "      <td>focal</td>\n",
       "      <td>2</td>\n",
       "      <td>True</td>\n",
       "      <td>5</td>\n",
       "      <td>64</td>\n",
       "      <td>790</td>\n",
       "      <td>28</td>\n",
       "      <td>2</td>\n",
       "      <td>gaussian_random_projection</td>\n",
       "      <td>True</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>None</td>\n",
       "      <td>0.609511</td>\n",
       "      <td>0.489517</td>\n",
       "      <td>[0.7385348421679572, 0.4137709137709138, 0.316...</td>\n",
       "      <td>0.490876</td>\n",
       "      <td>[0.7297551789077212, 0.4306764902880107, 0.312...</td>\n",
       "      <td>0.488690</td>\n",
       "      <td>[0.7475283337352303, 0.39814241486068114, 0.32...</td>\n",
       "      <td>None</td>\n",
       "      <td>0.742026</td>\n",
       "      <td>...</td>\n",
       "      <td>focal</td>\n",
       "      <td>2</td>\n",
       "      <td>True</td>\n",
       "      <td>5</td>\n",
       "      <td>64</td>\n",
       "      <td>790</td>\n",
       "      <td>28</td>\n",
       "      <td>2</td>\n",
       "      <td>gaussian_random_projection</td>\n",
       "      <td>True</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>None</td>\n",
       "      <td>0.604481</td>\n",
       "      <td>0.493301</td>\n",
       "      <td>[0.7306628172741488, 0.40918969264203664, 0.34...</td>\n",
       "      <td>0.493846</td>\n",
       "      <td>[0.728996639462314, 0.41033623910336237, 0.342...</td>\n",
       "      <td>0.492770</td>\n",
       "      <td>[0.732336628888353, 0.40804953560371515, 0.337...</td>\n",
       "      <td>None</td>\n",
       "      <td>0.744040</td>\n",
       "      <td>...</td>\n",
       "      <td>focal</td>\n",
       "      <td>2</td>\n",
       "      <td>True</td>\n",
       "      <td>5</td>\n",
       "      <td>64</td>\n",
       "      <td>790</td>\n",
       "      <td>28</td>\n",
       "      <td>2</td>\n",
       "      <td>gaussian_random_projection</td>\n",
       "      <td>True</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows  30 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "   loss  accuracy        f1  \\\n",
       "0  None  0.607682  0.487769   \n",
       "0  None  0.613931  0.499005   \n",
       "0  None  0.612102  0.503115   \n",
       "0  None  0.609511  0.489517   \n",
       "0  None  0.604481  0.493301   \n",
       "\n",
       "                                           f1_scores  precision  \\\n",
       "0  [0.7375328083989501, 0.4107657801986543, 0.315...   0.488826   \n",
       "0  [0.7391977145577906, 0.4161073825503355, 0.341...   0.500963   \n",
       "0  [0.73437876960193, 0.4318957493018926, 0.34307...   0.502770   \n",
       "0  [0.7385348421679572, 0.4137709137709138, 0.316...   0.490876   \n",
       "0  [0.7306628172741488, 0.40918969264203664, 0.34...   0.493846   \n",
       "\n",
       "                                    precision_scores    recall  \\\n",
       "0  [0.7298701298701299, 0.4256308100929615, 0.310...  0.487137   \n",
       "0  [0.729901269393512, 0.4299867899603699, 0.3430...  0.497419   \n",
       "0  [0.7347332850591359, 0.43283582089552236, 0.34...  0.503472   \n",
       "0  [0.7297551789077212, 0.4306764902880107, 0.312...  0.488690   \n",
       "0  [0.728996639462314, 0.41033623910336237, 0.342...  0.492770   \n",
       "\n",
       "                                       recall_scores valid_loss  \\\n",
       "0  [0.7453580901856764, 0.39690402476780184, 0.31...       None   \n",
       "0  [0.7487340245960936, 0.40309597523219814, 0.34...       None   \n",
       "0  [0.7340245960935616, 0.4309597523219814, 0.345...       None   \n",
       "0  [0.7475283337352303, 0.39814241486068114, 0.32...       None   \n",
       "0  [0.732336628888353, 0.40804953560371515, 0.337...       None   \n",
       "\n",
       "   valid_accuracy  ...  loss_function gamma  k_fold n_splits  batch_size  \\\n",
       "0        0.745495  ...          focal     2    True        5          64   \n",
       "0        0.745831  ...          focal     2    True        5          64   \n",
       "0        0.743928  ...          focal     2    True        5          64   \n",
       "0        0.742026  ...          focal     2    True        5          64   \n",
       "0        0.744040  ...          focal     2    True        5          64   \n",
       "\n",
       "  input_dim dimension  sig_depth                      method  log_signature  \n",
       "0       790        28          2  gaussian_random_projection           True  \n",
       "0       790        28          2  gaussian_random_projection           True  \n",
       "0       790        28          2  gaussian_random_projection           True  \n",
       "0       790        28          2  gaussian_random_projection           True  \n",
       "0       790        28          2  gaussian_random_projection           True  \n",
       "\n",
       "[5 rows x 30 columns]"
      ]
     },
     "execution_count": 23,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "best_ffn_logsignature_grp_kfold"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "0ff79def",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.49454129875840563"
      ]
     },
     "execution_count": 24,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "best_ffn_logsignature_grp_kfold[\"f1\"].mean()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "5d58b6c4",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.49545604731393744"
      ]
     },
     "execution_count": 25,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "best_ffn_logsignature_grp_kfold[\"precision\"].mean()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "65de0ee4",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.4938975025158072"
      ]
     },
     "execution_count": 26,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "best_ffn_logsignature_grp_kfold[\"recall\"].mean()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "d0301fcf",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([0.73606139, 0.4163459 , 0.3312166 ])"
      ]
     },
     "execution_count": 27,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "np.stack(best_ffn_logsignature_grp_kfold[\"f1_scores\"]).mean(axis=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "ee0738ae",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([0.7306513 , 0.42589323, 0.32982361])"
      ]
     },
     "execution_count": 28,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "np.stack(best_ffn_logsignature_grp_kfold[\"precision_scores\"]).mean(axis=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "id": "7d4bd7ed",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([0.74159633, 0.40743034, 0.33266583])"
      ]
     },
     "execution_count": 29,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "np.stack(best_ffn_logsignature_grp_kfold[\"recall_scores\"]).mean(axis=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5a4d4e72",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.16"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
