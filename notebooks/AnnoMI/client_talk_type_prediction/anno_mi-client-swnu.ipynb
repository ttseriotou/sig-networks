{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "a983a5e8",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pickle\n",
    "import os\n",
    "\n",
    "seed = 2023"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "e4e666cc",
   "metadata": {},
   "outputs": [],
   "source": [
    "from nlpsig_networks.scripts.swnu_network_functions import (\n",
    "    swnu_network_hyperparameter_search\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "6e918dde",
   "metadata": {},
   "outputs": [],
   "source": [
    "output_dir = \"client_talk_type_output\"\n",
    "if not os.path.isdir(output_dir):\n",
    "    os.makedirs(output_dir)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "id": "f7409a03",
   "metadata": {},
   "source": [
    "## AnnoMI"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "f00bb922",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>mi_quality</th>\n",
       "      <th>transcript_id</th>\n",
       "      <th>topic</th>\n",
       "      <th>utterance_id</th>\n",
       "      <th>interlocutor</th>\n",
       "      <th>timestamp</th>\n",
       "      <th>utterance_text</th>\n",
       "      <th>annotator_id</th>\n",
       "      <th>therapist_input_exists</th>\n",
       "      <th>therapist_input_subtype</th>\n",
       "      <th>reflection_exists</th>\n",
       "      <th>reflection_subtype</th>\n",
       "      <th>question_exists</th>\n",
       "      <th>question_subtype</th>\n",
       "      <th>main_therapist_behaviour</th>\n",
       "      <th>client_talk_type</th>\n",
       "      <th>datetime</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>high</td>\n",
       "      <td>0</td>\n",
       "      <td>reducing alcohol consumption</td>\n",
       "      <td>0</td>\n",
       "      <td>therapist</td>\n",
       "      <td>00:00:13</td>\n",
       "      <td>Thanks for filling it out. We give this form t...</td>\n",
       "      <td>3</td>\n",
       "      <td>False</td>\n",
       "      <td>NaN</td>\n",
       "      <td>False</td>\n",
       "      <td>NaN</td>\n",
       "      <td>True</td>\n",
       "      <td>open</td>\n",
       "      <td>question</td>\n",
       "      <td>NaN</td>\n",
       "      <td>2023-06-19 00:00:13</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>high</td>\n",
       "      <td>0</td>\n",
       "      <td>reducing alcohol consumption</td>\n",
       "      <td>1</td>\n",
       "      <td>client</td>\n",
       "      <td>00:00:24</td>\n",
       "      <td>Sure.</td>\n",
       "      <td>3</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>neutral</td>\n",
       "      <td>2023-06-19 00:00:24</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>high</td>\n",
       "      <td>0</td>\n",
       "      <td>reducing alcohol consumption</td>\n",
       "      <td>2</td>\n",
       "      <td>therapist</td>\n",
       "      <td>00:00:25</td>\n",
       "      <td>So, let's see. It looks that you put-- You dri...</td>\n",
       "      <td>3</td>\n",
       "      <td>True</td>\n",
       "      <td>information</td>\n",
       "      <td>False</td>\n",
       "      <td>NaN</td>\n",
       "      <td>False</td>\n",
       "      <td>NaN</td>\n",
       "      <td>therapist_input</td>\n",
       "      <td>NaN</td>\n",
       "      <td>2023-06-19 00:00:25</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>high</td>\n",
       "      <td>0</td>\n",
       "      <td>reducing alcohol consumption</td>\n",
       "      <td>3</td>\n",
       "      <td>client</td>\n",
       "      <td>00:00:34</td>\n",
       "      <td>Mm-hmm.</td>\n",
       "      <td>3</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>neutral</td>\n",
       "      <td>2023-06-19 00:00:34</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>high</td>\n",
       "      <td>0</td>\n",
       "      <td>reducing alcohol consumption</td>\n",
       "      <td>4</td>\n",
       "      <td>therapist</td>\n",
       "      <td>00:00:34</td>\n",
       "      <td>-and you usually have three to four drinks whe...</td>\n",
       "      <td>3</td>\n",
       "      <td>True</td>\n",
       "      <td>information</td>\n",
       "      <td>False</td>\n",
       "      <td>NaN</td>\n",
       "      <td>False</td>\n",
       "      <td>NaN</td>\n",
       "      <td>therapist_input</td>\n",
       "      <td>NaN</td>\n",
       "      <td>2023-06-19 00:00:34</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "  mi_quality  transcript_id                         topic  utterance_id  \\\n",
       "0       high              0  reducing alcohol consumption             0   \n",
       "1       high              0  reducing alcohol consumption             1   \n",
       "2       high              0  reducing alcohol consumption             2   \n",
       "3       high              0  reducing alcohol consumption             3   \n",
       "4       high              0  reducing alcohol consumption             4   \n",
       "\n",
       "  interlocutor timestamp                                     utterance_text  \\\n",
       "0    therapist  00:00:13  Thanks for filling it out. We give this form t...   \n",
       "1       client  00:00:24                                              Sure.   \n",
       "2    therapist  00:00:25  So, let's see. It looks that you put-- You dri...   \n",
       "3       client  00:00:34                                            Mm-hmm.   \n",
       "4    therapist  00:00:34  -and you usually have three to four drinks whe...   \n",
       "\n",
       "   annotator_id therapist_input_exists therapist_input_subtype  \\\n",
       "0             3                  False                     NaN   \n",
       "1             3                    NaN                     NaN   \n",
       "2             3                   True             information   \n",
       "3             3                    NaN                     NaN   \n",
       "4             3                   True             information   \n",
       "\n",
       "  reflection_exists reflection_subtype question_exists question_subtype  \\\n",
       "0             False                NaN            True             open   \n",
       "1               NaN                NaN             NaN              NaN   \n",
       "2             False                NaN           False              NaN   \n",
       "3               NaN                NaN             NaN              NaN   \n",
       "4             False                NaN           False              NaN   \n",
       "\n",
       "  main_therapist_behaviour client_talk_type            datetime  \n",
       "0                 question              NaN 2023-06-19 00:00:13  \n",
       "1                      NaN          neutral 2023-06-19 00:00:24  \n",
       "2          therapist_input              NaN 2023-06-19 00:00:25  \n",
       "3                      NaN          neutral 2023-06-19 00:00:34  \n",
       "4          therapist_input              NaN 2023-06-19 00:00:34  "
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "%run ../load_anno_mi.py"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "720d820f",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "therapist    6826\n",
       "client       6725\n",
       "Name: interlocutor, dtype: int64"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "anno_mi.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "84d5594d",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "other              0.313947\n",
       "question           0.286258\n",
       "reflection         0.251538\n",
       "therapist_input    0.148257\n",
       "Name: main_therapist_behaviour, dtype: float64"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "with open(\"../anno_mi_sbert.pkl\", \"rb\") as f:\n",
    "    sbert_embeddings = pickle.load(f)\n",
    "    \n",
    "sbert_embeddings.shape"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "id": "da4ff92d",
   "metadata": {},
   "source": [
    "# SWNU Network"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "id": "32ae1a72",
   "metadata": {},
   "source": [
    "## Obtaining path by looking at post history\n",
    "\n",
    "We can obtain a path by looking at the history of each post. Here we look at the last 10 posts (and pad with vectors of zeros if there are less than 10 posts) including the current post.\n",
    "\n",
    "We only want to consider paths that correspond to a client's utterance as we want to model a change in mood at that time. Their history will still contain the therapist's utterances too."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "id": "90bfd87c",
   "metadata": {},
   "outputs": [],
   "source": [
    "time_features = [\"time_encoding\", \"timeline_index\"]\n",
    "standardise_method = [\"minmax\", None]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "9cf4e16c",
   "metadata": {},
   "outputs": [],
   "source": [
    "sig_depths = [2,3]\n",
    "dim_reduce_methods = [\"gaussian_random_projection\", \"umap\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "43dbc33f",
   "metadata": {},
   "outputs": [],
   "source": [
    "output_dim = len(label_to_id)\n",
    "lstm_hidden_dims = [[8,8], [12,12,8]]\n",
    "num_time_features = len(time_features)\n",
    "conv_output_channels = [20, 10, 5]\n",
    "learning_rate = 1e-4"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "9a9b2b2c",
   "metadata": {},
   "outputs": [],
   "source": [
    "embedding_dim = 384\n",
    "dimensions = [embedding_dim, 100, 50, 30]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "id": "7b5652fc",
   "metadata": {},
   "outputs": [],
   "source": [
    "log_signature_dimensions_and_sig_depths = [(30, 2), (10, 3), (6, 4)]\n",
    "bilstm_log_signature_dimensions_and_sig_depths = [(int(30/2), 2), (int(10/2), 3), (int(6/2), 4)]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "id": "37f1fc01",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[(28, 2), (10, 3), (6, 4)]"
      ]
     },
     "execution_count": 34,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "log_signature_dimensions_and_sig_depths"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "id": "deef95e4",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[(14, 2), (5, 3), (3, 4)]"
      ]
     },
     "execution_count": 35,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "bilstm_log_signature_dimensions_and_sig_depths"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "id": "13a67a66",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "58403b9c74ac4b369e805ff6507c06d4",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/4 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "27b2372087034cfd84b515a65d4f45bf",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/4 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "35ba3864b2a14445ad02074845e4afd3",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/1 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "##################################################\n",
      "dimension: 384 | method: gaussian_random_projection\n",
      "[INFO] Concatenating the embeddings to the dataframe...\n",
      "[INFO] - columns beginning with 'e' denote the full embddings.\n",
      "[INFO] - columns beginning with 'd' denote the dimension reduced embeddings.\n",
      "[INFO] Adding time feature columns into dataframe in `.df`.\n",
      "[INFO] Adding 'time_encoding' and feature...\n",
      "[INFO] Adding 'time_diff' and feature...\n",
      "[INFO] Adding 'timeline_index' feature...\n",
      "[INFO] Padding ids and storing in `.df_padded` and `.array_padded` attributes.\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "897fc80435c3409f8b6d5b6834464496",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/13551 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[INFO] The path was created for each item in the dataframe, by looking at its history, so to include embeddings in the FFN input, we concatenate the embeddings for each sentence / text.\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "92463ff70c5e498390a35e94e75cbac8",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/3 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "cc0b35f2dadf4326a3d4f8755929b604",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/3 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "ec00ea00c614484b9245fa2034a898d3",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/3 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "008ecef83d93449993ba5043ace57498",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/3 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "4434fd5a7aa24f7999c5cc70e2eaa849",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/5 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[57], line 1\u001b[0m\n\u001b[0;32m----> 1\u001b[0m swnu_network_log_signature, best_swnu_network_log_signature, _, __ \u001b[39m=\u001b[39m swnu_network_hyperparameter_search(\n\u001b[1;32m      2\u001b[0m     num_epochs\u001b[39m=\u001b[39;49mnum_epochs,\n\u001b[1;32m      3\u001b[0m     df\u001b[39m=\u001b[39;49manno_mi,\n\u001b[1;32m      4\u001b[0m     id_column\u001b[39m=\u001b[39;49m\u001b[39m\"\u001b[39;49m\u001b[39mtranscript_id\u001b[39;49m\u001b[39m\"\u001b[39;49m,\n\u001b[1;32m      5\u001b[0m     label_column\u001b[39m=\u001b[39;49m\u001b[39m\"\u001b[39;49m\u001b[39mclient_talk_type\u001b[39;49m\u001b[39m\"\u001b[39;49m,\n\u001b[1;32m      6\u001b[0m     embeddings\u001b[39m=\u001b[39;49msbert_embeddings,\n\u001b[1;32m      7\u001b[0m     y_data\u001b[39m=\u001b[39;49my_data,\n\u001b[1;32m      8\u001b[0m     embedding_dim\u001b[39m=\u001b[39;49membedding_dim,\n\u001b[1;32m      9\u001b[0m     output_dim\u001b[39m=\u001b[39;49moutput_dim,\n\u001b[1;32m     10\u001b[0m     window_sizes\u001b[39m=\u001b[39;49mwindow_sizes,\n\u001b[1;32m     11\u001b[0m     dim_reduce_methods\u001b[39m=\u001b[39;49m[\u001b[39m\"\u001b[39;49m\u001b[39mgaussian_random_projection\u001b[39;49m\u001b[39m\"\u001b[39;49m],\n\u001b[1;32m     12\u001b[0m     dimensions\u001b[39m=\u001b[39;49mdimensions,\n\u001b[1;32m     13\u001b[0m     sig_depths\u001b[39m=\u001b[39;49m[x[\u001b[39m1\u001b[39;49m] \u001b[39mfor\u001b[39;49;00m x \u001b[39min\u001b[39;49;00m log_signature_dimensions_and_sig_depths],\n\u001b[1;32m     14\u001b[0m     log_signature\u001b[39m=\u001b[39;49m\u001b[39mTrue\u001b[39;49;00m,\n\u001b[1;32m     15\u001b[0m     conv_output_channels\u001b[39m=\u001b[39;49mconv_output_channels,\n\u001b[1;32m     16\u001b[0m     swnu_hidden_dim_sizes\u001b[39m=\u001b[39;49m[x[\u001b[39m0\u001b[39;49m] \u001b[39mfor\u001b[39;49;00m x \u001b[39min\u001b[39;49;00m log_signature_dimensions_and_sig_depths],\n\u001b[1;32m     17\u001b[0m     ffn_hidden_dim_sizes\u001b[39m=\u001b[39;49mhidden_dim_sizes,\n\u001b[1;32m     18\u001b[0m     dropout_rates\u001b[39m=\u001b[39;49mdropout_rates,\n\u001b[1;32m     19\u001b[0m     learning_rates\u001b[39m=\u001b[39;49mlearning_rates,\n\u001b[1;32m     20\u001b[0m     BiLSTM\u001b[39m=\u001b[39;49m\u001b[39mFalse\u001b[39;49;00m,\n\u001b[1;32m     21\u001b[0m     seeds\u001b[39m=\u001b[39;49mseeds,\n\u001b[1;32m     22\u001b[0m     loss\u001b[39m=\u001b[39;49mloss,\n\u001b[1;32m     23\u001b[0m     gamma\u001b[39m=\u001b[39;49mgamma,\n\u001b[1;32m     24\u001b[0m     time_feature\u001b[39m=\u001b[39;49mtime_features,\n\u001b[1;32m     25\u001b[0m     standardise_method\u001b[39m=\u001b[39;49mstandardise_method,\n\u001b[1;32m     26\u001b[0m     path_indices\u001b[39m=\u001b[39;49mclient_index,\n\u001b[1;32m     27\u001b[0m     k_fold\u001b[39m=\u001b[39;49m\u001b[39mFalse\u001b[39;49;00m,\n\u001b[1;32m     28\u001b[0m     validation_metric\u001b[39m=\u001b[39;49mvalidation_metric,\n\u001b[1;32m     29\u001b[0m     results_output\u001b[39m=\u001b[39;49m\u001b[39mf\u001b[39;49m\u001b[39m\"\u001b[39;49m\u001b[39m{\u001b[39;49;00moutput_dir\u001b[39m}\u001b[39;49;00m\u001b[39m/ffn_logsignature_grp_focal_\u001b[39;49m\u001b[39m{\u001b[39;49;00mgamma\u001b[39m}\u001b[39;49;00m\u001b[39m.csv\u001b[39;49m\u001b[39m\"\u001b[39;49m,\n\u001b[1;32m     30\u001b[0m     verbose\u001b[39m=\u001b[39;49m\u001b[39mFalse\u001b[39;49;00m\n\u001b[1;32m     31\u001b[0m )\n",
      "Cell \u001b[0;32mIn[52], line 325\u001b[0m, in \u001b[0;36mswnu_network_hyperparameter_search\u001b[0;34m(num_epochs, df, id_column, label_column, embeddings, y_data, embedding_dim, output_dim, window_sizes, dim_reduce_methods, dimensions, sig_depths, log_signature, conv_output_channels, swnu_hidden_dim_sizes, ffn_hidden_dim_sizes, dropout_rates, learning_rates, BiLSTM, seeds, loss, gamma, time_feature, standardise_method, augmentation_type, comb_method, path_indices, data_split_seed, k_fold, n_splits, validation_metric, results_output, verbose)\u001b[0m\n\u001b[1;32m    323\u001b[0m verbose_model \u001b[39m=\u001b[39m verbose\n\u001b[1;32m    324\u001b[0m \u001b[39mfor\u001b[39;00m seed \u001b[39min\u001b[39;00m seeds:\n\u001b[0;32m--> 325\u001b[0m     _, results \u001b[39m=\u001b[39m implement_swnu_network(\n\u001b[1;32m    326\u001b[0m         num_epochs\u001b[39m=\u001b[39;49mnum_epochs,\n\u001b[1;32m    327\u001b[0m         x_data\u001b[39m=\u001b[39;49mx_data,\n\u001b[1;32m    328\u001b[0m         y_data\u001b[39m=\u001b[39;49my_data,\n\u001b[1;32m    329\u001b[0m         input_channels\u001b[39m=\u001b[39;49minput_channels,\n\u001b[1;32m    330\u001b[0m         output_channels\u001b[39m=\u001b[39;49moutput_channels,\n\u001b[1;32m    331\u001b[0m         num_time_features\u001b[39m=\u001b[39;49m\u001b[39mlen\u001b[39;49m(time_feature),\n\u001b[1;32m    332\u001b[0m         embedding_dim\u001b[39m=\u001b[39;49membedding_dim,\n\u001b[1;32m    333\u001b[0m         log_signature\u001b[39m=\u001b[39;49mlog_signature,\n\u001b[1;32m    334\u001b[0m         sig_depth\u001b[39m=\u001b[39;49msig_depth,\n\u001b[1;32m    335\u001b[0m         lstm_hidden_dim\u001b[39m=\u001b[39;49mlstm_hidden_dim,\n\u001b[1;32m    336\u001b[0m         ffn_hidden_dim\u001b[39m=\u001b[39;49mffn_hidden_dim,\n\u001b[1;32m    337\u001b[0m         output_dim\u001b[39m=\u001b[39;49moutput_dim,\n\u001b[1;32m    338\u001b[0m         BiLSTM\u001b[39m=\u001b[39;49mBiLSTM,\n\u001b[1;32m    339\u001b[0m         dropout_rate\u001b[39m=\u001b[39;49mdropout,\n\u001b[1;32m    340\u001b[0m         learning_rate\u001b[39m=\u001b[39;49mlr,\n\u001b[1;32m    341\u001b[0m         seed\u001b[39m=\u001b[39;49mseed,\n\u001b[1;32m    342\u001b[0m         loss\u001b[39m=\u001b[39;49mloss,\n\u001b[1;32m    343\u001b[0m         gamma\u001b[39m=\u001b[39;49mgamma,\n\u001b[1;32m    344\u001b[0m         augmentation_type\u001b[39m=\u001b[39;49maugmentation_type,\n\u001b[1;32m    345\u001b[0m         comb_method\u001b[39m=\u001b[39;49mcomb_method,\n\u001b[1;32m    346\u001b[0m         data_split_seed\u001b[39m=\u001b[39;49mdata_split_seed,\n\u001b[1;32m    347\u001b[0m         k_fold\u001b[39m=\u001b[39;49mk_fold,\n\u001b[1;32m    348\u001b[0m         n_splits\u001b[39m=\u001b[39;49mn_splits,\n\u001b[1;32m    349\u001b[0m         verbose_training\u001b[39m=\u001b[39;49m\u001b[39mFalse\u001b[39;49;00m,\n\u001b[1;32m    350\u001b[0m         verbose_results\u001b[39m=\u001b[39;49mverbose,\n\u001b[1;32m    351\u001b[0m         verbose_model\u001b[39m=\u001b[39;49mverbose_model\n\u001b[1;32m    352\u001b[0m     )\n\u001b[1;32m    353\u001b[0m     \u001b[39m# save metric that we want to validate on\u001b[39;00m\n\u001b[1;32m    354\u001b[0m     \u001b[39m# taking the mean over the performance on the folds for the seed\u001b[39;00m\n\u001b[1;32m    355\u001b[0m     \u001b[39m# if k_fold=False, .mean() just returns the performance for the seed\u001b[39;00m\n\u001b[1;32m    356\u001b[0m     scores\u001b[39m.\u001b[39mappend(results[\u001b[39mf\u001b[39m\u001b[39m\"\u001b[39m\u001b[39mvalid_\u001b[39m\u001b[39m{\u001b[39;00mvalidation_metric\u001b[39m}\u001b[39;00m\u001b[39m\"\u001b[39m]\u001b[39m.\u001b[39mmean())\n",
      "Cell \u001b[0;32mIn[52], line 194\u001b[0m, in \u001b[0;36mimplement_swnu_network\u001b[0;34m(num_epochs, x_data, y_data, input_channels, output_channels, num_time_features, embedding_dim, log_signature, sig_depth, lstm_hidden_dim, ffn_hidden_dim, output_dim, BiLSTM, dropout_rate, learning_rate, seed, loss, gamma, augmentation_type, comb_method, data_split_seed, k_fold, n_splits, verbose_training, verbose_results, verbose_model)\u001b[0m\n\u001b[1;32m    191\u001b[0m optimizer \u001b[39m=\u001b[39m torch\u001b[39m.\u001b[39moptim\u001b[39m.\u001b[39mAdam(swnu_network_model\u001b[39m.\u001b[39mparameters(), lr\u001b[39m=\u001b[39mlearning_rate)\n\u001b[1;32m    193\u001b[0m \u001b[39m# train FFN\u001b[39;00m\n\u001b[0;32m--> 194\u001b[0m swnu_network_model \u001b[39m=\u001b[39m training_pytorch(model\u001b[39m=\u001b[39;49mswnu_network_model,\n\u001b[1;32m    195\u001b[0m                               train_loader\u001b[39m=\u001b[39;49mtrain,\n\u001b[1;32m    196\u001b[0m                               criterion\u001b[39m=\u001b[39;49mcriterion,\n\u001b[1;32m    197\u001b[0m                               optimizer\u001b[39m=\u001b[39;49moptimizer,\n\u001b[1;32m    198\u001b[0m                               num_epochs\u001b[39m=\u001b[39;49mnum_epochs,\n\u001b[1;32m    199\u001b[0m                               valid_loader\u001b[39m=\u001b[39;49mvalid,\n\u001b[1;32m    200\u001b[0m                               seed\u001b[39m=\u001b[39;49mseed,\n\u001b[1;32m    201\u001b[0m                               save_best\u001b[39m=\u001b[39;49msave_best,\n\u001b[1;32m    202\u001b[0m                               output\u001b[39m=\u001b[39;49mmodel_output,\n\u001b[1;32m    203\u001b[0m                               early_stopping\u001b[39m=\u001b[39;49mearly_stopping,\n\u001b[1;32m    204\u001b[0m                               validation_metric\u001b[39m=\u001b[39;49mvalidation_metric,\n\u001b[1;32m    205\u001b[0m                               patience\u001b[39m=\u001b[39;49mpatience,\n\u001b[1;32m    206\u001b[0m                               verbose\u001b[39m=\u001b[39;49mverbose_training)\n\u001b[1;32m    208\u001b[0m \u001b[39m# evaluate on validation\u001b[39;00m\n\u001b[1;32m    209\u001b[0m test_results \u001b[39m=\u001b[39m testing_pytorch(model\u001b[39m=\u001b[39mswnu_network_model,\n\u001b[1;32m    210\u001b[0m                                test_loader\u001b[39m=\u001b[39mtest,\n\u001b[1;32m    211\u001b[0m                                criterion\u001b[39m=\u001b[39mcriterion,\n\u001b[1;32m    212\u001b[0m                                verbose\u001b[39m=\u001b[39m\u001b[39mFalse\u001b[39;00m)\n",
      "File \u001b[0;32m~/Library/CloudStorage/OneDrive-TheAlanTuringInstitute/rough_paths/nlpsig-networks/nlpsig_networks/pytorch_utils.py:283\u001b[0m, in \u001b[0;36mtraining_pytorch\u001b[0;34m(model, train_loader, criterion, optimizer, num_epochs, scheduler, valid_loader, seed, save_best, output, early_stopping, validation_metric, patience, verbose, verbose_epoch)\u001b[0m\n\u001b[1;32m    281\u001b[0m     outputs \u001b[39m=\u001b[39m model(emb)\n\u001b[1;32m    282\u001b[0m     loss \u001b[39m=\u001b[39m criterion(outputs, labels)\n\u001b[0;32m--> 283\u001b[0m     loss\u001b[39m.\u001b[39;49mbackward()\n\u001b[1;32m    284\u001b[0m     optimizer\u001b[39m.\u001b[39mstep()\n\u001b[1;32m    286\u001b[0m \u001b[39m# show training progress\u001b[39;00m\n",
      "File \u001b[0;32m~/opt/miniconda3/envs/nlpsig-networks/lib/python3.8/site-packages/torch/_tensor.py:255\u001b[0m, in \u001b[0;36mTensor.backward\u001b[0;34m(self, gradient, retain_graph, create_graph, inputs)\u001b[0m\n\u001b[1;32m    246\u001b[0m \u001b[39mif\u001b[39;00m has_torch_function_unary(\u001b[39mself\u001b[39m):\n\u001b[1;32m    247\u001b[0m     \u001b[39mreturn\u001b[39;00m handle_torch_function(\n\u001b[1;32m    248\u001b[0m         Tensor\u001b[39m.\u001b[39mbackward,\n\u001b[1;32m    249\u001b[0m         (\u001b[39mself\u001b[39m,),\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m    253\u001b[0m         create_graph\u001b[39m=\u001b[39mcreate_graph,\n\u001b[1;32m    254\u001b[0m         inputs\u001b[39m=\u001b[39minputs)\n\u001b[0;32m--> 255\u001b[0m torch\u001b[39m.\u001b[39;49mautograd\u001b[39m.\u001b[39;49mbackward(\u001b[39mself\u001b[39;49m, gradient, retain_graph, create_graph, inputs\u001b[39m=\u001b[39;49minputs)\n",
      "File \u001b[0;32m~/opt/miniconda3/envs/nlpsig-networks/lib/python3.8/site-packages/torch/autograd/__init__.py:147\u001b[0m, in \u001b[0;36mbackward\u001b[0;34m(tensors, grad_tensors, retain_graph, create_graph, grad_variables, inputs)\u001b[0m\n\u001b[1;32m    144\u001b[0m \u001b[39mif\u001b[39;00m retain_graph \u001b[39mis\u001b[39;00m \u001b[39mNone\u001b[39;00m:\n\u001b[1;32m    145\u001b[0m     retain_graph \u001b[39m=\u001b[39m create_graph\n\u001b[0;32m--> 147\u001b[0m Variable\u001b[39m.\u001b[39;49m_execution_engine\u001b[39m.\u001b[39;49mrun_backward(\n\u001b[1;32m    148\u001b[0m     tensors, grad_tensors_, retain_graph, create_graph, inputs,\n\u001b[1;32m    149\u001b[0m     allow_unreachable\u001b[39m=\u001b[39;49m\u001b[39mTrue\u001b[39;49;00m, accumulate_grad\u001b[39m=\u001b[39;49m\u001b[39mTrue\u001b[39;49;00m)\n",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "size=20\n",
    "swnu_network_log_signature, best_swnu_network_log_signature, _, __ = swnu_network_hyperparameter_search(\n",
    "    num_epochs=num_epochs,\n",
    "    df=anno_mi,\n",
    "    id_column=\"transcript_id\",\n",
    "    label_column=\"client_talk_type\",\n",
    "    embeddings=sbert_embeddings,\n",
    "    y_data=y_data,\n",
    "    embedding_dim=embedding_dim,\n",
    "    output_dim=output_dim,\n",
    "    history_lengths=[size],\n",
    "    dim_reduce_methods=[\"gaussian_random_projection\"],\n",
    "    dimensions=dimensions,\n",
    "    sig_depths=[x[1] for x in log_signature_dimensions_and_sig_depths],\n",
    "    log_signature=True,\n",
    "    conv_output_channels=conv_output_channels,\n",
    "    swnu_hidden_dim_sizes=[x[0] for x in log_signature_dimensions_and_sig_depths],\n",
    "    ffn_hidden_dim_sizes=hidden_dim_sizes,\n",
    "    dropout_rates=dropout_rates,\n",
    "    learning_rates=learning_rates,\n",
    "    BiLSTM=False,\n",
    "    seeds=seeds,\n",
    "    loss=loss,\n",
    "    gamma=gamma,\n",
    "    time_feature=time_features,\n",
    "    standardise_method=standardise_method,\n",
    "    path_indices=client_index,\n",
    "    k_fold=False,\n",
    "    validation_metric=validation_metric,\n",
    "    results_output=f\"{output_dir}/swnu_network_logsignature_grp_focal_{gamma}.csv\",\n",
    "    verbose=False\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d6d7bd37",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4daab8de",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "nlpsig-networks",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.16"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
