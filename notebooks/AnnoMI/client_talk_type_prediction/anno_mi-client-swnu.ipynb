{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "a983a5e8",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pickle\n",
    "import os\n",
    "from tqdm.notebook import tqdm\n",
    "\n",
    "seed = 2023"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "e4e666cc",
   "metadata": {},
   "outputs": [],
   "source": [
    "from nlpsig_networks.scripts.swnu_network_functions import (\n",
    "    swnu_network_hyperparameter_search\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "6e918dde",
   "metadata": {},
   "outputs": [],
   "source": [
    "output_dir = \"client_talk_type_output\"\n",
    "if not os.path.isdir(output_dir):\n",
    "    os.makedirs(output_dir)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f7409a03",
   "metadata": {},
   "source": [
    "## AnnoMI"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "f00bb922",
   "metadata": {},
   "outputs": [],
   "source": [
    "%run ../load_anno_mi.py"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "720d820f",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>mi_quality</th>\n",
       "      <th>transcript_id</th>\n",
       "      <th>topic</th>\n",
       "      <th>utterance_id</th>\n",
       "      <th>interlocutor</th>\n",
       "      <th>timestamp</th>\n",
       "      <th>utterance_text</th>\n",
       "      <th>annotator_id</th>\n",
       "      <th>therapist_input_exists</th>\n",
       "      <th>therapist_input_subtype</th>\n",
       "      <th>reflection_exists</th>\n",
       "      <th>reflection_subtype</th>\n",
       "      <th>question_exists</th>\n",
       "      <th>question_subtype</th>\n",
       "      <th>main_therapist_behaviour</th>\n",
       "      <th>client_talk_type</th>\n",
       "      <th>datetime</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>high</td>\n",
       "      <td>0</td>\n",
       "      <td>reducing alcohol consumption</td>\n",
       "      <td>0</td>\n",
       "      <td>therapist</td>\n",
       "      <td>00:00:13</td>\n",
       "      <td>Thanks for filling it out. We give this form t...</td>\n",
       "      <td>3</td>\n",
       "      <td>False</td>\n",
       "      <td>NaN</td>\n",
       "      <td>False</td>\n",
       "      <td>NaN</td>\n",
       "      <td>True</td>\n",
       "      <td>open</td>\n",
       "      <td>question</td>\n",
       "      <td>NaN</td>\n",
       "      <td>2023-08-02 00:00:13</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>high</td>\n",
       "      <td>0</td>\n",
       "      <td>reducing alcohol consumption</td>\n",
       "      <td>1</td>\n",
       "      <td>client</td>\n",
       "      <td>00:00:24</td>\n",
       "      <td>Sure.</td>\n",
       "      <td>3</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>neutral</td>\n",
       "      <td>2023-08-02 00:00:24</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>high</td>\n",
       "      <td>0</td>\n",
       "      <td>reducing alcohol consumption</td>\n",
       "      <td>2</td>\n",
       "      <td>therapist</td>\n",
       "      <td>00:00:25</td>\n",
       "      <td>So, let's see. It looks that you put-- You dri...</td>\n",
       "      <td>3</td>\n",
       "      <td>True</td>\n",
       "      <td>information</td>\n",
       "      <td>False</td>\n",
       "      <td>NaN</td>\n",
       "      <td>False</td>\n",
       "      <td>NaN</td>\n",
       "      <td>therapist_input</td>\n",
       "      <td>NaN</td>\n",
       "      <td>2023-08-02 00:00:25</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>high</td>\n",
       "      <td>0</td>\n",
       "      <td>reducing alcohol consumption</td>\n",
       "      <td>3</td>\n",
       "      <td>client</td>\n",
       "      <td>00:00:34</td>\n",
       "      <td>Mm-hmm.</td>\n",
       "      <td>3</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>neutral</td>\n",
       "      <td>2023-08-02 00:00:34</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>high</td>\n",
       "      <td>0</td>\n",
       "      <td>reducing alcohol consumption</td>\n",
       "      <td>4</td>\n",
       "      <td>therapist</td>\n",
       "      <td>00:00:34</td>\n",
       "      <td>-and you usually have three to four drinks whe...</td>\n",
       "      <td>3</td>\n",
       "      <td>True</td>\n",
       "      <td>information</td>\n",
       "      <td>False</td>\n",
       "      <td>NaN</td>\n",
       "      <td>False</td>\n",
       "      <td>NaN</td>\n",
       "      <td>therapist_input</td>\n",
       "      <td>NaN</td>\n",
       "      <td>2023-08-02 00:00:34</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "  mi_quality  transcript_id                         topic  utterance_id  \\\n",
       "0       high              0  reducing alcohol consumption             0   \n",
       "1       high              0  reducing alcohol consumption             1   \n",
       "2       high              0  reducing alcohol consumption             2   \n",
       "3       high              0  reducing alcohol consumption             3   \n",
       "4       high              0  reducing alcohol consumption             4   \n",
       "\n",
       "  interlocutor timestamp                                     utterance_text  \\\n",
       "0    therapist  00:00:13  Thanks for filling it out. We give this form t...   \n",
       "1       client  00:00:24                                              Sure.   \n",
       "2    therapist  00:00:25  So, let's see. It looks that you put-- You dri...   \n",
       "3       client  00:00:34                                            Mm-hmm.   \n",
       "4    therapist  00:00:34  -and you usually have three to four drinks whe...   \n",
       "\n",
       "   annotator_id therapist_input_exists therapist_input_subtype  \\\n",
       "0             3                  False                     NaN   \n",
       "1             3                    NaN                     NaN   \n",
       "2             3                   True             information   \n",
       "3             3                    NaN                     NaN   \n",
       "4             3                   True             information   \n",
       "\n",
       "  reflection_exists reflection_subtype question_exists question_subtype  \\\n",
       "0             False                NaN            True             open   \n",
       "1               NaN                NaN             NaN              NaN   \n",
       "2             False                NaN           False              NaN   \n",
       "3               NaN                NaN             NaN              NaN   \n",
       "4             False                NaN           False              NaN   \n",
       "\n",
       "  main_therapist_behaviour client_talk_type            datetime  \n",
       "0                 question              NaN 2023-08-02 00:00:13  \n",
       "1                      NaN          neutral 2023-08-02 00:00:24  \n",
       "2          therapist_input              NaN 2023-08-02 00:00:25  \n",
       "3                      NaN          neutral 2023-08-02 00:00:34  \n",
       "4          therapist_input              NaN 2023-08-02 00:00:34  "
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "anno_mi.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "84d5594d",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(13551, 384)"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "with open(\"../anno_mi_sbert.pkl\", \"rb\") as f:\n",
    "    sbert_embeddings = pickle.load(f)\n",
    "    \n",
    "sbert_embeddings.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "da4ff92d",
   "metadata": {},
   "source": [
    "# SWNU Network"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "32ae1a72",
   "metadata": {},
   "source": [
    "## Obtaining path by looking at post history\n",
    "\n",
    "We can obtain a path by looking at the history of each post. Here we look at the last 10 posts (and pad with vectors of zeros if there are less than 10 posts) including the current post.\n",
    "\n",
    "We only want to consider paths that correspond to a client's utterance as we want to model a change in mood at that time. Their history will still contain the therapist's utterances too."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "90bfd87c",
   "metadata": {},
   "outputs": [],
   "source": [
    "time_features = [\"time_encoding\", \"timeline_index\"]\n",
    "standardise_method = [\"minmax\", None]\n",
    "num_features = len(time_features)\n",
    "add_time_in_path = True"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "9e9bee3b",
   "metadata": {},
   "outputs": [],
   "source": [
    "num_epochs = 100\n",
    "embedding_dim = 384\n",
    "dimensions = [15]\n",
    "swnu_hidden_dim_sizes_and_sig_depths = [([12], 3), ([10], 3), ([10], 4)]\n",
    "ffn_hidden_dim_sizes = [[64,64],[256,256],[512,512]]\n",
    "dropout_rates = [0.5, 0.1]\n",
    "learning_rates = [1e-3, 1e-4, 5e-4]\n",
    "seeds = [1, 12, 123]\n",
    "loss = \"focal\"\n",
    "gamma = 2\n",
    "validation_metric = \"f1\"\n",
    "patience = 5"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "3739e09a",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "786119449f494a46ac11aa3b57ef00c5",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/1 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "527f84281435436888b22f83a993c8bc",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/1 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "f2a25d37321d423d864f12460d644e74",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/1 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "##################################################\n",
      "dimension: 15 | method: umap\n",
      "[INFO] Concatenating the embeddings to the dataframe...\n",
      "[INFO] - columns beginning with 'e' denote the full embddings.\n",
      "[INFO] - columns beginning with 'd' denote the dimension reduced embeddings.\n",
      "[INFO] Adding time feature columns into dataframe in `.df`.\n",
      "[INFO] Adding 'time_encoding' and feature...\n",
      "[INFO] Adding 'time_diff' and feature...\n",
      "[INFO] Adding 'timeline_index' feature...\n",
      "[INFO] Padding ids and storing in `.df_padded` and `.array_padded` attributes.\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "7a9e5bbbd860432e87a9b381889da534",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/13551 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[INFO] The path was created for each item in the dataframe, by looking at its history, so to include embeddings in the FFN input, we concatenate the embeddings for each sentence / text.\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "b23c97078da34228a46261abd6dab1a6",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/3 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "6faa013c81664f789f244ce2e5ed2302",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/3 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "688d9f2ae2a34fd28773b8d4870bbbe3",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/1 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "22d0e7d0decc45d9af10fa68be8ef3af",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/2 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "6a6f288f1c0f48fd8999c99d4b5205ed",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/3 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "57cfedb6b9b84718b6d8e9b2e89ddab0",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/3 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "a6d0d270414742e9abc933a7e54206ce",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/1 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "e1f182d6fc6f4defb7e64784908c8dd0",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/2 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "397f615884984ee2a2b54f4ef5bd950d",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/3 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[9], line 2\u001b[0m\n\u001b[1;32m      1\u001b[0m size \u001b[38;5;241m=\u001b[39m \u001b[38;5;241m20\u001b[39m\n\u001b[0;32m----> 2\u001b[0m swnu_network_umap_kfold_20, best_swnu_network_umap_kfold_20, _, __ \u001b[38;5;241m=\u001b[39m \u001b[43mswnu_network_hyperparameter_search\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m      3\u001b[0m \u001b[43m    \u001b[49m\u001b[43mnum_epochs\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mnum_epochs\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m      4\u001b[0m \u001b[43m    \u001b[49m\u001b[43mdf\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43manno_mi\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m      5\u001b[0m \u001b[43m    \u001b[49m\u001b[43mid_column\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mtranscript_id\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m,\u001b[49m\n\u001b[1;32m      6\u001b[0m \u001b[43m    \u001b[49m\u001b[43mlabel_column\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mclient_talk_type\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m,\u001b[49m\n\u001b[1;32m      7\u001b[0m \u001b[43m    \u001b[49m\u001b[43membeddings\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43msbert_embeddings\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m      8\u001b[0m \u001b[43m    \u001b[49m\u001b[43my_data\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43my_data_client\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m      9\u001b[0m \u001b[43m    \u001b[49m\u001b[43membedding_dim\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43membedding_dim\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m     10\u001b[0m \u001b[43m    \u001b[49m\u001b[43moutput_dim\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43moutput_dim_client\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m     11\u001b[0m \u001b[43m    \u001b[49m\u001b[43mhistory_lengths\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43m[\u001b[49m\u001b[43msize\u001b[49m\u001b[43m]\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m     12\u001b[0m \u001b[43m    \u001b[49m\u001b[43mdim_reduce_methods\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43m[\u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mumap\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m]\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m     13\u001b[0m \u001b[43m    \u001b[49m\u001b[43mdimensions\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mdimensions\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m     14\u001b[0m \u001b[43m    \u001b[49m\u001b[43mlog_signature\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43;01mTrue\u001b[39;49;00m\u001b[43m,\u001b[49m\n\u001b[1;32m     15\u001b[0m \u001b[43m    \u001b[49m\u001b[43mconv_output_channels\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mconv_output_channels\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m     16\u001b[0m \u001b[43m    \u001b[49m\u001b[43mswnu_hidden_dim_sizes_and_sig_depths\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mswnu_hidden_dim_sizes_and_sig_depths\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m     17\u001b[0m \u001b[43m    \u001b[49m\u001b[43mffn_hidden_dim_sizes\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mffn_hidden_dim_sizes\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m     18\u001b[0m \u001b[43m    \u001b[49m\u001b[43mdropout_rates\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mdropout_rates\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m     19\u001b[0m \u001b[43m    \u001b[49m\u001b[43mlearning_rates\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mlearning_rates\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m     20\u001b[0m \u001b[43m    \u001b[49m\u001b[43mBiLSTM\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43;01mFalse\u001b[39;49;00m\u001b[43m,\u001b[49m\n\u001b[1;32m     21\u001b[0m \u001b[43m    \u001b[49m\u001b[43mseeds\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mseeds\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m     22\u001b[0m \u001b[43m    \u001b[49m\u001b[43mloss\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mloss\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m     23\u001b[0m \u001b[43m    \u001b[49m\u001b[43mgamma\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mgamma\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m     24\u001b[0m \u001b[43m    \u001b[49m\u001b[43mtime_feature\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mtime_features\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m     25\u001b[0m \u001b[43m    \u001b[49m\u001b[43mstandardise_method\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mstandardise_method\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m     26\u001b[0m \u001b[43m    \u001b[49m\u001b[43madd_time_in_path\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43madd_time_in_path\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m     27\u001b[0m \u001b[43m    \u001b[49m\u001b[43mpath_indices\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mclient_index\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m     28\u001b[0m \u001b[43m    \u001b[49m\u001b[43mk_fold\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43;01mTrue\u001b[39;49;00m\u001b[43m,\u001b[49m\n\u001b[1;32m     29\u001b[0m \u001b[43m    \u001b[49m\u001b[43mpatience\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mpatience\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m     30\u001b[0m \u001b[43m    \u001b[49m\u001b[43mvalidation_metric\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mvalidation_metric\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m     31\u001b[0m \u001b[43m    \u001b[49m\u001b[43mresults_output\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;124;43mf\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;132;43;01m{\u001b[39;49;00m\u001b[43moutput_dir\u001b[49m\u001b[38;5;132;43;01m}\u001b[39;49;00m\u001b[38;5;124;43m/swnu_network_umap_focal_\u001b[39;49m\u001b[38;5;132;43;01m{\u001b[39;49;00m\u001b[43mgamma\u001b[49m\u001b[38;5;132;43;01m}\u001b[39;49;00m\u001b[38;5;124;43m_\u001b[39;49m\u001b[38;5;132;43;01m{\u001b[39;49;00m\u001b[43msize\u001b[49m\u001b[38;5;132;43;01m}\u001b[39;49;00m\u001b[38;5;124;43m_kfold.csv\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m,\u001b[49m\n\u001b[1;32m     32\u001b[0m \u001b[43m    \u001b[49m\u001b[43mverbose\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43;01mFalse\u001b[39;49;00m\n\u001b[1;32m     33\u001b[0m \u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m~/Library/CloudStorage/OneDrive-TheAlanTuringInstitute/rough_paths/nlpsig-networks/nlpsig_networks/scripts/swnu_network_functions.py:258\u001b[0m, in \u001b[0;36mswnu_network_hyperparameter_search\u001b[0;34m(num_epochs, df, id_column, label_column, embeddings, y_data, embedding_dim, output_dim, history_lengths, dim_reduce_methods, dimensions, log_signature, conv_output_channels, swnu_hidden_dim_sizes_and_sig_depths, ffn_hidden_dim_sizes, dropout_rates, learning_rates, BiLSTM, seeds, loss, gamma, batch_size, time_feature, standardise_method, add_time_in_path, augmentation_type, hidden_dim_aug, comb_method, path_indices, data_split_seed, split_ids, split_indices, k_fold, n_splits, patience, validation_metric, results_output, verbose)\u001b[0m\n\u001b[1;32m    256\u001b[0m verbose_model \u001b[38;5;241m=\u001b[39m verbose\n\u001b[1;32m    257\u001b[0m \u001b[38;5;28;01mfor\u001b[39;00m seed \u001b[38;5;129;01min\u001b[39;00m seeds:\n\u001b[0;32m--> 258\u001b[0m     _, results \u001b[38;5;241m=\u001b[39m \u001b[43mimplement_swnu_network\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m    259\u001b[0m \u001b[43m        \u001b[49m\u001b[43mnum_epochs\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mnum_epochs\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    260\u001b[0m \u001b[43m        \u001b[49m\u001b[43mx_data\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mx_data\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    261\u001b[0m \u001b[43m        \u001b[49m\u001b[43my_data\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43my_data\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    262\u001b[0m \u001b[43m        \u001b[49m\u001b[43minput_channels\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43minput_channels\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    263\u001b[0m \u001b[43m        \u001b[49m\u001b[43moutput_channels\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43moutput_channels\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    264\u001b[0m \u001b[43m        \u001b[49m\u001b[43mnum_features\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43mlen\u001b[39;49m\u001b[43m(\u001b[49m\u001b[43mtime_feature\u001b[49m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    265\u001b[0m \u001b[43m        \u001b[49m\u001b[43membedding_dim\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43membedding_dim\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    266\u001b[0m \u001b[43m        \u001b[49m\u001b[43mlog_signature\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mlog_signature\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    267\u001b[0m \u001b[43m        \u001b[49m\u001b[43msig_depth\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43msig_depth\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    268\u001b[0m \u001b[43m        \u001b[49m\u001b[43mswnu_hidden_dim\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mswnu_hidden_dim\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    269\u001b[0m \u001b[43m        \u001b[49m\u001b[43mffn_hidden_dim\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mffn_hidden_dim\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    270\u001b[0m \u001b[43m        \u001b[49m\u001b[43moutput_dim\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43moutput_dim\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    271\u001b[0m \u001b[43m        \u001b[49m\u001b[43mBiLSTM\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mBiLSTM\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    272\u001b[0m \u001b[43m        \u001b[49m\u001b[43mdropout_rate\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mdropout\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    273\u001b[0m \u001b[43m        \u001b[49m\u001b[43mlearning_rate\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mlr\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    274\u001b[0m \u001b[43m        \u001b[49m\u001b[43mseed\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mseed\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    275\u001b[0m \u001b[43m        \u001b[49m\u001b[43mloss\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mloss\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    276\u001b[0m \u001b[43m        \u001b[49m\u001b[43mgamma\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mgamma\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    277\u001b[0m \u001b[43m        \u001b[49m\u001b[43mbatch_size\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mbatch_size\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    278\u001b[0m \u001b[43m        \u001b[49m\u001b[43maugmentation_type\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43maugmentation_type\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    279\u001b[0m \u001b[43m        \u001b[49m\u001b[43mhidden_dim_aug\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mhidden_dim_aug\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    280\u001b[0m \u001b[43m        \u001b[49m\u001b[43mcomb_method\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mcomb_method\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    281\u001b[0m \u001b[43m        \u001b[49m\u001b[43mdata_split_seed\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mdata_split_seed\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    282\u001b[0m \u001b[43m        \u001b[49m\u001b[43msplit_ids\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43msplit_ids\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    283\u001b[0m \u001b[43m        \u001b[49m\u001b[43msplit_indices\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43msplit_indices\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    284\u001b[0m \u001b[43m        \u001b[49m\u001b[43mk_fold\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mk_fold\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    285\u001b[0m \u001b[43m        \u001b[49m\u001b[43mn_splits\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mn_splits\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    286\u001b[0m \u001b[43m        \u001b[49m\u001b[43mpatience\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mpatience\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    287\u001b[0m \u001b[43m        \u001b[49m\u001b[43mverbose_training\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43;01mFalse\u001b[39;49;00m\u001b[43m,\u001b[49m\n\u001b[1;32m    288\u001b[0m \u001b[43m        \u001b[49m\u001b[43mverbose_results\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mverbose\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    289\u001b[0m \u001b[43m        \u001b[49m\u001b[43mverbose_model\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mverbose_model\u001b[49m\n\u001b[1;32m    290\u001b[0m \u001b[43m    \u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    291\u001b[0m     \u001b[38;5;66;03m# save metric that we want to validate on\u001b[39;00m\n\u001b[1;32m    292\u001b[0m     \u001b[38;5;66;03m# taking the mean over the performance on the folds for the seed\u001b[39;00m\n\u001b[1;32m    293\u001b[0m     \u001b[38;5;66;03m# if k_fold=False, .mean() just returns the performance for the seed\u001b[39;00m\n\u001b[1;32m    294\u001b[0m     scores\u001b[38;5;241m.\u001b[39mappend(results[\u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mvalid_\u001b[39m\u001b[38;5;132;01m{\u001b[39;00mvalidation_metric\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m\"\u001b[39m]\u001b[38;5;241m.\u001b[39mmean())\n",
      "File \u001b[0;32m~/Library/CloudStorage/OneDrive-TheAlanTuringInstitute/rough_paths/nlpsig-networks/nlpsig_networks/scripts/swnu_network_functions.py:137\u001b[0m, in \u001b[0;36mimplement_swnu_network\u001b[0;34m(num_epochs, x_data, y_data, input_channels, output_channels, num_features, embedding_dim, log_signature, sig_depth, swnu_hidden_dim, ffn_hidden_dim, output_dim, BiLSTM, dropout_rate, learning_rate, seed, loss, gamma, batch_size, augmentation_type, hidden_dim_aug, comb_method, data_split_seed, split_ids, split_indices, k_fold, n_splits, patience, verbose_training, verbose_results, verbose_model)\u001b[0m\n\u001b[1;32m    134\u001b[0m     y_data \u001b[38;5;241m=\u001b[39m torch\u001b[38;5;241m.\u001b[39mtensor(y_data)\n\u001b[1;32m    135\u001b[0m x_data \u001b[38;5;241m=\u001b[39m x_data\u001b[38;5;241m.\u001b[39mfloat()\n\u001b[0;32m--> 137\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mimplement_model\u001b[49m\u001b[43m(\u001b[49m\u001b[43mmodel\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mswnu_network_model\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    138\u001b[0m \u001b[43m                       \u001b[49m\u001b[43mnum_epochs\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mnum_epochs\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    139\u001b[0m \u001b[43m                       \u001b[49m\u001b[43mx_data\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mx_data\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    140\u001b[0m \u001b[43m                       \u001b[49m\u001b[43my_data\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43my_data\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    141\u001b[0m \u001b[43m                       \u001b[49m\u001b[43mlearning_rate\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mlearning_rate\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    142\u001b[0m \u001b[43m                       \u001b[49m\u001b[43mseed\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mseed\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    143\u001b[0m \u001b[43m                       \u001b[49m\u001b[43mloss\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mloss\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    144\u001b[0m \u001b[43m                       \u001b[49m\u001b[43mgamma\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mgamma\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    145\u001b[0m \u001b[43m                       \u001b[49m\u001b[43mbatch_size\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mbatch_size\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    146\u001b[0m \u001b[43m                       \u001b[49m\u001b[43mdata_split_seed\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mdata_split_seed\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    147\u001b[0m \u001b[43m                       \u001b[49m\u001b[43msplit_ids\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43msplit_ids\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    148\u001b[0m \u001b[43m                       \u001b[49m\u001b[43msplit_indices\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43msplit_indices\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    149\u001b[0m \u001b[43m                       \u001b[49m\u001b[43mk_fold\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mk_fold\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    150\u001b[0m \u001b[43m                       \u001b[49m\u001b[43mn_splits\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mn_splits\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    151\u001b[0m \u001b[43m                       \u001b[49m\u001b[43mpatience\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mpatience\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    152\u001b[0m \u001b[43m                       \u001b[49m\u001b[43mverbose_training\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mverbose_training\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    153\u001b[0m \u001b[43m                       \u001b[49m\u001b[43mverbose_results\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mverbose_results\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m~/Library/CloudStorage/OneDrive-TheAlanTuringInstitute/rough_paths/nlpsig-networks/nlpsig_networks/scripts/implement_model.py:67\u001b[0m, in \u001b[0;36mimplement_model\u001b[0;34m(model, num_epochs, x_data, y_data, learning_rate, seed, loss, gamma, batch_size, data_split_seed, split_ids, split_indices, k_fold, n_splits, patience, verbose_training, verbose_results)\u001b[0m\n\u001b[1;32m     60\u001b[0m     optimizer \u001b[38;5;241m=\u001b[39m torch\u001b[38;5;241m.\u001b[39moptim\u001b[38;5;241m.\u001b[39mAdam(model\u001b[38;5;241m.\u001b[39mparameters(),\n\u001b[1;32m     61\u001b[0m                                  lr\u001b[38;5;241m=\u001b[39mlearning_rate,\n\u001b[1;32m     62\u001b[0m                                  weight_decay\u001b[38;5;241m=\u001b[39mweight_decay_adam)\n\u001b[1;32m     64\u001b[0m     \u001b[38;5;66;03m# perform k-fold evaluation which returns a dataframe with columns for the\u001b[39;00m\n\u001b[1;32m     65\u001b[0m     \u001b[38;5;66;03m# loss, accuracy, f1 (macro) and individual f1-scores for each fold\u001b[39;00m\n\u001b[1;32m     66\u001b[0m     \u001b[38;5;66;03m# (for both validation and test set)\u001b[39;00m\n\u001b[0;32m---> 67\u001b[0m     results \u001b[38;5;241m=\u001b[39m \u001b[43mKFold_pytorch\u001b[49m\u001b[43m(\u001b[49m\u001b[43mfolds\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mfolds\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m     68\u001b[0m \u001b[43m                            \u001b[49m\u001b[43mmodel\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mmodel\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m     69\u001b[0m \u001b[43m                            \u001b[49m\u001b[43mcriterion\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mcriterion\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m     70\u001b[0m \u001b[43m                            \u001b[49m\u001b[43moptimizer\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43moptimizer\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m     71\u001b[0m \u001b[43m                            \u001b[49m\u001b[43mnum_epochs\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mnum_epochs\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m     72\u001b[0m \u001b[43m                            \u001b[49m\u001b[43mbatch_size\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mbatch_size\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m     73\u001b[0m \u001b[43m                            \u001b[49m\u001b[43mseed\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mseed\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m     74\u001b[0m \u001b[43m                            \u001b[49m\u001b[43mreturn_best\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mreturn_best\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m     75\u001b[0m \u001b[43m                            \u001b[49m\u001b[43mearly_stopping\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mearly_stopping\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m     76\u001b[0m \u001b[43m                            \u001b[49m\u001b[43mpatience\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mpatience\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m     77\u001b[0m \u001b[43m                            \u001b[49m\u001b[43mverbose\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mverbose_training\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m     78\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[1;32m     79\u001b[0m     \u001b[38;5;66;03m# split dataset\u001b[39;00m\n\u001b[1;32m     80\u001b[0m     data_loader_args \u001b[38;5;241m=\u001b[39m {\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mbatch_size\u001b[39m\u001b[38;5;124m\"\u001b[39m: batch_size, \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mshuffle\u001b[39m\u001b[38;5;124m\"\u001b[39m: \u001b[38;5;28;01mTrue\u001b[39;00m}\n",
      "File \u001b[0;32m~/Library/CloudStorage/OneDrive-TheAlanTuringInstitute/rough_paths/nlpsig-networks/nlpsig_networks/pytorch_utils.py:708\u001b[0m, in \u001b[0;36mKFold_pytorch\u001b[0;34m(folds, model, criterion, optimizer, num_epochs, batch_size, return_metric_for_each_fold, seed, return_best, early_stopping, patience, verbose, verbose_epoch)\u001b[0m\n\u001b[1;32m    705\u001b[0m train, valid, test \u001b[38;5;241m=\u001b[39m folds\u001b[38;5;241m.\u001b[39mget_splits(fold_index\u001b[38;5;241m=\u001b[39mfold, as_DataLoader\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mTrue\u001b[39;00m, data_loader_args\u001b[38;5;241m=\u001b[39mdata_loader_args)\n\u001b[1;32m    707\u001b[0m \u001b[38;5;66;03m# train pytorch model\u001b[39;00m\n\u001b[0;32m--> 708\u001b[0m model \u001b[38;5;241m=\u001b[39m \u001b[43mtraining_pytorch\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m    709\u001b[0m \u001b[43m    \u001b[49m\u001b[43mmodel\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mmodel\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    710\u001b[0m \u001b[43m    \u001b[49m\u001b[43mtrain_loader\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mtrain\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    711\u001b[0m \u001b[43m    \u001b[49m\u001b[43mvalid_loader\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mvalid\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    712\u001b[0m \u001b[43m    \u001b[49m\u001b[43mcriterion\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mcriterion\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    713\u001b[0m \u001b[43m    \u001b[49m\u001b[43moptimizer\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43moptimizer\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    714\u001b[0m \u001b[43m    \u001b[49m\u001b[43mnum_epochs\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mnum_epochs\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    715\u001b[0m \u001b[43m    \u001b[49m\u001b[43mseed\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mseed\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    716\u001b[0m \u001b[43m    \u001b[49m\u001b[43mreturn_best\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mreturn_best\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    717\u001b[0m \u001b[43m    \u001b[49m\u001b[43msave_best\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43;01mFalse\u001b[39;49;00m\u001b[43m,\u001b[49m\n\u001b[1;32m    718\u001b[0m \u001b[43m    \u001b[49m\u001b[43mearly_stopping\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mearly_stopping\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    719\u001b[0m \u001b[43m    \u001b[49m\u001b[43mpatience\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mpatience\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    720\u001b[0m \u001b[43m    \u001b[49m\u001b[43mverbose\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mverbose\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    721\u001b[0m \u001b[43m    \u001b[49m\u001b[43mverbose_epoch\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mverbose_epoch\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    722\u001b[0m \u001b[43m\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    724\u001b[0m \u001b[38;5;66;03m# test model\u001b[39;00m\n\u001b[1;32m    725\u001b[0m test_results \u001b[38;5;241m=\u001b[39m testing_pytorch(model\u001b[38;5;241m=\u001b[39mmodel,\n\u001b[1;32m    726\u001b[0m                                test_loader\u001b[38;5;241m=\u001b[39mtest,\n\u001b[1;32m    727\u001b[0m                                criterion\u001b[38;5;241m=\u001b[39mcriterion,\n\u001b[1;32m    728\u001b[0m                                verbose\u001b[38;5;241m=\u001b[39mverbose)\n",
      "File \u001b[0;32m~/Library/CloudStorage/OneDrive-TheAlanTuringInstitute/rough_paths/nlpsig-networks/nlpsig_networks/pytorch_utils.py:421\u001b[0m, in \u001b[0;36mtraining_pytorch\u001b[0;34m(model, train_loader, criterion, optimizer, num_epochs, scheduler, valid_loader, seed, return_best, save_best, output, early_stopping, validation_metric, patience, verbose, verbose_epoch)\u001b[0m\n\u001b[1;32m    419\u001b[0m     outputs \u001b[38;5;241m=\u001b[39m model(emb)\n\u001b[1;32m    420\u001b[0m     loss \u001b[38;5;241m=\u001b[39m criterion(outputs, labels)\n\u001b[0;32m--> 421\u001b[0m     \u001b[43mloss\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mbackward\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    422\u001b[0m     optimizer\u001b[38;5;241m.\u001b[39mstep()\n\u001b[1;32m    424\u001b[0m \u001b[38;5;66;03m# show training progress\u001b[39;00m\n",
      "File \u001b[0;32m~/opt/miniconda3/envs/nlpsig-networks/lib/python3.8/site-packages/torch/_tensor.py:255\u001b[0m, in \u001b[0;36mTensor.backward\u001b[0;34m(self, gradient, retain_graph, create_graph, inputs)\u001b[0m\n\u001b[1;32m    246\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m has_torch_function_unary(\u001b[38;5;28mself\u001b[39m):\n\u001b[1;32m    247\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m handle_torch_function(\n\u001b[1;32m    248\u001b[0m         Tensor\u001b[38;5;241m.\u001b[39mbackward,\n\u001b[1;32m    249\u001b[0m         (\u001b[38;5;28mself\u001b[39m,),\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m    253\u001b[0m         create_graph\u001b[38;5;241m=\u001b[39mcreate_graph,\n\u001b[1;32m    254\u001b[0m         inputs\u001b[38;5;241m=\u001b[39minputs)\n\u001b[0;32m--> 255\u001b[0m \u001b[43mtorch\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mautograd\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mbackward\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mgradient\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mretain_graph\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mcreate_graph\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43minputs\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43minputs\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m~/opt/miniconda3/envs/nlpsig-networks/lib/python3.8/site-packages/torch/autograd/__init__.py:147\u001b[0m, in \u001b[0;36mbackward\u001b[0;34m(tensors, grad_tensors, retain_graph, create_graph, grad_variables, inputs)\u001b[0m\n\u001b[1;32m    144\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m retain_graph \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[1;32m    145\u001b[0m     retain_graph \u001b[38;5;241m=\u001b[39m create_graph\n\u001b[0;32m--> 147\u001b[0m \u001b[43mVariable\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_execution_engine\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mrun_backward\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m    148\u001b[0m \u001b[43m    \u001b[49m\u001b[43mtensors\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mgrad_tensors_\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mretain_graph\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mcreate_graph\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43minputs\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    149\u001b[0m \u001b[43m    \u001b[49m\u001b[43mallow_unreachable\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43;01mTrue\u001b[39;49;00m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43maccumulate_grad\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43;01mTrue\u001b[39;49;00m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m~/opt/miniconda3/envs/nlpsig-networks/lib/python3.8/site-packages/torch/autograd/function.py:85\u001b[0m, in \u001b[0;36mBackwardCFunction.apply\u001b[0;34m(self, *args)\u001b[0m\n\u001b[1;32m     84\u001b[0m \u001b[38;5;28;01mclass\u001b[39;00m \u001b[38;5;21;01mBackwardCFunction\u001b[39;00m(_C\u001b[38;5;241m.\u001b[39m_FunctionBase, _ContextMethodMixin, _HookMixin):\n\u001b[0;32m---> 85\u001b[0m     \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mapply\u001b[39m(\u001b[38;5;28mself\u001b[39m, \u001b[38;5;241m*\u001b[39margs):\n\u001b[1;32m     86\u001b[0m         \u001b[38;5;66;03m# _forward_cls is defined by derived class\u001b[39;00m\n\u001b[1;32m     87\u001b[0m         \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_forward_cls\u001b[38;5;241m.\u001b[39mbackward(\u001b[38;5;28mself\u001b[39m, \u001b[38;5;241m*\u001b[39margs)\n",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "155c043a01764600858359a2a168b722",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/3 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "7f2f265a52fc497dbdc674e7711c8e5c",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/1 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "5d2d5e3af7244abc8ec48d0e4567bf9d",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/2 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "e640376aa7434235aa1517d87bcdc46d",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/3 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "285cdbea281f4bf0927874ab7c7cc6bf",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/3 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "48d1e687719c472f91074c8c6cf30d64",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/3 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "9c150ca6c7c44cdf8ed1216f5bdb6983",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/1 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "7e7ffe9941e6480c8b4842c860ff4488",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/2 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "dc28e48c45384343a14797d0bd9fe758",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/3 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "1a5f5131bd8e43bf8017f7d122258990",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/3 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "35677e54750c4150af624349c27f9028",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/1 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "5317fcf37df144379c46bf61575901cd",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/2 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "0753506012b64fde96da01e9373718f1",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/3 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "9ab2bb3c5cb148819239ae25f2de6819",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/3 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "53ad08db837a4af592656a11cb70b1fb",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/1 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "5705fc670c2c487a98e71f749b749f34",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/2 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "d491984e1a1d4a889e05c4cf80511691",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/3 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "dda725b1c8f941e199d35ece6838afc3",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/3 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "d03ffe2e5eba427a9bf113347725deb1",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/3 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "3a428b176a6a45af945f583ac9650fdd",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/1 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "2cd1939cc8d24b7ab1fa2b2fadaf57c2",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/2 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "6b17e28dba8c4b7faf0563a5e24e1bbc",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/3 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "97148a79616147e5a6e3365dd0bfd993",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/3 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "8f0cb8ef33954160bc774c2c286127f1",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/1 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "1ae71b7bf74a416ab8b146b16538118f",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/2 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "f6e5a121880b47ff83ec2a3b79dcdd80",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/3 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "fd990613edbf4e33bf867f05ae884c40",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/3 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "bfac951c77df48fbb712b3ca2fb1c6ff",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/1 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "b601e19b061840a2aa6ccc4a16185ff0",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/2 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "d00888b8deab41fe9338f761343d95f8",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/3 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "b9ea0f2157014c109649881c598fca9f",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/3 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[INFO] Concatenating the embeddings to the dataframe...\n",
      "[INFO] - columns beginning with 'e' denote the full embddings.\n",
      "[INFO] - columns beginning with 'd' denote the dimension reduced embeddings.\n",
      "[INFO] Adding time feature columns into dataframe in `.df`.\n",
      "[INFO] Adding 'time_encoding' and feature...\n",
      "[INFO] Adding 'time_diff' and feature...\n",
      "[INFO] Adding 'timeline_index' feature...\n",
      "[INFO] Padding ids and storing in `.df_padded` and `.array_padded` attributes.\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "052ca564d941484cbcb2543fddaede7c",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/13551 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[INFO] The path was created for each item in the dataframe, by looking at its history, so to include embeddings in the FFN input, we concatenate the embeddings for each sentence / text.\n",
      "saving results dataframe to CSV for this hyperparameter search in client_talk_type_output/swnu_network_umap_focal_2_20_kfold.csv\n"
     ]
    }
   ],
   "source": [
    "size = 20\n",
    "swnu_network_umap_kfold_20, best_swnu_network_umap_kfold_20, _, __ = swnu_network_hyperparameter_search(\n",
    "    num_epochs=num_epochs,\n",
    "    df=anno_mi,\n",
    "    id_column=\"transcript_id\",\n",
    "    label_column=\"client_talk_type\",\n",
    "    embeddings=sbert_embeddings,\n",
    "    y_data=y_data_client,\n",
    "    embedding_dim=embedding_dim,\n",
    "    output_dim=output_dim_client,\n",
    "    history_lengths=[size],\n",
    "    dim_reduce_methods=[\"umap\"],\n",
    "    dimensions=dimensions,\n",
    "    log_signature=True,\n",
    "    swnu_hidden_dim_sizes_and_sig_depths=swnu_hidden_dim_sizes_and_sig_depths,\n",
    "    ffn_hidden_dim_sizes=ffn_hidden_dim_sizes,\n",
    "    dropout_rates=dropout_rates,\n",
    "    learning_rates=learning_rates,\n",
    "    BiLSTM=True,\n",
    "    seeds=seeds,\n",
    "    loss=loss,\n",
    "    gamma=gamma,\n",
    "    time_feature=time_features,\n",
    "    standardise_method=standardise_method,\n",
    "    add_time_in_path=add_time_in_path,\n",
    "    path_indices=client_index,\n",
    "    split_ids=client_transcript_id,\n",
    "    k_fold=True,\n",
    "    patience=patience,\n",
    "    validation_metric=validation_metric,\n",
    "    results_output=f\"{output_dir}/swnu_network_umap_focal_{gamma}_{size}_kfold.csv\",\n",
    "    verbose=False\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "7fbe2178-4ae1-4163-8908-c4860e4cfce2",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/tmp/ipykernel_2678102/1182452915.py:1: FutureWarning: The default value of numeric_only in DataFrameGroupBy.mean is deprecated. In a future version, numeric_only will default to False. Either specify numeric_only or select only columns which should be valid for the function.\n",
      "  swnu_network_umap_kfold_20.groupby([\"dimensions\",\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th>accuracy</th>\n",
       "      <th>f1</th>\n",
       "      <th>precision</th>\n",
       "      <th>recall</th>\n",
       "      <th>valid_accuracy</th>\n",
       "      <th>valid_f1</th>\n",
       "      <th>valid_precision</th>\n",
       "      <th>valid_recall</th>\n",
       "      <th>k</th>\n",
       "      <th>sig_depth</th>\n",
       "      <th>...</th>\n",
       "      <th>num_time_features</th>\n",
       "      <th>embedding_dim</th>\n",
       "      <th>log_signature</th>\n",
       "      <th>seed</th>\n",
       "      <th>BiLSTM</th>\n",
       "      <th>gamma</th>\n",
       "      <th>k_fold</th>\n",
       "      <th>n_splits</th>\n",
       "      <th>batch_size</th>\n",
       "      <th>model_id</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>dimensions</th>\n",
       "      <th>swnu_hidden_dim</th>\n",
       "      <th>ffn_hidden_dim</th>\n",
       "      <th>dropout_rate</th>\n",
       "      <th>learning_rate</th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th rowspan=\"36\" valign=\"top\">15</th>\n",
       "      <th rowspan=\"18\" valign=\"top\">(10,)</th>\n",
       "      <th rowspan=\"6\" valign=\"top\">(64, 64)</th>\n",
       "      <th rowspan=\"3\" valign=\"top\">0.1</th>\n",
       "      <th>0.0001</th>\n",
       "      <td>0.613169</td>\n",
       "      <td>0.468655</td>\n",
       "      <td>0.476688</td>\n",
       "      <td>0.468976</td>\n",
       "      <td>0.654038</td>\n",
       "      <td>0.547365</td>\n",
       "      <td>0.558430</td>\n",
       "      <td>0.545620</td>\n",
       "      <td>20.0</td>\n",
       "      <td>3.5</td>\n",
       "      <td>...</td>\n",
       "      <td>2.0</td>\n",
       "      <td>384.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>45.333333</td>\n",
       "      <td>0.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>5.0</td>\n",
       "      <td>64.0</td>\n",
       "      <td>31.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>0.0005</th>\n",
       "      <td>0.614566</td>\n",
       "      <td>0.504715</td>\n",
       "      <td>0.501653</td>\n",
       "      <td>0.512279</td>\n",
       "      <td>0.659411</td>\n",
       "      <td>0.573586</td>\n",
       "      <td>0.572047</td>\n",
       "      <td>0.581221</td>\n",
       "      <td>20.0</td>\n",
       "      <td>3.5</td>\n",
       "      <td>...</td>\n",
       "      <td>2.0</td>\n",
       "      <td>384.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>45.333333</td>\n",
       "      <td>0.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>5.0</td>\n",
       "      <td>64.0</td>\n",
       "      <td>32.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>0.0010</th>\n",
       "      <td>0.623076</td>\n",
       "      <td>0.516702</td>\n",
       "      <td>0.516979</td>\n",
       "      <td>0.526030</td>\n",
       "      <td>0.656314</td>\n",
       "      <td>0.568405</td>\n",
       "      <td>0.573880</td>\n",
       "      <td>0.574778</td>\n",
       "      <td>20.0</td>\n",
       "      <td>3.5</td>\n",
       "      <td>...</td>\n",
       "      <td>2.0</td>\n",
       "      <td>384.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>45.333333</td>\n",
       "      <td>0.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>5.0</td>\n",
       "      <td>64.0</td>\n",
       "      <td>30.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th rowspan=\"3\" valign=\"top\">0.5</th>\n",
       "      <th>0.0001</th>\n",
       "      <td>0.625464</td>\n",
       "      <td>0.427209</td>\n",
       "      <td>0.472030</td>\n",
       "      <td>0.428963</td>\n",
       "      <td>0.644413</td>\n",
       "      <td>0.478499</td>\n",
       "      <td>0.538095</td>\n",
       "      <td>0.476464</td>\n",
       "      <td>20.0</td>\n",
       "      <td>3.5</td>\n",
       "      <td>...</td>\n",
       "      <td>2.0</td>\n",
       "      <td>384.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>45.333333</td>\n",
       "      <td>0.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>5.0</td>\n",
       "      <td>64.0</td>\n",
       "      <td>28.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>0.0005</th>\n",
       "      <td>0.613245</td>\n",
       "      <td>0.450575</td>\n",
       "      <td>0.472569</td>\n",
       "      <td>0.456032</td>\n",
       "      <td>0.640571</td>\n",
       "      <td>0.512704</td>\n",
       "      <td>0.546433</td>\n",
       "      <td>0.520356</td>\n",
       "      <td>20.0</td>\n",
       "      <td>3.5</td>\n",
       "      <td>...</td>\n",
       "      <td>2.0</td>\n",
       "      <td>384.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>45.333333</td>\n",
       "      <td>0.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>5.0</td>\n",
       "      <td>64.0</td>\n",
       "      <td>29.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>0.0010</th>\n",
       "      <td>0.626734</td>\n",
       "      <td>0.445429</td>\n",
       "      <td>0.486349</td>\n",
       "      <td>0.446968</td>\n",
       "      <td>0.646726</td>\n",
       "      <td>0.490561</td>\n",
       "      <td>0.545604</td>\n",
       "      <td>0.491234</td>\n",
       "      <td>20.0</td>\n",
       "      <td>3.5</td>\n",
       "      <td>...</td>\n",
       "      <td>2.0</td>\n",
       "      <td>384.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>45.333333</td>\n",
       "      <td>0.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>5.0</td>\n",
       "      <td>64.0</td>\n",
       "      <td>27.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th rowspan=\"6\" valign=\"top\">(256, 256)</th>\n",
       "      <th rowspan=\"3\" valign=\"top\">0.1</th>\n",
       "      <th>0.0001</th>\n",
       "      <td>0.606615</td>\n",
       "      <td>0.469528</td>\n",
       "      <td>0.472125</td>\n",
       "      <td>0.470915</td>\n",
       "      <td>0.646894</td>\n",
       "      <td>0.546596</td>\n",
       "      <td>0.549528</td>\n",
       "      <td>0.548699</td>\n",
       "      <td>20.0</td>\n",
       "      <td>3.5</td>\n",
       "      <td>...</td>\n",
       "      <td>2.0</td>\n",
       "      <td>384.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>45.333333</td>\n",
       "      <td>0.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>5.0</td>\n",
       "      <td>64.0</td>\n",
       "      <td>37.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>0.0005</th>\n",
       "      <td>0.610857</td>\n",
       "      <td>0.499041</td>\n",
       "      <td>0.498151</td>\n",
       "      <td>0.506700</td>\n",
       "      <td>0.644320</td>\n",
       "      <td>0.554494</td>\n",
       "      <td>0.554795</td>\n",
       "      <td>0.560124</td>\n",
       "      <td>20.0</td>\n",
       "      <td>3.5</td>\n",
       "      <td>...</td>\n",
       "      <td>2.0</td>\n",
       "      <td>384.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>45.333333</td>\n",
       "      <td>0.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>5.0</td>\n",
       "      <td>64.0</td>\n",
       "      <td>38.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>0.0010</th>\n",
       "      <td>0.619723</td>\n",
       "      <td>0.507790</td>\n",
       "      <td>0.508189</td>\n",
       "      <td>0.511924</td>\n",
       "      <td>0.646764</td>\n",
       "      <td>0.557733</td>\n",
       "      <td>0.560253</td>\n",
       "      <td>0.559688</td>\n",
       "      <td>20.0</td>\n",
       "      <td>3.5</td>\n",
       "      <td>...</td>\n",
       "      <td>2.0</td>\n",
       "      <td>384.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>45.333333</td>\n",
       "      <td>0.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>5.0</td>\n",
       "      <td>64.0</td>\n",
       "      <td>36.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th rowspan=\"3\" valign=\"top\">0.5</th>\n",
       "      <th>0.0001</th>\n",
       "      <td>0.591831</td>\n",
       "      <td>0.403604</td>\n",
       "      <td>0.425523</td>\n",
       "      <td>0.412614</td>\n",
       "      <td>0.611490</td>\n",
       "      <td>0.455923</td>\n",
       "      <td>0.496787</td>\n",
       "      <td>0.460743</td>\n",
       "      <td>20.0</td>\n",
       "      <td>3.5</td>\n",
       "      <td>...</td>\n",
       "      <td>2.0</td>\n",
       "      <td>384.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>45.333333</td>\n",
       "      <td>0.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>5.0</td>\n",
       "      <td>64.0</td>\n",
       "      <td>34.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>0.0005</th>\n",
       "      <td>0.604862</td>\n",
       "      <td>0.475608</td>\n",
       "      <td>0.479634</td>\n",
       "      <td>0.477322</td>\n",
       "      <td>0.629248</td>\n",
       "      <td>0.524599</td>\n",
       "      <td>0.532787</td>\n",
       "      <td>0.523847</td>\n",
       "      <td>20.0</td>\n",
       "      <td>3.5</td>\n",
       "      <td>...</td>\n",
       "      <td>2.0</td>\n",
       "      <td>384.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>45.333333</td>\n",
       "      <td>0.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>5.0</td>\n",
       "      <td>64.0</td>\n",
       "      <td>35.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>0.0010</th>\n",
       "      <td>0.618071</td>\n",
       "      <td>0.468772</td>\n",
       "      <td>0.489371</td>\n",
       "      <td>0.464271</td>\n",
       "      <td>0.641559</td>\n",
       "      <td>0.521945</td>\n",
       "      <td>0.544633</td>\n",
       "      <td>0.516775</td>\n",
       "      <td>20.0</td>\n",
       "      <td>3.5</td>\n",
       "      <td>...</td>\n",
       "      <td>2.0</td>\n",
       "      <td>384.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>45.333333</td>\n",
       "      <td>0.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>5.0</td>\n",
       "      <td>64.0</td>\n",
       "      <td>33.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th rowspan=\"6\" valign=\"top\">(512, 512)</th>\n",
       "      <th rowspan=\"3\" valign=\"top\">0.1</th>\n",
       "      <th>0.0001</th>\n",
       "      <td>0.606208</td>\n",
       "      <td>0.474642</td>\n",
       "      <td>0.475850</td>\n",
       "      <td>0.475516</td>\n",
       "      <td>0.643667</td>\n",
       "      <td>0.548655</td>\n",
       "      <td>0.550318</td>\n",
       "      <td>0.549756</td>\n",
       "      <td>20.0</td>\n",
       "      <td>3.5</td>\n",
       "      <td>...</td>\n",
       "      <td>2.0</td>\n",
       "      <td>384.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>45.333333</td>\n",
       "      <td>0.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>5.0</td>\n",
       "      <td>64.0</td>\n",
       "      <td>43.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>0.0005</th>\n",
       "      <td>0.604862</td>\n",
       "      <td>0.492333</td>\n",
       "      <td>0.492733</td>\n",
       "      <td>0.499030</td>\n",
       "      <td>0.636691</td>\n",
       "      <td>0.553764</td>\n",
       "      <td>0.553293</td>\n",
       "      <td>0.560155</td>\n",
       "      <td>20.0</td>\n",
       "      <td>3.5</td>\n",
       "      <td>...</td>\n",
       "      <td>2.0</td>\n",
       "      <td>384.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>45.333333</td>\n",
       "      <td>0.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>5.0</td>\n",
       "      <td>64.0</td>\n",
       "      <td>44.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>0.0010</th>\n",
       "      <td>0.607987</td>\n",
       "      <td>0.498680</td>\n",
       "      <td>0.497453</td>\n",
       "      <td>0.506288</td>\n",
       "      <td>0.639302</td>\n",
       "      <td>0.552692</td>\n",
       "      <td>0.552234</td>\n",
       "      <td>0.557207</td>\n",
       "      <td>20.0</td>\n",
       "      <td>3.5</td>\n",
       "      <td>...</td>\n",
       "      <td>2.0</td>\n",
       "      <td>384.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>45.333333</td>\n",
       "      <td>0.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>5.0</td>\n",
       "      <td>64.0</td>\n",
       "      <td>42.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th rowspan=\"3\" valign=\"top\">0.5</th>\n",
       "      <th>0.0001</th>\n",
       "      <td>0.625845</td>\n",
       "      <td>0.379685</td>\n",
       "      <td>0.456387</td>\n",
       "      <td>0.395602</td>\n",
       "      <td>0.608692</td>\n",
       "      <td>0.384830</td>\n",
       "      <td>0.474777</td>\n",
       "      <td>0.398408</td>\n",
       "      <td>20.0</td>\n",
       "      <td>3.5</td>\n",
       "      <td>...</td>\n",
       "      <td>2.0</td>\n",
       "      <td>384.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>45.333333</td>\n",
       "      <td>0.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>5.0</td>\n",
       "      <td>64.0</td>\n",
       "      <td>40.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>0.0005</th>\n",
       "      <td>0.598257</td>\n",
       "      <td>0.461253</td>\n",
       "      <td>0.467619</td>\n",
       "      <td>0.459633</td>\n",
       "      <td>0.609383</td>\n",
       "      <td>0.502366</td>\n",
       "      <td>0.511800</td>\n",
       "      <td>0.498308</td>\n",
       "      <td>20.0</td>\n",
       "      <td>3.5</td>\n",
       "      <td>...</td>\n",
       "      <td>2.0</td>\n",
       "      <td>384.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>45.333333</td>\n",
       "      <td>0.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>5.0</td>\n",
       "      <td>64.0</td>\n",
       "      <td>41.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>0.0010</th>\n",
       "      <td>0.612864</td>\n",
       "      <td>0.479003</td>\n",
       "      <td>0.491487</td>\n",
       "      <td>0.479649</td>\n",
       "      <td>0.629864</td>\n",
       "      <td>0.521280</td>\n",
       "      <td>0.535831</td>\n",
       "      <td>0.520135</td>\n",
       "      <td>20.0</td>\n",
       "      <td>3.5</td>\n",
       "      <td>...</td>\n",
       "      <td>2.0</td>\n",
       "      <td>384.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>45.333333</td>\n",
       "      <td>0.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>5.0</td>\n",
       "      <td>64.0</td>\n",
       "      <td>39.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th rowspan=\"18\" valign=\"top\">(12,)</th>\n",
       "      <th rowspan=\"6\" valign=\"top\">(64, 64)</th>\n",
       "      <th rowspan=\"3\" valign=\"top\">0.1</th>\n",
       "      <th>0.0001</th>\n",
       "      <td>0.611848</td>\n",
       "      <td>0.465885</td>\n",
       "      <td>0.474390</td>\n",
       "      <td>0.466998</td>\n",
       "      <td>0.652975</td>\n",
       "      <td>0.541303</td>\n",
       "      <td>0.552213</td>\n",
       "      <td>0.539281</td>\n",
       "      <td>20.0</td>\n",
       "      <td>3.0</td>\n",
       "      <td>...</td>\n",
       "      <td>2.0</td>\n",
       "      <td>384.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>45.333333</td>\n",
       "      <td>0.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>5.0</td>\n",
       "      <td>64.0</td>\n",
       "      <td>4.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>0.0005</th>\n",
       "      <td>0.603414</td>\n",
       "      <td>0.496652</td>\n",
       "      <td>0.492106</td>\n",
       "      <td>0.507656</td>\n",
       "      <td>0.649282</td>\n",
       "      <td>0.572070</td>\n",
       "      <td>0.564944</td>\n",
       "      <td>0.585842</td>\n",
       "      <td>20.0</td>\n",
       "      <td>3.0</td>\n",
       "      <td>...</td>\n",
       "      <td>2.0</td>\n",
       "      <td>384.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>45.333333</td>\n",
       "      <td>0.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>5.0</td>\n",
       "      <td>64.0</td>\n",
       "      <td>5.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>0.0010</th>\n",
       "      <td>0.605548</td>\n",
       "      <td>0.502016</td>\n",
       "      <td>0.500694</td>\n",
       "      <td>0.516282</td>\n",
       "      <td>0.652751</td>\n",
       "      <td>0.574041</td>\n",
       "      <td>0.571564</td>\n",
       "      <td>0.588164</td>\n",
       "      <td>20.0</td>\n",
       "      <td>3.0</td>\n",
       "      <td>...</td>\n",
       "      <td>2.0</td>\n",
       "      <td>384.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>45.333333</td>\n",
       "      <td>0.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>5.0</td>\n",
       "      <td>64.0</td>\n",
       "      <td>3.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th rowspan=\"3\" valign=\"top\">0.5</th>\n",
       "      <th>0.0001</th>\n",
       "      <td>0.617741</td>\n",
       "      <td>0.415520</td>\n",
       "      <td>0.459467</td>\n",
       "      <td>0.423115</td>\n",
       "      <td>0.643052</td>\n",
       "      <td>0.478066</td>\n",
       "      <td>0.537842</td>\n",
       "      <td>0.477068</td>\n",
       "      <td>20.0</td>\n",
       "      <td>3.0</td>\n",
       "      <td>...</td>\n",
       "      <td>2.0</td>\n",
       "      <td>384.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>45.333333</td>\n",
       "      <td>0.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>5.0</td>\n",
       "      <td>64.0</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>0.0005</th>\n",
       "      <td>0.608698</td>\n",
       "      <td>0.459144</td>\n",
       "      <td>0.474860</td>\n",
       "      <td>0.467243</td>\n",
       "      <td>0.640963</td>\n",
       "      <td>0.520744</td>\n",
       "      <td>0.538805</td>\n",
       "      <td>0.527899</td>\n",
       "      <td>20.0</td>\n",
       "      <td>3.0</td>\n",
       "      <td>...</td>\n",
       "      <td>2.0</td>\n",
       "      <td>384.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>45.333333</td>\n",
       "      <td>0.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>5.0</td>\n",
       "      <td>64.0</td>\n",
       "      <td>2.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>0.0010</th>\n",
       "      <td>0.617690</td>\n",
       "      <td>0.465527</td>\n",
       "      <td>0.484789</td>\n",
       "      <td>0.467160</td>\n",
       "      <td>0.642194</td>\n",
       "      <td>0.515307</td>\n",
       "      <td>0.541818</td>\n",
       "      <td>0.516234</td>\n",
       "      <td>20.0</td>\n",
       "      <td>3.0</td>\n",
       "      <td>...</td>\n",
       "      <td>2.0</td>\n",
       "      <td>384.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>45.333333</td>\n",
       "      <td>0.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>5.0</td>\n",
       "      <td>64.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th rowspan=\"6\" valign=\"top\">(256, 256)</th>\n",
       "      <th rowspan=\"3\" valign=\"top\">0.1</th>\n",
       "      <th>0.0001</th>\n",
       "      <td>0.611441</td>\n",
       "      <td>0.473720</td>\n",
       "      <td>0.477828</td>\n",
       "      <td>0.474416</td>\n",
       "      <td>0.649356</td>\n",
       "      <td>0.547813</td>\n",
       "      <td>0.553121</td>\n",
       "      <td>0.548065</td>\n",
       "      <td>20.0</td>\n",
       "      <td>3.0</td>\n",
       "      <td>...</td>\n",
       "      <td>2.0</td>\n",
       "      <td>384.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>45.333333</td>\n",
       "      <td>0.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>5.0</td>\n",
       "      <td>64.0</td>\n",
       "      <td>10.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>0.0005</th>\n",
       "      <td>0.610070</td>\n",
       "      <td>0.497848</td>\n",
       "      <td>0.496097</td>\n",
       "      <td>0.505144</td>\n",
       "      <td>0.647528</td>\n",
       "      <td>0.563423</td>\n",
       "      <td>0.559668</td>\n",
       "      <td>0.570810</td>\n",
       "      <td>20.0</td>\n",
       "      <td>3.0</td>\n",
       "      <td>...</td>\n",
       "      <td>2.0</td>\n",
       "      <td>384.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>45.333333</td>\n",
       "      <td>0.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>5.0</td>\n",
       "      <td>64.0</td>\n",
       "      <td>11.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>0.0010</th>\n",
       "      <td>0.609612</td>\n",
       "      <td>0.497637</td>\n",
       "      <td>0.496311</td>\n",
       "      <td>0.501049</td>\n",
       "      <td>0.642791</td>\n",
       "      <td>0.549870</td>\n",
       "      <td>0.551255</td>\n",
       "      <td>0.550804</td>\n",
       "      <td>20.0</td>\n",
       "      <td>3.0</td>\n",
       "      <td>...</td>\n",
       "      <td>2.0</td>\n",
       "      <td>384.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>45.333333</td>\n",
       "      <td>0.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>5.0</td>\n",
       "      <td>64.0</td>\n",
       "      <td>9.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th rowspan=\"3\" valign=\"top\">0.5</th>\n",
       "      <th>0.0001</th>\n",
       "      <td>0.543718</td>\n",
       "      <td>0.397547</td>\n",
       "      <td>0.433797</td>\n",
       "      <td>0.414497</td>\n",
       "      <td>0.541877</td>\n",
       "      <td>0.424187</td>\n",
       "      <td>0.469270</td>\n",
       "      <td>0.441157</td>\n",
       "      <td>20.0</td>\n",
       "      <td>3.0</td>\n",
       "      <td>...</td>\n",
       "      <td>2.0</td>\n",
       "      <td>384.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>45.333333</td>\n",
       "      <td>0.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>5.0</td>\n",
       "      <td>64.0</td>\n",
       "      <td>7.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>0.0005</th>\n",
       "      <td>0.577707</td>\n",
       "      <td>0.477824</td>\n",
       "      <td>0.475922</td>\n",
       "      <td>0.488172</td>\n",
       "      <td>0.603619</td>\n",
       "      <td>0.529811</td>\n",
       "      <td>0.527641</td>\n",
       "      <td>0.538962</td>\n",
       "      <td>20.0</td>\n",
       "      <td>3.0</td>\n",
       "      <td>...</td>\n",
       "      <td>2.0</td>\n",
       "      <td>384.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>45.333333</td>\n",
       "      <td>0.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>5.0</td>\n",
       "      <td>64.0</td>\n",
       "      <td>8.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>0.0010</th>\n",
       "      <td>0.609866</td>\n",
       "      <td>0.488579</td>\n",
       "      <td>0.491681</td>\n",
       "      <td>0.488622</td>\n",
       "      <td>0.629248</td>\n",
       "      <td>0.528112</td>\n",
       "      <td>0.533971</td>\n",
       "      <td>0.525777</td>\n",
       "      <td>20.0</td>\n",
       "      <td>3.0</td>\n",
       "      <td>...</td>\n",
       "      <td>2.0</td>\n",
       "      <td>384.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>45.333333</td>\n",
       "      <td>0.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>5.0</td>\n",
       "      <td>64.0</td>\n",
       "      <td>6.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th rowspan=\"6\" valign=\"top\">(512, 512)</th>\n",
       "      <th rowspan=\"3\" valign=\"top\">0.1</th>\n",
       "      <th>0.0001</th>\n",
       "      <td>0.617944</td>\n",
       "      <td>0.458188</td>\n",
       "      <td>0.471294</td>\n",
       "      <td>0.453499</td>\n",
       "      <td>0.643387</td>\n",
       "      <td>0.517823</td>\n",
       "      <td>0.537047</td>\n",
       "      <td>0.510081</td>\n",
       "      <td>20.0</td>\n",
       "      <td>3.0</td>\n",
       "      <td>...</td>\n",
       "      <td>2.0</td>\n",
       "      <td>384.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>45.333333</td>\n",
       "      <td>0.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>5.0</td>\n",
       "      <td>64.0</td>\n",
       "      <td>16.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>0.0005</th>\n",
       "      <td>0.608342</td>\n",
       "      <td>0.476596</td>\n",
       "      <td>0.484279</td>\n",
       "      <td>0.483948</td>\n",
       "      <td>0.637493</td>\n",
       "      <td>0.537076</td>\n",
       "      <td>0.542162</td>\n",
       "      <td>0.541611</td>\n",
       "      <td>20.0</td>\n",
       "      <td>3.0</td>\n",
       "      <td>...</td>\n",
       "      <td>2.0</td>\n",
       "      <td>384.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>45.333333</td>\n",
       "      <td>0.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>5.0</td>\n",
       "      <td>64.0</td>\n",
       "      <td>17.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>0.0010</th>\n",
       "      <td>0.614896</td>\n",
       "      <td>0.502275</td>\n",
       "      <td>0.502724</td>\n",
       "      <td>0.505509</td>\n",
       "      <td>0.632158</td>\n",
       "      <td>0.547168</td>\n",
       "      <td>0.547054</td>\n",
       "      <td>0.553954</td>\n",
       "      <td>20.0</td>\n",
       "      <td>3.0</td>\n",
       "      <td>...</td>\n",
       "      <td>2.0</td>\n",
       "      <td>384.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>45.333333</td>\n",
       "      <td>0.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>5.0</td>\n",
       "      <td>64.0</td>\n",
       "      <td>15.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th rowspan=\"3\" valign=\"top\">0.5</th>\n",
       "      <th>0.0001</th>\n",
       "      <td>0.620383</td>\n",
       "      <td>0.353335</td>\n",
       "      <td>0.473554</td>\n",
       "      <td>0.374937</td>\n",
       "      <td>0.596419</td>\n",
       "      <td>0.363008</td>\n",
       "      <td>0.453383</td>\n",
       "      <td>0.376095</td>\n",
       "      <td>20.0</td>\n",
       "      <td>3.0</td>\n",
       "      <td>...</td>\n",
       "      <td>2.0</td>\n",
       "      <td>384.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>45.333333</td>\n",
       "      <td>0.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>5.0</td>\n",
       "      <td>64.0</td>\n",
       "      <td>13.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>0.0005</th>\n",
       "      <td>0.590256</td>\n",
       "      <td>0.452340</td>\n",
       "      <td>0.458544</td>\n",
       "      <td>0.453631</td>\n",
       "      <td>0.607648</td>\n",
       "      <td>0.501387</td>\n",
       "      <td>0.508549</td>\n",
       "      <td>0.499180</td>\n",
       "      <td>20.0</td>\n",
       "      <td>3.0</td>\n",
       "      <td>...</td>\n",
       "      <td>2.0</td>\n",
       "      <td>384.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>45.333333</td>\n",
       "      <td>0.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>5.0</td>\n",
       "      <td>64.0</td>\n",
       "      <td>14.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>0.0010</th>\n",
       "      <td>0.608190</td>\n",
       "      <td>0.464305</td>\n",
       "      <td>0.480030</td>\n",
       "      <td>0.465952</td>\n",
       "      <td>0.628092</td>\n",
       "      <td>0.509038</td>\n",
       "      <td>0.530518</td>\n",
       "      <td>0.506164</td>\n",
       "      <td>20.0</td>\n",
       "      <td>3.0</td>\n",
       "      <td>...</td>\n",
       "      <td>2.0</td>\n",
       "      <td>384.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>45.333333</td>\n",
       "      <td>0.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>5.0</td>\n",
       "      <td>64.0</td>\n",
       "      <td>12.0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>36 rows  22 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                                                                      accuracy  \\\n",
       "dimensions swnu_hidden_dim ffn_hidden_dim dropout_rate learning_rate             \n",
       "15         (10,)           (64, 64)       0.1          0.0001         0.613169   \n",
       "                                                       0.0005         0.614566   \n",
       "                                                       0.0010         0.623076   \n",
       "                                          0.5          0.0001         0.625464   \n",
       "                                                       0.0005         0.613245   \n",
       "                                                       0.0010         0.626734   \n",
       "                           (256, 256)     0.1          0.0001         0.606615   \n",
       "                                                       0.0005         0.610857   \n",
       "                                                       0.0010         0.619723   \n",
       "                                          0.5          0.0001         0.591831   \n",
       "                                                       0.0005         0.604862   \n",
       "                                                       0.0010         0.618071   \n",
       "                           (512, 512)     0.1          0.0001         0.606208   \n",
       "                                                       0.0005         0.604862   \n",
       "                                                       0.0010         0.607987   \n",
       "                                          0.5          0.0001         0.625845   \n",
       "                                                       0.0005         0.598257   \n",
       "                                                       0.0010         0.612864   \n",
       "           (12,)           (64, 64)       0.1          0.0001         0.611848   \n",
       "                                                       0.0005         0.603414   \n",
       "                                                       0.0010         0.605548   \n",
       "                                          0.5          0.0001         0.617741   \n",
       "                                                       0.0005         0.608698   \n",
       "                                                       0.0010         0.617690   \n",
       "                           (256, 256)     0.1          0.0001         0.611441   \n",
       "                                                       0.0005         0.610070   \n",
       "                                                       0.0010         0.609612   \n",
       "                                          0.5          0.0001         0.543718   \n",
       "                                                       0.0005         0.577707   \n",
       "                                                       0.0010         0.609866   \n",
       "                           (512, 512)     0.1          0.0001         0.617944   \n",
       "                                                       0.0005         0.608342   \n",
       "                                                       0.0010         0.614896   \n",
       "                                          0.5          0.0001         0.620383   \n",
       "                                                       0.0005         0.590256   \n",
       "                                                       0.0010         0.608190   \n",
       "\n",
       "                                                                            f1  \\\n",
       "dimensions swnu_hidden_dim ffn_hidden_dim dropout_rate learning_rate             \n",
       "15         (10,)           (64, 64)       0.1          0.0001         0.468655   \n",
       "                                                       0.0005         0.504715   \n",
       "                                                       0.0010         0.516702   \n",
       "                                          0.5          0.0001         0.427209   \n",
       "                                                       0.0005         0.450575   \n",
       "                                                       0.0010         0.445429   \n",
       "                           (256, 256)     0.1          0.0001         0.469528   \n",
       "                                                       0.0005         0.499041   \n",
       "                                                       0.0010         0.507790   \n",
       "                                          0.5          0.0001         0.403604   \n",
       "                                                       0.0005         0.475608   \n",
       "                                                       0.0010         0.468772   \n",
       "                           (512, 512)     0.1          0.0001         0.474642   \n",
       "                                                       0.0005         0.492333   \n",
       "                                                       0.0010         0.498680   \n",
       "                                          0.5          0.0001         0.379685   \n",
       "                                                       0.0005         0.461253   \n",
       "                                                       0.0010         0.479003   \n",
       "           (12,)           (64, 64)       0.1          0.0001         0.465885   \n",
       "                                                       0.0005         0.496652   \n",
       "                                                       0.0010         0.502016   \n",
       "                                          0.5          0.0001         0.415520   \n",
       "                                                       0.0005         0.459144   \n",
       "                                                       0.0010         0.465527   \n",
       "                           (256, 256)     0.1          0.0001         0.473720   \n",
       "                                                       0.0005         0.497848   \n",
       "                                                       0.0010         0.497637   \n",
       "                                          0.5          0.0001         0.397547   \n",
       "                                                       0.0005         0.477824   \n",
       "                                                       0.0010         0.488579   \n",
       "                           (512, 512)     0.1          0.0001         0.458188   \n",
       "                                                       0.0005         0.476596   \n",
       "                                                       0.0010         0.502275   \n",
       "                                          0.5          0.0001         0.353335   \n",
       "                                                       0.0005         0.452340   \n",
       "                                                       0.0010         0.464305   \n",
       "\n",
       "                                                                      precision  \\\n",
       "dimensions swnu_hidden_dim ffn_hidden_dim dropout_rate learning_rate              \n",
       "15         (10,)           (64, 64)       0.1          0.0001          0.476688   \n",
       "                                                       0.0005          0.501653   \n",
       "                                                       0.0010          0.516979   \n",
       "                                          0.5          0.0001          0.472030   \n",
       "                                                       0.0005          0.472569   \n",
       "                                                       0.0010          0.486349   \n",
       "                           (256, 256)     0.1          0.0001          0.472125   \n",
       "                                                       0.0005          0.498151   \n",
       "                                                       0.0010          0.508189   \n",
       "                                          0.5          0.0001          0.425523   \n",
       "                                                       0.0005          0.479634   \n",
       "                                                       0.0010          0.489371   \n",
       "                           (512, 512)     0.1          0.0001          0.475850   \n",
       "                                                       0.0005          0.492733   \n",
       "                                                       0.0010          0.497453   \n",
       "                                          0.5          0.0001          0.456387   \n",
       "                                                       0.0005          0.467619   \n",
       "                                                       0.0010          0.491487   \n",
       "           (12,)           (64, 64)       0.1          0.0001          0.474390   \n",
       "                                                       0.0005          0.492106   \n",
       "                                                       0.0010          0.500694   \n",
       "                                          0.5          0.0001          0.459467   \n",
       "                                                       0.0005          0.474860   \n",
       "                                                       0.0010          0.484789   \n",
       "                           (256, 256)     0.1          0.0001          0.477828   \n",
       "                                                       0.0005          0.496097   \n",
       "                                                       0.0010          0.496311   \n",
       "                                          0.5          0.0001          0.433797   \n",
       "                                                       0.0005          0.475922   \n",
       "                                                       0.0010          0.491681   \n",
       "                           (512, 512)     0.1          0.0001          0.471294   \n",
       "                                                       0.0005          0.484279   \n",
       "                                                       0.0010          0.502724   \n",
       "                                          0.5          0.0001          0.473554   \n",
       "                                                       0.0005          0.458544   \n",
       "                                                       0.0010          0.480030   \n",
       "\n",
       "                                                                        recall  \\\n",
       "dimensions swnu_hidden_dim ffn_hidden_dim dropout_rate learning_rate             \n",
       "15         (10,)           (64, 64)       0.1          0.0001         0.468976   \n",
       "                                                       0.0005         0.512279   \n",
       "                                                       0.0010         0.526030   \n",
       "                                          0.5          0.0001         0.428963   \n",
       "                                                       0.0005         0.456032   \n",
       "                                                       0.0010         0.446968   \n",
       "                           (256, 256)     0.1          0.0001         0.470915   \n",
       "                                                       0.0005         0.506700   \n",
       "                                                       0.0010         0.511924   \n",
       "                                          0.5          0.0001         0.412614   \n",
       "                                                       0.0005         0.477322   \n",
       "                                                       0.0010         0.464271   \n",
       "                           (512, 512)     0.1          0.0001         0.475516   \n",
       "                                                       0.0005         0.499030   \n",
       "                                                       0.0010         0.506288   \n",
       "                                          0.5          0.0001         0.395602   \n",
       "                                                       0.0005         0.459633   \n",
       "                                                       0.0010         0.479649   \n",
       "           (12,)           (64, 64)       0.1          0.0001         0.466998   \n",
       "                                                       0.0005         0.507656   \n",
       "                                                       0.0010         0.516282   \n",
       "                                          0.5          0.0001         0.423115   \n",
       "                                                       0.0005         0.467243   \n",
       "                                                       0.0010         0.467160   \n",
       "                           (256, 256)     0.1          0.0001         0.474416   \n",
       "                                                       0.0005         0.505144   \n",
       "                                                       0.0010         0.501049   \n",
       "                                          0.5          0.0001         0.414497   \n",
       "                                                       0.0005         0.488172   \n",
       "                                                       0.0010         0.488622   \n",
       "                           (512, 512)     0.1          0.0001         0.453499   \n",
       "                                                       0.0005         0.483948   \n",
       "                                                       0.0010         0.505509   \n",
       "                                          0.5          0.0001         0.374937   \n",
       "                                                       0.0005         0.453631   \n",
       "                                                       0.0010         0.465952   \n",
       "\n",
       "                                                                      valid_accuracy  \\\n",
       "dimensions swnu_hidden_dim ffn_hidden_dim dropout_rate learning_rate                   \n",
       "15         (10,)           (64, 64)       0.1          0.0001               0.654038   \n",
       "                                                       0.0005               0.659411   \n",
       "                                                       0.0010               0.656314   \n",
       "                                          0.5          0.0001               0.644413   \n",
       "                                                       0.0005               0.640571   \n",
       "                                                       0.0010               0.646726   \n",
       "                           (256, 256)     0.1          0.0001               0.646894   \n",
       "                                                       0.0005               0.644320   \n",
       "                                                       0.0010               0.646764   \n",
       "                                          0.5          0.0001               0.611490   \n",
       "                                                       0.0005               0.629248   \n",
       "                                                       0.0010               0.641559   \n",
       "                           (512, 512)     0.1          0.0001               0.643667   \n",
       "                                                       0.0005               0.636691   \n",
       "                                                       0.0010               0.639302   \n",
       "                                          0.5          0.0001               0.608692   \n",
       "                                                       0.0005               0.609383   \n",
       "                                                       0.0010               0.629864   \n",
       "           (12,)           (64, 64)       0.1          0.0001               0.652975   \n",
       "                                                       0.0005               0.649282   \n",
       "                                                       0.0010               0.652751   \n",
       "                                          0.5          0.0001               0.643052   \n",
       "                                                       0.0005               0.640963   \n",
       "                                                       0.0010               0.642194   \n",
       "                           (256, 256)     0.1          0.0001               0.649356   \n",
       "                                                       0.0005               0.647528   \n",
       "                                                       0.0010               0.642791   \n",
       "                                          0.5          0.0001               0.541877   \n",
       "                                                       0.0005               0.603619   \n",
       "                                                       0.0010               0.629248   \n",
       "                           (512, 512)     0.1          0.0001               0.643387   \n",
       "                                                       0.0005               0.637493   \n",
       "                                                       0.0010               0.632158   \n",
       "                                          0.5          0.0001               0.596419   \n",
       "                                                       0.0005               0.607648   \n",
       "                                                       0.0010               0.628092   \n",
       "\n",
       "                                                                      valid_f1  \\\n",
       "dimensions swnu_hidden_dim ffn_hidden_dim dropout_rate learning_rate             \n",
       "15         (10,)           (64, 64)       0.1          0.0001         0.547365   \n",
       "                                                       0.0005         0.573586   \n",
       "                                                       0.0010         0.568405   \n",
       "                                          0.5          0.0001         0.478499   \n",
       "                                                       0.0005         0.512704   \n",
       "                                                       0.0010         0.490561   \n",
       "                           (256, 256)     0.1          0.0001         0.546596   \n",
       "                                                       0.0005         0.554494   \n",
       "                                                       0.0010         0.557733   \n",
       "                                          0.5          0.0001         0.455923   \n",
       "                                                       0.0005         0.524599   \n",
       "                                                       0.0010         0.521945   \n",
       "                           (512, 512)     0.1          0.0001         0.548655   \n",
       "                                                       0.0005         0.553764   \n",
       "                                                       0.0010         0.552692   \n",
       "                                          0.5          0.0001         0.384830   \n",
       "                                                       0.0005         0.502366   \n",
       "                                                       0.0010         0.521280   \n",
       "           (12,)           (64, 64)       0.1          0.0001         0.541303   \n",
       "                                                       0.0005         0.572070   \n",
       "                                                       0.0010         0.574041   \n",
       "                                          0.5          0.0001         0.478066   \n",
       "                                                       0.0005         0.520744   \n",
       "                                                       0.0010         0.515307   \n",
       "                           (256, 256)     0.1          0.0001         0.547813   \n",
       "                                                       0.0005         0.563423   \n",
       "                                                       0.0010         0.549870   \n",
       "                                          0.5          0.0001         0.424187   \n",
       "                                                       0.0005         0.529811   \n",
       "                                                       0.0010         0.528112   \n",
       "                           (512, 512)     0.1          0.0001         0.517823   \n",
       "                                                       0.0005         0.537076   \n",
       "                                                       0.0010         0.547168   \n",
       "                                          0.5          0.0001         0.363008   \n",
       "                                                       0.0005         0.501387   \n",
       "                                                       0.0010         0.509038   \n",
       "\n",
       "                                                                      valid_precision  \\\n",
       "dimensions swnu_hidden_dim ffn_hidden_dim dropout_rate learning_rate                    \n",
       "15         (10,)           (64, 64)       0.1          0.0001                0.558430   \n",
       "                                                       0.0005                0.572047   \n",
       "                                                       0.0010                0.573880   \n",
       "                                          0.5          0.0001                0.538095   \n",
       "                                                       0.0005                0.546433   \n",
       "                                                       0.0010                0.545604   \n",
       "                           (256, 256)     0.1          0.0001                0.549528   \n",
       "                                                       0.0005                0.554795   \n",
       "                                                       0.0010                0.560253   \n",
       "                                          0.5          0.0001                0.496787   \n",
       "                                                       0.0005                0.532787   \n",
       "                                                       0.0010                0.544633   \n",
       "                           (512, 512)     0.1          0.0001                0.550318   \n",
       "                                                       0.0005                0.553293   \n",
       "                                                       0.0010                0.552234   \n",
       "                                          0.5          0.0001                0.474777   \n",
       "                                                       0.0005                0.511800   \n",
       "                                                       0.0010                0.535831   \n",
       "           (12,)           (64, 64)       0.1          0.0001                0.552213   \n",
       "                                                       0.0005                0.564944   \n",
       "                                                       0.0010                0.571564   \n",
       "                                          0.5          0.0001                0.537842   \n",
       "                                                       0.0005                0.538805   \n",
       "                                                       0.0010                0.541818   \n",
       "                           (256, 256)     0.1          0.0001                0.553121   \n",
       "                                                       0.0005                0.559668   \n",
       "                                                       0.0010                0.551255   \n",
       "                                          0.5          0.0001                0.469270   \n",
       "                                                       0.0005                0.527641   \n",
       "                                                       0.0010                0.533971   \n",
       "                           (512, 512)     0.1          0.0001                0.537047   \n",
       "                                                       0.0005                0.542162   \n",
       "                                                       0.0010                0.547054   \n",
       "                                          0.5          0.0001                0.453383   \n",
       "                                                       0.0005                0.508549   \n",
       "                                                       0.0010                0.530518   \n",
       "\n",
       "                                                                      valid_recall  \\\n",
       "dimensions swnu_hidden_dim ffn_hidden_dim dropout_rate learning_rate                 \n",
       "15         (10,)           (64, 64)       0.1          0.0001             0.545620   \n",
       "                                                       0.0005             0.581221   \n",
       "                                                       0.0010             0.574778   \n",
       "                                          0.5          0.0001             0.476464   \n",
       "                                                       0.0005             0.520356   \n",
       "                                                       0.0010             0.491234   \n",
       "                           (256, 256)     0.1          0.0001             0.548699   \n",
       "                                                       0.0005             0.560124   \n",
       "                                                       0.0010             0.559688   \n",
       "                                          0.5          0.0001             0.460743   \n",
       "                                                       0.0005             0.523847   \n",
       "                                                       0.0010             0.516775   \n",
       "                           (512, 512)     0.1          0.0001             0.549756   \n",
       "                                                       0.0005             0.560155   \n",
       "                                                       0.0010             0.557207   \n",
       "                                          0.5          0.0001             0.398408   \n",
       "                                                       0.0005             0.498308   \n",
       "                                                       0.0010             0.520135   \n",
       "           (12,)           (64, 64)       0.1          0.0001             0.539281   \n",
       "                                                       0.0005             0.585842   \n",
       "                                                       0.0010             0.588164   \n",
       "                                          0.5          0.0001             0.477068   \n",
       "                                                       0.0005             0.527899   \n",
       "                                                       0.0010             0.516234   \n",
       "                           (256, 256)     0.1          0.0001             0.548065   \n",
       "                                                       0.0005             0.570810   \n",
       "                                                       0.0010             0.550804   \n",
       "                                          0.5          0.0001             0.441157   \n",
       "                                                       0.0005             0.538962   \n",
       "                                                       0.0010             0.525777   \n",
       "                           (512, 512)     0.1          0.0001             0.510081   \n",
       "                                                       0.0005             0.541611   \n",
       "                                                       0.0010             0.553954   \n",
       "                                          0.5          0.0001             0.376095   \n",
       "                                                       0.0005             0.499180   \n",
       "                                                       0.0010             0.506164   \n",
       "\n",
       "                                                                         k  \\\n",
       "dimensions swnu_hidden_dim ffn_hidden_dim dropout_rate learning_rate         \n",
       "15         (10,)           (64, 64)       0.1          0.0001         20.0   \n",
       "                                                       0.0005         20.0   \n",
       "                                                       0.0010         20.0   \n",
       "                                          0.5          0.0001         20.0   \n",
       "                                                       0.0005         20.0   \n",
       "                                                       0.0010         20.0   \n",
       "                           (256, 256)     0.1          0.0001         20.0   \n",
       "                                                       0.0005         20.0   \n",
       "                                                       0.0010         20.0   \n",
       "                                          0.5          0.0001         20.0   \n",
       "                                                       0.0005         20.0   \n",
       "                                                       0.0010         20.0   \n",
       "                           (512, 512)     0.1          0.0001         20.0   \n",
       "                                                       0.0005         20.0   \n",
       "                                                       0.0010         20.0   \n",
       "                                          0.5          0.0001         20.0   \n",
       "                                                       0.0005         20.0   \n",
       "                                                       0.0010         20.0   \n",
       "           (12,)           (64, 64)       0.1          0.0001         20.0   \n",
       "                                                       0.0005         20.0   \n",
       "                                                       0.0010         20.0   \n",
       "                                          0.5          0.0001         20.0   \n",
       "                                                       0.0005         20.0   \n",
       "                                                       0.0010         20.0   \n",
       "                           (256, 256)     0.1          0.0001         20.0   \n",
       "                                                       0.0005         20.0   \n",
       "                                                       0.0010         20.0   \n",
       "                                          0.5          0.0001         20.0   \n",
       "                                                       0.0005         20.0   \n",
       "                                                       0.0010         20.0   \n",
       "                           (512, 512)     0.1          0.0001         20.0   \n",
       "                                                       0.0005         20.0   \n",
       "                                                       0.0010         20.0   \n",
       "                                          0.5          0.0001         20.0   \n",
       "                                                       0.0005         20.0   \n",
       "                                                       0.0010         20.0   \n",
       "\n",
       "                                                                      sig_depth  \\\n",
       "dimensions swnu_hidden_dim ffn_hidden_dim dropout_rate learning_rate              \n",
       "15         (10,)           (64, 64)       0.1          0.0001               3.5   \n",
       "                                                       0.0005               3.5   \n",
       "                                                       0.0010               3.5   \n",
       "                                          0.5          0.0001               3.5   \n",
       "                                                       0.0005               3.5   \n",
       "                                                       0.0010               3.5   \n",
       "                           (256, 256)     0.1          0.0001               3.5   \n",
       "                                                       0.0005               3.5   \n",
       "                                                       0.0010               3.5   \n",
       "                                          0.5          0.0001               3.5   \n",
       "                                                       0.0005               3.5   \n",
       "                                                       0.0010               3.5   \n",
       "                           (512, 512)     0.1          0.0001               3.5   \n",
       "                                                       0.0005               3.5   \n",
       "                                                       0.0010               3.5   \n",
       "                                          0.5          0.0001               3.5   \n",
       "                                                       0.0005               3.5   \n",
       "                                                       0.0010               3.5   \n",
       "           (12,)           (64, 64)       0.1          0.0001               3.0   \n",
       "                                                       0.0005               3.0   \n",
       "                                                       0.0010               3.0   \n",
       "                                          0.5          0.0001               3.0   \n",
       "                                                       0.0005               3.0   \n",
       "                                                       0.0010               3.0   \n",
       "                           (256, 256)     0.1          0.0001               3.0   \n",
       "                                                       0.0005               3.0   \n",
       "                                                       0.0010               3.0   \n",
       "                                          0.5          0.0001               3.0   \n",
       "                                                       0.0005               3.0   \n",
       "                                                       0.0010               3.0   \n",
       "                           (512, 512)     0.1          0.0001               3.0   \n",
       "                                                       0.0005               3.0   \n",
       "                                                       0.0010               3.0   \n",
       "                                          0.5          0.0001               3.0   \n",
       "                                                       0.0005               3.0   \n",
       "                                                       0.0010               3.0   \n",
       "\n",
       "                                                                      ...  \\\n",
       "dimensions swnu_hidden_dim ffn_hidden_dim dropout_rate learning_rate  ...   \n",
       "15         (10,)           (64, 64)       0.1          0.0001         ...   \n",
       "                                                       0.0005         ...   \n",
       "                                                       0.0010         ...   \n",
       "                                          0.5          0.0001         ...   \n",
       "                                                       0.0005         ...   \n",
       "                                                       0.0010         ...   \n",
       "                           (256, 256)     0.1          0.0001         ...   \n",
       "                                                       0.0005         ...   \n",
       "                                                       0.0010         ...   \n",
       "                                          0.5          0.0001         ...   \n",
       "                                                       0.0005         ...   \n",
       "                                                       0.0010         ...   \n",
       "                           (512, 512)     0.1          0.0001         ...   \n",
       "                                                       0.0005         ...   \n",
       "                                                       0.0010         ...   \n",
       "                                          0.5          0.0001         ...   \n",
       "                                                       0.0005         ...   \n",
       "                                                       0.0010         ...   \n",
       "           (12,)           (64, 64)       0.1          0.0001         ...   \n",
       "                                                       0.0005         ...   \n",
       "                                                       0.0010         ...   \n",
       "                                          0.5          0.0001         ...   \n",
       "                                                       0.0005         ...   \n",
       "                                                       0.0010         ...   \n",
       "                           (256, 256)     0.1          0.0001         ...   \n",
       "                                                       0.0005         ...   \n",
       "                                                       0.0010         ...   \n",
       "                                          0.5          0.0001         ...   \n",
       "                                                       0.0005         ...   \n",
       "                                                       0.0010         ...   \n",
       "                           (512, 512)     0.1          0.0001         ...   \n",
       "                                                       0.0005         ...   \n",
       "                                                       0.0010         ...   \n",
       "                                          0.5          0.0001         ...   \n",
       "                                                       0.0005         ...   \n",
       "                                                       0.0010         ...   \n",
       "\n",
       "                                                                      num_time_features  \\\n",
       "dimensions swnu_hidden_dim ffn_hidden_dim dropout_rate learning_rate                      \n",
       "15         (10,)           (64, 64)       0.1          0.0001                       2.0   \n",
       "                                                       0.0005                       2.0   \n",
       "                                                       0.0010                       2.0   \n",
       "                                          0.5          0.0001                       2.0   \n",
       "                                                       0.0005                       2.0   \n",
       "                                                       0.0010                       2.0   \n",
       "                           (256, 256)     0.1          0.0001                       2.0   \n",
       "                                                       0.0005                       2.0   \n",
       "                                                       0.0010                       2.0   \n",
       "                                          0.5          0.0001                       2.0   \n",
       "                                                       0.0005                       2.0   \n",
       "                                                       0.0010                       2.0   \n",
       "                           (512, 512)     0.1          0.0001                       2.0   \n",
       "                                                       0.0005                       2.0   \n",
       "                                                       0.0010                       2.0   \n",
       "                                          0.5          0.0001                       2.0   \n",
       "                                                       0.0005                       2.0   \n",
       "                                                       0.0010                       2.0   \n",
       "           (12,)           (64, 64)       0.1          0.0001                       2.0   \n",
       "                                                       0.0005                       2.0   \n",
       "                                                       0.0010                       2.0   \n",
       "                                          0.5          0.0001                       2.0   \n",
       "                                                       0.0005                       2.0   \n",
       "                                                       0.0010                       2.0   \n",
       "                           (256, 256)     0.1          0.0001                       2.0   \n",
       "                                                       0.0005                       2.0   \n",
       "                                                       0.0010                       2.0   \n",
       "                                          0.5          0.0001                       2.0   \n",
       "                                                       0.0005                       2.0   \n",
       "                                                       0.0010                       2.0   \n",
       "                           (512, 512)     0.1          0.0001                       2.0   \n",
       "                                                       0.0005                       2.0   \n",
       "                                                       0.0010                       2.0   \n",
       "                                          0.5          0.0001                       2.0   \n",
       "                                                       0.0005                       2.0   \n",
       "                                                       0.0010                       2.0   \n",
       "\n",
       "                                                                      embedding_dim  \\\n",
       "dimensions swnu_hidden_dim ffn_hidden_dim dropout_rate learning_rate                  \n",
       "15         (10,)           (64, 64)       0.1          0.0001                 384.0   \n",
       "                                                       0.0005                 384.0   \n",
       "                                                       0.0010                 384.0   \n",
       "                                          0.5          0.0001                 384.0   \n",
       "                                                       0.0005                 384.0   \n",
       "                                                       0.0010                 384.0   \n",
       "                           (256, 256)     0.1          0.0001                 384.0   \n",
       "                                                       0.0005                 384.0   \n",
       "                                                       0.0010                 384.0   \n",
       "                                          0.5          0.0001                 384.0   \n",
       "                                                       0.0005                 384.0   \n",
       "                                                       0.0010                 384.0   \n",
       "                           (512, 512)     0.1          0.0001                 384.0   \n",
       "                                                       0.0005                 384.0   \n",
       "                                                       0.0010                 384.0   \n",
       "                                          0.5          0.0001                 384.0   \n",
       "                                                       0.0005                 384.0   \n",
       "                                                       0.0010                 384.0   \n",
       "           (12,)           (64, 64)       0.1          0.0001                 384.0   \n",
       "                                                       0.0005                 384.0   \n",
       "                                                       0.0010                 384.0   \n",
       "                                          0.5          0.0001                 384.0   \n",
       "                                                       0.0005                 384.0   \n",
       "                                                       0.0010                 384.0   \n",
       "                           (256, 256)     0.1          0.0001                 384.0   \n",
       "                                                       0.0005                 384.0   \n",
       "                                                       0.0010                 384.0   \n",
       "                                          0.5          0.0001                 384.0   \n",
       "                                                       0.0005                 384.0   \n",
       "                                                       0.0010                 384.0   \n",
       "                           (512, 512)     0.1          0.0001                 384.0   \n",
       "                                                       0.0005                 384.0   \n",
       "                                                       0.0010                 384.0   \n",
       "                                          0.5          0.0001                 384.0   \n",
       "                                                       0.0005                 384.0   \n",
       "                                                       0.0010                 384.0   \n",
       "\n",
       "                                                                      log_signature  \\\n",
       "dimensions swnu_hidden_dim ffn_hidden_dim dropout_rate learning_rate                  \n",
       "15         (10,)           (64, 64)       0.1          0.0001                   1.0   \n",
       "                                                       0.0005                   1.0   \n",
       "                                                       0.0010                   1.0   \n",
       "                                          0.5          0.0001                   1.0   \n",
       "                                                       0.0005                   1.0   \n",
       "                                                       0.0010                   1.0   \n",
       "                           (256, 256)     0.1          0.0001                   1.0   \n",
       "                                                       0.0005                   1.0   \n",
       "                                                       0.0010                   1.0   \n",
       "                                          0.5          0.0001                   1.0   \n",
       "                                                       0.0005                   1.0   \n",
       "                                                       0.0010                   1.0   \n",
       "                           (512, 512)     0.1          0.0001                   1.0   \n",
       "                                                       0.0005                   1.0   \n",
       "                                                       0.0010                   1.0   \n",
       "                                          0.5          0.0001                   1.0   \n",
       "                                                       0.0005                   1.0   \n",
       "                                                       0.0010                   1.0   \n",
       "           (12,)           (64, 64)       0.1          0.0001                   1.0   \n",
       "                                                       0.0005                   1.0   \n",
       "                                                       0.0010                   1.0   \n",
       "                                          0.5          0.0001                   1.0   \n",
       "                                                       0.0005                   1.0   \n",
       "                                                       0.0010                   1.0   \n",
       "                           (256, 256)     0.1          0.0001                   1.0   \n",
       "                                                       0.0005                   1.0   \n",
       "                                                       0.0010                   1.0   \n",
       "                                          0.5          0.0001                   1.0   \n",
       "                                                       0.0005                   1.0   \n",
       "                                                       0.0010                   1.0   \n",
       "                           (512, 512)     0.1          0.0001                   1.0   \n",
       "                                                       0.0005                   1.0   \n",
       "                                                       0.0010                   1.0   \n",
       "                                          0.5          0.0001                   1.0   \n",
       "                                                       0.0005                   1.0   \n",
       "                                                       0.0010                   1.0   \n",
       "\n",
       "                                                                           seed  \\\n",
       "dimensions swnu_hidden_dim ffn_hidden_dim dropout_rate learning_rate              \n",
       "15         (10,)           (64, 64)       0.1          0.0001         45.333333   \n",
       "                                                       0.0005         45.333333   \n",
       "                                                       0.0010         45.333333   \n",
       "                                          0.5          0.0001         45.333333   \n",
       "                                                       0.0005         45.333333   \n",
       "                                                       0.0010         45.333333   \n",
       "                           (256, 256)     0.1          0.0001         45.333333   \n",
       "                                                       0.0005         45.333333   \n",
       "                                                       0.0010         45.333333   \n",
       "                                          0.5          0.0001         45.333333   \n",
       "                                                       0.0005         45.333333   \n",
       "                                                       0.0010         45.333333   \n",
       "                           (512, 512)     0.1          0.0001         45.333333   \n",
       "                                                       0.0005         45.333333   \n",
       "                                                       0.0010         45.333333   \n",
       "                                          0.5          0.0001         45.333333   \n",
       "                                                       0.0005         45.333333   \n",
       "                                                       0.0010         45.333333   \n",
       "           (12,)           (64, 64)       0.1          0.0001         45.333333   \n",
       "                                                       0.0005         45.333333   \n",
       "                                                       0.0010         45.333333   \n",
       "                                          0.5          0.0001         45.333333   \n",
       "                                                       0.0005         45.333333   \n",
       "                                                       0.0010         45.333333   \n",
       "                           (256, 256)     0.1          0.0001         45.333333   \n",
       "                                                       0.0005         45.333333   \n",
       "                                                       0.0010         45.333333   \n",
       "                                          0.5          0.0001         45.333333   \n",
       "                                                       0.0005         45.333333   \n",
       "                                                       0.0010         45.333333   \n",
       "                           (512, 512)     0.1          0.0001         45.333333   \n",
       "                                                       0.0005         45.333333   \n",
       "                                                       0.0010         45.333333   \n",
       "                                          0.5          0.0001         45.333333   \n",
       "                                                       0.0005         45.333333   \n",
       "                                                       0.0010         45.333333   \n",
       "\n",
       "                                                                      BiLSTM  \\\n",
       "dimensions swnu_hidden_dim ffn_hidden_dim dropout_rate learning_rate           \n",
       "15         (10,)           (64, 64)       0.1          0.0001            0.0   \n",
       "                                                       0.0005            0.0   \n",
       "                                                       0.0010            0.0   \n",
       "                                          0.5          0.0001            0.0   \n",
       "                                                       0.0005            0.0   \n",
       "                                                       0.0010            0.0   \n",
       "                           (256, 256)     0.1          0.0001            0.0   \n",
       "                                                       0.0005            0.0   \n",
       "                                                       0.0010            0.0   \n",
       "                                          0.5          0.0001            0.0   \n",
       "                                                       0.0005            0.0   \n",
       "                                                       0.0010            0.0   \n",
       "                           (512, 512)     0.1          0.0001            0.0   \n",
       "                                                       0.0005            0.0   \n",
       "                                                       0.0010            0.0   \n",
       "                                          0.5          0.0001            0.0   \n",
       "                                                       0.0005            0.0   \n",
       "                                                       0.0010            0.0   \n",
       "           (12,)           (64, 64)       0.1          0.0001            0.0   \n",
       "                                                       0.0005            0.0   \n",
       "                                                       0.0010            0.0   \n",
       "                                          0.5          0.0001            0.0   \n",
       "                                                       0.0005            0.0   \n",
       "                                                       0.0010            0.0   \n",
       "                           (256, 256)     0.1          0.0001            0.0   \n",
       "                                                       0.0005            0.0   \n",
       "                                                       0.0010            0.0   \n",
       "                                          0.5          0.0001            0.0   \n",
       "                                                       0.0005            0.0   \n",
       "                                                       0.0010            0.0   \n",
       "                           (512, 512)     0.1          0.0001            0.0   \n",
       "                                                       0.0005            0.0   \n",
       "                                                       0.0010            0.0   \n",
       "                                          0.5          0.0001            0.0   \n",
       "                                                       0.0005            0.0   \n",
       "                                                       0.0010            0.0   \n",
       "\n",
       "                                                                      gamma  \\\n",
       "dimensions swnu_hidden_dim ffn_hidden_dim dropout_rate learning_rate          \n",
       "15         (10,)           (64, 64)       0.1          0.0001           2.0   \n",
       "                                                       0.0005           2.0   \n",
       "                                                       0.0010           2.0   \n",
       "                                          0.5          0.0001           2.0   \n",
       "                                                       0.0005           2.0   \n",
       "                                                       0.0010           2.0   \n",
       "                           (256, 256)     0.1          0.0001           2.0   \n",
       "                                                       0.0005           2.0   \n",
       "                                                       0.0010           2.0   \n",
       "                                          0.5          0.0001           2.0   \n",
       "                                                       0.0005           2.0   \n",
       "                                                       0.0010           2.0   \n",
       "                           (512, 512)     0.1          0.0001           2.0   \n",
       "                                                       0.0005           2.0   \n",
       "                                                       0.0010           2.0   \n",
       "                                          0.5          0.0001           2.0   \n",
       "                                                       0.0005           2.0   \n",
       "                                                       0.0010           2.0   \n",
       "           (12,)           (64, 64)       0.1          0.0001           2.0   \n",
       "                                                       0.0005           2.0   \n",
       "                                                       0.0010           2.0   \n",
       "                                          0.5          0.0001           2.0   \n",
       "                                                       0.0005           2.0   \n",
       "                                                       0.0010           2.0   \n",
       "                           (256, 256)     0.1          0.0001           2.0   \n",
       "                                                       0.0005           2.0   \n",
       "                                                       0.0010           2.0   \n",
       "                                          0.5          0.0001           2.0   \n",
       "                                                       0.0005           2.0   \n",
       "                                                       0.0010           2.0   \n",
       "                           (512, 512)     0.1          0.0001           2.0   \n",
       "                                                       0.0005           2.0   \n",
       "                                                       0.0010           2.0   \n",
       "                                          0.5          0.0001           2.0   \n",
       "                                                       0.0005           2.0   \n",
       "                                                       0.0010           2.0   \n",
       "\n",
       "                                                                      k_fold  \\\n",
       "dimensions swnu_hidden_dim ffn_hidden_dim dropout_rate learning_rate           \n",
       "15         (10,)           (64, 64)       0.1          0.0001            1.0   \n",
       "                                                       0.0005            1.0   \n",
       "                                                       0.0010            1.0   \n",
       "                                          0.5          0.0001            1.0   \n",
       "                                                       0.0005            1.0   \n",
       "                                                       0.0010            1.0   \n",
       "                           (256, 256)     0.1          0.0001            1.0   \n",
       "                                                       0.0005            1.0   \n",
       "                                                       0.0010            1.0   \n",
       "                                          0.5          0.0001            1.0   \n",
       "                                                       0.0005            1.0   \n",
       "                                                       0.0010            1.0   \n",
       "                           (512, 512)     0.1          0.0001            1.0   \n",
       "                                                       0.0005            1.0   \n",
       "                                                       0.0010            1.0   \n",
       "                                          0.5          0.0001            1.0   \n",
       "                                                       0.0005            1.0   \n",
       "                                                       0.0010            1.0   \n",
       "           (12,)           (64, 64)       0.1          0.0001            1.0   \n",
       "                                                       0.0005            1.0   \n",
       "                                                       0.0010            1.0   \n",
       "                                          0.5          0.0001            1.0   \n",
       "                                                       0.0005            1.0   \n",
       "                                                       0.0010            1.0   \n",
       "                           (256, 256)     0.1          0.0001            1.0   \n",
       "                                                       0.0005            1.0   \n",
       "                                                       0.0010            1.0   \n",
       "                                          0.5          0.0001            1.0   \n",
       "                                                       0.0005            1.0   \n",
       "                                                       0.0010            1.0   \n",
       "                           (512, 512)     0.1          0.0001            1.0   \n",
       "                                                       0.0005            1.0   \n",
       "                                                       0.0010            1.0   \n",
       "                                          0.5          0.0001            1.0   \n",
       "                                                       0.0005            1.0   \n",
       "                                                       0.0010            1.0   \n",
       "\n",
       "                                                                      n_splits  \\\n",
       "dimensions swnu_hidden_dim ffn_hidden_dim dropout_rate learning_rate             \n",
       "15         (10,)           (64, 64)       0.1          0.0001              5.0   \n",
       "                                                       0.0005              5.0   \n",
       "                                                       0.0010              5.0   \n",
       "                                          0.5          0.0001              5.0   \n",
       "                                                       0.0005              5.0   \n",
       "                                                       0.0010              5.0   \n",
       "                           (256, 256)     0.1          0.0001              5.0   \n",
       "                                                       0.0005              5.0   \n",
       "                                                       0.0010              5.0   \n",
       "                                          0.5          0.0001              5.0   \n",
       "                                                       0.0005              5.0   \n",
       "                                                       0.0010              5.0   \n",
       "                           (512, 512)     0.1          0.0001              5.0   \n",
       "                                                       0.0005              5.0   \n",
       "                                                       0.0010              5.0   \n",
       "                                          0.5          0.0001              5.0   \n",
       "                                                       0.0005              5.0   \n",
       "                                                       0.0010              5.0   \n",
       "           (12,)           (64, 64)       0.1          0.0001              5.0   \n",
       "                                                       0.0005              5.0   \n",
       "                                                       0.0010              5.0   \n",
       "                                          0.5          0.0001              5.0   \n",
       "                                                       0.0005              5.0   \n",
       "                                                       0.0010              5.0   \n",
       "                           (256, 256)     0.1          0.0001              5.0   \n",
       "                                                       0.0005              5.0   \n",
       "                                                       0.0010              5.0   \n",
       "                                          0.5          0.0001              5.0   \n",
       "                                                       0.0005              5.0   \n",
       "                                                       0.0010              5.0   \n",
       "                           (512, 512)     0.1          0.0001              5.0   \n",
       "                                                       0.0005              5.0   \n",
       "                                                       0.0010              5.0   \n",
       "                                          0.5          0.0001              5.0   \n",
       "                                                       0.0005              5.0   \n",
       "                                                       0.0010              5.0   \n",
       "\n",
       "                                                                      batch_size  \\\n",
       "dimensions swnu_hidden_dim ffn_hidden_dim dropout_rate learning_rate               \n",
       "15         (10,)           (64, 64)       0.1          0.0001               64.0   \n",
       "                                                       0.0005               64.0   \n",
       "                                                       0.0010               64.0   \n",
       "                                          0.5          0.0001               64.0   \n",
       "                                                       0.0005               64.0   \n",
       "                                                       0.0010               64.0   \n",
       "                           (256, 256)     0.1          0.0001               64.0   \n",
       "                                                       0.0005               64.0   \n",
       "                                                       0.0010               64.0   \n",
       "                                          0.5          0.0001               64.0   \n",
       "                                                       0.0005               64.0   \n",
       "                                                       0.0010               64.0   \n",
       "                           (512, 512)     0.1          0.0001               64.0   \n",
       "                                                       0.0005               64.0   \n",
       "                                                       0.0010               64.0   \n",
       "                                          0.5          0.0001               64.0   \n",
       "                                                       0.0005               64.0   \n",
       "                                                       0.0010               64.0   \n",
       "           (12,)           (64, 64)       0.1          0.0001               64.0   \n",
       "                                                       0.0005               64.0   \n",
       "                                                       0.0010               64.0   \n",
       "                                          0.5          0.0001               64.0   \n",
       "                                                       0.0005               64.0   \n",
       "                                                       0.0010               64.0   \n",
       "                           (256, 256)     0.1          0.0001               64.0   \n",
       "                                                       0.0005               64.0   \n",
       "                                                       0.0010               64.0   \n",
       "                                          0.5          0.0001               64.0   \n",
       "                                                       0.0005               64.0   \n",
       "                                                       0.0010               64.0   \n",
       "                           (512, 512)     0.1          0.0001               64.0   \n",
       "                                                       0.0005               64.0   \n",
       "                                                       0.0010               64.0   \n",
       "                                          0.5          0.0001               64.0   \n",
       "                                                       0.0005               64.0   \n",
       "                                                       0.0010               64.0   \n",
       "\n",
       "                                                                      model_id  \n",
       "dimensions swnu_hidden_dim ffn_hidden_dim dropout_rate learning_rate            \n",
       "15         (10,)           (64, 64)       0.1          0.0001             31.0  \n",
       "                                                       0.0005             32.0  \n",
       "                                                       0.0010             30.0  \n",
       "                                          0.5          0.0001             28.0  \n",
       "                                                       0.0005             29.0  \n",
       "                                                       0.0010             27.0  \n",
       "                           (256, 256)     0.1          0.0001             37.0  \n",
       "                                                       0.0005             38.0  \n",
       "                                                       0.0010             36.0  \n",
       "                                          0.5          0.0001             34.0  \n",
       "                                                       0.0005             35.0  \n",
       "                                                       0.0010             33.0  \n",
       "                           (512, 512)     0.1          0.0001             43.0  \n",
       "                                                       0.0005             44.0  \n",
       "                                                       0.0010             42.0  \n",
       "                                          0.5          0.0001             40.0  \n",
       "                                                       0.0005             41.0  \n",
       "                                                       0.0010             39.0  \n",
       "           (12,)           (64, 64)       0.1          0.0001              4.0  \n",
       "                                                       0.0005              5.0  \n",
       "                                                       0.0010              3.0  \n",
       "                                          0.5          0.0001              1.0  \n",
       "                                                       0.0005              2.0  \n",
       "                                                       0.0010              0.0  \n",
       "                           (256, 256)     0.1          0.0001             10.0  \n",
       "                                                       0.0005             11.0  \n",
       "                                                       0.0010              9.0  \n",
       "                                          0.5          0.0001              7.0  \n",
       "                                                       0.0005              8.0  \n",
       "                                                       0.0010              6.0  \n",
       "                           (512, 512)     0.1          0.0001             16.0  \n",
       "                                                       0.0005             17.0  \n",
       "                                                       0.0010             15.0  \n",
       "                                          0.5          0.0001             13.0  \n",
       "                                                       0.0005             14.0  \n",
       "                                                       0.0010             12.0  \n",
       "\n",
       "[36 rows x 22 columns]"
      ]
     },
     "execution_count": 25,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "swnu_network_umap_kfold_20.groupby([\"dimensions\",\n",
    "                                    \"swnu_hidden_dim\",\n",
    "                                    \"ffn_hidden_dim\",\n",
    "                                    \"dropout_rate\",\n",
    "                                    \"learning_rate\"]).mean()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "37afb0ff-1eed-4ff8-afdc-2387e93c5a3b",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>loss</th>\n",
       "      <th>accuracy</th>\n",
       "      <th>f1</th>\n",
       "      <th>f1_scores</th>\n",
       "      <th>precision</th>\n",
       "      <th>precision_scores</th>\n",
       "      <th>recall</th>\n",
       "      <th>recall_scores</th>\n",
       "      <th>valid_loss</th>\n",
       "      <th>valid_accuracy</th>\n",
       "      <th>...</th>\n",
       "      <th>seed</th>\n",
       "      <th>BiLSTM</th>\n",
       "      <th>loss_function</th>\n",
       "      <th>gamma</th>\n",
       "      <th>k_fold</th>\n",
       "      <th>n_splits</th>\n",
       "      <th>augmentation_type</th>\n",
       "      <th>hidden_dim_aug</th>\n",
       "      <th>comb_method</th>\n",
       "      <th>batch_size</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>None</td>\n",
       "      <td>0.618198</td>\n",
       "      <td>0.516449</td>\n",
       "      <td>[0.7427375677006401, 0.44791992492962157, 0.35...</td>\n",
       "      <td>0.511186</td>\n",
       "      <td>[0.7586120191098819, 0.4525916561314791, 0.322...</td>\n",
       "      <td>0.525038</td>\n",
       "      <td>[0.7275138654448999, 0.443343653250774, 0.4042...</td>\n",
       "      <td>None</td>\n",
       "      <td>0.667935</td>\n",
       "      <td>...</td>\n",
       "      <td>1</td>\n",
       "      <td>False</td>\n",
       "      <td>focal</td>\n",
       "      <td>2</td>\n",
       "      <td>True</td>\n",
       "      <td>5</td>\n",
       "      <td>Conv1d</td>\n",
       "      <td>None</td>\n",
       "      <td>concatenation</td>\n",
       "      <td>64</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>None</td>\n",
       "      <td>0.615455</td>\n",
       "      <td>0.504437</td>\n",
       "      <td>[0.7489853646537941, 0.4340608668920996, 0.330...</td>\n",
       "      <td>0.500322</td>\n",
       "      <td>[0.7643072289156626, 0.43101343101343104, 0.30...</td>\n",
       "      <td>0.510205</td>\n",
       "      <td>[0.7342657342657343, 0.4371517027863777, 0.359...</td>\n",
       "      <td>None</td>\n",
       "      <td>0.672300</td>\n",
       "      <td>...</td>\n",
       "      <td>12</td>\n",
       "      <td>False</td>\n",
       "      <td>focal</td>\n",
       "      <td>2</td>\n",
       "      <td>True</td>\n",
       "      <td>5</td>\n",
       "      <td>Conv1d</td>\n",
       "      <td>None</td>\n",
       "      <td>concatenation</td>\n",
       "      <td>64</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>None</td>\n",
       "      <td>0.616369</td>\n",
       "      <td>0.500178</td>\n",
       "      <td>[0.7523579201934705, 0.41666666666666663, 0.33...</td>\n",
       "      <td>0.498711</td>\n",
       "      <td>[0.7545476594712588, 0.44712562100780695, 0.29...</td>\n",
       "      <td>0.506499</td>\n",
       "      <td>[0.7501808536291295, 0.39009287925696595, 0.37...</td>\n",
       "      <td>None</td>\n",
       "      <td>0.660437</td>\n",
       "      <td>...</td>\n",
       "      <td>123</td>\n",
       "      <td>False</td>\n",
       "      <td>focal</td>\n",
       "      <td>2</td>\n",
       "      <td>True</td>\n",
       "      <td>5</td>\n",
       "      <td>Conv1d</td>\n",
       "      <td>None</td>\n",
       "      <td>concatenation</td>\n",
       "      <td>64</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>3 rows  42 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "   loss  accuracy        f1  \\\n",
       "0  None  0.618198  0.516449   \n",
       "0  None  0.615455  0.504437   \n",
       "0  None  0.616369  0.500178   \n",
       "\n",
       "                                           f1_scores  precision  \\\n",
       "0  [0.7427375677006401, 0.44791992492962157, 0.35...   0.511186   \n",
       "0  [0.7489853646537941, 0.4340608668920996, 0.330...   0.500322   \n",
       "0  [0.7523579201934705, 0.41666666666666663, 0.33...   0.498711   \n",
       "\n",
       "                                    precision_scores    recall  \\\n",
       "0  [0.7586120191098819, 0.4525916561314791, 0.322...  0.525038   \n",
       "0  [0.7643072289156626, 0.43101343101343104, 0.30...  0.510205   \n",
       "0  [0.7545476594712588, 0.44712562100780695, 0.29...  0.506499   \n",
       "\n",
       "                                       recall_scores valid_loss  \\\n",
       "0  [0.7275138654448999, 0.443343653250774, 0.4042...       None   \n",
       "0  [0.7342657342657343, 0.4371517027863777, 0.359...       None   \n",
       "0  [0.7501808536291295, 0.39009287925696595, 0.37...       None   \n",
       "\n",
       "   valid_accuracy  ...  seed BiLSTM  loss_function gamma  k_fold n_splits  \\\n",
       "0        0.667935  ...     1  False          focal     2    True        5   \n",
       "0        0.672300  ...    12  False          focal     2    True        5   \n",
       "0        0.660437  ...   123  False          focal     2    True        5   \n",
       "\n",
       "   augmentation_type  hidden_dim_aug    comb_method batch_size  \n",
       "0             Conv1d            None  concatenation         64  \n",
       "0             Conv1d            None  concatenation         64  \n",
       "0             Conv1d            None  concatenation         64  \n",
       "\n",
       "[3 rows x 42 columns]"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "best_swnu_network_umap_kfold_20"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "2d8e978d-4989-4cc6-8d37-5b314ed0e5df",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.507021382975529"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "best_swnu_network_umap_kfold_20[\"f1\"].mean()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "561ea9ca-9b3d-43ee-b987-016124ec580b",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.5034064276577233"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "best_swnu_network_umap_kfold_20[\"precision\"].mean()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "82603dd8-b062-4f94-a2c5-c0c7d6b0eecc",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.5139141151743111"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "best_swnu_network_umap_kfold_20[\"recall\"].mean()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "62f65124-e30c-4a25-8c5a-75ea771658ff",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([0.74802695, 0.43288249, 0.34015471])"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "np.stack(best_swnu_network_umap_kfold_20[\"f1_scores\"]).mean(axis=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "c81b3be2-b983-4a17-a49c-0b0c863cf52f",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([0.75915564, 0.4435769 , 0.30748674])"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "np.stack(best_swnu_network_umap_kfold_20[\"precision_scores\"]).mean(axis=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "ec27ebec-fb90-49bc-8a09-46280cf135e6",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([0.73732015, 0.42352941, 0.38089278])"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "np.stack(best_swnu_network_umap_kfold_20[\"recall_scores\"]).mean(axis=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "13a67a66",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "5b910a9f2f9644caa2e7f1b113ba308e",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/1 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "1185a2249d5f46f582e2e3a0cc37c0e6",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/1 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "5919b44c1b26495480350cbbc46c01ad",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/1 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "##################################################\n",
      "dimension: 15 | method: gaussian_random_projection\n",
      "[INFO] Concatenating the embeddings to the dataframe...\n",
      "[INFO] - columns beginning with 'e' denote the full embddings.\n",
      "[INFO] - columns beginning with 'd' denote the dimension reduced embeddings.\n",
      "[INFO] Adding time feature columns into dataframe in `.df`.\n",
      "[INFO] Adding 'time_encoding' and feature...\n",
      "[INFO] Adding 'time_diff' and feature...\n",
      "[INFO] Adding 'timeline_index' feature...\n",
      "[INFO] Padding ids and storing in `.df_padded` and `.array_padded` attributes.\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "422bcb181dba49ee9a760223dc6f8766",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/13551 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[INFO] The path was created for each item in the dataframe, by looking at its history, so to include embeddings in the FFN input, we concatenate the embeddings for each sentence / text.\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "b75b695b30b5430daa16f658a762ab17",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/3 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "0f3e99b46e104ee790352d21889b1dba",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/3 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "3da954e3ddd14cc3b245a57af88de6b7",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/1 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "dfeab92d14e44074840bb90826ba17a1",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/2 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "996b5d3e2cad40668a5f0c92da06c1d2",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/3 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "9f5b750a81c14c80917d56fb11f940df",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/3 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "0843ae523a594f198b0932b08cd1d2c7",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/1 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "30f6d4c775b7418c97e471a3c798f11d",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/2 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "da13a3ae74a349d4a1508f37142ac716",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/3 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[10], line 2\u001b[0m\n\u001b[1;32m      1\u001b[0m size \u001b[38;5;241m=\u001b[39m \u001b[38;5;241m20\u001b[39m\n\u001b[0;32m----> 2\u001b[0m swnu_network_grp_kfold_20, best_swnu_network_grp_kfold_20, _, __ \u001b[38;5;241m=\u001b[39m \u001b[43mswnu_network_hyperparameter_search\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m      3\u001b[0m \u001b[43m    \u001b[49m\u001b[43mnum_epochs\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mnum_epochs\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m      4\u001b[0m \u001b[43m    \u001b[49m\u001b[43mdf\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43manno_mi\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m      5\u001b[0m \u001b[43m    \u001b[49m\u001b[43mid_column\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mtranscript_id\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m,\u001b[49m\n\u001b[1;32m      6\u001b[0m \u001b[43m    \u001b[49m\u001b[43mlabel_column\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mclient_talk_type\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m,\u001b[49m\n\u001b[1;32m      7\u001b[0m \u001b[43m    \u001b[49m\u001b[43membeddings\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43msbert_embeddings\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m      8\u001b[0m \u001b[43m    \u001b[49m\u001b[43my_data\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43my_data_client\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m      9\u001b[0m \u001b[43m    \u001b[49m\u001b[43membedding_dim\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43membedding_dim\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m     10\u001b[0m \u001b[43m    \u001b[49m\u001b[43moutput_dim\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43moutput_dim_client\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m     11\u001b[0m \u001b[43m    \u001b[49m\u001b[43mhistory_lengths\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43m[\u001b[49m\u001b[43msize\u001b[49m\u001b[43m]\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m     12\u001b[0m \u001b[43m    \u001b[49m\u001b[43mdim_reduce_methods\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43m[\u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mgaussian_random_projection\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m]\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m     13\u001b[0m \u001b[43m    \u001b[49m\u001b[43mdimensions\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mdimensions\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m     14\u001b[0m \u001b[43m    \u001b[49m\u001b[43mlog_signature\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43;01mTrue\u001b[39;49;00m\u001b[43m,\u001b[49m\n\u001b[1;32m     15\u001b[0m \u001b[43m    \u001b[49m\u001b[43mswnu_hidden_dim_sizes_and_sig_depths\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mswnu_hidden_dim_sizes_and_sig_depths\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m     16\u001b[0m \u001b[43m    \u001b[49m\u001b[43mffn_hidden_dim_sizes\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mffn_hidden_dim_sizes\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m     17\u001b[0m \u001b[43m    \u001b[49m\u001b[43mdropout_rates\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mdropout_rates\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m     18\u001b[0m \u001b[43m    \u001b[49m\u001b[43mlearning_rates\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mlearning_rates\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m     19\u001b[0m \u001b[43m    \u001b[49m\u001b[43mBiLSTM\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43;01mFalse\u001b[39;49;00m\u001b[43m,\u001b[49m\n\u001b[1;32m     20\u001b[0m \u001b[43m    \u001b[49m\u001b[43mseeds\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mseeds\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m     21\u001b[0m \u001b[43m    \u001b[49m\u001b[43mloss\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mloss\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m     22\u001b[0m \u001b[43m    \u001b[49m\u001b[43mgamma\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mgamma\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m     23\u001b[0m \u001b[43m    \u001b[49m\u001b[43mtime_feature\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mtime_features\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m     24\u001b[0m \u001b[43m    \u001b[49m\u001b[43mstandardise_method\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mstandardise_method\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m     25\u001b[0m \u001b[43m    \u001b[49m\u001b[43mpath_indices\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mclient_index\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m     26\u001b[0m \u001b[43m    \u001b[49m\u001b[43msplit_ids\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mclient_transcript_id\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m     27\u001b[0m \u001b[43m    \u001b[49m\u001b[43mk_fold\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43;01mTrue\u001b[39;49;00m\u001b[43m,\u001b[49m\n\u001b[1;32m     28\u001b[0m \u001b[43m    \u001b[49m\u001b[43mpatience\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mpatience\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m     29\u001b[0m \u001b[43m    \u001b[49m\u001b[43mvalidation_metric\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mvalidation_metric\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m     30\u001b[0m \u001b[43m    \u001b[49m\u001b[43mresults_output\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;124;43mf\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;132;43;01m{\u001b[39;49;00m\u001b[43moutput_dir\u001b[49m\u001b[38;5;132;43;01m}\u001b[39;49;00m\u001b[38;5;124;43m/swnu_network_grp_focal_\u001b[39;49m\u001b[38;5;132;43;01m{\u001b[39;49;00m\u001b[43mgamma\u001b[49m\u001b[38;5;132;43;01m}\u001b[39;49;00m\u001b[38;5;124;43m_\u001b[39;49m\u001b[38;5;132;43;01m{\u001b[39;49;00m\u001b[43msize\u001b[49m\u001b[38;5;132;43;01m}\u001b[39;49;00m\u001b[38;5;124;43m_kfold.csv\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m,\u001b[49m\n\u001b[1;32m     31\u001b[0m \u001b[43m    \u001b[49m\u001b[43mverbose\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43;01mFalse\u001b[39;49;00m\n\u001b[1;32m     32\u001b[0m \u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m/bask/projects/v/vjgo8416-rough-paths/nlpsig-networks/nlpsig_networks/scripts/swnu_network_functions.py:261\u001b[0m, in \u001b[0;36mswnu_network_hyperparameter_search\u001b[0;34m(num_epochs, df, id_column, label_column, embeddings, y_data, embedding_dim, output_dim, history_lengths, dim_reduce_methods, dimensions, log_signature, swnu_hidden_dim_sizes_and_sig_depths, ffn_hidden_dim_sizes, dropout_rates, learning_rates, BiLSTM, seeds, loss, gamma, batch_size, time_feature, standardise_method, add_time_in_path, conv_output_channels, augmentation_type, hidden_dim_aug, comb_method, path_indices, data_split_seed, split_ids, split_indices, k_fold, n_splits, patience, validation_metric, results_output, verbose)\u001b[0m\n\u001b[1;32m    259\u001b[0m verbose_model \u001b[38;5;241m=\u001b[39m verbose\n\u001b[1;32m    260\u001b[0m \u001b[38;5;28;01mfor\u001b[39;00m seed \u001b[38;5;129;01min\u001b[39;00m seeds:\n\u001b[0;32m--> 261\u001b[0m     _, results \u001b[38;5;241m=\u001b[39m \u001b[43mimplement_swnu_network\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m    262\u001b[0m \u001b[43m        \u001b[49m\u001b[43mnum_epochs\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mnum_epochs\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    263\u001b[0m \u001b[43m        \u001b[49m\u001b[43mx_data\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mx_data\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    264\u001b[0m \u001b[43m        \u001b[49m\u001b[43my_data\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43my_data\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    265\u001b[0m \u001b[43m        \u001b[49m\u001b[43minput_channels\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43minput_channels\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    266\u001b[0m \u001b[43m        \u001b[49m\u001b[43moutput_channels\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43moutput_channels\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    267\u001b[0m \u001b[43m        \u001b[49m\u001b[43mnum_time_features\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43mlen\u001b[39;49m\u001b[43m(\u001b[49m\u001b[43mtime_feature\u001b[49m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    268\u001b[0m \u001b[43m        \u001b[49m\u001b[43membedding_dim\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43membedding_dim\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    269\u001b[0m \u001b[43m        \u001b[49m\u001b[43mlog_signature\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mlog_signature\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    270\u001b[0m \u001b[43m        \u001b[49m\u001b[43msig_depth\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43msig_depth\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    271\u001b[0m \u001b[43m        \u001b[49m\u001b[43mswnu_hidden_dim\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mswnu_hidden_dim\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    272\u001b[0m \u001b[43m        \u001b[49m\u001b[43mffn_hidden_dim\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mffn_hidden_dim\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    273\u001b[0m \u001b[43m        \u001b[49m\u001b[43moutput_dim\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43moutput_dim\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    274\u001b[0m \u001b[43m        \u001b[49m\u001b[43mBiLSTM\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mBiLSTM\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    275\u001b[0m \u001b[43m        \u001b[49m\u001b[43mdropout_rate\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mdropout\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    276\u001b[0m \u001b[43m        \u001b[49m\u001b[43mlearning_rate\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mlr\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    277\u001b[0m \u001b[43m        \u001b[49m\u001b[43mseed\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mseed\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    278\u001b[0m \u001b[43m        \u001b[49m\u001b[43mloss\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mloss\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    279\u001b[0m \u001b[43m        \u001b[49m\u001b[43mgamma\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mgamma\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    280\u001b[0m \u001b[43m        \u001b[49m\u001b[43mbatch_size\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mbatch_size\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    281\u001b[0m \u001b[43m        \u001b[49m\u001b[43maugmentation_type\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43maugmentation_type\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    282\u001b[0m \u001b[43m        \u001b[49m\u001b[43mhidden_dim_aug\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mhidden_dim_aug\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    283\u001b[0m \u001b[43m        \u001b[49m\u001b[43mcomb_method\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mcomb_method\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    284\u001b[0m \u001b[43m        \u001b[49m\u001b[43mdata_split_seed\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mdata_split_seed\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    285\u001b[0m \u001b[43m        \u001b[49m\u001b[43msplit_ids\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43msplit_ids\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    286\u001b[0m \u001b[43m        \u001b[49m\u001b[43msplit_indices\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43msplit_indices\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    287\u001b[0m \u001b[43m        \u001b[49m\u001b[43mk_fold\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mk_fold\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    288\u001b[0m \u001b[43m        \u001b[49m\u001b[43mn_splits\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mn_splits\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    289\u001b[0m \u001b[43m        \u001b[49m\u001b[43mpatience\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mpatience\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    290\u001b[0m \u001b[43m        \u001b[49m\u001b[43mverbose_training\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43;01mFalse\u001b[39;49;00m\u001b[43m,\u001b[49m\n\u001b[1;32m    291\u001b[0m \u001b[43m        \u001b[49m\u001b[43mverbose_results\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mverbose\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    292\u001b[0m \u001b[43m        \u001b[49m\u001b[43mverbose_model\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mverbose_model\u001b[49m\n\u001b[1;32m    293\u001b[0m \u001b[43m    \u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    294\u001b[0m     \u001b[38;5;66;03m# save metric that we want to validate on\u001b[39;00m\n\u001b[1;32m    295\u001b[0m     \u001b[38;5;66;03m# taking the mean over the performance on the folds for the seed\u001b[39;00m\n\u001b[1;32m    296\u001b[0m     \u001b[38;5;66;03m# if k_fold=False, .mean() just returns the performance for the seed\u001b[39;00m\n\u001b[1;32m    297\u001b[0m     scores\u001b[38;5;241m.\u001b[39mappend(results[\u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mvalid_\u001b[39m\u001b[38;5;132;01m{\u001b[39;00mvalidation_metric\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m\"\u001b[39m]\u001b[38;5;241m.\u001b[39mmean())\n",
      "File \u001b[0;32m/bask/projects/v/vjgo8416-rough-paths/nlpsig-networks/nlpsig_networks/scripts/swnu_network_functions.py:137\u001b[0m, in \u001b[0;36mimplement_swnu_network\u001b[0;34m(num_epochs, x_data, y_data, input_channels, num_time_features, embedding_dim, log_signature, sig_depth, swnu_hidden_dim, ffn_hidden_dim, output_dim, BiLSTM, dropout_rate, learning_rate, seed, loss, gamma, batch_size, output_channels, augmentation_type, hidden_dim_aug, comb_method, data_split_seed, split_ids, split_indices, k_fold, n_splits, patience, verbose_training, verbose_results, verbose_model)\u001b[0m\n\u001b[1;32m    134\u001b[0m     y_data \u001b[38;5;241m=\u001b[39m torch\u001b[38;5;241m.\u001b[39mtensor(y_data)\n\u001b[1;32m    135\u001b[0m x_data \u001b[38;5;241m=\u001b[39m x_data\u001b[38;5;241m.\u001b[39mfloat()\n\u001b[0;32m--> 137\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mimplement_model\u001b[49m\u001b[43m(\u001b[49m\u001b[43mmodel\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mswnu_network_model\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    138\u001b[0m \u001b[43m                       \u001b[49m\u001b[43mnum_epochs\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mnum_epochs\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    139\u001b[0m \u001b[43m                       \u001b[49m\u001b[43mx_data\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mx_data\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    140\u001b[0m \u001b[43m                       \u001b[49m\u001b[43my_data\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43my_data\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    141\u001b[0m \u001b[43m                       \u001b[49m\u001b[43mlearning_rate\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mlearning_rate\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    142\u001b[0m \u001b[43m                       \u001b[49m\u001b[43mseed\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mseed\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    143\u001b[0m \u001b[43m                       \u001b[49m\u001b[43mloss\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mloss\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    144\u001b[0m \u001b[43m                       \u001b[49m\u001b[43mgamma\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mgamma\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    145\u001b[0m \u001b[43m                       \u001b[49m\u001b[43mbatch_size\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mbatch_size\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    146\u001b[0m \u001b[43m                       \u001b[49m\u001b[43mdata_split_seed\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mdata_split_seed\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    147\u001b[0m \u001b[43m                       \u001b[49m\u001b[43msplit_ids\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43msplit_ids\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    148\u001b[0m \u001b[43m                       \u001b[49m\u001b[43msplit_indices\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43msplit_indices\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    149\u001b[0m \u001b[43m                       \u001b[49m\u001b[43mk_fold\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mk_fold\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    150\u001b[0m \u001b[43m                       \u001b[49m\u001b[43mn_splits\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mn_splits\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    151\u001b[0m \u001b[43m                       \u001b[49m\u001b[43mpatience\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mpatience\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    152\u001b[0m \u001b[43m                       \u001b[49m\u001b[43mverbose_training\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mverbose_training\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    153\u001b[0m \u001b[43m                       \u001b[49m\u001b[43mverbose_results\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mverbose_results\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m/bask/projects/v/vjgo8416-rough-paths/nlpsig-networks/nlpsig_networks/scripts/implement_model.py:67\u001b[0m, in \u001b[0;36mimplement_model\u001b[0;34m(model, num_epochs, x_data, y_data, learning_rate, seed, loss, gamma, batch_size, data_split_seed, split_ids, split_indices, k_fold, n_splits, patience, verbose_training, verbose_results)\u001b[0m\n\u001b[1;32m     60\u001b[0m     optimizer \u001b[38;5;241m=\u001b[39m torch\u001b[38;5;241m.\u001b[39moptim\u001b[38;5;241m.\u001b[39mAdam(model\u001b[38;5;241m.\u001b[39mparameters(),\n\u001b[1;32m     61\u001b[0m                                  lr\u001b[38;5;241m=\u001b[39mlearning_rate,\n\u001b[1;32m     62\u001b[0m                                  weight_decay\u001b[38;5;241m=\u001b[39mweight_decay_adam)\n\u001b[1;32m     64\u001b[0m     \u001b[38;5;66;03m# perform k-fold evaluation which returns a dataframe with columns for the\u001b[39;00m\n\u001b[1;32m     65\u001b[0m     \u001b[38;5;66;03m# loss, accuracy, f1 (macro) and individual f1-scores for each fold\u001b[39;00m\n\u001b[1;32m     66\u001b[0m     \u001b[38;5;66;03m# (for both validation and test set)\u001b[39;00m\n\u001b[0;32m---> 67\u001b[0m     results \u001b[38;5;241m=\u001b[39m \u001b[43mKFold_pytorch\u001b[49m\u001b[43m(\u001b[49m\u001b[43mfolds\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mfolds\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m     68\u001b[0m \u001b[43m                            \u001b[49m\u001b[43mmodel\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mmodel\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m     69\u001b[0m \u001b[43m                            \u001b[49m\u001b[43mcriterion\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mcriterion\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m     70\u001b[0m \u001b[43m                            \u001b[49m\u001b[43moptimizer\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43moptimizer\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m     71\u001b[0m \u001b[43m                            \u001b[49m\u001b[43mnum_epochs\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mnum_epochs\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m     72\u001b[0m \u001b[43m                            \u001b[49m\u001b[43mbatch_size\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mbatch_size\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m     73\u001b[0m \u001b[43m                            \u001b[49m\u001b[43mseed\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mseed\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m     74\u001b[0m \u001b[43m                            \u001b[49m\u001b[43mreturn_best\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mreturn_best\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m     75\u001b[0m \u001b[43m                            \u001b[49m\u001b[43mearly_stopping\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mearly_stopping\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m     76\u001b[0m \u001b[43m                            \u001b[49m\u001b[43mpatience\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mpatience\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m     77\u001b[0m \u001b[43m                            \u001b[49m\u001b[43mverbose\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mverbose_training\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m     78\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[1;32m     79\u001b[0m     \u001b[38;5;66;03m# split dataset\u001b[39;00m\n\u001b[1;32m     80\u001b[0m     data_loader_args \u001b[38;5;241m=\u001b[39m {\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mbatch_size\u001b[39m\u001b[38;5;124m\"\u001b[39m: batch_size, \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mshuffle\u001b[39m\u001b[38;5;124m\"\u001b[39m: \u001b[38;5;28;01mTrue\u001b[39;00m}\n",
      "File \u001b[0;32m/bask/projects/v/vjgo8416-rough-paths/nlpsig-networks/nlpsig_networks/pytorch_utils.py:708\u001b[0m, in \u001b[0;36mKFold_pytorch\u001b[0;34m(folds, model, criterion, optimizer, num_epochs, batch_size, return_metric_for_each_fold, seed, return_best, early_stopping, patience, verbose, verbose_epoch)\u001b[0m\n\u001b[1;32m    705\u001b[0m train, valid, test \u001b[38;5;241m=\u001b[39m folds\u001b[38;5;241m.\u001b[39mget_splits(fold_index\u001b[38;5;241m=\u001b[39mfold, as_DataLoader\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mTrue\u001b[39;00m, data_loader_args\u001b[38;5;241m=\u001b[39mdata_loader_args)\n\u001b[1;32m    707\u001b[0m \u001b[38;5;66;03m# train pytorch model\u001b[39;00m\n\u001b[0;32m--> 708\u001b[0m model \u001b[38;5;241m=\u001b[39m \u001b[43mtraining_pytorch\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m    709\u001b[0m \u001b[43m    \u001b[49m\u001b[43mmodel\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mmodel\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    710\u001b[0m \u001b[43m    \u001b[49m\u001b[43mtrain_loader\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mtrain\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    711\u001b[0m \u001b[43m    \u001b[49m\u001b[43mvalid_loader\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mvalid\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    712\u001b[0m \u001b[43m    \u001b[49m\u001b[43mcriterion\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mcriterion\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    713\u001b[0m \u001b[43m    \u001b[49m\u001b[43moptimizer\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43moptimizer\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    714\u001b[0m \u001b[43m    \u001b[49m\u001b[43mnum_epochs\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mnum_epochs\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    715\u001b[0m \u001b[43m    \u001b[49m\u001b[43mseed\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mseed\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    716\u001b[0m \u001b[43m    \u001b[49m\u001b[43mreturn_best\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mreturn_best\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    717\u001b[0m \u001b[43m    \u001b[49m\u001b[43msave_best\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43;01mFalse\u001b[39;49;00m\u001b[43m,\u001b[49m\n\u001b[1;32m    718\u001b[0m \u001b[43m    \u001b[49m\u001b[43mearly_stopping\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mearly_stopping\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    719\u001b[0m \u001b[43m    \u001b[49m\u001b[43mpatience\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mpatience\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    720\u001b[0m \u001b[43m    \u001b[49m\u001b[43mverbose\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mverbose\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    721\u001b[0m \u001b[43m    \u001b[49m\u001b[43mverbose_epoch\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mverbose_epoch\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    722\u001b[0m \u001b[43m\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    724\u001b[0m \u001b[38;5;66;03m# test model\u001b[39;00m\n\u001b[1;32m    725\u001b[0m test_results \u001b[38;5;241m=\u001b[39m testing_pytorch(model\u001b[38;5;241m=\u001b[39mmodel,\n\u001b[1;32m    726\u001b[0m                                test_loader\u001b[38;5;241m=\u001b[39mtest,\n\u001b[1;32m    727\u001b[0m                                criterion\u001b[38;5;241m=\u001b[39mcriterion,\n\u001b[1;32m    728\u001b[0m                                verbose\u001b[38;5;241m=\u001b[39mverbose)\n",
      "File \u001b[0;32m/bask/projects/v/vjgo8416-rough-paths/nlpsig-networks/nlpsig_networks/pytorch_utils.py:421\u001b[0m, in \u001b[0;36mtraining_pytorch\u001b[0;34m(model, train_loader, criterion, optimizer, num_epochs, scheduler, valid_loader, seed, return_best, save_best, output, early_stopping, validation_metric, patience, verbose, verbose_epoch)\u001b[0m\n\u001b[1;32m    419\u001b[0m     outputs \u001b[38;5;241m=\u001b[39m model(emb)\n\u001b[1;32m    420\u001b[0m     loss \u001b[38;5;241m=\u001b[39m criterion(outputs, labels)\n\u001b[0;32m--> 421\u001b[0m     \u001b[43mloss\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mbackward\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    422\u001b[0m     optimizer\u001b[38;5;241m.\u001b[39mstep()\n\u001b[1;32m    424\u001b[0m \u001b[38;5;66;03m# show training progress\u001b[39;00m\n",
      "File \u001b[0;32m/bask/projects/v/vjgo8416-rough-paths/envs/nlpsig-networks/lib/python3.8/site-packages/torch/_tensor.py:255\u001b[0m, in \u001b[0;36mTensor.backward\u001b[0;34m(self, gradient, retain_graph, create_graph, inputs)\u001b[0m\n\u001b[1;32m    246\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m has_torch_function_unary(\u001b[38;5;28mself\u001b[39m):\n\u001b[1;32m    247\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m handle_torch_function(\n\u001b[1;32m    248\u001b[0m         Tensor\u001b[38;5;241m.\u001b[39mbackward,\n\u001b[1;32m    249\u001b[0m         (\u001b[38;5;28mself\u001b[39m,),\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m    253\u001b[0m         create_graph\u001b[38;5;241m=\u001b[39mcreate_graph,\n\u001b[1;32m    254\u001b[0m         inputs\u001b[38;5;241m=\u001b[39minputs)\n\u001b[0;32m--> 255\u001b[0m \u001b[43mtorch\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mautograd\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mbackward\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mgradient\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mretain_graph\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mcreate_graph\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43minputs\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43minputs\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m/bask/projects/v/vjgo8416-rough-paths/envs/nlpsig-networks/lib/python3.8/site-packages/torch/autograd/__init__.py:147\u001b[0m, in \u001b[0;36mbackward\u001b[0;34m(tensors, grad_tensors, retain_graph, create_graph, grad_variables, inputs)\u001b[0m\n\u001b[1;32m    144\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m retain_graph \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[1;32m    145\u001b[0m     retain_graph \u001b[38;5;241m=\u001b[39m create_graph\n\u001b[0;32m--> 147\u001b[0m \u001b[43mVariable\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_execution_engine\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mrun_backward\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m    148\u001b[0m \u001b[43m    \u001b[49m\u001b[43mtensors\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mgrad_tensors_\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mretain_graph\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mcreate_graph\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43minputs\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    149\u001b[0m \u001b[43m    \u001b[49m\u001b[43mallow_unreachable\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43;01mTrue\u001b[39;49;00m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43maccumulate_grad\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43;01mTrue\u001b[39;49;00m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m/bask/projects/v/vjgo8416-rough-paths/envs/nlpsig-networks/lib/python3.8/site-packages/torch/autograd/function.py:87\u001b[0m, in \u001b[0;36mBackwardCFunction.apply\u001b[0;34m(self, *args)\u001b[0m\n\u001b[1;32m     85\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mapply\u001b[39m(\u001b[38;5;28mself\u001b[39m, \u001b[38;5;241m*\u001b[39margs):\n\u001b[1;32m     86\u001b[0m     \u001b[38;5;66;03m# _forward_cls is defined by derived class\u001b[39;00m\n\u001b[0;32m---> 87\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_forward_cls\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mbackward\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m/bask/projects/v/vjgo8416-rough-paths/envs/nlpsig-networks/lib/python3.8/site-packages/torch/autograd/function.py:204\u001b[0m, in \u001b[0;36monce_differentiable.<locals>.wrapper\u001b[0;34m(ctx, *args)\u001b[0m\n\u001b[1;32m    201\u001b[0m \u001b[38;5;129m@functools\u001b[39m\u001b[38;5;241m.\u001b[39mwraps(fn)\n\u001b[1;32m    202\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mwrapper\u001b[39m(ctx, \u001b[38;5;241m*\u001b[39margs):\n\u001b[1;32m    203\u001b[0m     \u001b[38;5;28;01mwith\u001b[39;00m torch\u001b[38;5;241m.\u001b[39mno_grad():\n\u001b[0;32m--> 204\u001b[0m         outputs \u001b[38;5;241m=\u001b[39m \u001b[43mfn\u001b[49m\u001b[43m(\u001b[49m\u001b[43mctx\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    206\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m torch\u001b[38;5;241m.\u001b[39mis_grad_enabled():\n\u001b[1;32m    207\u001b[0m         \u001b[38;5;28;01mreturn\u001b[39;00m outputs\n",
      "File \u001b[0;32m/bask/projects/v/vjgo8416-rough-paths/envs/nlpsig-networks/lib/python3.8/site-packages/signatory/signature_module.py:83\u001b[0m, in \u001b[0;36m_SignatureFunction.backward\u001b[0;34m(ctx, grad_result)\u001b[0m\n\u001b[1;32m     77\u001b[0m \u001b[38;5;66;03m# PyTorch 1.5 changed how clone etc. work wrt memory format; this can then throw an error unless we do this.\u001b[39;00m\n\u001b[1;32m     78\u001b[0m \u001b[38;5;66;03m# Ideally we'd go through all the code and make every memory-format-aware op actually create contiguous rather\u001b[39;00m\n\u001b[1;32m     79\u001b[0m \u001b[38;5;66;03m# than format-preserved tensors, but that's a lot more work and won't compile with pre-1.5, when the concept\u001b[39;00m\n\u001b[1;32m     80\u001b[0m \u001b[38;5;66;03m# didn't exist.\u001b[39;00m\n\u001b[1;32m     81\u001b[0m path_increments \u001b[38;5;241m=\u001b[39m path_increments\u001b[38;5;241m.\u001b[39mcontiguous()\n\u001b[0;32m---> 83\u001b[0m grad_path, grad_basepoint, grad_initial \u001b[38;5;241m=\u001b[39m \u001b[43mimpl\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43msignature_backward\u001b[49m\u001b[43m(\u001b[49m\u001b[43mgrad_result\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43msignature_\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mpath_increments\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m     84\u001b[0m \u001b[43m                                                                  \u001b[49m\u001b[43mctx\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mdepth\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mctx\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mstream\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mctx\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mbasepoint\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m     85\u001b[0m \u001b[43m                                                                  \u001b[49m\u001b[43mctx\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43minverse\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mctx\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43minitial\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mctx\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mscalar_term\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m     87\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m ctx\u001b[38;5;241m.\u001b[39mbasepoint_is_tensor:\n\u001b[1;32m     88\u001b[0m     grad_basepoint \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m\n",
      "File \u001b[0;32m/bask/projects/v/vjgo8416-rough-paths/envs/nlpsig-networks/lib/python3.8/site-packages/signatory/impl.py:36\u001b[0m, in \u001b[0;36m_wrap.<locals>.wrapped\u001b[0;34m(*args, **kwargs)\u001b[0m\n\u001b[1;32m     34\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mwrapped\u001b[39m(\u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs):\n\u001b[1;32m     35\u001b[0m     \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[0;32m---> 36\u001b[0m         \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mfn\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m     37\u001b[0m     \u001b[38;5;28;01mexcept\u001b[39;00m \u001b[38;5;167;01mRuntimeError\u001b[39;00m \u001b[38;5;28;01mas\u001b[39;00m e:\n\u001b[1;32m     38\u001b[0m         \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mValueError\u001b[39;00m(\u001b[38;5;28mstr\u001b[39m(e))\n",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "size = 20\n",
    "swnu_network_grp_kfold_20, best_swnu_network_grp_kfold_20, _, __ = swnu_network_hyperparameter_search(\n",
    "    num_epochs=num_epochs,\n",
    "    df=anno_mi,\n",
    "    id_column=\"transcript_id\",\n",
    "    label_column=\"client_talk_type\",\n",
    "    embeddings=sbert_embeddings,\n",
    "    y_data=y_data_client,\n",
    "    embedding_dim=embedding_dim,\n",
    "    output_dim=output_dim_client,\n",
    "    history_lengths=[size],\n",
    "    dim_reduce_methods=[\"gaussian_random_projection\"],\n",
    "    dimensions=dimensions,\n",
    "    log_signature=True,\n",
    "    swnu_hidden_dim_sizes_and_sig_depths=swnu_hidden_dim_sizes_and_sig_depths,\n",
    "    ffn_hidden_dim_sizes=ffn_hidden_dim_sizes,\n",
    "    dropout_rates=dropout_rates,\n",
    "    learning_rates=learning_rates,\n",
    "    BiLSTM=False,\n",
    "    seeds=seeds,\n",
    "    loss=loss,\n",
    "    gamma=gamma,\n",
    "    time_feature=time_features,\n",
    "    standardise_method=standardise_method,\n",
    "    path_indices=client_index,\n",
    "    split_ids=client_transcript_id,\n",
    "    k_fold=True,\n",
    "    patience=patience,\n",
    "    validation_metric=validation_metric,\n",
    "    results_output=f\"{output_dir}/swnu_network_grp_focal_{gamma}_{size}_kfold.csv\",\n",
    "    verbose=False\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d6d7bd37",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4daab8de",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "nlpsig-networks (Conda)",
   "language": "python",
   "name": "sys_nlpsig-networks"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.17"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
