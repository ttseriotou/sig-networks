{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "a983a5e8",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pickle\n",
    "import os\n",
    "\n",
    "seed = 2023"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "e4e666cc",
   "metadata": {},
   "outputs": [],
   "source": [
    "from nlpsig_networks.scripts.swmhau_network_functions import (\n",
    "    swmhau_network_hyperparameter_search\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "6e918dde",
   "metadata": {},
   "outputs": [],
   "source": [
    "output_dir = \"client_talk_type_output\"\n",
    "if not os.path.isdir(output_dir):\n",
    "    os.makedirs(output_dir)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f7409a03",
   "metadata": {},
   "source": [
    "## AnnoMI"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "f00bb922",
   "metadata": {},
   "outputs": [],
   "source": [
    "%run ../load_anno_mi.py"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "720d820f",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>mi_quality</th>\n",
       "      <th>transcript_id</th>\n",
       "      <th>topic</th>\n",
       "      <th>utterance_id</th>\n",
       "      <th>interlocutor</th>\n",
       "      <th>timestamp</th>\n",
       "      <th>utterance_text</th>\n",
       "      <th>annotator_id</th>\n",
       "      <th>therapist_input_exists</th>\n",
       "      <th>therapist_input_subtype</th>\n",
       "      <th>reflection_exists</th>\n",
       "      <th>reflection_subtype</th>\n",
       "      <th>question_exists</th>\n",
       "      <th>question_subtype</th>\n",
       "      <th>main_therapist_behaviour</th>\n",
       "      <th>client_talk_type</th>\n",
       "      <th>datetime</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>high</td>\n",
       "      <td>0</td>\n",
       "      <td>reducing alcohol consumption</td>\n",
       "      <td>0</td>\n",
       "      <td>therapist</td>\n",
       "      <td>00:00:13</td>\n",
       "      <td>Thanks for filling it out. We give this form t...</td>\n",
       "      <td>3</td>\n",
       "      <td>False</td>\n",
       "      <td>NaN</td>\n",
       "      <td>False</td>\n",
       "      <td>NaN</td>\n",
       "      <td>True</td>\n",
       "      <td>open</td>\n",
       "      <td>question</td>\n",
       "      <td>NaN</td>\n",
       "      <td>2023-08-16 00:00:13</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>high</td>\n",
       "      <td>0</td>\n",
       "      <td>reducing alcohol consumption</td>\n",
       "      <td>1</td>\n",
       "      <td>client</td>\n",
       "      <td>00:00:24</td>\n",
       "      <td>Sure.</td>\n",
       "      <td>3</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>neutral</td>\n",
       "      <td>2023-08-16 00:00:24</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>high</td>\n",
       "      <td>0</td>\n",
       "      <td>reducing alcohol consumption</td>\n",
       "      <td>2</td>\n",
       "      <td>therapist</td>\n",
       "      <td>00:00:25</td>\n",
       "      <td>So, let's see. It looks that you put-- You dri...</td>\n",
       "      <td>3</td>\n",
       "      <td>True</td>\n",
       "      <td>information</td>\n",
       "      <td>False</td>\n",
       "      <td>NaN</td>\n",
       "      <td>False</td>\n",
       "      <td>NaN</td>\n",
       "      <td>therapist_input</td>\n",
       "      <td>NaN</td>\n",
       "      <td>2023-08-16 00:00:25</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>high</td>\n",
       "      <td>0</td>\n",
       "      <td>reducing alcohol consumption</td>\n",
       "      <td>3</td>\n",
       "      <td>client</td>\n",
       "      <td>00:00:34</td>\n",
       "      <td>Mm-hmm.</td>\n",
       "      <td>3</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>neutral</td>\n",
       "      <td>2023-08-16 00:00:34</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>high</td>\n",
       "      <td>0</td>\n",
       "      <td>reducing alcohol consumption</td>\n",
       "      <td>4</td>\n",
       "      <td>therapist</td>\n",
       "      <td>00:00:34</td>\n",
       "      <td>-and you usually have three to four drinks whe...</td>\n",
       "      <td>3</td>\n",
       "      <td>True</td>\n",
       "      <td>information</td>\n",
       "      <td>False</td>\n",
       "      <td>NaN</td>\n",
       "      <td>False</td>\n",
       "      <td>NaN</td>\n",
       "      <td>therapist_input</td>\n",
       "      <td>NaN</td>\n",
       "      <td>2023-08-16 00:00:34</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "  mi_quality  transcript_id                         topic  utterance_id  \\\n",
       "0       high              0  reducing alcohol consumption             0   \n",
       "1       high              0  reducing alcohol consumption             1   \n",
       "2       high              0  reducing alcohol consumption             2   \n",
       "3       high              0  reducing alcohol consumption             3   \n",
       "4       high              0  reducing alcohol consumption             4   \n",
       "\n",
       "  interlocutor timestamp                                     utterance_text  \\\n",
       "0    therapist  00:00:13  Thanks for filling it out. We give this form t...   \n",
       "1       client  00:00:24                                              Sure.   \n",
       "2    therapist  00:00:25  So, let's see. It looks that you put-- You dri...   \n",
       "3       client  00:00:34                                            Mm-hmm.   \n",
       "4    therapist  00:00:34  -and you usually have three to four drinks whe...   \n",
       "\n",
       "   annotator_id therapist_input_exists therapist_input_subtype  \\\n",
       "0             3                  False                     NaN   \n",
       "1             3                    NaN                     NaN   \n",
       "2             3                   True             information   \n",
       "3             3                    NaN                     NaN   \n",
       "4             3                   True             information   \n",
       "\n",
       "  reflection_exists reflection_subtype question_exists question_subtype  \\\n",
       "0             False                NaN            True             open   \n",
       "1               NaN                NaN             NaN              NaN   \n",
       "2             False                NaN           False              NaN   \n",
       "3               NaN                NaN             NaN              NaN   \n",
       "4             False                NaN           False              NaN   \n",
       "\n",
       "  main_therapist_behaviour client_talk_type            datetime  \n",
       "0                 question              NaN 2023-08-16 00:00:13  \n",
       "1                      NaN          neutral 2023-08-16 00:00:24  \n",
       "2          therapist_input              NaN 2023-08-16 00:00:25  \n",
       "3                      NaN          neutral 2023-08-16 00:00:34  \n",
       "4          therapist_input              NaN 2023-08-16 00:00:34  "
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "anno_mi.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "84d5594d",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(13551, 384)"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "with open(\"../anno_mi_sbert.pkl\", \"rb\") as f:\n",
    "    sbert_embeddings = pickle.load(f)\n",
    "    \n",
    "sbert_embeddings.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "da4ff92d",
   "metadata": {},
   "source": [
    "# swmhau Network"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "32ae1a72",
   "metadata": {},
   "source": [
    "## Obtaining path by looking at post history\n",
    "\n",
    "We can obtain a path by looking at the history of each post. Here we look at the last 10 posts (and pad with vectors of zeros if there are less than 10 posts) including the current post.\n",
    "\n",
    "We only want to consider paths that correspond to a client's utterance as we want to model a change in mood at that time. Their history will still contain the therapist's utterances too."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "90bfd87c",
   "metadata": {},
   "outputs": [],
   "source": [
    "time_features = [\"time_encoding\", \"timeline_index\"]\n",
    "standardise_method = [\"minmax\", None]\n",
    "num_features = len(time_features)\n",
    "add_time_in_path = True"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "9e9bee3b",
   "metadata": {},
   "outputs": [],
   "source": [
    "num_epochs = 100\n",
    "embedding_dim = 384\n",
    "dimensions = [15] # [50, 15]\n",
    "# define swmhau parameters: (output_channels, sig_depth, num_heads)\n",
    "swmhau_parameters = [(12, 3, 10)]\n",
    "num_layers = [1, 2]\n",
    "ffn_hidden_dim_sizes = [256, 256] # [[64,64],[256,256],[512,512]]\n",
    "dropout_rates = [0.5, 0.1]\n",
    "learning_rates = [1e-3, 1e-4, 5e-4]\n",
    "seeds = [1] # [1, 12, 123]\n",
    "loss = \"focal\"\n",
    "gamma = 2\n",
    "validation_metric = \"f1\"\n",
    "patience = 5"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "3739e09a",
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "# size = 20\n",
    "# swmhau_network_umap_kfold_20, best_swmhau_network_umap_kfold_20, _, __ = swmhau_network_hyperparameter_search(\n",
    "#     num_epochs=num_epochs,\n",
    "#     df=anno_mi,\n",
    "#     id_column=\"transcript_id\",\n",
    "#     label_column=\"client_talk_type\",\n",
    "#     embeddings=sbert_embeddings,\n",
    "#     y_data=y_data_client,\n",
    "#     embedding_dim=embedding_dim,\n",
    "#     output_dim=output_dim_client,\n",
    "#     history_lengths=[size],\n",
    "#     dim_reduce_methods=[\"umap\"],\n",
    "#     dimensions=dimensions,\n",
    "#     log_signature=True,\n",
    "#     swmhau_parameters=swmhau_parameters,\n",
    "#     num_layers=num_layers,\n",
    "#     ffn_hidden_dim_sizes=ffn_hidden_dim_sizes,\n",
    "#     dropout_rates=dropout_rates,\n",
    "#     learning_rates=learning_rates,\n",
    "#     seeds=seeds,\n",
    "#     loss=loss,\n",
    "#     gamma=gamma,\n",
    "#     features=time_features,\n",
    "#     standardise_method=standardise_method,\n",
    "#     add_time_in_path=add_time_in_path,\n",
    "#     path_indices=client_index,\n",
    "#     k_fold=True,\n",
    "#     patience=patience,\n",
    "#     validation_metric=validation_metric,\n",
    "#     results_output=f\"{output_dir}/swmhau_network_umap_focal_{gamma}_{size}_kfold.csv\",\n",
    "#     verbose=False\n",
    "# )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "13a67a66",
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "69ebb88b2ebf4ba9ab8ccee3dde1221e",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/1 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "54e20bc9c72648c2b29d93265252e161",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/1 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "8b3cc479fc5640709f6f2282a5bbdad9",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/1 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "##################################################\n",
      "dimension: 15 | method: gaussian_random_projection\n",
      "[INFO] Concatenating the embeddings to the dataframe...\n",
      "[INFO] - columns beginning with 'e' denote the full embddings.\n",
      "[INFO] - columns beginning with 'd' denote the dimension reduced embeddings.\n",
      "[INFO] Adding time feature columns into dataframe in `.df`.\n",
      "[INFO] Adding 'time_encoding' feature...\n",
      "[INFO] Adding 'time_diff' feature...\n",
      "[INFO] Adding 'timeline_index' feature...\n",
      "[INFO] Padding ids and storing in `.df_padded` and `.array_padded` attributes.\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "6607eca6e0c8489b99183e48068959a7",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/13551 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[INFO] The path was created for each item in the dataframe, by looking at its history, so to include embeddings in the FFN input, we concatenate the embeddings for each sentence / text.\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "2595e5ee8f2f4ac09dabf437c7c32055",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/1 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "59237b2159e14764847c655ce9288d63",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/2 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "e174b59159b341eaabaab9d1b05c19f5",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/2 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "f2c45f1bf20e41f983fd1bfc5e5827f1",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/2 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "80f3852f302341249f2fc8246ff37a2a",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/3 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[13], line 2\u001b[0m\n\u001b[1;32m      1\u001b[0m size \u001b[39m=\u001b[39m \u001b[39m20\u001b[39m\n\u001b[0;32m----> 2\u001b[0m swmhau_network_grp_kfold_20, best_swmhau_network_grp_kfold_20, _, __ \u001b[39m=\u001b[39m swmhau_network_hyperparameter_search(\n\u001b[1;32m      3\u001b[0m     num_epochs\u001b[39m=\u001b[39;49mnum_epochs,\n\u001b[1;32m      4\u001b[0m     df\u001b[39m=\u001b[39;49manno_mi,\n\u001b[1;32m      5\u001b[0m     id_column\u001b[39m=\u001b[39;49m\u001b[39m\"\u001b[39;49m\u001b[39mtranscript_id\u001b[39;49m\u001b[39m\"\u001b[39;49m,\n\u001b[1;32m      6\u001b[0m     label_column\u001b[39m=\u001b[39;49m\u001b[39m\"\u001b[39;49m\u001b[39mclient_talk_type\u001b[39;49m\u001b[39m\"\u001b[39;49m,\n\u001b[1;32m      7\u001b[0m     embeddings\u001b[39m=\u001b[39;49msbert_embeddings,\n\u001b[1;32m      8\u001b[0m     y_data\u001b[39m=\u001b[39;49my_data_client,\n\u001b[1;32m      9\u001b[0m     embedding_dim\u001b[39m=\u001b[39;49membedding_dim,\n\u001b[1;32m     10\u001b[0m     output_dim\u001b[39m=\u001b[39;49moutput_dim_client,\n\u001b[1;32m     11\u001b[0m     history_lengths\u001b[39m=\u001b[39;49m[size],\n\u001b[1;32m     12\u001b[0m     dim_reduce_methods\u001b[39m=\u001b[39;49m[\u001b[39m\"\u001b[39;49m\u001b[39mgaussian_random_projection\u001b[39;49m\u001b[39m\"\u001b[39;49m],\n\u001b[1;32m     13\u001b[0m     dimensions\u001b[39m=\u001b[39;49mdimensions,\n\u001b[1;32m     14\u001b[0m     log_signature\u001b[39m=\u001b[39;49m\u001b[39mTrue\u001b[39;49;00m,\n\u001b[1;32m     15\u001b[0m     swmhau_parameters\u001b[39m=\u001b[39;49mswmhau_parameters,\n\u001b[1;32m     16\u001b[0m     num_layers\u001b[39m=\u001b[39;49mnum_layers,\n\u001b[1;32m     17\u001b[0m     ffn_hidden_dim_sizes\u001b[39m=\u001b[39;49mffn_hidden_dim_sizes,\n\u001b[1;32m     18\u001b[0m     dropout_rates\u001b[39m=\u001b[39;49mdropout_rates,\n\u001b[1;32m     19\u001b[0m     learning_rates\u001b[39m=\u001b[39;49mlearning_rates,\n\u001b[1;32m     20\u001b[0m     seeds\u001b[39m=\u001b[39;49mseeds,\n\u001b[1;32m     21\u001b[0m     loss\u001b[39m=\u001b[39;49mloss,\n\u001b[1;32m     22\u001b[0m     gamma\u001b[39m=\u001b[39;49mgamma,\n\u001b[1;32m     23\u001b[0m     features\u001b[39m=\u001b[39;49mtime_features,\n\u001b[1;32m     24\u001b[0m     standardise_method\u001b[39m=\u001b[39;49mstandardise_method,\n\u001b[1;32m     25\u001b[0m     path_indices\u001b[39m=\u001b[39;49mclient_index,\n\u001b[1;32m     26\u001b[0m     k_fold\u001b[39m=\u001b[39;49m\u001b[39mTrue\u001b[39;49;00m,\n\u001b[1;32m     27\u001b[0m     patience\u001b[39m=\u001b[39;49mpatience,\n\u001b[1;32m     28\u001b[0m     validation_metric\u001b[39m=\u001b[39;49mvalidation_metric,\n\u001b[1;32m     29\u001b[0m     results_output\u001b[39m=\u001b[39;49m\u001b[39mf\u001b[39;49m\u001b[39m\"\u001b[39;49m\u001b[39m{\u001b[39;49;00moutput_dir\u001b[39m}\u001b[39;49;00m\u001b[39m/swmhau_network_grp_focal_\u001b[39;49m\u001b[39m{\u001b[39;49;00mgamma\u001b[39m}\u001b[39;49;00m\u001b[39m_\u001b[39;49m\u001b[39m{\u001b[39;49;00msize\u001b[39m}\u001b[39;49;00m\u001b[39m_kfold.csv\u001b[39;49m\u001b[39m\"\u001b[39;49m,\n\u001b[1;32m     30\u001b[0m     verbose\u001b[39m=\u001b[39;49m\u001b[39mFalse\u001b[39;49;00m\n\u001b[1;32m     31\u001b[0m )\n",
      "File \u001b[0;32m~/Library/CloudStorage/OneDrive-TheAlanTuringInstitute/rough_paths/nlpsig-networks/nlpsig_networks/scripts/swmhau_network_functions.py:202\u001b[0m, in \u001b[0;36mswmhau_network_hyperparameter_search\u001b[0;34m(num_epochs, df, id_column, label_column, embeddings, y_data, embedding_dim, output_dim, history_lengths, dim_reduce_methods, dimensions, log_signature, swmhau_parameters, num_layers, ffn_hidden_dim_sizes, dropout_rates, learning_rates, seeds, loss, gamma, batch_size, features, standardise_method, add_time_in_path, augmentation_type, hidden_dim_aug, comb_method, path_indices, data_split_seed, split_ids, split_indices, k_fold, n_splits, patience, validation_metric, results_output, verbose)\u001b[0m\n\u001b[1;32m    200\u001b[0m verbose_model \u001b[39m=\u001b[39m verbose\n\u001b[1;32m    201\u001b[0m \u001b[39mfor\u001b[39;00m seed \u001b[39min\u001b[39;00m seeds:\n\u001b[0;32m--> 202\u001b[0m     _, results \u001b[39m=\u001b[39m implement_swmhau_network(\n\u001b[1;32m    203\u001b[0m         num_epochs\u001b[39m=\u001b[39;49mnum_epochs,\n\u001b[1;32m    204\u001b[0m         x_data\u001b[39m=\u001b[39;49mx_data,\n\u001b[1;32m    205\u001b[0m         y_data\u001b[39m=\u001b[39;49my_data,\n\u001b[1;32m    206\u001b[0m         input_channels\u001b[39m=\u001b[39;49minput_channels,\n\u001b[1;32m    207\u001b[0m         output_channels\u001b[39m=\u001b[39;49moutput_channels,\n\u001b[1;32m    208\u001b[0m         num_features\u001b[39m=\u001b[39;49m\u001b[39mlen\u001b[39;49m(features),\n\u001b[1;32m    209\u001b[0m         embedding_dim\u001b[39m=\u001b[39;49membedding_dim,\n\u001b[1;32m    210\u001b[0m         log_signature\u001b[39m=\u001b[39;49mlog_signature,\n\u001b[1;32m    211\u001b[0m         sig_depth\u001b[39m=\u001b[39;49msig_depth,\n\u001b[1;32m    212\u001b[0m         num_heads\u001b[39m=\u001b[39;49mnum_heads,\n\u001b[1;32m    213\u001b[0m         num_layers\u001b[39m=\u001b[39;49mn_layers,\n\u001b[1;32m    214\u001b[0m         ffn_hidden_dim\u001b[39m=\u001b[39;49mffn_hidden_dim,\n\u001b[1;32m    215\u001b[0m         output_dim\u001b[39m=\u001b[39;49moutput_dim,\n\u001b[1;32m    216\u001b[0m         dropout_rate\u001b[39m=\u001b[39;49mdropout,\n\u001b[1;32m    217\u001b[0m         learning_rate\u001b[39m=\u001b[39;49mlr,\n\u001b[1;32m    218\u001b[0m         seed\u001b[39m=\u001b[39;49mseed,\n\u001b[1;32m    219\u001b[0m         loss\u001b[39m=\u001b[39;49mloss,\n\u001b[1;32m    220\u001b[0m         gamma\u001b[39m=\u001b[39;49mgamma,\n\u001b[1;32m    221\u001b[0m         batch_size\u001b[39m=\u001b[39;49mbatch_size,\n\u001b[1;32m    222\u001b[0m         augmentation_type\u001b[39m=\u001b[39;49maugmentation_type,\n\u001b[1;32m    223\u001b[0m         hidden_dim_aug\u001b[39m=\u001b[39;49mhidden_dim_aug,\n\u001b[1;32m    224\u001b[0m         comb_method\u001b[39m=\u001b[39;49mcomb_method,\n\u001b[1;32m    225\u001b[0m         data_split_seed\u001b[39m=\u001b[39;49mdata_split_seed,\n\u001b[1;32m    226\u001b[0m         split_ids\u001b[39m=\u001b[39;49msplit_ids,\n\u001b[1;32m    227\u001b[0m         split_indices\u001b[39m=\u001b[39;49msplit_indices,\n\u001b[1;32m    228\u001b[0m         k_fold\u001b[39m=\u001b[39;49mk_fold,\n\u001b[1;32m    229\u001b[0m         n_splits\u001b[39m=\u001b[39;49mn_splits,\n\u001b[1;32m    230\u001b[0m         patience\u001b[39m=\u001b[39;49mpatience,\n\u001b[1;32m    231\u001b[0m         verbose_training\u001b[39m=\u001b[39;49m\u001b[39mFalse\u001b[39;49;00m,\n\u001b[1;32m    232\u001b[0m         verbose_results\u001b[39m=\u001b[39;49mverbose,\n\u001b[1;32m    233\u001b[0m         verbose_model\u001b[39m=\u001b[39;49mverbose_model\n\u001b[1;32m    234\u001b[0m     )\n\u001b[1;32m    235\u001b[0m     \u001b[39m# save metric that we want to validate on\u001b[39;00m\n\u001b[1;32m    236\u001b[0m     \u001b[39m# taking the mean over the performance on the folds for the seed\u001b[39;00m\n\u001b[1;32m    237\u001b[0m     \u001b[39m# if k_fold=False, .mean() just returns the performance for the seed\u001b[39;00m\n\u001b[1;32m    238\u001b[0m     scores\u001b[39m.\u001b[39mappend(results[\u001b[39mf\u001b[39m\u001b[39m\"\u001b[39m\u001b[39mvalid_\u001b[39m\u001b[39m{\u001b[39;00mvalidation_metric\u001b[39m}\u001b[39;00m\u001b[39m\"\u001b[39m]\u001b[39m.\u001b[39mmean())\n",
      "File \u001b[0;32m~/Library/CloudStorage/OneDrive-TheAlanTuringInstitute/rough_paths/nlpsig-networks/nlpsig_networks/scripts/swmhau_network_functions.py:81\u001b[0m, in \u001b[0;36mimplement_swmhau_network\u001b[0;34m(num_epochs, x_data, y_data, input_channels, num_features, embedding_dim, log_signature, sig_depth, num_heads, num_layers, ffn_hidden_dim, output_dim, dropout_rate, learning_rate, seed, loss, gamma, batch_size, output_channels, augmentation_type, hidden_dim_aug, comb_method, data_split_seed, split_ids, split_indices, k_fold, n_splits, patience, verbose_training, verbose_results, verbose_model)\u001b[0m\n\u001b[1;32m     78\u001b[0m     y_data \u001b[39m=\u001b[39m torch\u001b[39m.\u001b[39mtensor(y_data)\n\u001b[1;32m     79\u001b[0m x_data \u001b[39m=\u001b[39m x_data\u001b[39m.\u001b[39mfloat()\n\u001b[0;32m---> 81\u001b[0m \u001b[39mreturn\u001b[39;00m implement_model(model\u001b[39m=\u001b[39;49mswmhau_network_model,\n\u001b[1;32m     82\u001b[0m                        num_epochs\u001b[39m=\u001b[39;49mnum_epochs,\n\u001b[1;32m     83\u001b[0m                        x_data\u001b[39m=\u001b[39;49mx_data,\n\u001b[1;32m     84\u001b[0m                        y_data\u001b[39m=\u001b[39;49my_data,\n\u001b[1;32m     85\u001b[0m                        learning_rate\u001b[39m=\u001b[39;49mlearning_rate,\n\u001b[1;32m     86\u001b[0m                        seed\u001b[39m=\u001b[39;49mseed,\n\u001b[1;32m     87\u001b[0m                        loss\u001b[39m=\u001b[39;49mloss,\n\u001b[1;32m     88\u001b[0m                        gamma\u001b[39m=\u001b[39;49mgamma,\n\u001b[1;32m     89\u001b[0m                        batch_size\u001b[39m=\u001b[39;49mbatch_size,\n\u001b[1;32m     90\u001b[0m                        data_split_seed\u001b[39m=\u001b[39;49mdata_split_seed,\n\u001b[1;32m     91\u001b[0m                        split_ids\u001b[39m=\u001b[39;49msplit_ids,\n\u001b[1;32m     92\u001b[0m                        split_indices\u001b[39m=\u001b[39;49msplit_indices,\n\u001b[1;32m     93\u001b[0m                        k_fold\u001b[39m=\u001b[39;49mk_fold,\n\u001b[1;32m     94\u001b[0m                        n_splits\u001b[39m=\u001b[39;49mn_splits,\n\u001b[1;32m     95\u001b[0m                        patience\u001b[39m=\u001b[39;49mpatience,\n\u001b[1;32m     96\u001b[0m                        verbose_training\u001b[39m=\u001b[39;49mverbose_training,\n\u001b[1;32m     97\u001b[0m                        verbose_results\u001b[39m=\u001b[39;49mverbose_results)\n",
      "File \u001b[0;32m~/Library/CloudStorage/OneDrive-TheAlanTuringInstitute/rough_paths/nlpsig-networks/nlpsig_networks/scripts/implement_model.py:67\u001b[0m, in \u001b[0;36mimplement_model\u001b[0;34m(model, num_epochs, x_data, y_data, learning_rate, seed, loss, gamma, batch_size, data_split_seed, split_ids, split_indices, k_fold, n_splits, patience, verbose_training, verbose_results)\u001b[0m\n\u001b[1;32m     60\u001b[0m     optimizer \u001b[39m=\u001b[39m torch\u001b[39m.\u001b[39moptim\u001b[39m.\u001b[39mAdam(model\u001b[39m.\u001b[39mparameters(),\n\u001b[1;32m     61\u001b[0m                                  lr\u001b[39m=\u001b[39mlearning_rate,\n\u001b[1;32m     62\u001b[0m                                  weight_decay\u001b[39m=\u001b[39mweight_decay_adam)\n\u001b[1;32m     64\u001b[0m     \u001b[39m# perform k-fold evaluation which returns a dataframe with columns for the\u001b[39;00m\n\u001b[1;32m     65\u001b[0m     \u001b[39m# loss, accuracy, f1 (macro) and individual f1-scores for each fold\u001b[39;00m\n\u001b[1;32m     66\u001b[0m     \u001b[39m# (for both validation and test set)\u001b[39;00m\n\u001b[0;32m---> 67\u001b[0m     results \u001b[39m=\u001b[39m KFold_pytorch(folds\u001b[39m=\u001b[39;49mfolds,\n\u001b[1;32m     68\u001b[0m                             model\u001b[39m=\u001b[39;49mmodel,\n\u001b[1;32m     69\u001b[0m                             criterion\u001b[39m=\u001b[39;49mcriterion,\n\u001b[1;32m     70\u001b[0m                             optimizer\u001b[39m=\u001b[39;49moptimizer,\n\u001b[1;32m     71\u001b[0m                             num_epochs\u001b[39m=\u001b[39;49mnum_epochs,\n\u001b[1;32m     72\u001b[0m                             batch_size\u001b[39m=\u001b[39;49mbatch_size,\n\u001b[1;32m     73\u001b[0m                             seed\u001b[39m=\u001b[39;49mseed,\n\u001b[1;32m     74\u001b[0m                             return_best\u001b[39m=\u001b[39;49mreturn_best,\n\u001b[1;32m     75\u001b[0m                             early_stopping\u001b[39m=\u001b[39;49mearly_stopping,\n\u001b[1;32m     76\u001b[0m                             patience\u001b[39m=\u001b[39;49mpatience,\n\u001b[1;32m     77\u001b[0m                             verbose\u001b[39m=\u001b[39;49mverbose_training)\n\u001b[1;32m     78\u001b[0m \u001b[39melse\u001b[39;00m:\n\u001b[1;32m     79\u001b[0m     \u001b[39m# split dataset\u001b[39;00m\n\u001b[1;32m     80\u001b[0m     data_loader_args \u001b[39m=\u001b[39m {\u001b[39m\"\u001b[39m\u001b[39mbatch_size\u001b[39m\u001b[39m\"\u001b[39m: batch_size, \u001b[39m\"\u001b[39m\u001b[39mshuffle\u001b[39m\u001b[39m\"\u001b[39m: \u001b[39mTrue\u001b[39;00m}\n",
      "File \u001b[0;32m~/Library/CloudStorage/OneDrive-TheAlanTuringInstitute/rough_paths/nlpsig-networks/nlpsig_networks/pytorch_utils.py:708\u001b[0m, in \u001b[0;36mKFold_pytorch\u001b[0;34m(folds, model, criterion, optimizer, num_epochs, batch_size, return_metric_for_each_fold, seed, return_best, early_stopping, patience, verbose, verbose_epoch)\u001b[0m\n\u001b[1;32m    705\u001b[0m train, valid, test \u001b[39m=\u001b[39m folds\u001b[39m.\u001b[39mget_splits(fold_index\u001b[39m=\u001b[39mfold, as_DataLoader\u001b[39m=\u001b[39m\u001b[39mTrue\u001b[39;00m, data_loader_args\u001b[39m=\u001b[39mdata_loader_args)\n\u001b[1;32m    707\u001b[0m \u001b[39m# train pytorch model\u001b[39;00m\n\u001b[0;32m--> 708\u001b[0m model \u001b[39m=\u001b[39m training_pytorch(\n\u001b[1;32m    709\u001b[0m     model\u001b[39m=\u001b[39;49mmodel,\n\u001b[1;32m    710\u001b[0m     train_loader\u001b[39m=\u001b[39;49mtrain,\n\u001b[1;32m    711\u001b[0m     valid_loader\u001b[39m=\u001b[39;49mvalid,\n\u001b[1;32m    712\u001b[0m     criterion\u001b[39m=\u001b[39;49mcriterion,\n\u001b[1;32m    713\u001b[0m     optimizer\u001b[39m=\u001b[39;49moptimizer,\n\u001b[1;32m    714\u001b[0m     num_epochs\u001b[39m=\u001b[39;49mnum_epochs,\n\u001b[1;32m    715\u001b[0m     seed\u001b[39m=\u001b[39;49mseed,\n\u001b[1;32m    716\u001b[0m     return_best\u001b[39m=\u001b[39;49mreturn_best,\n\u001b[1;32m    717\u001b[0m     save_best\u001b[39m=\u001b[39;49m\u001b[39mFalse\u001b[39;49;00m,\n\u001b[1;32m    718\u001b[0m     early_stopping\u001b[39m=\u001b[39;49mearly_stopping,\n\u001b[1;32m    719\u001b[0m     patience\u001b[39m=\u001b[39;49mpatience,\n\u001b[1;32m    720\u001b[0m     verbose\u001b[39m=\u001b[39;49mverbose,\n\u001b[1;32m    721\u001b[0m     verbose_epoch\u001b[39m=\u001b[39;49mverbose_epoch,\n\u001b[1;32m    722\u001b[0m )\n\u001b[1;32m    724\u001b[0m \u001b[39m# test model\u001b[39;00m\n\u001b[1;32m    725\u001b[0m test_results \u001b[39m=\u001b[39m testing_pytorch(model\u001b[39m=\u001b[39mmodel,\n\u001b[1;32m    726\u001b[0m                                test_loader\u001b[39m=\u001b[39mtest,\n\u001b[1;32m    727\u001b[0m                                criterion\u001b[39m=\u001b[39mcriterion,\n\u001b[1;32m    728\u001b[0m                                verbose\u001b[39m=\u001b[39mverbose)\n",
      "File \u001b[0;32m~/Library/CloudStorage/OneDrive-TheAlanTuringInstitute/rough_paths/nlpsig-networks/nlpsig_networks/pytorch_utils.py:450\u001b[0m, in \u001b[0;36mtraining_pytorch\u001b[0;34m(model, train_loader, criterion, optimizer, num_epochs, scheduler, valid_loader, seed, return_best, save_best, output, early_stopping, validation_metric, patience, verbose, verbose_epoch)\u001b[0m\n\u001b[1;32m    444\u001b[0m metric_v \u001b[39m=\u001b[39m validation_results[validation_metric]\n\u001b[1;32m    446\u001b[0m \u001b[39mif\u001b[39;00m save_best \u001b[39m|\u001b[39m return_best:\n\u001b[1;32m    447\u001b[0m     \u001b[39m# compute loss, accuracy and F1 on training set as well\u001b[39;00m\n\u001b[1;32m    448\u001b[0m     \u001b[39m# this is to determine how well we're doing on the training set\u001b[39;00m\n\u001b[1;32m    449\u001b[0m     \u001b[39m# allows us to choose between models that have the same validation\u001b[39;00m\n\u001b[0;32m--> 450\u001b[0m     validation_results \u001b[39m=\u001b[39m validation_pytorch(\n\u001b[1;32m    451\u001b[0m         model\u001b[39m=\u001b[39;49mmodel,\n\u001b[1;32m    452\u001b[0m         valid_loader\u001b[39m=\u001b[39;49mtrain_loader,\n\u001b[1;32m    453\u001b[0m         criterion\u001b[39m=\u001b[39;49mcriterion,\n\u001b[1;32m    454\u001b[0m         epoch\u001b[39m=\u001b[39;49mepoch,\n\u001b[1;32m    455\u001b[0m         verbose\u001b[39m=\u001b[39;49m\u001b[39mFalse\u001b[39;49;00m,\n\u001b[1;32m    456\u001b[0m     )\n\u001b[1;32m    457\u001b[0m     \u001b[39m# save metric that we want to validate on\u001b[39;00m\n\u001b[1;32m    458\u001b[0m     metric_train \u001b[39m=\u001b[39m validation_results[validation_metric]\n",
      "File \u001b[0;32m~/Library/CloudStorage/OneDrive-TheAlanTuringInstitute/rough_paths/nlpsig-networks/nlpsig_networks/pytorch_utils.py:287\u001b[0m, in \u001b[0;36mvalidation_pytorch\u001b[0;34m(model, valid_loader, criterion, epoch, verbose, verbose_epoch)\u001b[0m\n\u001b[1;32m    284\u001b[0m \u001b[39mwith\u001b[39;00m torch\u001b[39m.\u001b[39mno_grad():\n\u001b[1;32m    285\u001b[0m     \u001b[39mfor\u001b[39;00m emb_v, labels_v \u001b[39min\u001b[39;00m valid_loader:\n\u001b[1;32m    286\u001b[0m         \u001b[39m# make prediction\u001b[39;00m\n\u001b[0;32m--> 287\u001b[0m         outputs \u001b[39m=\u001b[39m model(emb_v)\n\u001b[1;32m    288\u001b[0m         _, predicted_v \u001b[39m=\u001b[39m torch\u001b[39m.\u001b[39mmax(outputs\u001b[39m.\u001b[39mdata, \u001b[39m1\u001b[39m)\n\u001b[1;32m    289\u001b[0m         \u001b[39m# compute loss\u001b[39;00m\n",
      "File \u001b[0;32m~/opt/miniconda3/envs/nlpsig-networks/lib/python3.8/site-packages/torch/nn/modules/module.py:1051\u001b[0m, in \u001b[0;36mModule._call_impl\u001b[0;34m(self, *input, **kwargs)\u001b[0m\n\u001b[1;32m   1047\u001b[0m \u001b[39m# If we don't have any hooks, we want to skip the rest of the logic in\u001b[39;00m\n\u001b[1;32m   1048\u001b[0m \u001b[39m# this function, and just call forward.\u001b[39;00m\n\u001b[1;32m   1049\u001b[0m \u001b[39mif\u001b[39;00m \u001b[39mnot\u001b[39;00m (\u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_backward_hooks \u001b[39mor\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_forward_hooks \u001b[39mor\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_forward_pre_hooks \u001b[39mor\u001b[39;00m _global_backward_hooks\n\u001b[1;32m   1050\u001b[0m         \u001b[39mor\u001b[39;00m _global_forward_hooks \u001b[39mor\u001b[39;00m _global_forward_pre_hooks):\n\u001b[0;32m-> 1051\u001b[0m     \u001b[39mreturn\u001b[39;00m forward_call(\u001b[39m*\u001b[39;49m\u001b[39minput\u001b[39;49m, \u001b[39m*\u001b[39;49m\u001b[39m*\u001b[39;49mkwargs)\n\u001b[1;32m   1052\u001b[0m \u001b[39m# Do not call functions when jit is used\u001b[39;00m\n\u001b[1;32m   1053\u001b[0m full_backward_hooks, non_full_backward_hooks \u001b[39m=\u001b[39m [], []\n",
      "File \u001b[0;32m~/Library/CloudStorage/OneDrive-TheAlanTuringInstitute/rough_paths/nlpsig-networks/nlpsig_networks/swmhau_network.py:157\u001b[0m, in \u001b[0;36mSWMHAUNetwork.forward\u001b[0;34m(self, x)\u001b[0m\n\u001b[1;32m    154\u001b[0m \u001b[39mdef\u001b[39;00m \u001b[39mforward\u001b[39m(\u001b[39mself\u001b[39m, x: torch\u001b[39m.\u001b[39mTensor):\n\u001b[1;32m    155\u001b[0m     \u001b[39m# x has dimensions [batch, length of signal, channels]\u001b[39;00m\n\u001b[1;32m    156\u001b[0m     \u001b[39m# use SWMHAU to obtain feature set\u001b[39;00m\n\u001b[0;32m--> 157\u001b[0m     out \u001b[39m=\u001b[39m \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49mswmhau(x)\n\u001b[1;32m    159\u001b[0m     \u001b[39m# combine last post embedding\u001b[39;00m\n\u001b[1;32m    160\u001b[0m     \u001b[39mif\u001b[39;00m x\u001b[39m.\u001b[39mshape[\u001b[39m2\u001b[39m] \u001b[39m>\u001b[39m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39minput_channels:\n\u001b[1;32m    161\u001b[0m         \u001b[39m# we have things to concatenate to the path\u001b[39;00m\n",
      "File \u001b[0;32m~/opt/miniconda3/envs/nlpsig-networks/lib/python3.8/site-packages/torch/nn/modules/module.py:1051\u001b[0m, in \u001b[0;36mModule._call_impl\u001b[0;34m(self, *input, **kwargs)\u001b[0m\n\u001b[1;32m   1047\u001b[0m \u001b[39m# If we don't have any hooks, we want to skip the rest of the logic in\u001b[39;00m\n\u001b[1;32m   1048\u001b[0m \u001b[39m# this function, and just call forward.\u001b[39;00m\n\u001b[1;32m   1049\u001b[0m \u001b[39mif\u001b[39;00m \u001b[39mnot\u001b[39;00m (\u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_backward_hooks \u001b[39mor\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_forward_hooks \u001b[39mor\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_forward_pre_hooks \u001b[39mor\u001b[39;00m _global_backward_hooks\n\u001b[1;32m   1050\u001b[0m         \u001b[39mor\u001b[39;00m _global_forward_hooks \u001b[39mor\u001b[39;00m _global_forward_pre_hooks):\n\u001b[0;32m-> 1051\u001b[0m     \u001b[39mreturn\u001b[39;00m forward_call(\u001b[39m*\u001b[39;49m\u001b[39minput\u001b[39;49m, \u001b[39m*\u001b[39;49m\u001b[39m*\u001b[39;49mkwargs)\n\u001b[1;32m   1052\u001b[0m \u001b[39m# Do not call functions when jit is used\u001b[39;00m\n\u001b[1;32m   1053\u001b[0m full_backward_hooks, non_full_backward_hooks \u001b[39m=\u001b[39m [], []\n",
      "File \u001b[0;32m~/Library/CloudStorage/OneDrive-TheAlanTuringInstitute/rough_paths/nlpsig-networks/nlpsig_networks/swmhau.py:233\u001b[0m, in \u001b[0;36mSWMHAU.forward\u001b[0;34m(self, x)\u001b[0m\n\u001b[1;32m    226\u001b[0m \u001b[39melif\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39maugmentation_type \u001b[39m==\u001b[39m \u001b[39m\"\u001b[39m\u001b[39msignatory\u001b[39m\u001b[39m\"\u001b[39m:\n\u001b[1;32m    227\u001b[0m     \u001b[39m# input has dimensions [batch, length of signal, channels]\u001b[39;00m\n\u001b[1;32m    228\u001b[0m     \u001b[39m# (signatory.Augment expects this)\u001b[39;00m\n\u001b[1;32m    229\u001b[0m     \u001b[39m# and get only the path information\u001b[39;00m\n\u001b[1;32m    230\u001b[0m     \u001b[39m# output has dimensions [batch, length of signal, channels]\u001b[39;00m\n\u001b[1;32m    231\u001b[0m     out \u001b[39m=\u001b[39m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39maugment(x[:, :, : \u001b[39mself\u001b[39m\u001b[39m.\u001b[39minput_channels])\n\u001b[0;32m--> 233\u001b[0m out \u001b[39m=\u001b[39m \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49mswmha(out)\n\u001b[1;32m    235\u001b[0m \u001b[39mreturn\u001b[39;00m out\n",
      "File \u001b[0;32m~/opt/miniconda3/envs/nlpsig-networks/lib/python3.8/site-packages/torch/nn/modules/module.py:1051\u001b[0m, in \u001b[0;36mModule._call_impl\u001b[0;34m(self, *input, **kwargs)\u001b[0m\n\u001b[1;32m   1047\u001b[0m \u001b[39m# If we don't have any hooks, we want to skip the rest of the logic in\u001b[39;00m\n\u001b[1;32m   1048\u001b[0m \u001b[39m# this function, and just call forward.\u001b[39;00m\n\u001b[1;32m   1049\u001b[0m \u001b[39mif\u001b[39;00m \u001b[39mnot\u001b[39;00m (\u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_backward_hooks \u001b[39mor\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_forward_hooks \u001b[39mor\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_forward_pre_hooks \u001b[39mor\u001b[39;00m _global_backward_hooks\n\u001b[1;32m   1050\u001b[0m         \u001b[39mor\u001b[39;00m _global_forward_hooks \u001b[39mor\u001b[39;00m _global_forward_pre_hooks):\n\u001b[0;32m-> 1051\u001b[0m     \u001b[39mreturn\u001b[39;00m forward_call(\u001b[39m*\u001b[39;49m\u001b[39minput\u001b[39;49m, \u001b[39m*\u001b[39;49m\u001b[39m*\u001b[39;49mkwargs)\n\u001b[1;32m   1052\u001b[0m \u001b[39m# Do not call functions when jit is used\u001b[39;00m\n\u001b[1;32m   1053\u001b[0m full_backward_hooks, non_full_backward_hooks \u001b[39m=\u001b[39m [], []\n",
      "File \u001b[0;32m~/Library/CloudStorage/OneDrive-TheAlanTuringInstitute/rough_paths/nlpsig-networks/nlpsig_networks/swmhau.py:110\u001b[0m, in \u001b[0;36mSWMHA.forward\u001b[0;34m(self, x)\u001b[0m\n\u001b[1;32m    108\u001b[0m x \u001b[39m=\u001b[39m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39msignature_layers[l](x)\n\u001b[1;32m    109\u001b[0m \u001b[39m# apply MHA layer\u001b[39;00m\n\u001b[0;32m--> 110\u001b[0m x \u001b[39m=\u001b[39m \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49mmha_layers[l](x, x, x)[\u001b[39m0\u001b[39m]\n\u001b[1;32m    111\u001b[0m \u001b[39m# apply linear layer\u001b[39;00m\n\u001b[1;32m    112\u001b[0m x \u001b[39m=\u001b[39m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mlinear_layers[l](x)\n",
      "File \u001b[0;32m~/opt/miniconda3/envs/nlpsig-networks/lib/python3.8/site-packages/torch/nn/modules/module.py:1051\u001b[0m, in \u001b[0;36mModule._call_impl\u001b[0;34m(self, *input, **kwargs)\u001b[0m\n\u001b[1;32m   1047\u001b[0m \u001b[39m# If we don't have any hooks, we want to skip the rest of the logic in\u001b[39;00m\n\u001b[1;32m   1048\u001b[0m \u001b[39m# this function, and just call forward.\u001b[39;00m\n\u001b[1;32m   1049\u001b[0m \u001b[39mif\u001b[39;00m \u001b[39mnot\u001b[39;00m (\u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_backward_hooks \u001b[39mor\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_forward_hooks \u001b[39mor\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_forward_pre_hooks \u001b[39mor\u001b[39;00m _global_backward_hooks\n\u001b[1;32m   1050\u001b[0m         \u001b[39mor\u001b[39;00m _global_forward_hooks \u001b[39mor\u001b[39;00m _global_forward_pre_hooks):\n\u001b[0;32m-> 1051\u001b[0m     \u001b[39mreturn\u001b[39;00m forward_call(\u001b[39m*\u001b[39;49m\u001b[39minput\u001b[39;49m, \u001b[39m*\u001b[39;49m\u001b[39m*\u001b[39;49mkwargs)\n\u001b[1;32m   1052\u001b[0m \u001b[39m# Do not call functions when jit is used\u001b[39;00m\n\u001b[1;32m   1053\u001b[0m full_backward_hooks, non_full_backward_hooks \u001b[39m=\u001b[39m [], []\n",
      "File \u001b[0;32m~/opt/miniconda3/envs/nlpsig-networks/lib/python3.8/site-packages/torch/nn/modules/activation.py:1031\u001b[0m, in \u001b[0;36mMultiheadAttention.forward\u001b[0;34m(self, query, key, value, key_padding_mask, need_weights, attn_mask)\u001b[0m\n\u001b[1;32m   1020\u001b[0m     attn_output, attn_output_weights \u001b[39m=\u001b[39m F\u001b[39m.\u001b[39mmulti_head_attention_forward(\n\u001b[1;32m   1021\u001b[0m         query, key, value, \u001b[39mself\u001b[39m\u001b[39m.\u001b[39membed_dim, \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mnum_heads,\n\u001b[1;32m   1022\u001b[0m         \u001b[39mself\u001b[39m\u001b[39m.\u001b[39min_proj_weight, \u001b[39mself\u001b[39m\u001b[39m.\u001b[39min_proj_bias,\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m   1028\u001b[0m         q_proj_weight\u001b[39m=\u001b[39m\u001b[39mself\u001b[39m\u001b[39m.\u001b[39mq_proj_weight, k_proj_weight\u001b[39m=\u001b[39m\u001b[39mself\u001b[39m\u001b[39m.\u001b[39mk_proj_weight,\n\u001b[1;32m   1029\u001b[0m         v_proj_weight\u001b[39m=\u001b[39m\u001b[39mself\u001b[39m\u001b[39m.\u001b[39mv_proj_weight)\n\u001b[1;32m   1030\u001b[0m \u001b[39melse\u001b[39;00m:\n\u001b[0;32m-> 1031\u001b[0m     attn_output, attn_output_weights \u001b[39m=\u001b[39m F\u001b[39m.\u001b[39;49mmulti_head_attention_forward(\n\u001b[1;32m   1032\u001b[0m         query, key, value, \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49membed_dim, \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49mnum_heads,\n\u001b[1;32m   1033\u001b[0m         \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49min_proj_weight, \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49min_proj_bias,\n\u001b[1;32m   1034\u001b[0m         \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49mbias_k, \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49mbias_v, \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49madd_zero_attn,\n\u001b[1;32m   1035\u001b[0m         \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49mdropout, \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49mout_proj\u001b[39m.\u001b[39;49mweight, \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49mout_proj\u001b[39m.\u001b[39;49mbias,\n\u001b[1;32m   1036\u001b[0m         training\u001b[39m=\u001b[39;49m\u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49mtraining,\n\u001b[1;32m   1037\u001b[0m         key_padding_mask\u001b[39m=\u001b[39;49mkey_padding_mask, need_weights\u001b[39m=\u001b[39;49mneed_weights,\n\u001b[1;32m   1038\u001b[0m         attn_mask\u001b[39m=\u001b[39;49mattn_mask)\n\u001b[1;32m   1039\u001b[0m \u001b[39mif\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mbatch_first:\n\u001b[1;32m   1040\u001b[0m     \u001b[39mreturn\u001b[39;00m attn_output\u001b[39m.\u001b[39mtranspose(\u001b[39m1\u001b[39m, \u001b[39m0\u001b[39m), attn_output_weights\n",
      "File \u001b[0;32m~/opt/miniconda3/envs/nlpsig-networks/lib/python3.8/site-packages/torch/nn/functional.py:5082\u001b[0m, in \u001b[0;36mmulti_head_attention_forward\u001b[0;34m(query, key, value, embed_dim_to_check, num_heads, in_proj_weight, in_proj_bias, bias_k, bias_v, add_zero_attn, dropout_p, out_proj_weight, out_proj_bias, training, key_padding_mask, need_weights, attn_mask, use_separate_proj_weight, q_proj_weight, k_proj_weight, v_proj_weight, static_k, static_v)\u001b[0m\n\u001b[1;32m   5077\u001b[0m     dropout_p \u001b[39m=\u001b[39m \u001b[39m0.0\u001b[39m\n\u001b[1;32m   5079\u001b[0m \u001b[39m#\u001b[39;00m\n\u001b[1;32m   5080\u001b[0m \u001b[39m# (deep breath) calculate attention and out projection\u001b[39;00m\n\u001b[1;32m   5081\u001b[0m \u001b[39m#\u001b[39;00m\n\u001b[0;32m-> 5082\u001b[0m attn_output, attn_output_weights \u001b[39m=\u001b[39m _scaled_dot_product_attention(q, k, v, attn_mask, dropout_p)\n\u001b[1;32m   5083\u001b[0m attn_output \u001b[39m=\u001b[39m attn_output\u001b[39m.\u001b[39mtranspose(\u001b[39m0\u001b[39m, \u001b[39m1\u001b[39m)\u001b[39m.\u001b[39mcontiguous()\u001b[39m.\u001b[39mview(tgt_len, bsz, embed_dim)\n\u001b[1;32m   5084\u001b[0m attn_output \u001b[39m=\u001b[39m linear(attn_output, out_proj_weight, out_proj_bias)\n",
      "File \u001b[0;32m~/opt/miniconda3/envs/nlpsig-networks/lib/python3.8/site-packages/torch/nn/functional.py:4825\u001b[0m, in \u001b[0;36m_scaled_dot_product_attention\u001b[0;34m(q, k, v, attn_mask, dropout_p)\u001b[0m\n\u001b[1;32m   4823\u001b[0m q \u001b[39m=\u001b[39m q \u001b[39m/\u001b[39m math\u001b[39m.\u001b[39msqrt(E)\n\u001b[1;32m   4824\u001b[0m \u001b[39m# (B, Nt, E) x (B, E, Ns) -> (B, Nt, Ns)\u001b[39;00m\n\u001b[0;32m-> 4825\u001b[0m attn \u001b[39m=\u001b[39m torch\u001b[39m.\u001b[39;49mbmm(q, k\u001b[39m.\u001b[39;49mtranspose(\u001b[39m-\u001b[39;49m\u001b[39m2\u001b[39;49m, \u001b[39m-\u001b[39;49m\u001b[39m1\u001b[39;49m))\n\u001b[1;32m   4826\u001b[0m \u001b[39mif\u001b[39;00m attn_mask \u001b[39mis\u001b[39;00m \u001b[39mnot\u001b[39;00m \u001b[39mNone\u001b[39;00m:\n\u001b[1;32m   4827\u001b[0m     attn \u001b[39m+\u001b[39m\u001b[39m=\u001b[39m attn_mask\n",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "size = 20\n",
    "swmhau_network_grp_kfold_20, best_swmhau_network_grp_kfold_20, _, __ = swmhau_network_hyperparameter_search(\n",
    "    num_epochs=num_epochs,\n",
    "    df=anno_mi,\n",
    "    id_column=\"transcript_id\",\n",
    "    label_column=\"client_talk_type\",\n",
    "    embeddings=sbert_embeddings,\n",
    "    y_data=y_data_client,\n",
    "    embedding_dim=embedding_dim,\n",
    "    output_dim=output_dim_client,\n",
    "    history_lengths=[size],\n",
    "    dim_reduce_methods=[\"gaussian_random_projection\"],\n",
    "    dimensions=dimensions,\n",
    "    log_signature=True,\n",
    "    swmhau_parameters=swmhau_parameters,\n",
    "    num_layers=num_layers,\n",
    "    ffn_hidden_dim_sizes=ffn_hidden_dim_sizes,\n",
    "    dropout_rates=dropout_rates,\n",
    "    learning_rates=learning_rates,\n",
    "    seeds=seeds,\n",
    "    loss=loss,\n",
    "    gamma=gamma,\n",
    "    features=time_features,\n",
    "    standardise_method=standardise_method,\n",
    "    path_indices=client_index,\n",
    "    k_fold=True,\n",
    "    patience=patience,\n",
    "    validation_metric=validation_metric,\n",
    "    results_output=f\"{output_dir}/swmhau_network_grp_focal_{gamma}_{size}_kfold.csv\",\n",
    "    verbose=False\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4daab8de",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "nlpsig-networks",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.16"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
