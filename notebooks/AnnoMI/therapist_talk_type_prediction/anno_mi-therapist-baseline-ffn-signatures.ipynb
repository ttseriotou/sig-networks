{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "a983a5e8",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pickle\n",
    "import os\n",
    "\n",
    "seed = 2023"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "e4e666cc",
   "metadata": {},
   "outputs": [],
   "source": [
    "from nlpsig_networks.scripts.ffn_baseline_functions import (\n",
    "    histories_baseline_hyperparameter_search\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "6e918dde",
   "metadata": {},
   "outputs": [],
   "source": [
    "output_dir = \"therapist_talk_type_output\"\n",
    "if not os.path.isdir(output_dir):\n",
    "    os.makedirs(output_dir)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f7409a03",
   "metadata": {},
   "source": [
    "## AnnoMI"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "f00bb922",
   "metadata": {},
   "outputs": [],
   "source": [
    "%run ../load_anno_mi.py"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "720d820f",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>mi_quality</th>\n",
       "      <th>transcript_id</th>\n",
       "      <th>topic</th>\n",
       "      <th>utterance_id</th>\n",
       "      <th>interlocutor</th>\n",
       "      <th>timestamp</th>\n",
       "      <th>utterance_text</th>\n",
       "      <th>annotator_id</th>\n",
       "      <th>therapist_input_exists</th>\n",
       "      <th>therapist_input_subtype</th>\n",
       "      <th>reflection_exists</th>\n",
       "      <th>reflection_subtype</th>\n",
       "      <th>question_exists</th>\n",
       "      <th>question_subtype</th>\n",
       "      <th>main_therapist_behaviour</th>\n",
       "      <th>client_talk_type</th>\n",
       "      <th>datetime</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>high</td>\n",
       "      <td>0</td>\n",
       "      <td>reducing alcohol consumption</td>\n",
       "      <td>0</td>\n",
       "      <td>therapist</td>\n",
       "      <td>00:00:13</td>\n",
       "      <td>Thanks for filling it out. We give this form t...</td>\n",
       "      <td>3</td>\n",
       "      <td>False</td>\n",
       "      <td>NaN</td>\n",
       "      <td>False</td>\n",
       "      <td>NaN</td>\n",
       "      <td>True</td>\n",
       "      <td>open</td>\n",
       "      <td>question</td>\n",
       "      <td>NaN</td>\n",
       "      <td>2023-07-27 00:00:13</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>high</td>\n",
       "      <td>0</td>\n",
       "      <td>reducing alcohol consumption</td>\n",
       "      <td>1</td>\n",
       "      <td>client</td>\n",
       "      <td>00:00:24</td>\n",
       "      <td>Sure.</td>\n",
       "      <td>3</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>neutral</td>\n",
       "      <td>2023-07-27 00:00:24</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>high</td>\n",
       "      <td>0</td>\n",
       "      <td>reducing alcohol consumption</td>\n",
       "      <td>2</td>\n",
       "      <td>therapist</td>\n",
       "      <td>00:00:25</td>\n",
       "      <td>So, let's see. It looks that you put-- You dri...</td>\n",
       "      <td>3</td>\n",
       "      <td>True</td>\n",
       "      <td>information</td>\n",
       "      <td>False</td>\n",
       "      <td>NaN</td>\n",
       "      <td>False</td>\n",
       "      <td>NaN</td>\n",
       "      <td>therapist_input</td>\n",
       "      <td>NaN</td>\n",
       "      <td>2023-07-27 00:00:25</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>high</td>\n",
       "      <td>0</td>\n",
       "      <td>reducing alcohol consumption</td>\n",
       "      <td>3</td>\n",
       "      <td>client</td>\n",
       "      <td>00:00:34</td>\n",
       "      <td>Mm-hmm.</td>\n",
       "      <td>3</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>neutral</td>\n",
       "      <td>2023-07-27 00:00:34</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>high</td>\n",
       "      <td>0</td>\n",
       "      <td>reducing alcohol consumption</td>\n",
       "      <td>4</td>\n",
       "      <td>therapist</td>\n",
       "      <td>00:00:34</td>\n",
       "      <td>-and you usually have three to four drinks whe...</td>\n",
       "      <td>3</td>\n",
       "      <td>True</td>\n",
       "      <td>information</td>\n",
       "      <td>False</td>\n",
       "      <td>NaN</td>\n",
       "      <td>False</td>\n",
       "      <td>NaN</td>\n",
       "      <td>therapist_input</td>\n",
       "      <td>NaN</td>\n",
       "      <td>2023-07-27 00:00:34</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "  mi_quality  transcript_id                         topic  utterance_id  \\\n",
       "0       high              0  reducing alcohol consumption             0   \n",
       "1       high              0  reducing alcohol consumption             1   \n",
       "2       high              0  reducing alcohol consumption             2   \n",
       "3       high              0  reducing alcohol consumption             3   \n",
       "4       high              0  reducing alcohol consumption             4   \n",
       "\n",
       "  interlocutor timestamp                                     utterance_text  \\\n",
       "0    therapist  00:00:13  Thanks for filling it out. We give this form t...   \n",
       "1       client  00:00:24                                              Sure.   \n",
       "2    therapist  00:00:25  So, let's see. It looks that you put-- You dri...   \n",
       "3       client  00:00:34                                            Mm-hmm.   \n",
       "4    therapist  00:00:34  -and you usually have three to four drinks whe...   \n",
       "\n",
       "   annotator_id therapist_input_exists therapist_input_subtype  \\\n",
       "0             3                  False                     NaN   \n",
       "1             3                    NaN                     NaN   \n",
       "2             3                   True             information   \n",
       "3             3                    NaN                     NaN   \n",
       "4             3                   True             information   \n",
       "\n",
       "  reflection_exists reflection_subtype question_exists question_subtype  \\\n",
       "0             False                NaN            True             open   \n",
       "1               NaN                NaN             NaN              NaN   \n",
       "2             False                NaN           False              NaN   \n",
       "3               NaN                NaN             NaN              NaN   \n",
       "4             False                NaN           False              NaN   \n",
       "\n",
       "  main_therapist_behaviour client_talk_type            datetime  \n",
       "0                 question              NaN 2023-07-27 00:00:13  \n",
       "1                      NaN          neutral 2023-07-27 00:00:24  \n",
       "2          therapist_input              NaN 2023-07-27 00:00:25  \n",
       "3                      NaN          neutral 2023-07-27 00:00:34  \n",
       "4          therapist_input              NaN 2023-07-27 00:00:34  "
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "anno_mi.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "84d5594d",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(13551, 384)"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "with open(\"../anno_mi_sbert.pkl\", \"rb\") as f:\n",
    "    sbert_embeddings = pickle.load(f)\n",
    "    \n",
    "sbert_embeddings.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "cb4dff32",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[True,\n",
       " False,\n",
       " True,\n",
       " False,\n",
       " True,\n",
       " False,\n",
       " True,\n",
       " False,\n",
       " True,\n",
       " False,\n",
       " True,\n",
       " False,\n",
       " True,\n",
       " False,\n",
       " True,\n",
       " False,\n",
       " True,\n",
       " False,\n",
       " True,\n",
       " False,\n",
       " True,\n",
       " False,\n",
       " True,\n",
       " False,\n",
       " True,\n",
       " False,\n",
       " True,\n",
       " False,\n",
       " True,\n",
       " False,\n",
       " True,\n",
       " False,\n",
       " True,\n",
       " False,\n",
       " True,\n",
       " False,\n",
       " True,\n",
       " False,\n",
       " True,\n",
       " False,\n",
       " True,\n",
       " False,\n",
       " True,\n",
       " False,\n",
       " True,\n",
       " False,\n",
       " True,\n",
       " False,\n",
       " True,\n",
       " False,\n",
       " True,\n",
       " False,\n",
       " True,\n",
       " False,\n",
       " True,\n",
       " False,\n",
       " True,\n",
       " False,\n",
       " True,\n",
       " False,\n",
       " True,\n",
       " False,\n",
       " True,\n",
       " False,\n",
       " True,\n",
       " False,\n",
       " True,\n",
       " False,\n",
       " True,\n",
       " False,\n",
       " True,\n",
       " False,\n",
       " True,\n",
       " False,\n",
       " True,\n",
       " False,\n",
       " True,\n",
       " False,\n",
       " True,\n",
       " False,\n",
       " True,\n",
       " False,\n",
       " True,\n",
       " False,\n",
       " True,\n",
       " False,\n",
       " True,\n",
       " False,\n",
       " True,\n",
       " False,\n",
       " True,\n",
       " True,\n",
       " False,\n",
       " True,\n",
       " False,\n",
       " True,\n",
       " False,\n",
       " True,\n",
       " False,\n",
       " True,\n",
       " False,\n",
       " True,\n",
       " False,\n",
       " True,\n",
       " False,\n",
       " True,\n",
       " False,\n",
       " True,\n",
       " False,\n",
       " True,\n",
       " False,\n",
       " True,\n",
       " False,\n",
       " True,\n",
       " False,\n",
       " True,\n",
       " False,\n",
       " True,\n",
       " False,\n",
       " True,\n",
       " False,\n",
       " True,\n",
       " False,\n",
       " True,\n",
       " False,\n",
       " True,\n",
       " False,\n",
       " False,\n",
       " True,\n",
       " False,\n",
       " True,\n",
       " False,\n",
       " True,\n",
       " False,\n",
       " True,\n",
       " False,\n",
       " True,\n",
       " False,\n",
       " True,\n",
       " False,\n",
       " True,\n",
       " False,\n",
       " True,\n",
       " True,\n",
       " False,\n",
       " True,\n",
       " False,\n",
       " True,\n",
       " False,\n",
       " True,\n",
       " False,\n",
       " True,\n",
       " False,\n",
       " True,\n",
       " False,\n",
       " True,\n",
       " False,\n",
       " True,\n",
       " False,\n",
       " True,\n",
       " False,\n",
       " True,\n",
       " False,\n",
       " True,\n",
       " False,\n",
       " True,\n",
       " False,\n",
       " True,\n",
       " False,\n",
       " True,\n",
       " False,\n",
       " True,\n",
       " False,\n",
       " True,\n",
       " False,\n",
       " True,\n",
       " False,\n",
       " True,\n",
       " False,\n",
       " True,\n",
       " False,\n",
       " True,\n",
       " False,\n",
       " True,\n",
       " False,\n",
       " True,\n",
       " False,\n",
       " True,\n",
       " False,\n",
       " True,\n",
       " False,\n",
       " True,\n",
       " False,\n",
       " True,\n",
       " False,\n",
       " True,\n",
       " False,\n",
       " True,\n",
       " False,\n",
       " True,\n",
       " False,\n",
       " True,\n",
       " True,\n",
       " False,\n",
       " True,\n",
       " False,\n",
       " True,\n",
       " False,\n",
       " True,\n",
       " False,\n",
       " True,\n",
       " False,\n",
       " True,\n",
       " False,\n",
       " True,\n",
       " False,\n",
       " True,\n",
       " False,\n",
       " True,\n",
       " False,\n",
       " True,\n",
       " False,\n",
       " True,\n",
       " False,\n",
       " True,\n",
       " False,\n",
       " True,\n",
       " False,\n",
       " True,\n",
       " False,\n",
       " True,\n",
       " False,\n",
       " True,\n",
       " False,\n",
       " True,\n",
       " False,\n",
       " True,\n",
       " False,\n",
       " True,\n",
       " False,\n",
       " True,\n",
       " False,\n",
       " True,\n",
       " False,\n",
       " True,\n",
       " False,\n",
       " True,\n",
       " False,\n",
       " True,\n",
       " False,\n",
       " True,\n",
       " False,\n",
       " True,\n",
       " False,\n",
       " True,\n",
       " False,\n",
       " True,\n",
       " False,\n",
       " True,\n",
       " False,\n",
       " True,\n",
       " False,\n",
       " True,\n",
       " False,\n",
       " True,\n",
       " False,\n",
       " True,\n",
       " False,\n",
       " True,\n",
       " False,\n",
       " True,\n",
       " False,\n",
       " True,\n",
       " False,\n",
       " True,\n",
       " False,\n",
       " True,\n",
       " False,\n",
       " True,\n",
       " False,\n",
       " True,\n",
       " False,\n",
       " True,\n",
       " False,\n",
       " True,\n",
       " False,\n",
       " True,\n",
       " False,\n",
       " True,\n",
       " False,\n",
       " True,\n",
       " False,\n",
       " True,\n",
       " False,\n",
       " True,\n",
       " False,\n",
       " True,\n",
       " False,\n",
       " True,\n",
       " False,\n",
       " True,\n",
       " False,\n",
       " True,\n",
       " False,\n",
       " True,\n",
       " False,\n",
       " True,\n",
       " False,\n",
       " True,\n",
       " False,\n",
       " True,\n",
       " False,\n",
       " True,\n",
       " False,\n",
       " True,\n",
       " False,\n",
       " True,\n",
       " False,\n",
       " True,\n",
       " False,\n",
       " True,\n",
       " False,\n",
       " True,\n",
       " False,\n",
       " True,\n",
       " False,\n",
       " True,\n",
       " False,\n",
       " True,\n",
       " False,\n",
       " True,\n",
       " False,\n",
       " True,\n",
       " False,\n",
       " True,\n",
       " False,\n",
       " True,\n",
       " False,\n",
       " True,\n",
       " False,\n",
       " True,\n",
       " False,\n",
       " True,\n",
       " False,\n",
       " True,\n",
       " False,\n",
       " True,\n",
       " False,\n",
       " True,\n",
       " False,\n",
       " True,\n",
       " False,\n",
       " True,\n",
       " False,\n",
       " True,\n",
       " False,\n",
       " True,\n",
       " False,\n",
       " True,\n",
       " False,\n",
       " True,\n",
       " False,\n",
       " True,\n",
       " False,\n",
       " True,\n",
       " False,\n",
       " True,\n",
       " False,\n",
       " True,\n",
       " False,\n",
       " True,\n",
       " False,\n",
       " True,\n",
       " False,\n",
       " True,\n",
       " False,\n",
       " True,\n",
       " False,\n",
       " True,\n",
       " False,\n",
       " True,\n",
       " False,\n",
       " True,\n",
       " False,\n",
       " True,\n",
       " False,\n",
       " True,\n",
       " False,\n",
       " True,\n",
       " False,\n",
       " True,\n",
       " False,\n",
       " True,\n",
       " False,\n",
       " True,\n",
       " False,\n",
       " True,\n",
       " False,\n",
       " True,\n",
       " False,\n",
       " True,\n",
       " False,\n",
       " True,\n",
       " False,\n",
       " True,\n",
       " True,\n",
       " False,\n",
       " True,\n",
       " False,\n",
       " True,\n",
       " False,\n",
       " True,\n",
       " False,\n",
       " True,\n",
       " False,\n",
       " True,\n",
       " False,\n",
       " True,\n",
       " False,\n",
       " True,\n",
       " False,\n",
       " True,\n",
       " False,\n",
       " True,\n",
       " False,\n",
       " True,\n",
       " False,\n",
       " True,\n",
       " False,\n",
       " True,\n",
       " False,\n",
       " True,\n",
       " False,\n",
       " True,\n",
       " False,\n",
       " True,\n",
       " False,\n",
       " True,\n",
       " False,\n",
       " True,\n",
       " False,\n",
       " True,\n",
       " False,\n",
       " True,\n",
       " False,\n",
       " True,\n",
       " False,\n",
       " True,\n",
       " False,\n",
       " True,\n",
       " False,\n",
       " True,\n",
       " False,\n",
       " True,\n",
       " False,\n",
       " True,\n",
       " False,\n",
       " True,\n",
       " True,\n",
       " True,\n",
       " True,\n",
       " True,\n",
       " True,\n",
       " True,\n",
       " True,\n",
       " True,\n",
       " True,\n",
       " True,\n",
       " False,\n",
       " False,\n",
       " False,\n",
       " False,\n",
       " False,\n",
       " False,\n",
       " False,\n",
       " False,\n",
       " False,\n",
       " False,\n",
       " True,\n",
       " True,\n",
       " True,\n",
       " True,\n",
       " True,\n",
       " True,\n",
       " True,\n",
       " True,\n",
       " True,\n",
       " True,\n",
       " False,\n",
       " False,\n",
       " False,\n",
       " False,\n",
       " False,\n",
       " False,\n",
       " False,\n",
       " False,\n",
       " False,\n",
       " False,\n",
       " True,\n",
       " True,\n",
       " True,\n",
       " True,\n",
       " True,\n",
       " True,\n",
       " True,\n",
       " True,\n",
       " True,\n",
       " True,\n",
       " False,\n",
       " False,\n",
       " False,\n",
       " False,\n",
       " False,\n",
       " False,\n",
       " False,\n",
       " False,\n",
       " False,\n",
       " False,\n",
       " True,\n",
       " True,\n",
       " True,\n",
       " True,\n",
       " True,\n",
       " True,\n",
       " True,\n",
       " True,\n",
       " True,\n",
       " True,\n",
       " False,\n",
       " False,\n",
       " False,\n",
       " False,\n",
       " False,\n",
       " False,\n",
       " False,\n",
       " False,\n",
       " False,\n",
       " False,\n",
       " True,\n",
       " True,\n",
       " True,\n",
       " True,\n",
       " True,\n",
       " True,\n",
       " True,\n",
       " True,\n",
       " True,\n",
       " True,\n",
       " False,\n",
       " False,\n",
       " False,\n",
       " False,\n",
       " False,\n",
       " False,\n",
       " False,\n",
       " False,\n",
       " False,\n",
       " False,\n",
       " True,\n",
       " True,\n",
       " True,\n",
       " True,\n",
       " True,\n",
       " True,\n",
       " True,\n",
       " True,\n",
       " True,\n",
       " True,\n",
       " False,\n",
       " False,\n",
       " False,\n",
       " False,\n",
       " False,\n",
       " False,\n",
       " False,\n",
       " False,\n",
       " False,\n",
       " False,\n",
       " True,\n",
       " True,\n",
       " True,\n",
       " True,\n",
       " True,\n",
       " True,\n",
       " True,\n",
       " True,\n",
       " True,\n",
       " True,\n",
       " False,\n",
       " False,\n",
       " False,\n",
       " False,\n",
       " False,\n",
       " False,\n",
       " False,\n",
       " False,\n",
       " False,\n",
       " False,\n",
       " True,\n",
       " True,\n",
       " True,\n",
       " True,\n",
       " True,\n",
       " True,\n",
       " True,\n",
       " True,\n",
       " True,\n",
       " True,\n",
       " False,\n",
       " False,\n",
       " False,\n",
       " False,\n",
       " False,\n",
       " False,\n",
       " False,\n",
       " False,\n",
       " False,\n",
       " False,\n",
       " True,\n",
       " True,\n",
       " True,\n",
       " True,\n",
       " True,\n",
       " True,\n",
       " True,\n",
       " True,\n",
       " True,\n",
       " True,\n",
       " False,\n",
       " False,\n",
       " False,\n",
       " False,\n",
       " False,\n",
       " False,\n",
       " False,\n",
       " False,\n",
       " False,\n",
       " False,\n",
       " True,\n",
       " True,\n",
       " True,\n",
       " True,\n",
       " True,\n",
       " True,\n",
       " True,\n",
       " True,\n",
       " True,\n",
       " True,\n",
       " False,\n",
       " False,\n",
       " False,\n",
       " False,\n",
       " False,\n",
       " False,\n",
       " False,\n",
       " False,\n",
       " False,\n",
       " False,\n",
       " True,\n",
       " True,\n",
       " True,\n",
       " True,\n",
       " True,\n",
       " True,\n",
       " True,\n",
       " True,\n",
       " True,\n",
       " True,\n",
       " False,\n",
       " False,\n",
       " False,\n",
       " False,\n",
       " False,\n",
       " False,\n",
       " False,\n",
       " False,\n",
       " False,\n",
       " False,\n",
       " True,\n",
       " True,\n",
       " True,\n",
       " True,\n",
       " True,\n",
       " True,\n",
       " True,\n",
       " True,\n",
       " True,\n",
       " True,\n",
       " False,\n",
       " False,\n",
       " False,\n",
       " False,\n",
       " False,\n",
       " False,\n",
       " False,\n",
       " False,\n",
       " False,\n",
       " False,\n",
       " True,\n",
       " True,\n",
       " True,\n",
       " True,\n",
       " True,\n",
       " True,\n",
       " True,\n",
       " True,\n",
       " True,\n",
       " True,\n",
       " False,\n",
       " False,\n",
       " False,\n",
       " False,\n",
       " False,\n",
       " False,\n",
       " False,\n",
       " False,\n",
       " False,\n",
       " False,\n",
       " True,\n",
       " True,\n",
       " True,\n",
       " True,\n",
       " True,\n",
       " True,\n",
       " True,\n",
       " True,\n",
       " True,\n",
       " True,\n",
       " False,\n",
       " False,\n",
       " False,\n",
       " False,\n",
       " False,\n",
       " False,\n",
       " False,\n",
       " False,\n",
       " False,\n",
       " False,\n",
       " True,\n",
       " True,\n",
       " True,\n",
       " True,\n",
       " True,\n",
       " True,\n",
       " True,\n",
       " True,\n",
       " True,\n",
       " True,\n",
       " False,\n",
       " False,\n",
       " False,\n",
       " False,\n",
       " False,\n",
       " False,\n",
       " False,\n",
       " False,\n",
       " False,\n",
       " False,\n",
       " True,\n",
       " True,\n",
       " True,\n",
       " True,\n",
       " True,\n",
       " True,\n",
       " True,\n",
       " True,\n",
       " True,\n",
       " True,\n",
       " False,\n",
       " False,\n",
       " False,\n",
       " False,\n",
       " False,\n",
       " False,\n",
       " False,\n",
       " False,\n",
       " False,\n",
       " False,\n",
       " True,\n",
       " True,\n",
       " True,\n",
       " True,\n",
       " True,\n",
       " True,\n",
       " True,\n",
       " True,\n",
       " True,\n",
       " True,\n",
       " False,\n",
       " False,\n",
       " False,\n",
       " False,\n",
       " False,\n",
       " False,\n",
       " False,\n",
       " False,\n",
       " False,\n",
       " False,\n",
       " True,\n",
       " True,\n",
       " True,\n",
       " True,\n",
       " True,\n",
       " True,\n",
       " True,\n",
       " True,\n",
       " True,\n",
       " True,\n",
       " False,\n",
       " False,\n",
       " False,\n",
       " False,\n",
       " False,\n",
       " False,\n",
       " False,\n",
       " False,\n",
       " False,\n",
       " False,\n",
       " True,\n",
       " True,\n",
       " True,\n",
       " True,\n",
       " True,\n",
       " True,\n",
       " True,\n",
       " True,\n",
       " True,\n",
       " True,\n",
       " False,\n",
       " False,\n",
       " False,\n",
       " False,\n",
       " False,\n",
       " False,\n",
       " False,\n",
       " False,\n",
       " False,\n",
       " False,\n",
       " True,\n",
       " True,\n",
       " True,\n",
       " True,\n",
       " True,\n",
       " True,\n",
       " True,\n",
       " True,\n",
       " True,\n",
       " True,\n",
       " False,\n",
       " False,\n",
       " False,\n",
       " False,\n",
       " False,\n",
       " False,\n",
       " False,\n",
       " False,\n",
       " False,\n",
       " False,\n",
       " True,\n",
       " True,\n",
       " True,\n",
       " True,\n",
       " True,\n",
       " True,\n",
       " True,\n",
       " True,\n",
       " True,\n",
       " True,\n",
       " False,\n",
       " False,\n",
       " False,\n",
       " False,\n",
       " False,\n",
       " False,\n",
       " False,\n",
       " False,\n",
       " False,\n",
       " False,\n",
       " True,\n",
       " True,\n",
       " True,\n",
       " True,\n",
       " True,\n",
       " True,\n",
       " True,\n",
       " True,\n",
       " True,\n",
       " True,\n",
       " False,\n",
       " False,\n",
       " False,\n",
       " False,\n",
       " False,\n",
       " False,\n",
       " False,\n",
       " False,\n",
       " False,\n",
       " False,\n",
       " True,\n",
       " True,\n",
       " True,\n",
       " True,\n",
       " True,\n",
       " True,\n",
       " True,\n",
       " True,\n",
       " True,\n",
       " True,\n",
       " False,\n",
       " False,\n",
       " False,\n",
       " False,\n",
       " False,\n",
       " False,\n",
       " False,\n",
       " False,\n",
       " False,\n",
       " False,\n",
       " True,\n",
       " True,\n",
       " True,\n",
       " True,\n",
       " True,\n",
       " True,\n",
       " True,\n",
       " True,\n",
       " True,\n",
       " True,\n",
       " False,\n",
       " False,\n",
       " False,\n",
       " False,\n",
       " False,\n",
       " False,\n",
       " False,\n",
       " False,\n",
       " False,\n",
       " False,\n",
       " True,\n",
       " True,\n",
       " True,\n",
       " True,\n",
       " True,\n",
       " True,\n",
       " True,\n",
       " True,\n",
       " True,\n",
       " True,\n",
       " False,\n",
       " False,\n",
       " False,\n",
       " False,\n",
       " False,\n",
       " False,\n",
       " False,\n",
       " False,\n",
       " False,\n",
       " False,\n",
       " True,\n",
       " True,\n",
       " True,\n",
       " True,\n",
       " True,\n",
       " True,\n",
       " True,\n",
       " True,\n",
       " True,\n",
       " True,\n",
       " False,\n",
       " False,\n",
       " False,\n",
       " False,\n",
       " False,\n",
       " False,\n",
       " False,\n",
       " False,\n",
       " False,\n",
       " False,\n",
       " True,\n",
       " True,\n",
       " True,\n",
       " True,\n",
       " True,\n",
       " True,\n",
       " True,\n",
       " True,\n",
       " True,\n",
       " True,\n",
       " False,\n",
       " False,\n",
       " False,\n",
       " False,\n",
       " False,\n",
       " False,\n",
       " False,\n",
       " False,\n",
       " False,\n",
       " False,\n",
       " True,\n",
       " True,\n",
       " ...]"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "therapist_index"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "ce04f676",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([  0,   0,   0,  ..., 131, 131, 131])"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "therapist_transcript_id"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0cf51402",
   "metadata": {},
   "source": [
    "# Baseline: FFN using signatures\n",
    "\n",
    "First, we dimension reduce these and then take signatures. We use the path signature as input to the FFN for classification.\n",
    "\n",
    "We want to choose a dimension and signature depth such that the number of terms in the signature is _roughly_ 384 so that it is comparable to the number of features that we used for the previous baseline where we computed the mean of the history. Again, we are concatenating the features we obtain with the current utterance embedding."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "f691b640",
   "metadata": {},
   "outputs": [],
   "source": [
    "num_epochs = 100\n",
    "hidden_dim_sizes = [[128,128],[256,256],[512,512]]\n",
    "dropout_rates = [0.5, 0.2, 0.1]\n",
    "learning_rates = [1e-3, 1e-4, 5e-4]\n",
    "seeds = [0, 1, 12, 123, 1234]\n",
    "loss = \"focal\"\n",
    "gamma = 2\n",
    "validation_metric = \"f1\"\n",
    "patience = 5"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "871fe909",
   "metadata": {},
   "source": [
    "## Using log signature"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "08de59af",
   "metadata": {},
   "outputs": [],
   "source": [
    "log_signature_dimensions_and_sig_depths = [(28, 2), (10, 3), (6, 4)]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "b5480b5f",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[406, 385, 406]"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import signatory\n",
    "\n",
    "[signatory.logsignature_channels(channels, depth)\n",
    " for (channels, depth) in log_signature_dimensions_and_sig_depths]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9ae2ba07",
   "metadata": {},
   "source": [
    "### Using UMAP"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "b9cd8cf0",
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "63e2df84f64a4526ae57869e6404c1eb",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/3 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "df2c3610c6674a5d8a67a6d400822bbd",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/1 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[INFO] Concatenating the embeddings to the dataframe...\n",
      "[INFO] - columns beginning with 'e' denote the full embddings.\n",
      "[INFO] - columns beginning with 'd' denote the dimension reduced embeddings.\n",
      "[INFO] Adding time feature columns into dataframe in `.df`.\n",
      "[INFO] Adding 'time_encoding' and feature...\n",
      "[INFO] Adding 'time_diff' and feature...\n",
      "[INFO] Adding 'timeline_index' feature...\n",
      "[INFO] Padding ids and storing in `.df_padded` and `.array_padded` attributes.\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "1f76455ab72445af9d7e093cec75170e",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/13551 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "cc42cd4e2e114a9ab167c80d52eba1da",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/3 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "a28ff3df95ce4cadafeb1cf75ad290a7",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/3 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "163053ed50384315bb64b3ca58a5c8c0",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/3 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "05403dd0660a42ec94f3faf518512b53",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/3 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "45ff138f76244d189dbaf8fa30a0adfe",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/3 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "167c6676a6bc4de1854a72a749ad158a",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/3 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "cf955f66b8e844d6a07abe4d9ca2496f",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/3 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "977a73e030474909ad6de928c2d6589d",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/3 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "e0f2f9dfcacb417d9aac2698bdb282f2",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/3 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "241df16b30414924af8045f1180e77f3",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/3 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "4a018dd1a0d04f1fbf70b28116e6c9bf",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/3 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "c77d975c023d40f4aafe551d66f24d70",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/3 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "ca9d0227ed6041929df88e521e1cb900",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/3 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "8469c793462c45618a5eff44cad024fa",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/1 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[INFO] Concatenating the embeddings to the dataframe...\n",
      "[INFO] - columns beginning with 'e' denote the full embddings.\n",
      "[INFO] - columns beginning with 'd' denote the dimension reduced embeddings.\n",
      "[INFO] Adding time feature columns into dataframe in `.df`.\n",
      "[INFO] Adding 'time_encoding' and feature...\n",
      "[INFO] Adding 'time_diff' and feature...\n",
      "[INFO] Adding 'timeline_index' feature...\n",
      "[INFO] Padding ids and storing in `.df_padded` and `.array_padded` attributes.\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "5420193585564632bae5f9004a5d7600",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/13551 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "c330b9a6cadf45839168ad04ecbd5212",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/3 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "fc2fe049639f4c3c9e77eda85d09e665",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/3 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "18f884e7719743c2ae2b9c8eb01e1170",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/3 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "c94f169808354320a799dd9a330741b9",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/3 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "7550657f2fa74daf9c0235e4632f88d1",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/3 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "5c2103d7f01b48308ed72534aaf42c81",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/3 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "37ccb21e600d47e7905cd8b7d14c188d",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/3 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "9c303bcaf6914bbc953a8b1e19d793ab",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/3 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "29ec6206714d420286e55a877d177af8",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/3 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "6115cb1960d9488796764c06cf05f469",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/3 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "fbb62af0df4b459da93ef5559dc5312e",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/3 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "c28032ce6b994576a028c4de14113158",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/3 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "60081450287d44b1a1b5f192c057b613",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/3 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "37f113abbadd4f03b8a71bc2acd79262",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/1 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[INFO] Concatenating the embeddings to the dataframe...\n",
      "[INFO] - columns beginning with 'e' denote the full embddings.\n",
      "[INFO] - columns beginning with 'd' denote the dimension reduced embeddings.\n",
      "[INFO] Adding time feature columns into dataframe in `.df`.\n",
      "[INFO] Adding 'time_encoding' and feature...\n",
      "[INFO] Adding 'time_diff' and feature...\n",
      "[INFO] Adding 'timeline_index' feature...\n",
      "[INFO] Padding ids and storing in `.df_padded` and `.array_padded` attributes.\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "0c6cd1e0a1cc4a4ca299c1e4cbb50485",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/13551 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "d551cfc552294da88822116db899c627",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/3 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "25422955182e44a184f3efae97b01d58",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/3 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "cfa229febd3b4757bea1d5af25ecb970",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/3 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "0dc9ec49a2ef475a8fa2e5aeda95c67c",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/3 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "008500f7fe25485b89cefb292c3de468",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/3 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "f0b8d49ce957410c949eded9c310add1",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/3 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "fe84944a86ed486e899bd8c8226f79e2",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/3 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "f82e02dba3df48a1857c60f27a1af980",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/3 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "ba75a0281ced42a2af3c5316c35a3f67",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/3 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "5578b181b9474719bd9ffd2d7d559e61",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/3 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "83715a656ea444d7b483764c0ad112f1",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/3 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "df5969ef1fc740d395c9d4da49704747",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/3 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "45b3507c021f4b44a4d4b2e4e3852a5d",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/3 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[INFO] Concatenating the embeddings to the dataframe...\n",
      "[INFO] - columns beginning with 'e' denote the full embddings.\n",
      "[INFO] - columns beginning with 'd' denote the dimension reduced embeddings.\n",
      "[INFO] Adding time feature columns into dataframe in `.df`.\n",
      "[INFO] Adding 'time_encoding' and feature...\n",
      "[INFO] Adding 'time_diff' and feature...\n",
      "[INFO] Adding 'timeline_index' feature...\n",
      "[INFO] Padding ids and storing in `.df_padded` and `.array_padded` attributes.\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "846d00b2acb046b9b58e39dca6ee7348",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/13551 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "saving results dataframe to CSV for this hyperparameter search in therapist_talk_type_output/ffn_logsignature_umap_focal_2_kfold.csv\n",
      "saving the best model results dataframe to CSV for this hyperparameter search in therapist_talk_type_output/ffn_logsignature_umap_focal_2_kfold_best_model.csv\n"
     ]
    }
   ],
   "source": [
    "ffn_logsignature_umap_kfold, best_ffn_logsignature_umap_kfold, _, __ = histories_baseline_hyperparameter_search(\n",
    "    num_epochs=num_epochs,\n",
    "    df=anno_mi,\n",
    "    id_column=\"transcript_id\",\n",
    "    label_column=\"main_therapist_behaviour\",\n",
    "    embeddings=sbert_embeddings,\n",
    "    y_data=y_data_therapist,\n",
    "    output_dim=output_dim_therapist,\n",
    "    hidden_dim_sizes=hidden_dim_sizes,\n",
    "    dropout_rates=dropout_rates,\n",
    "    learning_rates=learning_rates,\n",
    "    use_signatures=True,\n",
    "    seeds=seeds,\n",
    "    loss=loss,\n",
    "    gamma=gamma,\n",
    "    log_signature=True,\n",
    "    dim_reduce_methods=[\"umap\"],\n",
    "    dimension_and_sig_depths=log_signature_dimensions_and_sig_depths,\n",
    "    path_indices=therapist_index,\n",
    "    split_ids=therapist_transcript_id,\n",
    "    k_fold=True,\n",
    "    patience=patience,\n",
    "    validation_metric=validation_metric,\n",
    "    results_output=f\"{output_dir}/ffn_logsignature_umap_focal_{gamma}_kfold.csv\",\n",
    "    verbose=False\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "f8b363bd",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/var/folders/l7/bnn1j6bs3bqfskq2jlq55yh80000gr/T/ipykernel_53974/3138393360.py:1: FutureWarning: The default value of numeric_only in DataFrameGroupBy.mean is deprecated. In a future version, numeric_only will default to False. Either specify numeric_only or select only columns which should be valid for the function.\n",
      "  ffn_logsignature_umap_kfold.groupby([\"dimension\", \"sig_depth\", \"hidden_dim\", \"dropout_rate\", \"learning_rate\"]).mean()\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th>accuracy</th>\n",
       "      <th>f1</th>\n",
       "      <th>precision</th>\n",
       "      <th>recall</th>\n",
       "      <th>valid_accuracy</th>\n",
       "      <th>valid_f1</th>\n",
       "      <th>valid_precision</th>\n",
       "      <th>valid_recall</th>\n",
       "      <th>seed</th>\n",
       "      <th>gamma</th>\n",
       "      <th>k_fold</th>\n",
       "      <th>n_splits</th>\n",
       "      <th>batch_size</th>\n",
       "      <th>model_id</th>\n",
       "      <th>input_dim</th>\n",
       "      <th>log_signature</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>dimension</th>\n",
       "      <th>sig_depth</th>\n",
       "      <th>hidden_dim</th>\n",
       "      <th>dropout_rate</th>\n",
       "      <th>learning_rate</th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th rowspan=\"5\" valign=\"top\">6</th>\n",
       "      <th rowspan=\"5\" valign=\"top\">4</th>\n",
       "      <th rowspan=\"5\" valign=\"top\">(128, 128)</th>\n",
       "      <th rowspan=\"3\" valign=\"top\">0.1</th>\n",
       "      <th>0.0001</th>\n",
       "      <td>0.385488</td>\n",
       "      <td>0.349648</td>\n",
       "      <td>0.350472</td>\n",
       "      <td>0.354166</td>\n",
       "      <td>0.640538</td>\n",
       "      <td>0.627678</td>\n",
       "      <td>0.633008</td>\n",
       "      <td>0.626170</td>\n",
       "      <td>274.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>5.0</td>\n",
       "      <td>64.0</td>\n",
       "      <td>2.70</td>\n",
       "      <td>790.0</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>0.0005</th>\n",
       "      <td>0.399940</td>\n",
       "      <td>0.359578</td>\n",
       "      <td>0.362823</td>\n",
       "      <td>0.364128</td>\n",
       "      <td>0.632738</td>\n",
       "      <td>0.619846</td>\n",
       "      <td>0.626767</td>\n",
       "      <td>0.618201</td>\n",
       "      <td>274.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>5.0</td>\n",
       "      <td>64.0</td>\n",
       "      <td>2.80</td>\n",
       "      <td>790.0</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>0.0010</th>\n",
       "      <td>0.395565</td>\n",
       "      <td>0.355270</td>\n",
       "      <td>0.358817</td>\n",
       "      <td>0.358780</td>\n",
       "      <td>0.617978</td>\n",
       "      <td>0.604468</td>\n",
       "      <td>0.614329</td>\n",
       "      <td>0.601997</td>\n",
       "      <td>274.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>5.0</td>\n",
       "      <td>64.0</td>\n",
       "      <td>2.60</td>\n",
       "      <td>790.0</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th rowspan=\"2\" valign=\"top\">0.2</th>\n",
       "      <th>0.0001</th>\n",
       "      <td>0.391432</td>\n",
       "      <td>0.351451</td>\n",
       "      <td>0.353796</td>\n",
       "      <td>0.356168</td>\n",
       "      <td>0.624807</td>\n",
       "      <td>0.612047</td>\n",
       "      <td>0.620743</td>\n",
       "      <td>0.609670</td>\n",
       "      <td>274.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>5.0</td>\n",
       "      <td>64.0</td>\n",
       "      <td>2.40</td>\n",
       "      <td>790.0</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>0.0005</th>\n",
       "      <td>0.406607</td>\n",
       "      <td>0.364229</td>\n",
       "      <td>0.368924</td>\n",
       "      <td>0.368157</td>\n",
       "      <td>0.605904</td>\n",
       "      <td>0.593036</td>\n",
       "      <td>0.607972</td>\n",
       "      <td>0.590129</td>\n",
       "      <td>274.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>5.0</td>\n",
       "      <td>64.0</td>\n",
       "      <td>2.50</td>\n",
       "      <td>790.0</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <th>...</th>\n",
       "      <th>...</th>\n",
       "      <th>...</th>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th rowspan=\"5\" valign=\"top\">28</th>\n",
       "      <th rowspan=\"5\" valign=\"top\">2</th>\n",
       "      <th rowspan=\"5\" valign=\"top\">(512, 512)</th>\n",
       "      <th rowspan=\"2\" valign=\"top\">0.2</th>\n",
       "      <th>0.0005</th>\n",
       "      <td>0.556705</td>\n",
       "      <td>0.531473</td>\n",
       "      <td>0.534058</td>\n",
       "      <td>0.534555</td>\n",
       "      <td>0.707513</td>\n",
       "      <td>0.692375</td>\n",
       "      <td>0.692905</td>\n",
       "      <td>0.694220</td>\n",
       "      <td>274.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>5.0</td>\n",
       "      <td>64.0</td>\n",
       "      <td>0.23</td>\n",
       "      <td>790.0</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>0.0010</th>\n",
       "      <td>0.553507</td>\n",
       "      <td>0.528184</td>\n",
       "      <td>0.531857</td>\n",
       "      <td>0.529797</td>\n",
       "      <td>0.692509</td>\n",
       "      <td>0.677736</td>\n",
       "      <td>0.678737</td>\n",
       "      <td>0.679667</td>\n",
       "      <td>274.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>5.0</td>\n",
       "      <td>64.0</td>\n",
       "      <td>0.21</td>\n",
       "      <td>790.0</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th rowspan=\"3\" valign=\"top\">0.5</th>\n",
       "      <th>0.0001</th>\n",
       "      <td>0.558998</td>\n",
       "      <td>0.532636</td>\n",
       "      <td>0.534921</td>\n",
       "      <td>0.534628</td>\n",
       "      <td>0.722736</td>\n",
       "      <td>0.709574</td>\n",
       "      <td>0.710372</td>\n",
       "      <td>0.711372</td>\n",
       "      <td>274.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>5.0</td>\n",
       "      <td>64.0</td>\n",
       "      <td>0.19</td>\n",
       "      <td>790.0</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>0.0005</th>\n",
       "      <td>0.565364</td>\n",
       "      <td>0.537719</td>\n",
       "      <td>0.539924</td>\n",
       "      <td>0.541377</td>\n",
       "      <td>0.706081</td>\n",
       "      <td>0.691460</td>\n",
       "      <td>0.691465</td>\n",
       "      <td>0.693431</td>\n",
       "      <td>274.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>5.0</td>\n",
       "      <td>64.0</td>\n",
       "      <td>0.20</td>\n",
       "      <td>790.0</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>0.0010</th>\n",
       "      <td>0.552331</td>\n",
       "      <td>0.521688</td>\n",
       "      <td>0.526154</td>\n",
       "      <td>0.524966</td>\n",
       "      <td>0.684314</td>\n",
       "      <td>0.668668</td>\n",
       "      <td>0.670453</td>\n",
       "      <td>0.670563</td>\n",
       "      <td>274.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>5.0</td>\n",
       "      <td>64.0</td>\n",
       "      <td>0.18</td>\n",
       "      <td>790.0</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>81 rows × 16 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                                                           accuracy        f1  \\\n",
       "dimension sig_depth hidden_dim dropout_rate learning_rate                       \n",
       "6         4         (128, 128) 0.1          0.0001         0.385488  0.349648   \n",
       "                                            0.0005         0.399940  0.359578   \n",
       "                                            0.0010         0.395565  0.355270   \n",
       "                               0.2          0.0001         0.391432  0.351451   \n",
       "                                            0.0005         0.406607  0.364229   \n",
       "...                                                             ...       ...   \n",
       "28        2         (512, 512) 0.2          0.0005         0.556705  0.531473   \n",
       "                                            0.0010         0.553507  0.528184   \n",
       "                               0.5          0.0001         0.558998  0.532636   \n",
       "                                            0.0005         0.565364  0.537719   \n",
       "                                            0.0010         0.552331  0.521688   \n",
       "\n",
       "                                                           precision  \\\n",
       "dimension sig_depth hidden_dim dropout_rate learning_rate              \n",
       "6         4         (128, 128) 0.1          0.0001          0.350472   \n",
       "                                            0.0005          0.362823   \n",
       "                                            0.0010          0.358817   \n",
       "                               0.2          0.0001          0.353796   \n",
       "                                            0.0005          0.368924   \n",
       "...                                                              ...   \n",
       "28        2         (512, 512) 0.2          0.0005          0.534058   \n",
       "                                            0.0010          0.531857   \n",
       "                               0.5          0.0001          0.534921   \n",
       "                                            0.0005          0.539924   \n",
       "                                            0.0010          0.526154   \n",
       "\n",
       "                                                             recall  \\\n",
       "dimension sig_depth hidden_dim dropout_rate learning_rate             \n",
       "6         4         (128, 128) 0.1          0.0001         0.354166   \n",
       "                                            0.0005         0.364128   \n",
       "                                            0.0010         0.358780   \n",
       "                               0.2          0.0001         0.356168   \n",
       "                                            0.0005         0.368157   \n",
       "...                                                             ...   \n",
       "28        2         (512, 512) 0.2          0.0005         0.534555   \n",
       "                                            0.0010         0.529797   \n",
       "                               0.5          0.0001         0.534628   \n",
       "                                            0.0005         0.541377   \n",
       "                                            0.0010         0.524966   \n",
       "\n",
       "                                                           valid_accuracy  \\\n",
       "dimension sig_depth hidden_dim dropout_rate learning_rate                   \n",
       "6         4         (128, 128) 0.1          0.0001               0.640538   \n",
       "                                            0.0005               0.632738   \n",
       "                                            0.0010               0.617978   \n",
       "                               0.2          0.0001               0.624807   \n",
       "                                            0.0005               0.605904   \n",
       "...                                                                   ...   \n",
       "28        2         (512, 512) 0.2          0.0005               0.707513   \n",
       "                                            0.0010               0.692509   \n",
       "                               0.5          0.0001               0.722736   \n",
       "                                            0.0005               0.706081   \n",
       "                                            0.0010               0.684314   \n",
       "\n",
       "                                                           valid_f1  \\\n",
       "dimension sig_depth hidden_dim dropout_rate learning_rate             \n",
       "6         4         (128, 128) 0.1          0.0001         0.627678   \n",
       "                                            0.0005         0.619846   \n",
       "                                            0.0010         0.604468   \n",
       "                               0.2          0.0001         0.612047   \n",
       "                                            0.0005         0.593036   \n",
       "...                                                             ...   \n",
       "28        2         (512, 512) 0.2          0.0005         0.692375   \n",
       "                                            0.0010         0.677736   \n",
       "                               0.5          0.0001         0.709574   \n",
       "                                            0.0005         0.691460   \n",
       "                                            0.0010         0.668668   \n",
       "\n",
       "                                                           valid_precision  \\\n",
       "dimension sig_depth hidden_dim dropout_rate learning_rate                    \n",
       "6         4         (128, 128) 0.1          0.0001                0.633008   \n",
       "                                            0.0005                0.626767   \n",
       "                                            0.0010                0.614329   \n",
       "                               0.2          0.0001                0.620743   \n",
       "                                            0.0005                0.607972   \n",
       "...                                                                    ...   \n",
       "28        2         (512, 512) 0.2          0.0005                0.692905   \n",
       "                                            0.0010                0.678737   \n",
       "                               0.5          0.0001                0.710372   \n",
       "                                            0.0005                0.691465   \n",
       "                                            0.0010                0.670453   \n",
       "\n",
       "                                                           valid_recall  \\\n",
       "dimension sig_depth hidden_dim dropout_rate learning_rate                 \n",
       "6         4         (128, 128) 0.1          0.0001             0.626170   \n",
       "                                            0.0005             0.618201   \n",
       "                                            0.0010             0.601997   \n",
       "                               0.2          0.0001             0.609670   \n",
       "                                            0.0005             0.590129   \n",
       "...                                                                 ...   \n",
       "28        2         (512, 512) 0.2          0.0005             0.694220   \n",
       "                                            0.0010             0.679667   \n",
       "                               0.5          0.0001             0.711372   \n",
       "                                            0.0005             0.693431   \n",
       "                                            0.0010             0.670563   \n",
       "\n",
       "                                                            seed  gamma  \\\n",
       "dimension sig_depth hidden_dim dropout_rate learning_rate                 \n",
       "6         4         (128, 128) 0.1          0.0001         274.0    2.0   \n",
       "                                            0.0005         274.0    2.0   \n",
       "                                            0.0010         274.0    2.0   \n",
       "                               0.2          0.0001         274.0    2.0   \n",
       "                                            0.0005         274.0    2.0   \n",
       "...                                                          ...    ...   \n",
       "28        2         (512, 512) 0.2          0.0005         274.0    2.0   \n",
       "                                            0.0010         274.0    2.0   \n",
       "                               0.5          0.0001         274.0    2.0   \n",
       "                                            0.0005         274.0    2.0   \n",
       "                                            0.0010         274.0    2.0   \n",
       "\n",
       "                                                           k_fold  n_splits  \\\n",
       "dimension sig_depth hidden_dim dropout_rate learning_rate                     \n",
       "6         4         (128, 128) 0.1          0.0001            1.0       5.0   \n",
       "                                            0.0005            1.0       5.0   \n",
       "                                            0.0010            1.0       5.0   \n",
       "                               0.2          0.0001            1.0       5.0   \n",
       "                                            0.0005            1.0       5.0   \n",
       "...                                                           ...       ...   \n",
       "28        2         (512, 512) 0.2          0.0005            1.0       5.0   \n",
       "                                            0.0010            1.0       5.0   \n",
       "                               0.5          0.0001            1.0       5.0   \n",
       "                                            0.0005            1.0       5.0   \n",
       "                                            0.0010            1.0       5.0   \n",
       "\n",
       "                                                           batch_size  \\\n",
       "dimension sig_depth hidden_dim dropout_rate learning_rate               \n",
       "6         4         (128, 128) 0.1          0.0001               64.0   \n",
       "                                            0.0005               64.0   \n",
       "                                            0.0010               64.0   \n",
       "                               0.2          0.0001               64.0   \n",
       "                                            0.0005               64.0   \n",
       "...                                                               ...   \n",
       "28        2         (512, 512) 0.2          0.0005               64.0   \n",
       "                                            0.0010               64.0   \n",
       "                               0.5          0.0001               64.0   \n",
       "                                            0.0005               64.0   \n",
       "                                            0.0010               64.0   \n",
       "\n",
       "                                                           model_id  \\\n",
       "dimension sig_depth hidden_dim dropout_rate learning_rate             \n",
       "6         4         (128, 128) 0.1          0.0001             2.70   \n",
       "                                            0.0005             2.80   \n",
       "                                            0.0010             2.60   \n",
       "                               0.2          0.0001             2.40   \n",
       "                                            0.0005             2.50   \n",
       "...                                                             ...   \n",
       "28        2         (512, 512) 0.2          0.0005             0.23   \n",
       "                                            0.0010             0.21   \n",
       "                               0.5          0.0001             0.19   \n",
       "                                            0.0005             0.20   \n",
       "                                            0.0010             0.18   \n",
       "\n",
       "                                                           input_dim  \\\n",
       "dimension sig_depth hidden_dim dropout_rate learning_rate              \n",
       "6         4         (128, 128) 0.1          0.0001             790.0   \n",
       "                                            0.0005             790.0   \n",
       "                                            0.0010             790.0   \n",
       "                               0.2          0.0001             790.0   \n",
       "                                            0.0005             790.0   \n",
       "...                                                              ...   \n",
       "28        2         (512, 512) 0.2          0.0005             790.0   \n",
       "                                            0.0010             790.0   \n",
       "                               0.5          0.0001             790.0   \n",
       "                                            0.0005             790.0   \n",
       "                                            0.0010             790.0   \n",
       "\n",
       "                                                           log_signature  \n",
       "dimension sig_depth hidden_dim dropout_rate learning_rate                 \n",
       "6         4         (128, 128) 0.1          0.0001                   1.0  \n",
       "                                            0.0005                   1.0  \n",
       "                                            0.0010                   1.0  \n",
       "                               0.2          0.0001                   1.0  \n",
       "                                            0.0005                   1.0  \n",
       "...                                                                  ...  \n",
       "28        2         (512, 512) 0.2          0.0005                   1.0  \n",
       "                                            0.0010                   1.0  \n",
       "                               0.5          0.0001                   1.0  \n",
       "                                            0.0005                   1.0  \n",
       "                                            0.0010                   1.0  \n",
       "\n",
       "[81 rows x 16 columns]"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "ffn_logsignature_umap_kfold.groupby([\"dimension\", \"sig_depth\", \"hidden_dim\", \"dropout_rate\", \"learning_rate\"]).mean()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "d1ea8817",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>loss</th>\n",
       "      <th>accuracy</th>\n",
       "      <th>f1</th>\n",
       "      <th>f1_scores</th>\n",
       "      <th>precision</th>\n",
       "      <th>precision_scores</th>\n",
       "      <th>recall</th>\n",
       "      <th>recall_scores</th>\n",
       "      <th>valid_loss</th>\n",
       "      <th>valid_accuracy</th>\n",
       "      <th>...</th>\n",
       "      <th>loss_function</th>\n",
       "      <th>gamma</th>\n",
       "      <th>k_fold</th>\n",
       "      <th>n_splits</th>\n",
       "      <th>batch_size</th>\n",
       "      <th>input_dim</th>\n",
       "      <th>dimension</th>\n",
       "      <th>sig_depth</th>\n",
       "      <th>method</th>\n",
       "      <th>log_signature</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>None</td>\n",
       "      <td>0.563735</td>\n",
       "      <td>0.535800</td>\n",
       "      <td>[0.5480354879594423, 0.3586597451628126, 0.476...</td>\n",
       "      <td>0.535847</td>\n",
       "      <td>[0.5557840616966581, 0.32148900169204736, 0.50...</td>\n",
       "      <td>0.539116</td>\n",
       "      <td>[0.5405, 0.4055496264674493, 0.448920023350846...</td>\n",
       "      <td>None</td>\n",
       "      <td>0.732540</td>\n",
       "      <td>...</td>\n",
       "      <td>focal</td>\n",
       "      <td>2</td>\n",
       "      <td>True</td>\n",
       "      <td>5</td>\n",
       "      <td>64</td>\n",
       "      <td>790</td>\n",
       "      <td>28</td>\n",
       "      <td>2</td>\n",
       "      <td>umap</td>\n",
       "      <td>True</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>None</td>\n",
       "      <td>0.567506</td>\n",
       "      <td>0.537299</td>\n",
       "      <td>[0.5556869236226057, 0.35235732009925563, 0.46...</td>\n",
       "      <td>0.540395</td>\n",
       "      <td>[0.5271422162404665, 0.3293135435992579, 0.507...</td>\n",
       "      <td>0.537892</td>\n",
       "      <td>[0.5875, 0.37886872998932764, 0.42673671920607...</td>\n",
       "      <td>None</td>\n",
       "      <td>0.729566</td>\n",
       "      <td>...</td>\n",
       "      <td>focal</td>\n",
       "      <td>2</td>\n",
       "      <td>True</td>\n",
       "      <td>5</td>\n",
       "      <td>64</td>\n",
       "      <td>790</td>\n",
       "      <td>28</td>\n",
       "      <td>2</td>\n",
       "      <td>umap</td>\n",
       "      <td>True</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>None</td>\n",
       "      <td>0.550158</td>\n",
       "      <td>0.522643</td>\n",
       "      <td>[0.5192540566723178, 0.32952853598014886, 0.46...</td>\n",
       "      <td>0.526138</td>\n",
       "      <td>[0.5035227806481917, 0.3079777365491651, 0.482...</td>\n",
       "      <td>0.521232</td>\n",
       "      <td>[0.536, 0.35432230522945574, 0.455341506129597...</td>\n",
       "      <td>None</td>\n",
       "      <td>0.725711</td>\n",
       "      <td>...</td>\n",
       "      <td>focal</td>\n",
       "      <td>2</td>\n",
       "      <td>True</td>\n",
       "      <td>5</td>\n",
       "      <td>64</td>\n",
       "      <td>790</td>\n",
       "      <td>28</td>\n",
       "      <td>2</td>\n",
       "      <td>umap</td>\n",
       "      <td>True</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>None</td>\n",
       "      <td>0.550309</td>\n",
       "      <td>0.526594</td>\n",
       "      <td>[0.5241069198101423, 0.35545454545454547, 0.45...</td>\n",
       "      <td>0.529580</td>\n",
       "      <td>[0.5237144283574638, 0.3095803642121932, 0.482...</td>\n",
       "      <td>0.528892</td>\n",
       "      <td>[0.5245, 0.41728922091782283, 0.43199065966141...</td>\n",
       "      <td>None</td>\n",
       "      <td>0.732320</td>\n",
       "      <td>...</td>\n",
       "      <td>focal</td>\n",
       "      <td>2</td>\n",
       "      <td>True</td>\n",
       "      <td>5</td>\n",
       "      <td>64</td>\n",
       "      <td>790</td>\n",
       "      <td>28</td>\n",
       "      <td>2</td>\n",
       "      <td>umap</td>\n",
       "      <td>True</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>None</td>\n",
       "      <td>0.555740</td>\n",
       "      <td>0.532936</td>\n",
       "      <td>[0.5250059822924145, 0.3744075829383886, 0.462...</td>\n",
       "      <td>0.536962</td>\n",
       "      <td>[0.5034419458467186, 0.33674339300937767, 0.49...</td>\n",
       "      <td>0.533899</td>\n",
       "      <td>[0.5485, 0.4215581643543223, 0.430823117338003...</td>\n",
       "      <td>None</td>\n",
       "      <td>0.725380</td>\n",
       "      <td>...</td>\n",
       "      <td>focal</td>\n",
       "      <td>2</td>\n",
       "      <td>True</td>\n",
       "      <td>5</td>\n",
       "      <td>64</td>\n",
       "      <td>790</td>\n",
       "      <td>28</td>\n",
       "      <td>2</td>\n",
       "      <td>umap</td>\n",
       "      <td>True</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows × 30 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "   loss  accuracy        f1  \\\n",
       "0  None  0.563735  0.535800   \n",
       "0  None  0.567506  0.537299   \n",
       "0  None  0.550158  0.522643   \n",
       "0  None  0.550309  0.526594   \n",
       "0  None  0.555740  0.532936   \n",
       "\n",
       "                                           f1_scores  precision  \\\n",
       "0  [0.5480354879594423, 0.3586597451628126, 0.476...   0.535847   \n",
       "0  [0.5556869236226057, 0.35235732009925563, 0.46...   0.540395   \n",
       "0  [0.5192540566723178, 0.32952853598014886, 0.46...   0.526138   \n",
       "0  [0.5241069198101423, 0.35545454545454547, 0.45...   0.529580   \n",
       "0  [0.5250059822924145, 0.3744075829383886, 0.462...   0.536962   \n",
       "\n",
       "                                    precision_scores    recall  \\\n",
       "0  [0.5557840616966581, 0.32148900169204736, 0.50...  0.539116   \n",
       "0  [0.5271422162404665, 0.3293135435992579, 0.507...  0.537892   \n",
       "0  [0.5035227806481917, 0.3079777365491651, 0.482...  0.521232   \n",
       "0  [0.5237144283574638, 0.3095803642121932, 0.482...  0.528892   \n",
       "0  [0.5034419458467186, 0.33674339300937767, 0.49...  0.533899   \n",
       "\n",
       "                                       recall_scores valid_loss  \\\n",
       "0  [0.5405, 0.4055496264674493, 0.448920023350846...       None   \n",
       "0  [0.5875, 0.37886872998932764, 0.42673671920607...       None   \n",
       "0  [0.536, 0.35432230522945574, 0.455341506129597...       None   \n",
       "0  [0.5245, 0.41728922091782283, 0.43199065966141...       None   \n",
       "0  [0.5485, 0.4215581643543223, 0.430823117338003...       None   \n",
       "\n",
       "   valid_accuracy  ...  loss_function gamma  k_fold n_splits  batch_size  \\\n",
       "0        0.732540  ...          focal     2    True        5          64   \n",
       "0        0.729566  ...          focal     2    True        5          64   \n",
       "0        0.725711  ...          focal     2    True        5          64   \n",
       "0        0.732320  ...          focal     2    True        5          64   \n",
       "0        0.725380  ...          focal     2    True        5          64   \n",
       "\n",
       "  input_dim dimension  sig_depth  method  log_signature  \n",
       "0       790        28          2    umap           True  \n",
       "0       790        28          2    umap           True  \n",
       "0       790        28          2    umap           True  \n",
       "0       790        28          2    umap           True  \n",
       "0       790        28          2    umap           True  \n",
       "\n",
       "[5 rows x 30 columns]"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "best_ffn_logsignature_umap_kfold"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "db662960",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.5310541080409561"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "best_ffn_logsignature_umap_kfold[\"f1\"].mean()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "266373f0",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.5337843288286749"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "best_ffn_logsignature_umap_kfold[\"precision\"].mean()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "11064150",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.5322062593169047"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "best_ffn_logsignature_umap_kfold[\"recall\"].mean()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "f9d8a18b",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([0.53441787, 0.35408155, 0.46530654, 0.77041048])"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "np.stack(best_ffn_logsignature_umap_kfold[\"f1_scores\"]).mean(axis=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "28d6b708",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([0.52272109, 0.32102081, 0.49567492, 0.7957205 ])"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "np.stack(best_ffn_logsignature_umap_kfold[\"precision_scores\"]).mean(axis=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "4f57cc89",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([0.5474    , 0.39551761, 0.43876241, 0.74714502])"
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "np.stack(best_ffn_logsignature_umap_kfold[\"recall_scores\"]).mean(axis=0)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0de6f338",
   "metadata": {},
   "source": [
    "### Using random projections"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "bcf5003d",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "0526437887344611801ee7a8f60ea54e",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/3 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "676878a281eb430682f982d8dc5f5906",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/1 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[INFO] Concatenating the embeddings to the dataframe...\n",
      "[INFO] - columns beginning with 'e' denote the full embddings.\n",
      "[INFO] - columns beginning with 'd' denote the dimension reduced embeddings.\n",
      "[INFO] Adding time feature columns into dataframe in `.df`.\n",
      "[INFO] Adding 'time_encoding' and feature...\n",
      "[INFO] Adding 'time_diff' and feature...\n",
      "[INFO] Adding 'timeline_index' feature...\n",
      "[INFO] Padding ids and storing in `.df_padded` and `.array_padded` attributes.\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "601c0be4061443e49b34a43dbcb32b26",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/13551 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "ffn_logsignature_grp_kfold, best_ffn_logsignature_grp_kfold, _, __ = histories_baseline_hyperparameter_search(\n",
    "    num_epochs=num_epochs,\n",
    "    df=anno_mi,\n",
    "    id_column=\"transcript_id\",\n",
    "    label_column=\"main_therapist_behaviour\",\n",
    "    embeddings=sbert_embeddings,\n",
    "    y_data=y_data_therapist,\n",
    "    output_dim=output_dim_therapist,\n",
    "    hidden_dim_sizes=hidden_dim_sizes,\n",
    "    dropout_rates=dropout_rates,\n",
    "    learning_rates=learning_rates,\n",
    "    use_signatures=True,\n",
    "    seeds=seeds,\n",
    "    loss=loss,\n",
    "    gamma=gamma,\n",
    "    log_signature=True,\n",
    "    dim_reduce_methods=[\"gaussian_random_projection\"],\n",
    "    dimension_and_sig_depths=log_signature_dimensions_and_sig_depths,\n",
    "    path_indices=therapist_index,\n",
    "    split_ids=therapist_transcript_id,\n",
    "    k_fold=True,\n",
    "    patience=patience,\n",
    "    validation_metric=validation_metric,\n",
    "    results_output=f\"{output_dir}/ffn_logsignature_grp_focal_{gamma}_kfold.csv\",\n",
    "    verbose=False\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "id": "9c137d34",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/var/folders/l7/bnn1j6bs3bqfskq2jlq55yh80000gr/T/ipykernel_53974/2536377135.py:1: FutureWarning: The default value of numeric_only in DataFrameGroupBy.mean is deprecated. In a future version, numeric_only will default to False. Either specify numeric_only or select only columns which should be valid for the function.\n",
      "  ffn_logsignature_grp_kfold.groupby([\"dimension\", \"sig_depth\", \"hidden_dim\", \"dropout_rate\", \"learning_rate\"]).mean()\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th>accuracy</th>\n",
       "      <th>f1</th>\n",
       "      <th>precision</th>\n",
       "      <th>recall</th>\n",
       "      <th>valid_accuracy</th>\n",
       "      <th>valid_f1</th>\n",
       "      <th>valid_precision</th>\n",
       "      <th>valid_recall</th>\n",
       "      <th>seed</th>\n",
       "      <th>gamma</th>\n",
       "      <th>k_fold</th>\n",
       "      <th>n_splits</th>\n",
       "      <th>batch_size</th>\n",
       "      <th>model_id</th>\n",
       "      <th>input_dim</th>\n",
       "      <th>log_signature</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>dimension</th>\n",
       "      <th>sig_depth</th>\n",
       "      <th>hidden_dim</th>\n",
       "      <th>dropout_rate</th>\n",
       "      <th>learning_rate</th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th rowspan=\"5\" valign=\"top\">6</th>\n",
       "      <th rowspan=\"5\" valign=\"top\">4</th>\n",
       "      <th rowspan=\"5\" valign=\"top\">(128, 128)</th>\n",
       "      <th rowspan=\"3\" valign=\"top\">0.1</th>\n",
       "      <th>0.0001</th>\n",
       "      <td>0.664806</td>\n",
       "      <td>0.638037</td>\n",
       "      <td>0.639940</td>\n",
       "      <td>0.639976</td>\n",
       "      <td>0.783675</td>\n",
       "      <td>0.768401</td>\n",
       "      <td>0.766770</td>\n",
       "      <td>0.770608</td>\n",
       "      <td>274.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>5.0</td>\n",
       "      <td>64.0</td>\n",
       "      <td>2.70</td>\n",
       "      <td>790.0</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>0.0005</th>\n",
       "      <td>0.660854</td>\n",
       "      <td>0.635033</td>\n",
       "      <td>0.637411</td>\n",
       "      <td>0.637084</td>\n",
       "      <td>0.777704</td>\n",
       "      <td>0.762778</td>\n",
       "      <td>0.760982</td>\n",
       "      <td>0.765788</td>\n",
       "      <td>274.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>5.0</td>\n",
       "      <td>64.0</td>\n",
       "      <td>2.80</td>\n",
       "      <td>790.0</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>0.0010</th>\n",
       "      <td>0.661518</td>\n",
       "      <td>0.634862</td>\n",
       "      <td>0.637938</td>\n",
       "      <td>0.636096</td>\n",
       "      <td>0.773408</td>\n",
       "      <td>0.758661</td>\n",
       "      <td>0.756863</td>\n",
       "      <td>0.761814</td>\n",
       "      <td>274.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>5.0</td>\n",
       "      <td>64.0</td>\n",
       "      <td>2.60</td>\n",
       "      <td>790.0</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th rowspan=\"2\" valign=\"top\">0.2</th>\n",
       "      <th>0.0001</th>\n",
       "      <td>0.667914</td>\n",
       "      <td>0.641010</td>\n",
       "      <td>0.643034</td>\n",
       "      <td>0.642754</td>\n",
       "      <td>0.785371</td>\n",
       "      <td>0.770002</td>\n",
       "      <td>0.768645</td>\n",
       "      <td>0.771798</td>\n",
       "      <td>274.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>5.0</td>\n",
       "      <td>64.0</td>\n",
       "      <td>2.40</td>\n",
       "      <td>790.0</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>0.0005</th>\n",
       "      <td>0.664474</td>\n",
       "      <td>0.638683</td>\n",
       "      <td>0.640833</td>\n",
       "      <td>0.640276</td>\n",
       "      <td>0.780833</td>\n",
       "      <td>0.765605</td>\n",
       "      <td>0.764007</td>\n",
       "      <td>0.768112</td>\n",
       "      <td>274.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>5.0</td>\n",
       "      <td>64.0</td>\n",
       "      <td>2.50</td>\n",
       "      <td>790.0</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <th>...</th>\n",
       "      <th>...</th>\n",
       "      <th>...</th>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th rowspan=\"5\" valign=\"top\">28</th>\n",
       "      <th rowspan=\"5\" valign=\"top\">2</th>\n",
       "      <th rowspan=\"5\" valign=\"top\">(512, 512)</th>\n",
       "      <th rowspan=\"2\" valign=\"top\">0.2</th>\n",
       "      <th>0.0005</th>\n",
       "      <td>0.655604</td>\n",
       "      <td>0.629211</td>\n",
       "      <td>0.628320</td>\n",
       "      <td>0.632133</td>\n",
       "      <td>0.776382</td>\n",
       "      <td>0.761243</td>\n",
       "      <td>0.759283</td>\n",
       "      <td>0.765094</td>\n",
       "      <td>274.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>5.0</td>\n",
       "      <td>64.0</td>\n",
       "      <td>0.23</td>\n",
       "      <td>790.0</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>0.0010</th>\n",
       "      <td>0.656087</td>\n",
       "      <td>0.629127</td>\n",
       "      <td>0.628296</td>\n",
       "      <td>0.631871</td>\n",
       "      <td>0.770015</td>\n",
       "      <td>0.755492</td>\n",
       "      <td>0.753396</td>\n",
       "      <td>0.760240</td>\n",
       "      <td>274.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>5.0</td>\n",
       "      <td>64.0</td>\n",
       "      <td>0.21</td>\n",
       "      <td>790.0</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th rowspan=\"3\" valign=\"top\">0.5</th>\n",
       "      <th>0.0001</th>\n",
       "      <td>0.660582</td>\n",
       "      <td>0.632962</td>\n",
       "      <td>0.632499</td>\n",
       "      <td>0.634008</td>\n",
       "      <td>0.787729</td>\n",
       "      <td>0.772755</td>\n",
       "      <td>0.771369</td>\n",
       "      <td>0.774924</td>\n",
       "      <td>274.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>5.0</td>\n",
       "      <td>64.0</td>\n",
       "      <td>0.19</td>\n",
       "      <td>790.0</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>0.0005</th>\n",
       "      <td>0.659496</td>\n",
       "      <td>0.631181</td>\n",
       "      <td>0.630660</td>\n",
       "      <td>0.632602</td>\n",
       "      <td>0.779863</td>\n",
       "      <td>0.764584</td>\n",
       "      <td>0.763053</td>\n",
       "      <td>0.767549</td>\n",
       "      <td>274.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>5.0</td>\n",
       "      <td>64.0</td>\n",
       "      <td>0.20</td>\n",
       "      <td>790.0</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>0.0010</th>\n",
       "      <td>0.659949</td>\n",
       "      <td>0.631869</td>\n",
       "      <td>0.631239</td>\n",
       "      <td>0.634474</td>\n",
       "      <td>0.774664</td>\n",
       "      <td>0.758755</td>\n",
       "      <td>0.757094</td>\n",
       "      <td>0.761900</td>\n",
       "      <td>274.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>5.0</td>\n",
       "      <td>64.0</td>\n",
       "      <td>0.18</td>\n",
       "      <td>790.0</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>81 rows × 16 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                                                           accuracy        f1  \\\n",
       "dimension sig_depth hidden_dim dropout_rate learning_rate                       \n",
       "6         4         (128, 128) 0.1          0.0001         0.664806  0.638037   \n",
       "                                            0.0005         0.660854  0.635033   \n",
       "                                            0.0010         0.661518  0.634862   \n",
       "                               0.2          0.0001         0.667914  0.641010   \n",
       "                                            0.0005         0.664474  0.638683   \n",
       "...                                                             ...       ...   \n",
       "28        2         (512, 512) 0.2          0.0005         0.655604  0.629211   \n",
       "                                            0.0010         0.656087  0.629127   \n",
       "                               0.5          0.0001         0.660582  0.632962   \n",
       "                                            0.0005         0.659496  0.631181   \n",
       "                                            0.0010         0.659949  0.631869   \n",
       "\n",
       "                                                           precision  \\\n",
       "dimension sig_depth hidden_dim dropout_rate learning_rate              \n",
       "6         4         (128, 128) 0.1          0.0001          0.639940   \n",
       "                                            0.0005          0.637411   \n",
       "                                            0.0010          0.637938   \n",
       "                               0.2          0.0001          0.643034   \n",
       "                                            0.0005          0.640833   \n",
       "...                                                              ...   \n",
       "28        2         (512, 512) 0.2          0.0005          0.628320   \n",
       "                                            0.0010          0.628296   \n",
       "                               0.5          0.0001          0.632499   \n",
       "                                            0.0005          0.630660   \n",
       "                                            0.0010          0.631239   \n",
       "\n",
       "                                                             recall  \\\n",
       "dimension sig_depth hidden_dim dropout_rate learning_rate             \n",
       "6         4         (128, 128) 0.1          0.0001         0.639976   \n",
       "                                            0.0005         0.637084   \n",
       "                                            0.0010         0.636096   \n",
       "                               0.2          0.0001         0.642754   \n",
       "                                            0.0005         0.640276   \n",
       "...                                                             ...   \n",
       "28        2         (512, 512) 0.2          0.0005         0.632133   \n",
       "                                            0.0010         0.631871   \n",
       "                               0.5          0.0001         0.634008   \n",
       "                                            0.0005         0.632602   \n",
       "                                            0.0010         0.634474   \n",
       "\n",
       "                                                           valid_accuracy  \\\n",
       "dimension sig_depth hidden_dim dropout_rate learning_rate                   \n",
       "6         4         (128, 128) 0.1          0.0001               0.783675   \n",
       "                                            0.0005               0.777704   \n",
       "                                            0.0010               0.773408   \n",
       "                               0.2          0.0001               0.785371   \n",
       "                                            0.0005               0.780833   \n",
       "...                                                                   ...   \n",
       "28        2         (512, 512) 0.2          0.0005               0.776382   \n",
       "                                            0.0010               0.770015   \n",
       "                               0.5          0.0001               0.787729   \n",
       "                                            0.0005               0.779863   \n",
       "                                            0.0010               0.774664   \n",
       "\n",
       "                                                           valid_f1  \\\n",
       "dimension sig_depth hidden_dim dropout_rate learning_rate             \n",
       "6         4         (128, 128) 0.1          0.0001         0.768401   \n",
       "                                            0.0005         0.762778   \n",
       "                                            0.0010         0.758661   \n",
       "                               0.2          0.0001         0.770002   \n",
       "                                            0.0005         0.765605   \n",
       "...                                                             ...   \n",
       "28        2         (512, 512) 0.2          0.0005         0.761243   \n",
       "                                            0.0010         0.755492   \n",
       "                               0.5          0.0001         0.772755   \n",
       "                                            0.0005         0.764584   \n",
       "                                            0.0010         0.758755   \n",
       "\n",
       "                                                           valid_precision  \\\n",
       "dimension sig_depth hidden_dim dropout_rate learning_rate                    \n",
       "6         4         (128, 128) 0.1          0.0001                0.766770   \n",
       "                                            0.0005                0.760982   \n",
       "                                            0.0010                0.756863   \n",
       "                               0.2          0.0001                0.768645   \n",
       "                                            0.0005                0.764007   \n",
       "...                                                                    ...   \n",
       "28        2         (512, 512) 0.2          0.0005                0.759283   \n",
       "                                            0.0010                0.753396   \n",
       "                               0.5          0.0001                0.771369   \n",
       "                                            0.0005                0.763053   \n",
       "                                            0.0010                0.757094   \n",
       "\n",
       "                                                           valid_recall  \\\n",
       "dimension sig_depth hidden_dim dropout_rate learning_rate                 \n",
       "6         4         (128, 128) 0.1          0.0001             0.770608   \n",
       "                                            0.0005             0.765788   \n",
       "                                            0.0010             0.761814   \n",
       "                               0.2          0.0001             0.771798   \n",
       "                                            0.0005             0.768112   \n",
       "...                                                                 ...   \n",
       "28        2         (512, 512) 0.2          0.0005             0.765094   \n",
       "                                            0.0010             0.760240   \n",
       "                               0.5          0.0001             0.774924   \n",
       "                                            0.0005             0.767549   \n",
       "                                            0.0010             0.761900   \n",
       "\n",
       "                                                            seed  gamma  \\\n",
       "dimension sig_depth hidden_dim dropout_rate learning_rate                 \n",
       "6         4         (128, 128) 0.1          0.0001         274.0    2.0   \n",
       "                                            0.0005         274.0    2.0   \n",
       "                                            0.0010         274.0    2.0   \n",
       "                               0.2          0.0001         274.0    2.0   \n",
       "                                            0.0005         274.0    2.0   \n",
       "...                                                          ...    ...   \n",
       "28        2         (512, 512) 0.2          0.0005         274.0    2.0   \n",
       "                                            0.0010         274.0    2.0   \n",
       "                               0.5          0.0001         274.0    2.0   \n",
       "                                            0.0005         274.0    2.0   \n",
       "                                            0.0010         274.0    2.0   \n",
       "\n",
       "                                                           k_fold  n_splits  \\\n",
       "dimension sig_depth hidden_dim dropout_rate learning_rate                     \n",
       "6         4         (128, 128) 0.1          0.0001            1.0       5.0   \n",
       "                                            0.0005            1.0       5.0   \n",
       "                                            0.0010            1.0       5.0   \n",
       "                               0.2          0.0001            1.0       5.0   \n",
       "                                            0.0005            1.0       5.0   \n",
       "...                                                           ...       ...   \n",
       "28        2         (512, 512) 0.2          0.0005            1.0       5.0   \n",
       "                                            0.0010            1.0       5.0   \n",
       "                               0.5          0.0001            1.0       5.0   \n",
       "                                            0.0005            1.0       5.0   \n",
       "                                            0.0010            1.0       5.0   \n",
       "\n",
       "                                                           batch_size  \\\n",
       "dimension sig_depth hidden_dim dropout_rate learning_rate               \n",
       "6         4         (128, 128) 0.1          0.0001               64.0   \n",
       "                                            0.0005               64.0   \n",
       "                                            0.0010               64.0   \n",
       "                               0.2          0.0001               64.0   \n",
       "                                            0.0005               64.0   \n",
       "...                                                               ...   \n",
       "28        2         (512, 512) 0.2          0.0005               64.0   \n",
       "                                            0.0010               64.0   \n",
       "                               0.5          0.0001               64.0   \n",
       "                                            0.0005               64.0   \n",
       "                                            0.0010               64.0   \n",
       "\n",
       "                                                           model_id  \\\n",
       "dimension sig_depth hidden_dim dropout_rate learning_rate             \n",
       "6         4         (128, 128) 0.1          0.0001             2.70   \n",
       "                                            0.0005             2.80   \n",
       "                                            0.0010             2.60   \n",
       "                               0.2          0.0001             2.40   \n",
       "                                            0.0005             2.50   \n",
       "...                                                             ...   \n",
       "28        2         (512, 512) 0.2          0.0005             0.23   \n",
       "                                            0.0010             0.21   \n",
       "                               0.5          0.0001             0.19   \n",
       "                                            0.0005             0.20   \n",
       "                                            0.0010             0.18   \n",
       "\n",
       "                                                           input_dim  \\\n",
       "dimension sig_depth hidden_dim dropout_rate learning_rate              \n",
       "6         4         (128, 128) 0.1          0.0001             790.0   \n",
       "                                            0.0005             790.0   \n",
       "                                            0.0010             790.0   \n",
       "                               0.2          0.0001             790.0   \n",
       "                                            0.0005             790.0   \n",
       "...                                                              ...   \n",
       "28        2         (512, 512) 0.2          0.0005             790.0   \n",
       "                                            0.0010             790.0   \n",
       "                               0.5          0.0001             790.0   \n",
       "                                            0.0005             790.0   \n",
       "                                            0.0010             790.0   \n",
       "\n",
       "                                                           log_signature  \n",
       "dimension sig_depth hidden_dim dropout_rate learning_rate                 \n",
       "6         4         (128, 128) 0.1          0.0001                   1.0  \n",
       "                                            0.0005                   1.0  \n",
       "                                            0.0010                   1.0  \n",
       "                               0.2          0.0001                   1.0  \n",
       "                                            0.0005                   1.0  \n",
       "...                                                                  ...  \n",
       "28        2         (512, 512) 0.2          0.0005                   1.0  \n",
       "                                            0.0010                   1.0  \n",
       "                               0.5          0.0001                   1.0  \n",
       "                                            0.0005                   1.0  \n",
       "                                            0.0010                   1.0  \n",
       "\n",
       "[81 rows x 16 columns]"
      ]
     },
     "execution_count": 40,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "ffn_logsignature_grp_kfold.groupby([\"dimension\", \"sig_depth\", \"hidden_dim\", \"dropout_rate\", \"learning_rate\"]).mean()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "id": "3fc8b08d",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>loss</th>\n",
       "      <th>accuracy</th>\n",
       "      <th>f1</th>\n",
       "      <th>f1_scores</th>\n",
       "      <th>precision</th>\n",
       "      <th>precision_scores</th>\n",
       "      <th>recall</th>\n",
       "      <th>recall_scores</th>\n",
       "      <th>valid_loss</th>\n",
       "      <th>valid_accuracy</th>\n",
       "      <th>...</th>\n",
       "      <th>loss_function</th>\n",
       "      <th>gamma</th>\n",
       "      <th>k_fold</th>\n",
       "      <th>n_splits</th>\n",
       "      <th>batch_size</th>\n",
       "      <th>input_dim</th>\n",
       "      <th>dimension</th>\n",
       "      <th>sig_depth</th>\n",
       "      <th>method</th>\n",
       "      <th>log_signature</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>None</td>\n",
       "      <td>0.665711</td>\n",
       "      <td>0.635158</td>\n",
       "      <td>[0.6934875534322353, 0.47052280311457173, 0.57...</td>\n",
       "      <td>0.636587</td>\n",
       "      <td>[0.697521497218007, 0.4912891986062718, 0.5746...</td>\n",
       "      <td>0.634396</td>\n",
       "      <td>[0.6895, 0.45144076840981856, 0.57501459427904...</td>\n",
       "      <td>None</td>\n",
       "      <td>0.787178</td>\n",
       "      <td>...</td>\n",
       "      <td>focal</td>\n",
       "      <td>2</td>\n",
       "      <td>True</td>\n",
       "      <td>5</td>\n",
       "      <td>64</td>\n",
       "      <td>790</td>\n",
       "      <td>28</td>\n",
       "      <td>2</td>\n",
       "      <td>gaussian_random_projection</td>\n",
       "      <td>True</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>None</td>\n",
       "      <td>0.665108</td>\n",
       "      <td>0.636989</td>\n",
       "      <td>[0.6986128625472887, 0.4807590933052187, 0.573...</td>\n",
       "      <td>0.636205</td>\n",
       "      <td>[0.7048346055979644, 0.475, 0.5843446601941747...</td>\n",
       "      <td>0.638087</td>\n",
       "      <td>[0.6925, 0.48665955176093917, 0.56217162872154...</td>\n",
       "      <td>None</td>\n",
       "      <td>0.790482</td>\n",
       "      <td>...</td>\n",
       "      <td>focal</td>\n",
       "      <td>2</td>\n",
       "      <td>True</td>\n",
       "      <td>5</td>\n",
       "      <td>64</td>\n",
       "      <td>790</td>\n",
       "      <td>28</td>\n",
       "      <td>2</td>\n",
       "      <td>gaussian_random_projection</td>\n",
       "      <td>True</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>None</td>\n",
       "      <td>0.665711</td>\n",
       "      <td>0.636030</td>\n",
       "      <td>[0.6984126984126984, 0.46935568360398117, 0.56...</td>\n",
       "      <td>0.635073</td>\n",
       "      <td>[0.7039106145251397, 0.4609053497942387, 0.575...</td>\n",
       "      <td>0.637251</td>\n",
       "      <td>[0.693, 0.4781216648879402, 0.5557501459427904...</td>\n",
       "      <td>None</td>\n",
       "      <td>0.788940</td>\n",
       "      <td>...</td>\n",
       "      <td>focal</td>\n",
       "      <td>2</td>\n",
       "      <td>True</td>\n",
       "      <td>5</td>\n",
       "      <td>64</td>\n",
       "      <td>790</td>\n",
       "      <td>28</td>\n",
       "      <td>2</td>\n",
       "      <td>gaussian_random_projection</td>\n",
       "      <td>True</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>None</td>\n",
       "      <td>0.658169</td>\n",
       "      <td>0.630600</td>\n",
       "      <td>[0.687888198757764, 0.46961038961038964, 0.571...</td>\n",
       "      <td>0.629797</td>\n",
       "      <td>[0.7129828326180258, 0.4574898785425101, 0.570...</td>\n",
       "      <td>0.632141</td>\n",
       "      <td>[0.6645, 0.4823906083244397, 0.572679509632224...</td>\n",
       "      <td>None</td>\n",
       "      <td>0.791584</td>\n",
       "      <td>...</td>\n",
       "      <td>focal</td>\n",
       "      <td>2</td>\n",
       "      <td>True</td>\n",
       "      <td>5</td>\n",
       "      <td>64</td>\n",
       "      <td>790</td>\n",
       "      <td>28</td>\n",
       "      <td>2</td>\n",
       "      <td>gaussian_random_projection</td>\n",
       "      <td>True</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>None</td>\n",
       "      <td>0.670840</td>\n",
       "      <td>0.642574</td>\n",
       "      <td>[0.7000503271263211, 0.4844981607987389, 0.579...</td>\n",
       "      <td>0.641693</td>\n",
       "      <td>[0.704660587639311, 0.4772256728778468, 0.5912...</td>\n",
       "      <td>0.643758</td>\n",
       "      <td>[0.6955, 0.4919957310565635, 0.567425569176882...</td>\n",
       "      <td>None</td>\n",
       "      <td>0.789381</td>\n",
       "      <td>...</td>\n",
       "      <td>focal</td>\n",
       "      <td>2</td>\n",
       "      <td>True</td>\n",
       "      <td>5</td>\n",
       "      <td>64</td>\n",
       "      <td>790</td>\n",
       "      <td>28</td>\n",
       "      <td>2</td>\n",
       "      <td>gaussian_random_projection</td>\n",
       "      <td>True</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows × 30 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "   loss  accuracy        f1  \\\n",
       "0  None  0.665711  0.635158   \n",
       "0  None  0.665108  0.636989   \n",
       "0  None  0.665711  0.636030   \n",
       "0  None  0.658169  0.630600   \n",
       "0  None  0.670840  0.642574   \n",
       "\n",
       "                                           f1_scores  precision  \\\n",
       "0  [0.6934875534322353, 0.47052280311457173, 0.57...   0.636587   \n",
       "0  [0.6986128625472887, 0.4807590933052187, 0.573...   0.636205   \n",
       "0  [0.6984126984126984, 0.46935568360398117, 0.56...   0.635073   \n",
       "0  [0.687888198757764, 0.46961038961038964, 0.571...   0.629797   \n",
       "0  [0.7000503271263211, 0.4844981607987389, 0.579...   0.641693   \n",
       "\n",
       "                                    precision_scores    recall  \\\n",
       "0  [0.697521497218007, 0.4912891986062718, 0.5746...  0.634396   \n",
       "0  [0.7048346055979644, 0.475, 0.5843446601941747...  0.638087   \n",
       "0  [0.7039106145251397, 0.4609053497942387, 0.575...  0.637251   \n",
       "0  [0.7129828326180258, 0.4574898785425101, 0.570...  0.632141   \n",
       "0  [0.704660587639311, 0.4772256728778468, 0.5912...  0.643758   \n",
       "\n",
       "                                       recall_scores valid_loss  \\\n",
       "0  [0.6895, 0.45144076840981856, 0.57501459427904...       None   \n",
       "0  [0.6925, 0.48665955176093917, 0.56217162872154...       None   \n",
       "0  [0.693, 0.4781216648879402, 0.5557501459427904...       None   \n",
       "0  [0.6645, 0.4823906083244397, 0.572679509632224...       None   \n",
       "0  [0.6955, 0.4919957310565635, 0.567425569176882...       None   \n",
       "\n",
       "   valid_accuracy  ...  loss_function gamma  k_fold n_splits  batch_size  \\\n",
       "0        0.787178  ...          focal     2    True        5          64   \n",
       "0        0.790482  ...          focal     2    True        5          64   \n",
       "0        0.788940  ...          focal     2    True        5          64   \n",
       "0        0.791584  ...          focal     2    True        5          64   \n",
       "0        0.789381  ...          focal     2    True        5          64   \n",
       "\n",
       "  input_dim dimension  sig_depth                      method  log_signature  \n",
       "0       790        28          2  gaussian_random_projection           True  \n",
       "0       790        28          2  gaussian_random_projection           True  \n",
       "0       790        28          2  gaussian_random_projection           True  \n",
       "0       790        28          2  gaussian_random_projection           True  \n",
       "0       790        28          2  gaussian_random_projection           True  \n",
       "\n",
       "[5 rows x 30 columns]"
      ]
     },
     "execution_count": 33,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "best_ffn_logsignature_grp_kfold"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "id": "0ff79def",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.6362703006106869"
      ]
     },
     "execution_count": 34,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "best_ffn_logsignature_grp_kfold[\"f1\"].mean()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "id": "5d58b6c4",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.6358709901229604"
      ]
     },
     "execution_count": 35,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "best_ffn_logsignature_grp_kfold[\"precision\"].mean()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "id": "65de0ee4",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.6371265260022316"
      ]
     },
     "execution_count": 36,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "best_ffn_logsignature_grp_kfold[\"recall\"].mean()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "id": "d0301fcf",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([0.69569033, 0.47494923, 0.57276259, 0.80167906])"
      ]
     },
     "execution_count": 37,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "np.stack(best_ffn_logsignature_grp_kfold[\"f1_scores\"]).mean(axis=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "id": "ee0738ae",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([0.70478203, 0.47238202, 0.57917129, 0.78714862])"
      ]
     },
     "execution_count": 38,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "np.stack(best_ffn_logsignature_grp_kfold[\"precision_scores\"]).mean(axis=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "id": "7d4bd7ed",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([0.687     , 0.47812166, 0.56660829, 0.81677615])"
      ]
     },
     "execution_count": 39,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "np.stack(best_ffn_logsignature_grp_kfold[\"recall_scores\"]).mean(axis=0)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "nlpsig-networks",
   "language": "python",
   "name": "nlpsig-networks"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.16"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
