{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "2a2ab372-fcac-4506-add6-2cfc51d61ab8",
   "metadata": {},
   "outputs": [],
   "source": [
    "seed = 2023\n",
    "from nlpsig_networks.scripts.swnu_network_functions import (\n",
    "    obtain_SWNUNetwork_input\n",
    ")\n",
    "from nlpsig_networks.utils import obtain_paths_mask, obtain_signatures_mask"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "4a3f950d",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "os.chdir(\"Rumours/\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4e0ad91f-9f08-419e-8119-c93715159d28",
   "metadata": {},
   "source": [
    "## Rumours"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "dff20ec3-c34b-4058-8ec5-ddf94d63e348",
   "metadata": {},
   "outputs": [],
   "source": [
    "%run load_sbert-embeddings.py"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "24fadcec-ab8d-4a2b-b7f5-e746c4ee1f8c",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>id</th>\n",
       "      <th>label</th>\n",
       "      <th>datetime</th>\n",
       "      <th>text</th>\n",
       "      <th>timeline_id</th>\n",
       "      <th>set</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>5.249902e+17</td>\n",
       "      <td>0</td>\n",
       "      <td>2014-10-22 18:26:23</td>\n",
       "      <td>Police have clarified that there were two shoo...</td>\n",
       "      <td>0</td>\n",
       "      <td>train</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>5.249906e+17</td>\n",
       "      <td>0</td>\n",
       "      <td>2014-10-22 18:27:58</td>\n",
       "      <td>@CTVNews you guys \"confirmed\" there were 3 sho...</td>\n",
       "      <td>0</td>\n",
       "      <td>train</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>5.249908e+17</td>\n",
       "      <td>1</td>\n",
       "      <td>2014-10-22 18:28:46</td>\n",
       "      <td>@CTVNews get it right. http://t.co/GHYxMuzPG9</td>\n",
       "      <td>0</td>\n",
       "      <td>train</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>5.249927e+17</td>\n",
       "      <td>1</td>\n",
       "      <td>2014-10-22 18:36:29</td>\n",
       "      <td>RT @CTVNews Police have clarified that there w...</td>\n",
       "      <td>0</td>\n",
       "      <td>train</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>5.250038e+17</td>\n",
       "      <td>1</td>\n",
       "      <td>2014-10-22 19:20:41</td>\n",
       "      <td>@CTVNews @ctvsaskatoon so what happened at Rid...</td>\n",
       "      <td>0</td>\n",
       "      <td>train</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "             id label            datetime  \\\n",
       "0  5.249902e+17     0 2014-10-22 18:26:23   \n",
       "1  5.249906e+17     0 2014-10-22 18:27:58   \n",
       "2  5.249908e+17     1 2014-10-22 18:28:46   \n",
       "3  5.249927e+17     1 2014-10-22 18:36:29   \n",
       "4  5.250038e+17     1 2014-10-22 19:20:41   \n",
       "\n",
       "                                                text timeline_id    set  \n",
       "0  Police have clarified that there were two shoo...           0  train  \n",
       "1  @CTVNews you guys \"confirmed\" there were 3 sho...           0  train  \n",
       "2      @CTVNews get it right. http://t.co/GHYxMuzPG9           0  train  \n",
       "3  RT @CTVNews Police have clarified that there w...           0  train  \n",
       "4  @CTVNews @ctvsaskatoon so what happened at Rid...           0  train  "
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_rumours.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "cd2259de",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "5568"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(df_rumours)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "e1908cc0-4b2b-4c1d-8b17-6c237ed1849a",
   "metadata": {
    "scrolled": true,
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[INFO] Concatenating the embeddings to the dataframe...\n",
      "[INFO] - columns beginning with 'e' denote the full embddings.\n",
      "[INFO] - columns beginning with 'd' denote the dimension reduced embeddings.\n",
      "[INFO] Adding time feature columns into dataframe in `.df`.\n",
      "[INFO] Adding 'time_encoding' feature...\n",
      "[INFO] Adding 'time_diff' feature...\n",
      "[INFO] Adding 'timeline_index' feature...\n",
      "[INFO] Padding ids and storing in `.df_padded` and `.array_padded` attributes.\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "19a6f75daa624649bce773dcfe4ef8c4",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/5568 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[INFO] The path was created for each item in the dataframe, by looking at its history, so to include embeddings in the FFN input, we concatenate the embeddings for each sentence / text.\n"
     ]
    }
   ],
   "source": [
    "x_data = obtain_SWNUNetwork_input(\n",
    "    method=\"umap\",\n",
    "    dimension=3,\n",
    "    df=df_rumours,\n",
    "    id_column='timeline_id',\n",
    "    label_column='label',\n",
    "    embeddings=sbert_embeddings,\n",
    "    k=10,\n",
    "    features=['time_encoding', 'timeline_index'],\n",
    "    standardise_method=None,\n",
    "    include_features_in_path=False,\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "63006582",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "dict_keys(['x_data', 'input_channels', 'embedding_dim', 'num_features'])"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "x_data.keys()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "ecadb0dc",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'path': tensor([[[ 4.2708, 11.1495, 10.6158],\n",
       "          [ 0.0000,  0.0000,  0.0000],\n",
       "          [ 0.0000,  0.0000,  0.0000],\n",
       "          ...,\n",
       "          [ 0.0000,  0.0000,  0.0000],\n",
       "          [ 0.0000,  0.0000,  0.0000],\n",
       "          [ 0.0000,  0.0000,  0.0000]],\n",
       " \n",
       "         [[ 4.2708, 11.1495, 10.6158],\n",
       "          [ 3.4460,  9.6966, 12.5073],\n",
       "          [ 0.0000,  0.0000,  0.0000],\n",
       "          ...,\n",
       "          [ 0.0000,  0.0000,  0.0000],\n",
       "          [ 0.0000,  0.0000,  0.0000],\n",
       "          [ 0.0000,  0.0000,  0.0000]],\n",
       " \n",
       "         [[ 4.2708, 11.1495, 10.6158],\n",
       "          [ 3.4460,  9.6966, 12.5073],\n",
       "          [ 9.4265,  7.5356, 12.5888],\n",
       "          ...,\n",
       "          [ 0.0000,  0.0000,  0.0000],\n",
       "          [ 0.0000,  0.0000,  0.0000],\n",
       "          [ 0.0000,  0.0000,  0.0000]],\n",
       " \n",
       "         ...,\n",
       " \n",
       "         [[ 4.9594, 10.2321, 11.3985],\n",
       "          [ 0.8624,  9.3122, 11.9263],\n",
       "          [ 2.2617, 10.3596, 12.9991],\n",
       "          ...,\n",
       "          [ 2.4673,  7.1607, 12.4286],\n",
       "          [ 2.9867,  7.8778, 12.6077],\n",
       "          [ 0.9499,  8.9366, 13.1869]],\n",
       " \n",
       "         [[ 0.8624,  9.3122, 11.9263],\n",
       "          [ 2.2617, 10.3596, 12.9991],\n",
       "          [ 3.0017, 10.6473, 11.2386],\n",
       "          ...,\n",
       "          [ 2.9867,  7.8778, 12.6077],\n",
       "          [ 0.9499,  8.9366, 13.1869],\n",
       "          [ 2.5714,  8.6735, 13.2103]],\n",
       " \n",
       "         [[ 2.2617, 10.3596, 12.9991],\n",
       "          [ 3.0017, 10.6473, 11.2386],\n",
       "          [ 0.9858,  6.1898, 17.6910],\n",
       "          ...,\n",
       "          [ 0.9499,  8.9366, 13.1869],\n",
       "          [ 2.5714,  8.6735, 13.2103],\n",
       "          [ 2.3202,  8.0964, 13.8633]]], dtype=torch.float64),\n",
       " 'features': tensor([[ 6.4823e-02,  9.3748e-03, -3.3364e-02,  ...,  1.8542e-03,\n",
       "           2.0148e+03,  1.0000e+00],\n",
       "         [-2.9260e-02, -5.3905e-02, -3.9863e-02,  ...,  9.3606e-02,\n",
       "           2.0148e+03,  2.0000e+00],\n",
       "         [-3.1863e-02,  5.5065e-02, -2.4028e-02,  ...,  9.3310e-02,\n",
       "           2.0148e+03,  3.0000e+00],\n",
       "         ...,\n",
       "         [-2.2057e-03,  8.0860e-02, -9.9185e-02,  ..., -2.3929e-02,\n",
       "           2.0148e+03,  2.2000e+01],\n",
       "         [-3.1252e-02,  3.5479e-02,  7.2934e-03,  ..., -1.3536e-02,\n",
       "           2.0148e+03,  2.3000e+01],\n",
       "         [ 1.1187e-02,  8.0548e-02, -4.1098e-02,  ...,  8.9290e-02,\n",
       "           2.0148e+03,  2.4000e+01]])}"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "x_data[\"x_data\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "2abd7518",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([5568, 10, 3])"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "x_data[\"x_data\"][\"path\"].shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "cdee30cb",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[ 6.4823e-02,  9.3748e-03, -3.3364e-02,  ...,  1.8542e-03,\n",
       "          2.0148e+03,  1.0000e+00],\n",
       "        [-2.9260e-02, -5.3905e-02, -3.9863e-02,  ...,  9.3606e-02,\n",
       "          2.0148e+03,  2.0000e+00],\n",
       "        [-3.1863e-02,  5.5065e-02, -2.4028e-02,  ...,  9.3310e-02,\n",
       "          2.0148e+03,  3.0000e+00],\n",
       "        ...,\n",
       "        [-2.2057e-03,  8.0860e-02, -9.9185e-02,  ..., -2.3929e-02,\n",
       "          2.0148e+03,  2.2000e+01],\n",
       "        [-3.1252e-02,  3.5479e-02,  7.2934e-03,  ..., -1.3536e-02,\n",
       "          2.0148e+03,  2.3000e+01],\n",
       "        [ 1.1187e-02,  8.0548e-02, -4.1098e-02,  ...,  8.9290e-02,\n",
       "          2.0148e+03,  2.4000e+01]])"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "x_data[\"x_data\"][\"features\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "65c266e5",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "3"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "x_data[\"input_channels\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "20ebaf67",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "384"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "x_data[\"embedding_dim\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "297955c3",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "2"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "x_data[\"num_features\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "f0b55c30-40af-42b9-9325-a0fcd3547ec0",
   "metadata": {},
   "outputs": [],
   "source": [
    "path = x_data[\"x_data\"][\"path\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "155810f6-0e44-4d7d-a379-fd75d373b5ea",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([5568, 10, 3])"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "path.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "bd0279d2",
   "metadata": {},
   "outputs": [],
   "source": [
    "import signatory"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "5d93c687",
   "metadata": {},
   "outputs": [],
   "source": [
    "signatures = signatory.logsignature(path, 2, stream=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "24dfcc8a",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([5568, 9, 6])"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "signatures.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "b83def21",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[ 4.2708, 11.1495, 10.6158],\n",
       "        [ 0.0000,  0.0000,  0.0000],\n",
       "        [ 0.0000,  0.0000,  0.0000],\n",
       "        [ 0.0000,  0.0000,  0.0000],\n",
       "        [ 0.0000,  0.0000,  0.0000],\n",
       "        [ 0.0000,  0.0000,  0.0000],\n",
       "        [ 0.0000,  0.0000,  0.0000],\n",
       "        [ 0.0000,  0.0000,  0.0000],\n",
       "        [ 0.0000,  0.0000,  0.0000],\n",
       "        [ 0.0000,  0.0000,  0.0000]], dtype=torch.float64)"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "path[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "c6292716",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[ -4.2708, -11.1495, -10.6158,   0.0000,   0.0000,   0.0000],\n",
       "        [ -4.2708, -11.1495, -10.6158,   0.0000,   0.0000,   0.0000],\n",
       "        [ -4.2708, -11.1495, -10.6158,   0.0000,   0.0000,   0.0000],\n",
       "        [ -4.2708, -11.1495, -10.6158,   0.0000,   0.0000,   0.0000],\n",
       "        [ -4.2708, -11.1495, -10.6158,   0.0000,   0.0000,   0.0000],\n",
       "        [ -4.2708, -11.1495, -10.6158,   0.0000,   0.0000,   0.0000],\n",
       "        [ -4.2708, -11.1495, -10.6158,   0.0000,   0.0000,   0.0000],\n",
       "        [ -4.2708, -11.1495, -10.6158,   0.0000,   0.0000,   0.0000],\n",
       "        [ -4.2708, -11.1495, -10.6158,   0.0000,   0.0000,   0.0000]],\n",
       "       dtype=torch.float64)"
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "signatures[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "b39081ce",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[ 4.2708, 11.1495, 10.6158],\n",
       "        [ 3.4460,  9.6966, 12.5073],\n",
       "        [ 9.4265,  7.5356, 12.5888],\n",
       "        [ 0.0000,  0.0000,  0.0000],\n",
       "        [ 0.0000,  0.0000,  0.0000],\n",
       "        [ 0.0000,  0.0000,  0.0000],\n",
       "        [ 0.0000,  0.0000,  0.0000],\n",
       "        [ 0.0000,  0.0000,  0.0000],\n",
       "        [ 0.0000,  0.0000,  0.0000],\n",
       "        [ 0.0000,  0.0000,  0.0000]], dtype=torch.float64)"
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "path[2]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "929d040d",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[ -0.8247,  -1.4529,   1.8914,   0.0000,   0.0000,   0.0000],\n",
       "        [  5.1557,  -3.6139,   1.9729,   5.2355,  -5.6894,   1.9845],\n",
       "        [ -4.2708, -11.1495, -10.6158, -31.2234, -28.8427,  32.1654],\n",
       "        [ -4.2708, -11.1495, -10.6158, -31.2234, -28.8427,  32.1654],\n",
       "        [ -4.2708, -11.1495, -10.6158, -31.2234, -28.8427,  32.1654],\n",
       "        [ -4.2708, -11.1495, -10.6158, -31.2234, -28.8427,  32.1654],\n",
       "        [ -4.2708, -11.1495, -10.6158, -31.2234, -28.8427,  32.1654],\n",
       "        [ -4.2708, -11.1495, -10.6158, -31.2234, -28.8427,  32.1654],\n",
       "        [ -4.2708, -11.1495, -10.6158, -31.2234, -28.8427,  32.1654]],\n",
       "       dtype=torch.float64)"
      ]
     },
     "execution_count": 22,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "signatures[2]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9760fab0-d2c8-4651-b95e-fdfaf755fedb",
   "metadata": {},
   "source": [
    "`True` values in the mask are the ones that indicate to MultiheadAttention to ignore in attention calculation."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "6d2aefe3",
   "metadata": {},
   "outputs": [],
   "source": [
    "path_mask = obtain_paths_mask(path)\n",
    "signatures_mask = obtain_signatures_mask(signatures)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "9801f163",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([5568, 10])"
      ]
     },
     "execution_count": 24,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "path_mask.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "c92745bc",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([5568, 9])"
      ]
     },
     "execution_count": 25,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "signatures_mask.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "0b0b3a75",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([False,  True,  True,  True,  True,  True,  True,  True,  True,  True])"
      ]
     },
     "execution_count": 26,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "path_mask[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "1f45ae97",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([False,  True,  True,  True,  True,  True,  True,  True,  True])"
      ]
     },
     "execution_count": 27,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "signatures_mask[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "393a8e83",
   "metadata": {},
   "outputs": [],
   "source": [
    "path_mask_ = (torch.sum(path, 2) == 0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "id": "b553656a",
   "metadata": {},
   "outputs": [],
   "source": [
    "signatures_mask_ = path_mask[:,:-1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "id": "f0814d1e",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([False,  True,  True,  True,  True,  True,  True,  True,  True,  True])"
      ]
     },
     "execution_count": 30,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "path_mask_[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "id": "7da36c54",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 31,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "torch.equal(path_mask, path_mask_)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "id": "a586cf62",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 32,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "torch.equal(signatures_mask, signatures_mask_)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "id": "cbbe03bf",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.bool"
      ]
     },
     "execution_count": 33,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "path_mask.dtype"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "id": "c5bdbf15-52da-4cb6-822e-a58dd52ec239",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[ 4.2708, 11.1495, 10.6158],\n",
       "        [ 0.0000,  0.0000,  0.0000],\n",
       "        [ 0.0000,  0.0000,  0.0000],\n",
       "        [ 0.0000,  0.0000,  0.0000],\n",
       "        [ 0.0000,  0.0000,  0.0000],\n",
       "        [ 0.0000,  0.0000,  0.0000],\n",
       "        [ 0.0000,  0.0000,  0.0000],\n",
       "        [ 0.0000,  0.0000,  0.0000],\n",
       "        [ 0.0000,  0.0000,  0.0000],\n",
       "        [ 0.0000,  0.0000,  0.0000]], dtype=torch.float64)"
      ]
     },
     "execution_count": 34,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "path[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "id": "fe949afd",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[ -4.2708, -11.1495, -10.6158,   0.0000,   0.0000,   0.0000],\n",
       "        [ -4.2708, -11.1495, -10.6158,   0.0000,   0.0000,   0.0000],\n",
       "        [ -4.2708, -11.1495, -10.6158,   0.0000,   0.0000,   0.0000],\n",
       "        [ -4.2708, -11.1495, -10.6158,   0.0000,   0.0000,   0.0000],\n",
       "        [ -4.2708, -11.1495, -10.6158,   0.0000,   0.0000,   0.0000],\n",
       "        [ -4.2708, -11.1495, -10.6158,   0.0000,   0.0000,   0.0000],\n",
       "        [ -4.2708, -11.1495, -10.6158,   0.0000,   0.0000,   0.0000],\n",
       "        [ -4.2708, -11.1495, -10.6158,   0.0000,   0.0000,   0.0000],\n",
       "        [ -4.2708, -11.1495, -10.6158,   0.0000,   0.0000,   0.0000]],\n",
       "       dtype=torch.float64)"
      ]
     },
     "execution_count": 35,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "signatures[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "id": "c69488a9-dec3-46ca-ade8-11c64324186e",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([False,  True,  True,  True,  True,  True,  True,  True,  True,  True])"
      ]
     },
     "execution_count": 36,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "path_mask[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "id": "2e441b09-6a16-49d4-920b-d01f7acc33d1",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([False,  True,  True,  True,  True,  True,  True,  True,  True])"
      ]
     },
     "execution_count": 37,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "signatures_mask[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "id": "1a3c253c-4385-4dcc-b67f-8d4ed77de2fb",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[ 4.2708, 11.1495, 10.6158],\n",
       "        [ 3.4460,  9.6966, 12.5073],\n",
       "        [ 0.0000,  0.0000,  0.0000],\n",
       "        [ 0.0000,  0.0000,  0.0000],\n",
       "        [ 0.0000,  0.0000,  0.0000],\n",
       "        [ 0.0000,  0.0000,  0.0000],\n",
       "        [ 0.0000,  0.0000,  0.0000],\n",
       "        [ 0.0000,  0.0000,  0.0000],\n",
       "        [ 0.0000,  0.0000,  0.0000],\n",
       "        [ 0.0000,  0.0000,  0.0000]], dtype=torch.float64)"
      ]
     },
     "execution_count": 38,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "path[1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "id": "b01e9058",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[ -0.8247,  -1.4529,   1.8914,   0.0000,   0.0000,   0.0000],\n",
       "        [ -4.2708, -11.1495, -10.6158,   1.4952,   8.4165,  18.2558],\n",
       "        [ -4.2708, -11.1495, -10.6158,   1.4952,   8.4165,  18.2558],\n",
       "        [ -4.2708, -11.1495, -10.6158,   1.4952,   8.4165,  18.2558],\n",
       "        [ -4.2708, -11.1495, -10.6158,   1.4952,   8.4165,  18.2558],\n",
       "        [ -4.2708, -11.1495, -10.6158,   1.4952,   8.4165,  18.2558],\n",
       "        [ -4.2708, -11.1495, -10.6158,   1.4952,   8.4165,  18.2558],\n",
       "        [ -4.2708, -11.1495, -10.6158,   1.4952,   8.4165,  18.2558],\n",
       "        [ -4.2708, -11.1495, -10.6158,   1.4952,   8.4165,  18.2558]],\n",
       "       dtype=torch.float64)"
      ]
     },
     "execution_count": 39,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "signatures[1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "id": "fff7e21c-6344-4948-b1b7-0fb234e3fee9",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([False, False,  True,  True,  True,  True,  True,  True,  True,  True])"
      ]
     },
     "execution_count": 40,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "path_mask[1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "id": "4ef1a39d-a37d-4d94-a796-146cab881392",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([False, False,  True,  True,  True,  True,  True,  True,  True])"
      ]
     },
     "execution_count": 41,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "signatures_mask[1]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5c3996f6",
   "metadata": {},
   "source": [
    "## Path mask"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "id": "6f3d090f",
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch.nn as nn\n",
    "mha = nn.MultiheadAttention(\n",
    "    embed_dim=path.shape[2],\n",
    "    num_heads=1,\n",
    "    batch_first=True,\n",
    ").double()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "id": "11f2d8a1",
   "metadata": {},
   "outputs": [],
   "source": [
    "attn_output, attn_output_weights = mha(path.double(),\n",
    "                                       path.double(),\n",
    "                                       path.double(),\n",
    "                                       key_padding_mask=path_mask)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "id": "5744ef37",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([[ 4.2708, 11.1495, 10.6158],\n",
      "        [ 0.0000,  0.0000,  0.0000],\n",
      "        [ 0.0000,  0.0000,  0.0000],\n",
      "        [ 0.0000,  0.0000,  0.0000],\n",
      "        [ 0.0000,  0.0000,  0.0000],\n",
      "        [ 0.0000,  0.0000,  0.0000],\n",
      "        [ 0.0000,  0.0000,  0.0000],\n",
      "        [ 0.0000,  0.0000,  0.0000],\n",
      "        [ 0.0000,  0.0000,  0.0000],\n",
      "        [ 0.0000,  0.0000,  0.0000]], dtype=torch.float64)\n",
      "tensor([False,  True,  True,  True,  True,  True,  True,  True,  True,  True])\n",
      "tensor([[ 0.2119, -3.1534, -2.9155],\n",
      "        [ 0.2119, -3.1534, -2.9155],\n",
      "        [ 0.2119, -3.1534, -2.9155],\n",
      "        [ 0.2119, -3.1534, -2.9155],\n",
      "        [ 0.2119, -3.1534, -2.9155],\n",
      "        [ 0.2119, -3.1534, -2.9155],\n",
      "        [ 0.2119, -3.1534, -2.9155],\n",
      "        [ 0.2119, -3.1534, -2.9155],\n",
      "        [ 0.2119, -3.1534, -2.9155],\n",
      "        [ 0.2119, -3.1534, -2.9155]], dtype=torch.float64,\n",
      "       grad_fn=<SelectBackward>)\n"
     ]
    }
   ],
   "source": [
    "i=0\n",
    "print(path[i])\n",
    "print(path_mask[i])\n",
    "print(attn_output[i])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "id": "f839e9be",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([[ 4.2708, 11.1495, 10.6158],\n",
      "        [ 3.4460,  9.6966, 12.5073],\n",
      "        [ 0.0000,  0.0000,  0.0000],\n",
      "        [ 0.0000,  0.0000,  0.0000],\n",
      "        [ 0.0000,  0.0000,  0.0000],\n",
      "        [ 0.0000,  0.0000,  0.0000],\n",
      "        [ 0.0000,  0.0000,  0.0000],\n",
      "        [ 0.0000,  0.0000,  0.0000],\n",
      "        [ 0.0000,  0.0000,  0.0000],\n",
      "        [ 0.0000,  0.0000,  0.0000]], dtype=torch.float64)\n",
      "tensor([False, False,  True,  True,  True,  True,  True,  True,  True,  True])\n",
      "tensor([[ 0.1054, -2.6965, -2.4112],\n",
      "        [ 0.1054, -2.6964, -2.4110],\n",
      "        [ 0.1586, -2.9248, -2.6631],\n",
      "        [ 0.1586, -2.9248, -2.6631],\n",
      "        [ 0.1586, -2.9248, -2.6631],\n",
      "        [ 0.1586, -2.9248, -2.6631],\n",
      "        [ 0.1586, -2.9248, -2.6631],\n",
      "        [ 0.1586, -2.9248, -2.6631],\n",
      "        [ 0.1586, -2.9248, -2.6631],\n",
      "        [ 0.1586, -2.9248, -2.6631]], dtype=torch.float64,\n",
      "       grad_fn=<SelectBackward>)\n"
     ]
    }
   ],
   "source": [
    "i=1\n",
    "print(path[i])\n",
    "print(path_mask[i])\n",
    "print(attn_output[i])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "id": "4e68f3fb",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([[ 4.2708, 11.1495, 10.6158],\n",
      "        [ 3.4460,  9.6966, 12.5073],\n",
      "        [ 9.4265,  7.5356, 12.5888],\n",
      "        [ 0.0000,  0.0000,  0.0000],\n",
      "        [ 0.0000,  0.0000,  0.0000],\n",
      "        [ 0.0000,  0.0000,  0.0000],\n",
      "        [ 0.0000,  0.0000,  0.0000],\n",
      "        [ 0.0000,  0.0000,  0.0000],\n",
      "        [ 0.0000,  0.0000,  0.0000],\n",
      "        [ 0.0000,  0.0000,  0.0000]], dtype=torch.float64)\n",
      "tensor([False, False, False,  True,  True,  True,  True,  True,  True,  True])\n",
      "tensor([[ 0.1054, -2.6965, -2.4112],\n",
      "        [ 0.1054, -2.6964, -2.4110],\n",
      "        [ 0.1065, -2.7013, -2.4164],\n",
      "        [ 0.3979, -3.3791, -2.5113],\n",
      "        [ 0.3979, -3.3791, -2.5113],\n",
      "        [ 0.3979, -3.3791, -2.5113],\n",
      "        [ 0.3979, -3.3791, -2.5113],\n",
      "        [ 0.3979, -3.3791, -2.5113],\n",
      "        [ 0.3979, -3.3791, -2.5113],\n",
      "        [ 0.3979, -3.3791, -2.5113]], dtype=torch.float64,\n",
      "       grad_fn=<SelectBackward>)\n"
     ]
    }
   ],
   "source": [
    "i=2\n",
    "print(path[i])\n",
    "print(path_mask[i])\n",
    "print(attn_output[i])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "id": "76953e2c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([[ 4.2708, 11.1495, 10.6158],\n",
      "        [ 3.4460,  9.6966, 12.5073],\n",
      "        [ 9.4265,  7.5356, 12.5888],\n",
      "        [ 4.4903, 11.1706, 10.8094],\n",
      "        [ 4.4021, 10.7961, 13.9463],\n",
      "        [ 0.0000,  0.0000,  0.0000],\n",
      "        [ 0.0000,  0.0000,  0.0000],\n",
      "        [ 0.0000,  0.0000,  0.0000],\n",
      "        [ 0.0000,  0.0000,  0.0000],\n",
      "        [ 0.0000,  0.0000,  0.0000]], dtype=torch.float64)\n",
      "tensor([False, False, False, False, False,  True,  True,  True,  True,  True])\n",
      "tensor([[ 0.1055, -2.6969, -2.4114],\n",
      "        [ 0.1055, -2.6967, -2.4112],\n",
      "        [ 0.1073, -2.7047, -2.4193],\n",
      "        [ 0.1055, -2.6969, -2.4114],\n",
      "        [ 0.1054, -2.6965, -2.4110],\n",
      "        [ 0.3233, -3.3099, -2.6364],\n",
      "        [ 0.3233, -3.3099, -2.6364],\n",
      "        [ 0.3233, -3.3099, -2.6364],\n",
      "        [ 0.3233, -3.3099, -2.6364],\n",
      "        [ 0.3233, -3.3099, -2.6364]], dtype=torch.float64,\n",
      "       grad_fn=<SelectBackward>)\n"
     ]
    }
   ],
   "source": [
    "i=4\n",
    "print(path[i])\n",
    "print(path_mask[i])\n",
    "print(attn_output[i])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ae9b5792",
   "metadata": {},
   "source": [
    "## Signatures mask"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "id": "5070d2a8",
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch.nn as nn\n",
    "mha = nn.MultiheadAttention(\n",
    "    embed_dim=signatures.shape[2],\n",
    "    num_heads=1,\n",
    "    batch_first=True,\n",
    ").double()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "id": "799731db",
   "metadata": {},
   "outputs": [],
   "source": [
    "attn_output, attn_output_weights = mha(signatures.double(),\n",
    "                                       signatures.double(),\n",
    "                                       signatures.double(),\n",
    "                                       key_padding_mask=signatures_mask)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "id": "fe151a73",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([[ 4.2708, 11.1495, 10.6158],\n",
      "        [ 0.0000,  0.0000,  0.0000],\n",
      "        [ 0.0000,  0.0000,  0.0000],\n",
      "        [ 0.0000,  0.0000,  0.0000],\n",
      "        [ 0.0000,  0.0000,  0.0000],\n",
      "        [ 0.0000,  0.0000,  0.0000],\n",
      "        [ 0.0000,  0.0000,  0.0000],\n",
      "        [ 0.0000,  0.0000,  0.0000],\n",
      "        [ 0.0000,  0.0000,  0.0000],\n",
      "        [ 0.0000,  0.0000,  0.0000]], dtype=torch.float64)\n",
      "tensor([[ -4.2708, -11.1495, -10.6158,   0.0000,   0.0000,   0.0000],\n",
      "        [ -4.2708, -11.1495, -10.6158,   0.0000,   0.0000,   0.0000],\n",
      "        [ -4.2708, -11.1495, -10.6158,   0.0000,   0.0000,   0.0000],\n",
      "        [ -4.2708, -11.1495, -10.6158,   0.0000,   0.0000,   0.0000],\n",
      "        [ -4.2708, -11.1495, -10.6158,   0.0000,   0.0000,   0.0000],\n",
      "        [ -4.2708, -11.1495, -10.6158,   0.0000,   0.0000,   0.0000],\n",
      "        [ -4.2708, -11.1495, -10.6158,   0.0000,   0.0000,   0.0000],\n",
      "        [ -4.2708, -11.1495, -10.6158,   0.0000,   0.0000,   0.0000],\n",
      "        [ -4.2708, -11.1495, -10.6158,   0.0000,   0.0000,   0.0000]],\n",
      "       dtype=torch.float64)\n",
      "tensor([False,  True,  True,  True,  True,  True,  True,  True,  True])\n",
      "tensor([[-1.3817,  0.7638,  1.6566,  1.0076, -0.6364,  0.5818],\n",
      "        [-1.3817,  0.7638,  1.6566,  1.0076, -0.6364,  0.5818],\n",
      "        [-1.3817,  0.7638,  1.6566,  1.0076, -0.6364,  0.5818],\n",
      "        [-1.3817,  0.7638,  1.6566,  1.0076, -0.6364,  0.5818],\n",
      "        [-1.3817,  0.7638,  1.6566,  1.0076, -0.6364,  0.5818],\n",
      "        [-1.3817,  0.7638,  1.6566,  1.0076, -0.6364,  0.5818],\n",
      "        [-1.3817,  0.7638,  1.6566,  1.0076, -0.6364,  0.5818],\n",
      "        [-1.3817,  0.7638,  1.6566,  1.0076, -0.6364,  0.5818],\n",
      "        [-1.3817,  0.7638,  1.6566,  1.0076, -0.6364,  0.5818]],\n",
      "       dtype=torch.float64, grad_fn=<SelectBackward>)\n"
     ]
    }
   ],
   "source": [
    "i=0\n",
    "print(path[i])\n",
    "print(signatures[i])\n",
    "print(signatures_mask[i])\n",
    "print(attn_output[i])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "id": "b31204be",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([[ 4.2708, 11.1495, 10.6158],\n",
      "        [ 3.4460,  9.6966, 12.5073],\n",
      "        [ 0.0000,  0.0000,  0.0000],\n",
      "        [ 0.0000,  0.0000,  0.0000],\n",
      "        [ 0.0000,  0.0000,  0.0000],\n",
      "        [ 0.0000,  0.0000,  0.0000],\n",
      "        [ 0.0000,  0.0000,  0.0000],\n",
      "        [ 0.0000,  0.0000,  0.0000],\n",
      "        [ 0.0000,  0.0000,  0.0000],\n",
      "        [ 0.0000,  0.0000,  0.0000]], dtype=torch.float64)\n",
      "tensor([[ -0.8247,  -1.4529,   1.8914,   0.0000,   0.0000,   0.0000],\n",
      "        [ -4.2708, -11.1495, -10.6158,   1.4952,   8.4165,  18.2558],\n",
      "        [ -4.2708, -11.1495, -10.6158,   1.4952,   8.4165,  18.2558],\n",
      "        [ -4.2708, -11.1495, -10.6158,   1.4952,   8.4165,  18.2558],\n",
      "        [ -4.2708, -11.1495, -10.6158,   1.4952,   8.4165,  18.2558],\n",
      "        [ -4.2708, -11.1495, -10.6158,   1.4952,   8.4165,  18.2558],\n",
      "        [ -4.2708, -11.1495, -10.6158,   1.4952,   8.4165,  18.2558],\n",
      "        [ -4.2708, -11.1495, -10.6158,   1.4952,   8.4165,  18.2558],\n",
      "        [ -4.2708, -11.1495, -10.6158,   1.4952,   8.4165,  18.2558]],\n",
      "       dtype=torch.float64)\n",
      "tensor([False, False,  True,  True,  True,  True,  True,  True,  True])\n",
      "tensor([[-1.3068,  0.0687,  0.6741,  0.0280,  0.0495, -0.0562],\n",
      "        [-4.7593,  1.2969,  2.7764, -0.2022, -0.3387, -0.1806],\n",
      "        [-4.7593,  1.2969,  2.7764, -0.2022, -0.3387, -0.1806],\n",
      "        [-4.7593,  1.2969,  2.7764, -0.2022, -0.3387, -0.1806],\n",
      "        [-4.7593,  1.2969,  2.7764, -0.2022, -0.3387, -0.1806],\n",
      "        [-4.7593,  1.2969,  2.7764, -0.2022, -0.3387, -0.1806],\n",
      "        [-4.7593,  1.2969,  2.7764, -0.2022, -0.3387, -0.1806],\n",
      "        [-4.7593,  1.2969,  2.7764, -0.2022, -0.3387, -0.1806],\n",
      "        [-4.7593,  1.2969,  2.7764, -0.2022, -0.3387, -0.1806]],\n",
      "       dtype=torch.float64, grad_fn=<SelectBackward>)\n"
     ]
    }
   ],
   "source": [
    "i=1\n",
    "print(path[i])\n",
    "print(signatures[i])\n",
    "print(signatures_mask[i])\n",
    "print(attn_output[i])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "id": "975ac9aa",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([[ 4.2708, 11.1495, 10.6158],\n",
      "        [ 3.4460,  9.6966, 12.5073],\n",
      "        [ 9.4265,  7.5356, 12.5888],\n",
      "        [ 0.0000,  0.0000,  0.0000],\n",
      "        [ 0.0000,  0.0000,  0.0000],\n",
      "        [ 0.0000,  0.0000,  0.0000],\n",
      "        [ 0.0000,  0.0000,  0.0000],\n",
      "        [ 0.0000,  0.0000,  0.0000],\n",
      "        [ 0.0000,  0.0000,  0.0000],\n",
      "        [ 0.0000,  0.0000,  0.0000]], dtype=torch.float64)\n",
      "tensor([[ -0.8247,  -1.4529,   1.8914,   0.0000,   0.0000,   0.0000],\n",
      "        [  5.1557,  -3.6139,   1.9729,   5.2355,  -5.6894,   1.9845],\n",
      "        [ -4.2708, -11.1495, -10.6158, -31.2234, -28.8427,  32.1654],\n",
      "        [ -4.2708, -11.1495, -10.6158, -31.2234, -28.8427,  32.1654],\n",
      "        [ -4.2708, -11.1495, -10.6158, -31.2234, -28.8427,  32.1654],\n",
      "        [ -4.2708, -11.1495, -10.6158, -31.2234, -28.8427,  32.1654],\n",
      "        [ -4.2708, -11.1495, -10.6158, -31.2234, -28.8427,  32.1654],\n",
      "        [ -4.2708, -11.1495, -10.6158, -31.2234, -28.8427,  32.1654],\n",
      "        [ -4.2708, -11.1495, -10.6158, -31.2234, -28.8427,  32.1654]],\n",
      "       dtype=torch.float64)\n",
      "tensor([False, False, False,  True,  True,  True,  True,  True,  True])\n",
      "tensor([[-10.9829,  -8.4152,  12.5909,  -9.1314, -12.8212,   7.2558],\n",
      "        [ -0.9235,  -0.0677,   0.4410,   0.0538,   0.0925,  -0.0423],\n",
      "        [ -0.9274,  -0.0741,   0.4526,   0.0693,   0.0887,  -0.0381],\n",
      "        [ -0.9274,  -0.0741,   0.4526,   0.0693,   0.0887,  -0.0381],\n",
      "        [ -0.9274,  -0.0741,   0.4526,   0.0693,   0.0887,  -0.0381],\n",
      "        [ -0.9274,  -0.0741,   0.4526,   0.0693,   0.0887,  -0.0381],\n",
      "        [ -0.9274,  -0.0741,   0.4526,   0.0693,   0.0887,  -0.0381],\n",
      "        [ -0.9274,  -0.0741,   0.4526,   0.0693,   0.0887,  -0.0381],\n",
      "        [ -0.9274,  -0.0741,   0.4526,   0.0693,   0.0887,  -0.0381]],\n",
      "       dtype=torch.float64, grad_fn=<SelectBackward>)\n"
     ]
    }
   ],
   "source": [
    "i=2\n",
    "print(path[i])\n",
    "print(signatures[i])\n",
    "print(signatures_mask[i])\n",
    "print(attn_output[i])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "id": "66ed096a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([[ 4.2708, 11.1495, 10.6158],\n",
      "        [ 3.4460,  9.6966, 12.5073],\n",
      "        [ 9.4265,  7.5356, 12.5888],\n",
      "        [ 4.4903, 11.1706, 10.8094],\n",
      "        [ 4.4021, 10.7961, 13.9463],\n",
      "        [ 0.0000,  0.0000,  0.0000],\n",
      "        [ 0.0000,  0.0000,  0.0000],\n",
      "        [ 0.0000,  0.0000,  0.0000],\n",
      "        [ 0.0000,  0.0000,  0.0000],\n",
      "        [ 0.0000,  0.0000,  0.0000]], dtype=torch.float64)\n",
      "tensor([[-8.2473e-01, -1.4529e+00,  1.8914e+00,  0.0000e+00,  0.0000e+00,\n",
      "          0.0000e+00],\n",
      "        [ 5.1557e+00, -3.6139e+00,  1.9729e+00,  5.2355e+00, -5.6894e+00,\n",
      "          1.9845e+00],\n",
      "        [ 2.1951e-01,  2.1107e-02,  1.9351e-01,  5.6866e+00, -5.4071e+00,\n",
      "          1.6140e+00],\n",
      "        [ 1.3132e-01, -3.5339e-01,  3.3305e+00,  5.6464e+00, -5.0542e+00,\n",
      "          1.6833e+00],\n",
      "        [-4.2708e+00, -1.1149e+01, -1.0616e+01,  4.1597e+00,  1.3605e+00,\n",
      "          2.2126e+01],\n",
      "        [-4.2708e+00, -1.1149e+01, -1.0616e+01,  4.1597e+00,  1.3605e+00,\n",
      "          2.2126e+01],\n",
      "        [-4.2708e+00, -1.1149e+01, -1.0616e+01,  4.1597e+00,  1.3605e+00,\n",
      "          2.2126e+01],\n",
      "        [-4.2708e+00, -1.1149e+01, -1.0616e+01,  4.1597e+00,  1.3605e+00,\n",
      "          2.2126e+01],\n",
      "        [-4.2708e+00, -1.1149e+01, -1.0616e+01,  4.1597e+00,  1.3605e+00,\n",
      "          2.2126e+01]], dtype=torch.float64)\n",
      "tensor([False, False, False, False, False,  True,  True,  True,  True])\n",
      "tensor([[-1.4634, -0.5957,  1.4118,  1.2694, -0.6452,  0.5199],\n",
      "        [-0.9236, -0.0677,  0.4410,  0.0539,  0.0925, -0.0423],\n",
      "        [-1.0869, -0.3265,  0.9027,  0.6729, -0.0754,  0.1345],\n",
      "        [-1.1189, -0.3781,  0.9713,  0.7848, -0.1511,  0.1913],\n",
      "        [-6.4063, -0.0101,  4.7580,  0.3720, -2.0992,  0.9816],\n",
      "        [-6.4063, -0.0101,  4.7580,  0.3720, -2.0992,  0.9816],\n",
      "        [-6.4063, -0.0101,  4.7580,  0.3720, -2.0992,  0.9816],\n",
      "        [-6.4063, -0.0101,  4.7580,  0.3720, -2.0992,  0.9816],\n",
      "        [-6.4063, -0.0101,  4.7580,  0.3720, -2.0992,  0.9816]],\n",
      "       dtype=torch.float64, grad_fn=<SelectBackward>)\n"
     ]
    }
   ],
   "source": [
    "i=4\n",
    "print(path[i])\n",
    "print(signatures[i])\n",
    "print(signatures_mask[i])\n",
    "print(attn_output[i])"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "nlpsig-networks (Conda)",
   "language": "python",
   "name": "sys_nlpsig-networks"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.17"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
