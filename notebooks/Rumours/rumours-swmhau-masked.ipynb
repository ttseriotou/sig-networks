{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "a983a5e8",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pickle\n",
    "import os\n",
    "\n",
    "seed = 2023"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "a4b2805b-1454-407d-9a0a-740341ebfd3c",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'cuda'"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import torch\n",
    "\n",
    "# set device\n",
    "device = \"cuda\" if torch.cuda.is_available() else \"cpu\"\n",
    "device"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "e4e666cc",
   "metadata": {},
   "outputs": [],
   "source": [
    "from nlpsig_networks.scripts.swmhau_network_functions import (\n",
    "    swmhau_network_hyperparameter_search\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "6e918dde",
   "metadata": {},
   "outputs": [],
   "source": [
    "output_dir = \"rumours_output\"\n",
    "if not os.path.isdir(output_dir):\n",
    "    os.makedirs(output_dir)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f7409a03",
   "metadata": {},
   "source": [
    "## Rumours"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "f00bb922",
   "metadata": {},
   "outputs": [],
   "source": [
    "%run load_sbert-embeddings.py"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "720d820f",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>id</th>\n",
       "      <th>label</th>\n",
       "      <th>datetime</th>\n",
       "      <th>text</th>\n",
       "      <th>timeline_id</th>\n",
       "      <th>set</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>5.249902e+17</td>\n",
       "      <td>0</td>\n",
       "      <td>2014-10-22 18:26:23</td>\n",
       "      <td>Police have clarified that there were two shoo...</td>\n",
       "      <td>0</td>\n",
       "      <td>train</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>5.249906e+17</td>\n",
       "      <td>0</td>\n",
       "      <td>2014-10-22 18:27:58</td>\n",
       "      <td>@CTVNews you guys \"confirmed\" there were 3 sho...</td>\n",
       "      <td>0</td>\n",
       "      <td>train</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>5.249908e+17</td>\n",
       "      <td>1</td>\n",
       "      <td>2014-10-22 18:28:46</td>\n",
       "      <td>@CTVNews get it right. http://t.co/GHYxMuzPG9</td>\n",
       "      <td>0</td>\n",
       "      <td>train</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>5.249927e+17</td>\n",
       "      <td>1</td>\n",
       "      <td>2014-10-22 18:36:29</td>\n",
       "      <td>RT @CTVNews Police have clarified that there w...</td>\n",
       "      <td>0</td>\n",
       "      <td>train</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>5.250038e+17</td>\n",
       "      <td>1</td>\n",
       "      <td>2014-10-22 19:20:41</td>\n",
       "      <td>@CTVNews @ctvsaskatoon so what happened at Rid...</td>\n",
       "      <td>0</td>\n",
       "      <td>train</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "             id label            datetime  \\\n",
       "0  5.249902e+17     0 2014-10-22 18:26:23   \n",
       "1  5.249906e+17     0 2014-10-22 18:27:58   \n",
       "2  5.249908e+17     1 2014-10-22 18:28:46   \n",
       "3  5.249927e+17     1 2014-10-22 18:36:29   \n",
       "4  5.250038e+17     1 2014-10-22 19:20:41   \n",
       "\n",
       "                                                text timeline_id    set  \n",
       "0  Police have clarified that there were two shoo...           0  train  \n",
       "1  @CTVNews you guys \"confirmed\" there were 3 sho...           0  train  \n",
       "2      @CTVNews get it right. http://t.co/GHYxMuzPG9           0  train  \n",
       "3  RT @CTVNews Police have clarified that there w...           0  train  \n",
       "4  @CTVNews @ctvsaskatoon so what happened at Rid...           0  train  "
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_rumours.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "da4ff92d",
   "metadata": {},
   "source": [
    "# swmhau Network"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "90bfd87c",
   "metadata": {},
   "outputs": [],
   "source": [
    "features = [\"time_encoding\", \"timeline_index\"]\n",
    "standardise_method = [\"z_score\", None]\n",
    "num_features = len(features)\n",
    "add_time_in_path = True"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "9e9bee3b",
   "metadata": {},
   "outputs": [],
   "source": [
    "num_epochs = 100\n",
    "embedding_dim = 384\n",
    "dimensions = [15] # [50, 15]\n",
    "# define swmhau parameters: (output_channels, sig_depth, num_heads)\n",
    "swmhau_parameters = [(12, 3, 10), (8, 4, 6), (8, 4, 12)]\n",
    "num_layers = [1]\n",
    "ffn_hidden_dim_sizes = [[256,256],[512,512]]\n",
    "dropout_rates = [0.5, 0.1]\n",
    "learning_rates = [1e-3, 1e-4, 5e-4]\n",
    "seeds = [1, 12, 123]\n",
    "loss = \"focal\"\n",
    "gamma = 2\n",
    "validation_metric = \"f1\"\n",
    "patience = 5\n",
    "split_indices = (df_rumours[df_rumours['set']=='train'].index,\n",
    "                 df_rumours[df_rumours['set']=='dev'].index,\n",
    "                 df_rumours[df_rumours['set']=='test'].index)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "89a4bcc6-f9e4-4763-9bdf-b21003d5d257",
   "metadata": {},
   "source": [
    "## UMAP"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "3739e09a",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "8fa9981f0e3243f982dccd2de9358c8c",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/1 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "ee341853933348419237b3db65b5f015",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/1 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "4916226b18fa4f5f8fdcd4e442145c3a",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/1 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "##################################################\n",
      "dimension: 15 | method: umap\n",
      "[INFO] Concatenating the embeddings to the dataframe...\n",
      "[INFO] - columns beginning with 'e' denote the full embddings.\n",
      "[INFO] - columns beginning with 'd' denote the dimension reduced embeddings.\n",
      "[INFO] Adding time feature columns into dataframe in `.df`.\n",
      "[INFO] Adding 'time_encoding' feature...\n",
      "[INFO] Adding 'time_diff' feature...\n",
      "[INFO] Adding 'timeline_index' feature...\n",
      "[INFO] Padding ids and storing in `.df_padded` and `.array_padded` attributes.\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "be9a42c7d7ef4b9dbc86a009fd9f7223",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/5568 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[INFO] The path was created for each item in the dataframe, by looking at its history, so to include embeddings in the FFN input, we concatenate the embeddings for each sentence / text.\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "8ca1d94f97f741e48e33ee33c4acf32f",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/3 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "b7c395a64344467293c8100527a0c1a1",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/1 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "445e80edfbdc4a58b951d0b4c9963ef0",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/2 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "15794db5bb7f43d285d8dc1db336e458",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/2 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "3eb4968a49884e968f301286bd555729",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/3 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[10], line 2\u001b[0m\n\u001b[1;32m      1\u001b[0m size \u001b[38;5;241m=\u001b[39m \u001b[38;5;241m35\u001b[39m\n\u001b[0;32m----> 2\u001b[0m swmhau_network_umap, best_swmhau_network_umap, _, __ \u001b[38;5;241m=\u001b[39m \u001b[43mswmhau_network_hyperparameter_search\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m      3\u001b[0m \u001b[43m    \u001b[49m\u001b[43mnum_epochs\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mnum_epochs\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m      4\u001b[0m \u001b[43m    \u001b[49m\u001b[43mdf\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mdf_rumours\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m      5\u001b[0m \u001b[43m    \u001b[49m\u001b[43mid_column\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mtimeline_id\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m,\u001b[49m\n\u001b[1;32m      6\u001b[0m \u001b[43m    \u001b[49m\u001b[43mlabel_column\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mlabel\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m,\u001b[49m\n\u001b[1;32m      7\u001b[0m \u001b[43m    \u001b[49m\u001b[43membeddings\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43msbert_embeddings\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m      8\u001b[0m \u001b[43m    \u001b[49m\u001b[43my_data\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43my_data\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m      9\u001b[0m \u001b[43m    \u001b[49m\u001b[43membedding_dim\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43membedding_dim\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m     10\u001b[0m \u001b[43m    \u001b[49m\u001b[43moutput_dim\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43moutput_dim\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m     11\u001b[0m \u001b[43m    \u001b[49m\u001b[43mhistory_lengths\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43m[\u001b[49m\u001b[43msize\u001b[49m\u001b[43m]\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m     12\u001b[0m \u001b[43m    \u001b[49m\u001b[43mdim_reduce_methods\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43m[\u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mumap\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m]\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m     13\u001b[0m \u001b[43m    \u001b[49m\u001b[43mdimensions\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mdimensions\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m     14\u001b[0m \u001b[43m    \u001b[49m\u001b[43mlog_signature\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43;01mTrue\u001b[39;49;00m\u001b[43m,\u001b[49m\n\u001b[1;32m     15\u001b[0m \u001b[43m    \u001b[49m\u001b[43mswmhau_parameters\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mswmhau_parameters\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m     16\u001b[0m \u001b[43m    \u001b[49m\u001b[43mnum_layers\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mnum_layers\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m     17\u001b[0m \u001b[43m    \u001b[49m\u001b[43mffn_hidden_dim_sizes\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mffn_hidden_dim_sizes\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m     18\u001b[0m \u001b[43m    \u001b[49m\u001b[43mdropout_rates\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mdropout_rates\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m     19\u001b[0m \u001b[43m    \u001b[49m\u001b[43mlearning_rates\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mlearning_rates\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m     20\u001b[0m \u001b[43m    \u001b[49m\u001b[43mseeds\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mseeds\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m     21\u001b[0m \u001b[43m    \u001b[49m\u001b[43mloss\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mloss\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m     22\u001b[0m \u001b[43m    \u001b[49m\u001b[43mgamma\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mgamma\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m     23\u001b[0m \u001b[43m    \u001b[49m\u001b[43msplit_indices\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43msplit_indices\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m     24\u001b[0m \u001b[43m    \u001b[49m\u001b[43mk_fold\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43;01mFalse\u001b[39;49;00m\u001b[43m,\u001b[49m\n\u001b[1;32m     25\u001b[0m \u001b[43m    \u001b[49m\u001b[43mfeatures\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mfeatures\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m     26\u001b[0m \u001b[43m    \u001b[49m\u001b[43mstandardise_method\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mstandardise_method\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m     27\u001b[0m \u001b[43m    \u001b[49m\u001b[43madd_time_in_path\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43madd_time_in_path\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m     28\u001b[0m \u001b[43m    \u001b[49m\u001b[43mpatience\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mpatience\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m     29\u001b[0m \u001b[43m    \u001b[49m\u001b[43mvalidation_metric\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mvalidation_metric\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m     30\u001b[0m \u001b[43m    \u001b[49m\u001b[43mresults_output\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;124;43mf\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;132;43;01m{\u001b[39;49;00m\u001b[43moutput_dir\u001b[49m\u001b[38;5;132;43;01m}\u001b[39;49;00m\u001b[38;5;124;43m/swmhau_network_umap_focal_\u001b[39;49m\u001b[38;5;132;43;01m{\u001b[39;49;00m\u001b[43mgamma\u001b[49m\u001b[38;5;132;43;01m}\u001b[39;49;00m\u001b[38;5;124;43m_\u001b[39;49m\u001b[38;5;132;43;01m{\u001b[39;49;00m\u001b[43msize\u001b[49m\u001b[38;5;132;43;01m}\u001b[39;49;00m\u001b[38;5;124;43m.csv\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m,\u001b[49m\n\u001b[1;32m     31\u001b[0m \u001b[43m    \u001b[49m\u001b[43mverbose\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43;01mFalse\u001b[39;49;00m\n\u001b[1;32m     32\u001b[0m \u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m/bask/projects/v/vjgo8416-rough-paths/nlpsig-networks/nlpsig_networks/scripts/swmhau_network_functions.py:205\u001b[0m, in \u001b[0;36mswmhau_network_hyperparameter_search\u001b[0;34m(num_epochs, df, id_column, label_column, embeddings, y_data, embedding_dim, output_dim, history_lengths, dim_reduce_methods, dimensions, log_signature, swmhau_parameters, num_layers, ffn_hidden_dim_sizes, dropout_rates, learning_rates, seeds, loss, gamma, device, batch_size, features, standardise_method, add_time_in_path, augmentation_type, hidden_dim_aug, comb_method, path_indices, data_split_seed, split_ids, split_indices, k_fold, n_splits, patience, validation_metric, results_output, verbose)\u001b[0m\n\u001b[1;32m    203\u001b[0m verbose_model \u001b[38;5;241m=\u001b[39m verbose\n\u001b[1;32m    204\u001b[0m \u001b[38;5;28;01mfor\u001b[39;00m seed \u001b[38;5;129;01min\u001b[39;00m seeds:\n\u001b[0;32m--> 205\u001b[0m     _, results \u001b[38;5;241m=\u001b[39m \u001b[43mimplement_swmhau_network\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m    206\u001b[0m \u001b[43m        \u001b[49m\u001b[43mnum_epochs\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mnum_epochs\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    207\u001b[0m \u001b[43m        \u001b[49m\u001b[43mx_data\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mx_data\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    208\u001b[0m \u001b[43m        \u001b[49m\u001b[43my_data\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43my_data\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    209\u001b[0m \u001b[43m        \u001b[49m\u001b[43minput_channels\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43minput_channels\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    210\u001b[0m \u001b[43m        \u001b[49m\u001b[43moutput_channels\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43moutput_channels\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    211\u001b[0m \u001b[43m        \u001b[49m\u001b[43mnum_features\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43mlen\u001b[39;49m\u001b[43m(\u001b[49m\u001b[43mfeatures\u001b[49m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    212\u001b[0m \u001b[43m        \u001b[49m\u001b[43membedding_dim\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43membedding_dim\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    213\u001b[0m \u001b[43m        \u001b[49m\u001b[43mlog_signature\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mlog_signature\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    214\u001b[0m \u001b[43m        \u001b[49m\u001b[43msig_depth\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43msig_depth\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    215\u001b[0m \u001b[43m        \u001b[49m\u001b[43mnum_heads\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mnum_heads\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    216\u001b[0m \u001b[43m        \u001b[49m\u001b[43mnum_layers\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mn_layers\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    217\u001b[0m \u001b[43m        \u001b[49m\u001b[43mffn_hidden_dim\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mffn_hidden_dim\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    218\u001b[0m \u001b[43m        \u001b[49m\u001b[43moutput_dim\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43moutput_dim\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    219\u001b[0m \u001b[43m        \u001b[49m\u001b[43mdropout_rate\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mdropout\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    220\u001b[0m \u001b[43m        \u001b[49m\u001b[43mlearning_rate\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mlr\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    221\u001b[0m \u001b[43m        \u001b[49m\u001b[43mseed\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mseed\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    222\u001b[0m \u001b[43m        \u001b[49m\u001b[43mloss\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mloss\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    223\u001b[0m \u001b[43m        \u001b[49m\u001b[43mgamma\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mgamma\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    224\u001b[0m \u001b[43m        \u001b[49m\u001b[43mdevice\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mdevice\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    225\u001b[0m \u001b[43m        \u001b[49m\u001b[43mbatch_size\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mbatch_size\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    226\u001b[0m \u001b[43m        \u001b[49m\u001b[43maugmentation_type\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43maugmentation_type\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    227\u001b[0m \u001b[43m        \u001b[49m\u001b[43mhidden_dim_aug\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mhidden_dim_aug\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    228\u001b[0m \u001b[43m        \u001b[49m\u001b[43mcomb_method\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mcomb_method\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    229\u001b[0m \u001b[43m        \u001b[49m\u001b[43mdata_split_seed\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mdata_split_seed\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    230\u001b[0m \u001b[43m        \u001b[49m\u001b[43msplit_ids\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43msplit_ids\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    231\u001b[0m \u001b[43m        \u001b[49m\u001b[43msplit_indices\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43msplit_indices\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    232\u001b[0m \u001b[43m        \u001b[49m\u001b[43mk_fold\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mk_fold\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    233\u001b[0m \u001b[43m        \u001b[49m\u001b[43mn_splits\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mn_splits\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    234\u001b[0m \u001b[43m        \u001b[49m\u001b[43mpatience\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mpatience\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    235\u001b[0m \u001b[43m        \u001b[49m\u001b[43mverbose_training\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43;01mFalse\u001b[39;49;00m\u001b[43m,\u001b[49m\n\u001b[1;32m    236\u001b[0m \u001b[43m        \u001b[49m\u001b[43mverbose_results\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mverbose\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    237\u001b[0m \u001b[43m        \u001b[49m\u001b[43mverbose_model\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mverbose_model\u001b[49m\n\u001b[1;32m    238\u001b[0m \u001b[43m    \u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    239\u001b[0m     \u001b[38;5;66;03m# save metric that we want to validate on\u001b[39;00m\n\u001b[1;32m    240\u001b[0m     \u001b[38;5;66;03m# taking the mean over the performance on the folds for the seed\u001b[39;00m\n\u001b[1;32m    241\u001b[0m     \u001b[38;5;66;03m# if k_fold=False, .mean() just returns the performance for the seed\u001b[39;00m\n\u001b[1;32m    242\u001b[0m     scores\u001b[38;5;241m.\u001b[39mappend(results[\u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mvalid_\u001b[39m\u001b[38;5;132;01m{\u001b[39;00mvalidation_metric\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m\"\u001b[39m]\u001b[38;5;241m.\u001b[39mmean())\n",
      "File \u001b[0;32m/bask/projects/v/vjgo8416-rough-paths/nlpsig-networks/nlpsig_networks/scripts/swmhau_network_functions.py:82\u001b[0m, in \u001b[0;36mimplement_swmhau_network\u001b[0;34m(num_epochs, x_data, y_data, input_channels, num_features, embedding_dim, log_signature, sig_depth, num_heads, num_layers, ffn_hidden_dim, output_dim, dropout_rate, learning_rate, seed, loss, gamma, device, batch_size, output_channels, augmentation_type, hidden_dim_aug, comb_method, data_split_seed, split_ids, split_indices, k_fold, n_splits, patience, verbose_training, verbose_results, verbose_model)\u001b[0m\n\u001b[1;32m     79\u001b[0m     y_data \u001b[38;5;241m=\u001b[39m torch\u001b[38;5;241m.\u001b[39mtensor(y_data)\n\u001b[1;32m     80\u001b[0m x_data \u001b[38;5;241m=\u001b[39m x_data\u001b[38;5;241m.\u001b[39mfloat()\n\u001b[0;32m---> 82\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mimplement_model\u001b[49m\u001b[43m(\u001b[49m\u001b[43mmodel\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mswmhau_network_model\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m     83\u001b[0m \u001b[43m                       \u001b[49m\u001b[43mnum_epochs\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mnum_epochs\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m     84\u001b[0m \u001b[43m                       \u001b[49m\u001b[43mx_data\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mx_data\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m     85\u001b[0m \u001b[43m                       \u001b[49m\u001b[43my_data\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43my_data\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m     86\u001b[0m \u001b[43m                       \u001b[49m\u001b[43mlearning_rate\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mlearning_rate\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m     87\u001b[0m \u001b[43m                       \u001b[49m\u001b[43mseed\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mseed\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m     88\u001b[0m \u001b[43m                       \u001b[49m\u001b[43mloss\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mloss\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m     89\u001b[0m \u001b[43m                       \u001b[49m\u001b[43mgamma\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mgamma\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m     90\u001b[0m \u001b[43m                       \u001b[49m\u001b[43mdevice\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mdevice\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m     91\u001b[0m \u001b[43m                       \u001b[49m\u001b[43mbatch_size\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mbatch_size\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m     92\u001b[0m \u001b[43m                       \u001b[49m\u001b[43mdata_split_seed\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mdata_split_seed\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m     93\u001b[0m \u001b[43m                       \u001b[49m\u001b[43msplit_ids\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43msplit_ids\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m     94\u001b[0m \u001b[43m                       \u001b[49m\u001b[43msplit_indices\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43msplit_indices\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m     95\u001b[0m \u001b[43m                       \u001b[49m\u001b[43mk_fold\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mk_fold\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m     96\u001b[0m \u001b[43m                       \u001b[49m\u001b[43mn_splits\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mn_splits\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m     97\u001b[0m \u001b[43m                       \u001b[49m\u001b[43mpatience\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mpatience\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m     98\u001b[0m \u001b[43m                       \u001b[49m\u001b[43mverbose_training\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mverbose_training\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m     99\u001b[0m \u001b[43m                       \u001b[49m\u001b[43mverbose_results\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mverbose_results\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m/bask/projects/v/vjgo8416-rough-paths/nlpsig-networks/nlpsig_networks/scripts/implement_model.py:125\u001b[0m, in \u001b[0;36mimplement_model\u001b[0;34m(model, num_epochs, x_data, y_data, learning_rate, seed, loss, gamma, device, batch_size, data_split_seed, split_ids, split_indices, k_fold, n_splits, patience, verbose_training, verbose_results)\u001b[0m\n\u001b[1;32m    120\u001b[0m optimizer \u001b[38;5;241m=\u001b[39m torch\u001b[38;5;241m.\u001b[39moptim\u001b[38;5;241m.\u001b[39mAdam(model\u001b[38;5;241m.\u001b[39mparameters(),\n\u001b[1;32m    121\u001b[0m                              lr\u001b[38;5;241m=\u001b[39mlearning_rate,\n\u001b[1;32m    122\u001b[0m                              weight_decay\u001b[38;5;241m=\u001b[39mweight_decay_adam)\n\u001b[1;32m    124\u001b[0m \u001b[38;5;66;03m# train model\u001b[39;00m\n\u001b[0;32m--> 125\u001b[0m model \u001b[38;5;241m=\u001b[39m \u001b[43mtraining_pytorch\u001b[49m\u001b[43m(\u001b[49m\u001b[43mmodel\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mmodel\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    126\u001b[0m \u001b[43m                         \u001b[49m\u001b[43mtrain_loader\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mtrain\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    127\u001b[0m \u001b[43m                         \u001b[49m\u001b[43mcriterion\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mcriterion\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    128\u001b[0m \u001b[43m                         \u001b[49m\u001b[43moptimizer\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43moptimizer\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    129\u001b[0m \u001b[43m                         \u001b[49m\u001b[43mnum_epochs\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mnum_epochs\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    130\u001b[0m \u001b[43m                         \u001b[49m\u001b[43mvalid_loader\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mvalid\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    131\u001b[0m \u001b[43m                         \u001b[49m\u001b[43mseed\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mseed\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    132\u001b[0m \u001b[43m                         \u001b[49m\u001b[43mreturn_best\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mreturn_best\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    133\u001b[0m \u001b[43m                         \u001b[49m\u001b[43moutput\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mmodel_output\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    134\u001b[0m \u001b[43m                         \u001b[49m\u001b[43mearly_stopping\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mearly_stopping\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    135\u001b[0m \u001b[43m                         \u001b[49m\u001b[43mvalidation_metric\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mvalidation_metric\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    136\u001b[0m \u001b[43m                         \u001b[49m\u001b[43mpatience\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mpatience\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    137\u001b[0m \u001b[43m                         \u001b[49m\u001b[43mdevice\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mdevice\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    138\u001b[0m \u001b[43m                         \u001b[49m\u001b[43mverbose\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mverbose_training\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    140\u001b[0m \u001b[38;5;66;03m# evaluate on validation\u001b[39;00m\n\u001b[1;32m    141\u001b[0m valid_results \u001b[38;5;241m=\u001b[39m testing_pytorch(model\u001b[38;5;241m=\u001b[39mmodel,\n\u001b[1;32m    142\u001b[0m                                 test_loader\u001b[38;5;241m=\u001b[39mvalid,\n\u001b[1;32m    143\u001b[0m                                 criterion\u001b[38;5;241m=\u001b[39mcriterion,\n\u001b[1;32m    144\u001b[0m                                 device\u001b[38;5;241m=\u001b[39mdevice,\n\u001b[1;32m    145\u001b[0m                                 verbose\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mFalse\u001b[39;00m)\n",
      "File \u001b[0;32m/bask/projects/v/vjgo8416-rough-paths/nlpsig-networks/nlpsig_networks/pytorch_utils.py:440\u001b[0m, in \u001b[0;36mtraining_pytorch\u001b[0;34m(model, train_loader, criterion, optimizer, num_epochs, scheduler, valid_loader, seed, return_best, save_best, output, early_stopping, validation_metric, patience, device, verbose, verbose_epoch)\u001b[0m\n\u001b[1;32m    434\u001b[0m         \u001b[38;5;28mprint\u001b[39m(\n\u001b[1;32m    435\u001b[0m             \u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m[Train] | Epoch: \u001b[39m\u001b[38;5;132;01m{\u001b[39;00mepoch\u001b[38;5;241m+\u001b[39m\u001b[38;5;241m1\u001b[39m\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m/\u001b[39m\u001b[38;5;132;01m{\u001b[39;00mnum_epochs\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m || \u001b[39m\u001b[38;5;124m\"\u001b[39m \u001b[38;5;241m+\u001b[39m \u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mLoss: \u001b[39m\u001b[38;5;132;01m{\u001b[39;00mloss\u001b[38;5;241m.\u001b[39mitem()\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m\"\u001b[39m\n\u001b[1;32m    436\u001b[0m         )\n\u001b[1;32m    438\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28misinstance\u001b[39m(valid_loader, DataLoader):\n\u001b[1;32m    439\u001b[0m     \u001b[38;5;66;03m# compute loss, accuracy and F1 on validation set\u001b[39;00m\n\u001b[0;32m--> 440\u001b[0m     validation_results \u001b[38;5;241m=\u001b[39m \u001b[43mvalidation_pytorch\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m    441\u001b[0m \u001b[43m        \u001b[49m\u001b[43mmodel\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mmodel\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    442\u001b[0m \u001b[43m        \u001b[49m\u001b[43mvalid_loader\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mvalid_loader\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    443\u001b[0m \u001b[43m        \u001b[49m\u001b[43mcriterion\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mcriterion\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    444\u001b[0m \u001b[43m        \u001b[49m\u001b[43mepoch\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mepoch\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    445\u001b[0m \u001b[43m        \u001b[49m\u001b[43mdevice\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mdevice\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    446\u001b[0m \u001b[43m        \u001b[49m\u001b[43mverbose\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mverbose\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    447\u001b[0m \u001b[43m        \u001b[49m\u001b[43mverbose_epoch\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mverbose_epoch\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    448\u001b[0m \u001b[43m    \u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    450\u001b[0m     \u001b[38;5;66;03m# save metric that we want to use on validation set\u001b[39;00m\n\u001b[1;32m    451\u001b[0m     metric_v \u001b[38;5;241m=\u001b[39m validation_results[validation_metric]\n",
      "File \u001b[0;32m/bask/projects/v/vjgo8416-rough-paths/nlpsig-networks/nlpsig_networks/pytorch_utils.py:288\u001b[0m, in \u001b[0;36mvalidation_pytorch\u001b[0;34m(model, valid_loader, criterion, epoch, device, verbose, verbose_epoch)\u001b[0m\n\u001b[1;32m    285\u001b[0m \u001b[38;5;28;01mwith\u001b[39;00m torch\u001b[38;5;241m.\u001b[39mno_grad():\n\u001b[1;32m    286\u001b[0m     \u001b[38;5;28;01mfor\u001b[39;00m emb_v, labels_v \u001b[38;5;129;01min\u001b[39;00m valid_loader:\n\u001b[1;32m    287\u001b[0m         \u001b[38;5;66;03m# make prediction\u001b[39;00m\n\u001b[0;32m--> 288\u001b[0m         outputs \u001b[38;5;241m=\u001b[39m \u001b[43mmodel\u001b[49m\u001b[43m(\u001b[49m\u001b[43memb_v\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    289\u001b[0m         _, predicted_v \u001b[38;5;241m=\u001b[39m torch\u001b[38;5;241m.\u001b[39mmax(outputs\u001b[38;5;241m.\u001b[39mdata, \u001b[38;5;241m1\u001b[39m)\n\u001b[1;32m    290\u001b[0m         \u001b[38;5;66;03m# compute loss\u001b[39;00m\n",
      "File \u001b[0;32m/bask/projects/v/vjgo8416-rough-paths/envs/nlpsig-networks/lib/python3.8/site-packages/torch/nn/modules/module.py:1051\u001b[0m, in \u001b[0;36mModule._call_impl\u001b[0;34m(self, *input, **kwargs)\u001b[0m\n\u001b[1;32m   1047\u001b[0m \u001b[38;5;66;03m# If we don't have any hooks, we want to skip the rest of the logic in\u001b[39;00m\n\u001b[1;32m   1048\u001b[0m \u001b[38;5;66;03m# this function, and just call forward.\u001b[39;00m\n\u001b[1;32m   1049\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m (\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_backward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_forward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_backward_hooks\n\u001b[1;32m   1050\u001b[0m         \u001b[38;5;129;01mor\u001b[39;00m _global_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_forward_pre_hooks):\n\u001b[0;32m-> 1051\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mforward_call\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;28;43minput\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m   1052\u001b[0m \u001b[38;5;66;03m# Do not call functions when jit is used\u001b[39;00m\n\u001b[1;32m   1053\u001b[0m full_backward_hooks, non_full_backward_hooks \u001b[38;5;241m=\u001b[39m [], []\n",
      "File \u001b[0;32m/bask/projects/v/vjgo8416-rough-paths/nlpsig-networks/nlpsig_networks/swmhau_network.py:157\u001b[0m, in \u001b[0;36mSWMHAUNetwork.forward\u001b[0;34m(self, x)\u001b[0m\n\u001b[1;32m    154\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mforward\u001b[39m(\u001b[38;5;28mself\u001b[39m, x: torch\u001b[38;5;241m.\u001b[39mTensor):\n\u001b[1;32m    155\u001b[0m     \u001b[38;5;66;03m# x has dimensions [batch, length of signal, channels]\u001b[39;00m\n\u001b[1;32m    156\u001b[0m     \u001b[38;5;66;03m# use SWMHAU to obtain feature set\u001b[39;00m\n\u001b[0;32m--> 157\u001b[0m     out \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mswmhau\u001b[49m\u001b[43m(\u001b[49m\u001b[43mx\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    159\u001b[0m     \u001b[38;5;66;03m# combine last post embedding\u001b[39;00m\n\u001b[1;32m    160\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m x\u001b[38;5;241m.\u001b[39mshape[\u001b[38;5;241m2\u001b[39m] \u001b[38;5;241m>\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39minput_channels:\n\u001b[1;32m    161\u001b[0m         \u001b[38;5;66;03m# we have things to concatenate to the path\u001b[39;00m\n",
      "File \u001b[0;32m/bask/projects/v/vjgo8416-rough-paths/envs/nlpsig-networks/lib/python3.8/site-packages/torch/nn/modules/module.py:1051\u001b[0m, in \u001b[0;36mModule._call_impl\u001b[0;34m(self, *input, **kwargs)\u001b[0m\n\u001b[1;32m   1047\u001b[0m \u001b[38;5;66;03m# If we don't have any hooks, we want to skip the rest of the logic in\u001b[39;00m\n\u001b[1;32m   1048\u001b[0m \u001b[38;5;66;03m# this function, and just call forward.\u001b[39;00m\n\u001b[1;32m   1049\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m (\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_backward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_forward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_backward_hooks\n\u001b[1;32m   1050\u001b[0m         \u001b[38;5;129;01mor\u001b[39;00m _global_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_forward_pre_hooks):\n\u001b[0;32m-> 1051\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mforward_call\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;28;43minput\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m   1052\u001b[0m \u001b[38;5;66;03m# Do not call functions when jit is used\u001b[39;00m\n\u001b[1;32m   1053\u001b[0m full_backward_hooks, non_full_backward_hooks \u001b[38;5;241m=\u001b[39m [], []\n",
      "File \u001b[0;32m/bask/projects/v/vjgo8416-rough-paths/nlpsig-networks/nlpsig_networks/swmhau.py:238\u001b[0m, in \u001b[0;36mSWMHAU.forward\u001b[0;34m(self, x)\u001b[0m\n\u001b[1;32m    231\u001b[0m \u001b[38;5;28;01melif\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39maugmentation_type \u001b[38;5;241m==\u001b[39m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124msignatory\u001b[39m\u001b[38;5;124m\"\u001b[39m:\n\u001b[1;32m    232\u001b[0m     \u001b[38;5;66;03m# input has dimensions [batch, length of signal, channels]\u001b[39;00m\n\u001b[1;32m    233\u001b[0m     \u001b[38;5;66;03m# (signatory.Augment expects this)\u001b[39;00m\n\u001b[1;32m    234\u001b[0m     \u001b[38;5;66;03m# and get only the path information\u001b[39;00m\n\u001b[1;32m    235\u001b[0m     \u001b[38;5;66;03m# output has dimensions [batch, length of signal, channels]\u001b[39;00m\n\u001b[1;32m    236\u001b[0m     out \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39maugment(x[:, :, : \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39minput_channels])\n\u001b[0;32m--> 238\u001b[0m out \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mswmha\u001b[49m\u001b[43m(\u001b[49m\u001b[43mout\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    240\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m out\n",
      "File \u001b[0;32m/bask/projects/v/vjgo8416-rough-paths/envs/nlpsig-networks/lib/python3.8/site-packages/torch/nn/modules/module.py:1051\u001b[0m, in \u001b[0;36mModule._call_impl\u001b[0;34m(self, *input, **kwargs)\u001b[0m\n\u001b[1;32m   1047\u001b[0m \u001b[38;5;66;03m# If we don't have any hooks, we want to skip the rest of the logic in\u001b[39;00m\n\u001b[1;32m   1048\u001b[0m \u001b[38;5;66;03m# this function, and just call forward.\u001b[39;00m\n\u001b[1;32m   1049\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m (\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_backward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_forward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_backward_hooks\n\u001b[1;32m   1050\u001b[0m         \u001b[38;5;129;01mor\u001b[39;00m _global_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_forward_pre_hooks):\n\u001b[0;32m-> 1051\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mforward_call\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;28;43minput\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m   1052\u001b[0m \u001b[38;5;66;03m# Do not call functions when jit is used\u001b[39;00m\n\u001b[1;32m   1053\u001b[0m full_backward_hooks, non_full_backward_hooks \u001b[38;5;241m=\u001b[39m [], []\n",
      "File \u001b[0;32m/bask/projects/v/vjgo8416-rough-paths/nlpsig-networks/nlpsig_networks/swmhau.py:111\u001b[0m, in \u001b[0;36mSWMHA.forward\u001b[0;34m(self, x)\u001b[0m\n\u001b[1;32m    105\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mforward\u001b[39m(\u001b[38;5;28mself\u001b[39m, x: torch\u001b[38;5;241m.\u001b[39mTensor):\n\u001b[1;32m    106\u001b[0m     \u001b[38;5;66;03m# x has dimensions [batch, length of signal, channels]\u001b[39;00m\n\u001b[1;32m    107\u001b[0m     \n\u001b[1;32m    108\u001b[0m     \u001b[38;5;66;03m# take signature lifts and lstm\u001b[39;00m\n\u001b[1;32m    109\u001b[0m     \u001b[38;5;28;01mfor\u001b[39;00m l \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28mrange\u001b[39m(\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mnum_layers):\n\u001b[1;32m    110\u001b[0m         \u001b[38;5;66;03m# apply signature with lift layer\u001b[39;00m\n\u001b[0;32m--> 111\u001b[0m         x \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43msignature_layers\u001b[49m\u001b[43m[\u001b[49m\u001b[43ml\u001b[49m\u001b[43m]\u001b[49m\u001b[43m(\u001b[49m\u001b[43mx\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    112\u001b[0m         \u001b[38;5;66;03m# apply MHA layer to the signatures\u001b[39;00m\n\u001b[1;32m    113\u001b[0m         attention_out \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mmha_layers[l](x, x, x)[\u001b[38;5;241m0\u001b[39m]\n",
      "File \u001b[0;32m/bask/projects/v/vjgo8416-rough-paths/envs/nlpsig-networks/lib/python3.8/site-packages/torch/nn/modules/module.py:1051\u001b[0m, in \u001b[0;36mModule._call_impl\u001b[0;34m(self, *input, **kwargs)\u001b[0m\n\u001b[1;32m   1047\u001b[0m \u001b[38;5;66;03m# If we don't have any hooks, we want to skip the rest of the logic in\u001b[39;00m\n\u001b[1;32m   1048\u001b[0m \u001b[38;5;66;03m# this function, and just call forward.\u001b[39;00m\n\u001b[1;32m   1049\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m (\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_backward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_forward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_backward_hooks\n\u001b[1;32m   1050\u001b[0m         \u001b[38;5;129;01mor\u001b[39;00m _global_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_forward_pre_hooks):\n\u001b[0;32m-> 1051\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mforward_call\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;28;43minput\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m   1052\u001b[0m \u001b[38;5;66;03m# Do not call functions when jit is used\u001b[39;00m\n\u001b[1;32m   1053\u001b[0m full_backward_hooks, non_full_backward_hooks \u001b[38;5;241m=\u001b[39m [], []\n",
      "File \u001b[0;32m/bask/projects/v/vjgo8416-rough-paths/envs/nlpsig-networks/lib/python3.8/site-packages/signatory/logsignature_module.py:332\u001b[0m, in \u001b[0;36mLogSignature.forward\u001b[0;34m(self, path, basepoint)\u001b[0m\n\u001b[1;32m    320\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mforward\u001b[39m(\u001b[38;5;28mself\u001b[39m, path: torch\u001b[38;5;241m.\u001b[39mTensor, basepoint: Union[\u001b[38;5;28mbool\u001b[39m, torch\u001b[38;5;241m.\u001b[39mTensor] \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mFalse\u001b[39;00m) \u001b[38;5;241m-\u001b[39m\u001b[38;5;241m>\u001b[39m torch\u001b[38;5;241m.\u001b[39mTensor:\n\u001b[1;32m    321\u001b[0m \u001b[38;5;250m    \u001b[39m\u001b[38;5;124;03m\"\"\"The forward operation.\u001b[39;00m\n\u001b[1;32m    322\u001b[0m \n\u001b[1;32m    323\u001b[0m \u001b[38;5;124;03m    Arguments:\u001b[39;00m\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m    329\u001b[0m \u001b[38;5;124;03m        As :func:`signatory.logsignature`.\u001b[39;00m\n\u001b[1;32m    330\u001b[0m \u001b[38;5;124;03m    \"\"\"\u001b[39;00m\n\u001b[0;32m--> 332\u001b[0m     signature \u001b[38;5;241m=\u001b[39m \u001b[43msmodule\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43msignature\u001b[49m\u001b[43m(\u001b[49m\u001b[43mpath\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_depth\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mstream\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_stream\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mbasepoint\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mbasepoint\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    333\u001b[0m \u001b[43m                                  \u001b[49m\u001b[43minverse\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_inverse\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43minitial\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43;01mNone\u001b[39;49;00m\u001b[43m)\u001b[49m\n\u001b[1;32m    334\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_get_signature_to_logsignature_instance(path\u001b[38;5;241m.\u001b[39msize(\u001b[38;5;241m-\u001b[39m\u001b[38;5;241m1\u001b[39m))(signature)\n",
      "File \u001b[0;32m/bask/projects/v/vjgo8416-rough-paths/envs/nlpsig-networks/lib/python3.8/site-packages/signatory/signature_module.py:252\u001b[0m, in \u001b[0;36msignature\u001b[0;34m(path, depth, stream, basepoint, inverse, initial, scalar_term)\u001b[0m\n\u001b[1;32m    250\u001b[0m result \u001b[38;5;241m=\u001b[39m _signature_batch_trick(path, depth, stream, basepoint, inverse, initial, scalar_term)\n\u001b[1;32m    251\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m result \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:  \u001b[38;5;66;03m# Either because we disabled use of the batch trick, or because the batch trick doesn't apply\u001b[39;00m\n\u001b[0;32m--> 252\u001b[0m     result \u001b[38;5;241m=\u001b[39m \u001b[43m_SignatureFunction\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mapply\u001b[49m\u001b[43m(\u001b[49m\u001b[43mpath\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mtranspose\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m0\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m1\u001b[39;49m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mdepth\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mstream\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mbasepoint\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43minverse\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43minitial\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mscalar_term\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    254\u001b[0m \u001b[38;5;66;03m# We have to do the transpose outside of autograd.Function.apply to avoid PyTorch bug 24413\u001b[39;00m\n\u001b[1;32m    255\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m stream:\n\u001b[1;32m    256\u001b[0m     \u001b[38;5;66;03m# NOT .transpose_ - the underlying TensorImpl (in C++) is used elsewhere and we don't want to change it.\u001b[39;00m\n",
      "File \u001b[0;32m/bask/projects/v/vjgo8416-rough-paths/envs/nlpsig-networks/lib/python3.8/site-packages/signatory/signature_module.py:61\u001b[0m, in \u001b[0;36m_SignatureFunction.forward\u001b[0;34m(ctx, path, depth, stream, basepoint, inverse, initial, scalar_term)\u001b[0m\n\u001b[1;32m     57\u001b[0m basepoint, basepoint_value \u001b[38;5;241m=\u001b[39m interpret_basepoint(basepoint, path\u001b[38;5;241m.\u001b[39msize(\u001b[38;5;241m-\u001b[39m\u001b[38;5;241m2\u001b[39m), path\u001b[38;5;241m.\u001b[39msize(\u001b[38;5;241m-\u001b[39m\u001b[38;5;241m1\u001b[39m), path\u001b[38;5;241m.\u001b[39mdtype,\n\u001b[1;32m     58\u001b[0m                                                  path\u001b[38;5;241m.\u001b[39mdevice)\n\u001b[1;32m     59\u001b[0m initial, initial_value \u001b[38;5;241m=\u001b[39m interpret_initial(initial)\n\u001b[0;32m---> 61\u001b[0m signature_, path_increments \u001b[38;5;241m=\u001b[39m \u001b[43mimpl\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43msignature_forward\u001b[49m\u001b[43m(\u001b[49m\u001b[43mpath\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mdepth\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mstream\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mbasepoint\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mbasepoint_value\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43minverse\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m     62\u001b[0m \u001b[43m                                                     \u001b[49m\u001b[43minitial\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43minitial_value\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mscalar_term\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m     63\u001b[0m ctx\u001b[38;5;241m.\u001b[39msave_for_backward(signature_, path_increments)\n\u001b[1;32m     64\u001b[0m ctx\u001b[38;5;241m.\u001b[39mdepth \u001b[38;5;241m=\u001b[39m depth\n",
      "File \u001b[0;32m/bask/projects/v/vjgo8416-rough-paths/envs/nlpsig-networks/lib/python3.8/site-packages/signatory/impl.py:36\u001b[0m, in \u001b[0;36m_wrap.<locals>.wrapped\u001b[0;34m(*args, **kwargs)\u001b[0m\n\u001b[1;32m     34\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mwrapped\u001b[39m(\u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs):\n\u001b[1;32m     35\u001b[0m     \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[0;32m---> 36\u001b[0m         \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mfn\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m     37\u001b[0m     \u001b[38;5;28;01mexcept\u001b[39;00m \u001b[38;5;167;01mRuntimeError\u001b[39;00m \u001b[38;5;28;01mas\u001b[39;00m e:\n\u001b[1;32m     38\u001b[0m         \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mValueError\u001b[39;00m(\u001b[38;5;28mstr\u001b[39m(e))\n",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "size = 35\n",
    "swmhau_network_umap, best_swmhau_network_umap, _, __ = swmhau_network_hyperparameter_search(\n",
    "    num_epochs=num_epochs,\n",
    "    df=df_rumours,\n",
    "    id_column=\"timeline_id\",\n",
    "    label_column=\"label\",\n",
    "    embeddings=sbert_embeddings,\n",
    "    y_data=y_data,\n",
    "    embedding_dim=embedding_dim,\n",
    "    output_dim=output_dim,\n",
    "    history_lengths=[size],\n",
    "    dim_reduce_methods=[\"umap\"],\n",
    "    dimensions=dimensions,\n",
    "    log_signature=True,\n",
    "    swmhau_parameters=swmhau_parameters,\n",
    "    num_layers=num_layers,\n",
    "    ffn_hidden_dim_sizes=ffn_hidden_dim_sizes,\n",
    "    dropout_rates=dropout_rates,\n",
    "    learning_rates=learning_rates,\n",
    "    seeds=seeds,\n",
    "    loss=loss,\n",
    "    gamma=gamma,\n",
    "    split_indices=split_indices,\n",
    "    k_fold=False,\n",
    "    features=features,\n",
    "    standardise_method=standardise_method,\n",
    "    add_time_in_path=add_time_in_path,\n",
    "    patience=patience,\n",
    "    validation_metric=validation_metric,\n",
    "    results_output=f\"{output_dir}/swmhau_network_umap_focal_{gamma}_{size}.csv\",\n",
    "    verbose=False\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "db912cd7-e74a-4893-987b-037b69c1fec8",
   "metadata": {},
   "outputs": [],
   "source": [
    "swmhau_network_umap.groupby([\"dimensions\",\n",
    "                             \"output_channels\",\n",
    "                             \"sig_depth\",\n",
    "                             \"num_heads\",\n",
    "                             \"num_layers\",\n",
    "                             \"ffn_hidden_dim\",\n",
    "                             \"learning_rate\"]).mean()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "089e89fa-e2bc-4bd2-a063-d9c7d35ba390",
   "metadata": {},
   "outputs": [],
   "source": [
    "best_swmhau_network_umap"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "978d2bdc-9e44-49ac-a88c-71540aa34777",
   "metadata": {},
   "outputs": [],
   "source": [
    "best_swmhau_network_umap[[\"dimensions\",\n",
    "                          \"output_channels\",\n",
    "                          \"sig_depth\",\n",
    "                          \"num_heads\",\n",
    "                          \"num_layers\",\n",
    "                          \"ffn_hidden_dim\",\n",
    "                          \"dropout_rate\",\n",
    "                          \"learning_rate\"]]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "78b1127f-0371-40b9-a521-14f6f38f150f",
   "metadata": {},
   "outputs": [],
   "source": [
    "best_swmhau_network_umap[\"f1\"].mean()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "500a7f96-d4df-44c0-93dc-60e3f38b5e7e",
   "metadata": {},
   "outputs": [],
   "source": [
    "best_swmhau_network_umap[\"precision\"].mean()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "eb46a36b-60fd-4ff8-9c44-301db7b1c806",
   "metadata": {},
   "outputs": [],
   "source": [
    "best_swmhau_network_umap[\"recall\"].mean()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "088a2cba-e1ee-45f3-9ebf-950d6828c9b6",
   "metadata": {},
   "outputs": [],
   "source": [
    "np.stack(best_swmhau_network_umap[\"f1_scores\"]).mean(axis=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7fe395fe-9dfe-441c-bda8-e2304f3710db",
   "metadata": {},
   "outputs": [],
   "source": [
    "np.stack(best_swmhau_network_umap[\"precision_scores\"]).mean(axis=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6a62f0f1-1ba4-432e-a9c5-537150ea3a59",
   "metadata": {},
   "outputs": [],
   "source": [
    "np.stack(best_swmhau_network_umap[\"recall_scores\"]).mean(axis=0)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f0787150-8266-48ee-97f5-5f711ce899c7",
   "metadata": {},
   "source": [
    "## Random Projections"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "13a67a66",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "64947b24eac84ee0bb47a0258c3e2428",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/1 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "7a9c739f147b4251947d87ae7b00bf65",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/1 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "05314158216e48558c066ca3b0fc77d4",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/1 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "##################################################\n",
      "dimension: 15 | method: gaussian_random_projection\n",
      "[INFO] Concatenating the embeddings to the dataframe...\n",
      "[INFO] - columns beginning with 'e' denote the full embddings.\n",
      "[INFO] - columns beginning with 'd' denote the dimension reduced embeddings.\n",
      "[INFO] Adding time feature columns into dataframe in `.df`.\n",
      "[INFO] Adding 'time_encoding' feature...\n",
      "[INFO] Adding 'time_diff' feature...\n",
      "[INFO] Adding 'timeline_index' feature...\n",
      "[INFO] Padding ids and storing in `.df_padded` and `.array_padded` attributes.\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "c188ed0931f74e73a6f78d020b5bfcff",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/5568 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[INFO] The path was created for each item in the dataframe, by looking at its history, so to include embeddings in the FFN input, we concatenate the embeddings for each sentence / text.\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "8e70f93c701e4544a9d73ee3f9f5acf4",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/3 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "5a881419b90040d883380572fa68f16c",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/1 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "649d34c8b7ae4af2a2fa9394f84d1c51",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/2 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "f76fd3eca4e54d1fa92809100d9bad90",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/2 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "3c33817aab74430185e57a10a68527b3",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/3 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "6f1f1b75da574374b3fd9387a725bdc3",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/3 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "b57b58ea13c1455a8f0b532dbb57e89f",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/2 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "c1ac9d310aa94ee4bd1fcbc12da91cb1",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/3 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "0d61a05b65664c3bbd072189b2f7c24a",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/3 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "9822ff1c797a4dc4973ba83905214031",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/1 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "7fb88a35d9574982af8c2b0842151ce8",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/2 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "d09c520d904147d0a5482393af509c6e",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/2 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "aa9bdf8379fb43d4aed101ae795546ff",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/3 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "b6bc59a8d626479391e51d610d92100b",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/3 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "ddf3ce84f435474dbf3eeb88fb513e90",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/2 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "55ff606941f94b0d97d4bb2fdbfd0dde",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/3 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "28483c9465fa4189bb560ded91beae27",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/3 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "7b40f47cf26a4b1ab395788bd24512e9",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/1 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "b2890f7d95aa43a89d010f13edb0c0bb",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/2 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "e0640bf40faf4e26ae9dff4a4558daf8",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/2 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "03f862012e4d4f3d8742b0d359cb0690",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/3 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "6921d3a1f220465781cc2941ac674643",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/3 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "a400767582af42f5a2754724efe1c2c5",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/2 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "ff54659f09bc47c7af43d083d1266ecb",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/3 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "61947fa72e064e5bb416de07043ed674",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/3 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[INFO] Concatenating the embeddings to the dataframe...\n",
      "[INFO] - columns beginning with 'e' denote the full embddings.\n",
      "[INFO] - columns beginning with 'd' denote the dimension reduced embeddings.\n",
      "[INFO] Adding time feature columns into dataframe in `.df`.\n",
      "[INFO] Adding 'time_encoding' feature...\n",
      "[INFO] Adding 'time_diff' feature...\n",
      "[INFO] Adding 'timeline_index' feature...\n",
      "[INFO] Padding ids and storing in `.df_padded` and `.array_padded` attributes.\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "17e3742022d1425a94c6a5f8cb688418",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/5568 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[INFO] The path was created for each item in the dataframe, by looking at its history, so to include embeddings in the FFN input, we concatenate the embeddings for each sentence / text.\n",
      "saving results dataframe to CSV for this hyperparameter search in rumours_output/swmhau_network_grp_focal_2_35_kfold.csv\n",
      "saving the best model results dataframe to CSV for this hyperparameter search in rumours_output/swmhau_network_grp_focal_2_35_kfold_best_model.csv\n"
     ]
    }
   ],
   "source": [
    "size = 35\n",
    "swmhau_network_grp, best_swmhau_network_grp, _, __ = swmhau_network_hyperparameter_search(\n",
    "    num_epochs=num_epochs,\n",
    "    df=df_rumours,\n",
    "    id_column=\"timeline_id\",\n",
    "    label_column=\"label\",\n",
    "    embeddings=sbert_embeddings,\n",
    "    y_data=y_data,\n",
    "    embedding_dim=embedding_dim,\n",
    "    output_dim=output_dim,\n",
    "    history_lengths=[size],\n",
    "    dim_reduce_methods=[\"gaussian_random_projection\"],\n",
    "    dimensions=dimensions,\n",
    "    log_signature=True,\n",
    "    swmhau_parameters=swmhau_parameters,\n",
    "    num_layers=num_layers,\n",
    "    ffn_hidden_dim_sizes=ffn_hidden_dim_sizes,\n",
    "    dropout_rates=dropout_rates,\n",
    "    learning_rates=learning_rates,\n",
    "    seeds=seeds,\n",
    "    loss=loss,\n",
    "    gamma=gamma,\n",
    "    split_indices=split_indices,\n",
    "    k_fold=False,\n",
    "    features=features,\n",
    "    standardise_method=standardise_method,\n",
    "    add_time_in_path=add_time_in_path,\n",
    "    patience=patience,\n",
    "    validation_metric=validation_metric,\n",
    "    results_output=f\"{output_dir}/swmhau_network_grp_focal_{gamma}_{size}.csv\",\n",
    "    verbose=False\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "0ec7c660",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/tmp/ipykernel_3944524/1948036447.py:1: FutureWarning: The default value of numeric_only in DataFrameGroupBy.mean is deprecated. In a future version, numeric_only will default to False. Either specify numeric_only or select only columns which should be valid for the function.\n",
      "  swmhau_network_grp_kfold_20.groupby([\"dimensions\",\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th>loss</th>\n",
       "      <th>accuracy</th>\n",
       "      <th>f1</th>\n",
       "      <th>precision</th>\n",
       "      <th>recall</th>\n",
       "      <th>valid_loss</th>\n",
       "      <th>valid_accuracy</th>\n",
       "      <th>valid_f1</th>\n",
       "      <th>valid_precision</th>\n",
       "      <th>valid_recall</th>\n",
       "      <th>...</th>\n",
       "      <th>input_channels</th>\n",
       "      <th>add_time_in_path</th>\n",
       "      <th>num_features</th>\n",
       "      <th>embedding_dim</th>\n",
       "      <th>log_signature</th>\n",
       "      <th>seed</th>\n",
       "      <th>gamma</th>\n",
       "      <th>k_fold</th>\n",
       "      <th>batch_size</th>\n",
       "      <th>model_id</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>dimensions</th>\n",
       "      <th>output_channels</th>\n",
       "      <th>sig_depth</th>\n",
       "      <th>num_heads</th>\n",
       "      <th>num_layers</th>\n",
       "      <th>ffn_hidden_dim</th>\n",
       "      <th>dropout_rate</th>\n",
       "      <th>learning_rate</th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th rowspan=\"36\" valign=\"top\">15</th>\n",
       "      <th rowspan=\"24\" valign=\"top\">8</th>\n",
       "      <th rowspan=\"24\" valign=\"top\">4</th>\n",
       "      <th rowspan=\"12\" valign=\"top\">6</th>\n",
       "      <th rowspan=\"12\" valign=\"top\">1</th>\n",
       "      <th rowspan=\"6\" valign=\"top\">(256, 256)</th>\n",
       "      <th rowspan=\"3\" valign=\"top\">0.1</th>\n",
       "      <th>0.0001</th>\n",
       "      <td>0.437324</td>\n",
       "      <td>0.632031</td>\n",
       "      <td>0.631136</td>\n",
       "      <td>0.635017</td>\n",
       "      <td>0.633487</td>\n",
       "      <td>0.286125</td>\n",
       "      <td>0.667853</td>\n",
       "      <td>0.600958</td>\n",
       "      <td>0.639850</td>\n",
       "      <td>0.602229</td>\n",
       "      <td>...</td>\n",
       "      <td>17.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>384.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>45.333333</td>\n",
       "      <td>2.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>64.0</td>\n",
       "      <td>16.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>0.0005</th>\n",
       "      <td>0.497362</td>\n",
       "      <td>0.636479</td>\n",
       "      <td>0.633870</td>\n",
       "      <td>0.645095</td>\n",
       "      <td>0.639611</td>\n",
       "      <td>0.203662</td>\n",
       "      <td>0.714116</td>\n",
       "      <td>0.676161</td>\n",
       "      <td>0.693083</td>\n",
       "      <td>0.670172</td>\n",
       "      <td>...</td>\n",
       "      <td>17.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>384.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>45.333333</td>\n",
       "      <td>2.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>64.0</td>\n",
       "      <td>17.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>0.0010</th>\n",
       "      <td>0.479793</td>\n",
       "      <td>0.615825</td>\n",
       "      <td>0.608849</td>\n",
       "      <td>0.630976</td>\n",
       "      <td>0.620355</td>\n",
       "      <td>0.222472</td>\n",
       "      <td>0.685646</td>\n",
       "      <td>0.649962</td>\n",
       "      <td>0.659568</td>\n",
       "      <td>0.647123</td>\n",
       "      <td>...</td>\n",
       "      <td>17.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>384.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>45.333333</td>\n",
       "      <td>2.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>64.0</td>\n",
       "      <td>15.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th rowspan=\"3\" valign=\"top\">0.5</th>\n",
       "      <th>0.0001</th>\n",
       "      <td>0.400435</td>\n",
       "      <td>0.620909</td>\n",
       "      <td>0.620536</td>\n",
       "      <td>0.620989</td>\n",
       "      <td>0.621106</td>\n",
       "      <td>0.205582</td>\n",
       "      <td>0.718861</td>\n",
       "      <td>0.666193</td>\n",
       "      <td>0.704705</td>\n",
       "      <td>0.665462</td>\n",
       "      <td>...</td>\n",
       "      <td>17.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>384.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>45.333333</td>\n",
       "      <td>2.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>64.0</td>\n",
       "      <td>13.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>0.0005</th>\n",
       "      <td>0.503324</td>\n",
       "      <td>0.629171</td>\n",
       "      <td>0.627057</td>\n",
       "      <td>0.634685</td>\n",
       "      <td>0.631350</td>\n",
       "      <td>0.214372</td>\n",
       "      <td>0.715302</td>\n",
       "      <td>0.686140</td>\n",
       "      <td>0.691222</td>\n",
       "      <td>0.683052</td>\n",
       "      <td>...</td>\n",
       "      <td>17.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>384.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>45.333333</td>\n",
       "      <td>2.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>64.0</td>\n",
       "      <td>14.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>0.0010</th>\n",
       "      <td>0.421962</td>\n",
       "      <td>0.628853</td>\n",
       "      <td>0.627584</td>\n",
       "      <td>0.628607</td>\n",
       "      <td>0.628041</td>\n",
       "      <td>0.206338</td>\n",
       "      <td>0.704626</td>\n",
       "      <td>0.640897</td>\n",
       "      <td>0.693559</td>\n",
       "      <td>0.640934</td>\n",
       "      <td>...</td>\n",
       "      <td>17.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>384.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>45.333333</td>\n",
       "      <td>2.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>64.0</td>\n",
       "      <td>12.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th rowspan=\"6\" valign=\"top\">(512, 512)</th>\n",
       "      <th rowspan=\"3\" valign=\"top\">0.1</th>\n",
       "      <th>0.0001</th>\n",
       "      <td>0.397865</td>\n",
       "      <td>0.632348</td>\n",
       "      <td>0.628817</td>\n",
       "      <td>0.645633</td>\n",
       "      <td>0.637480</td>\n",
       "      <td>0.219558</td>\n",
       "      <td>0.735469</td>\n",
       "      <td>0.711003</td>\n",
       "      <td>0.717649</td>\n",
       "      <td>0.708721</td>\n",
       "      <td>...</td>\n",
       "      <td>17.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>384.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>45.333333</td>\n",
       "      <td>2.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>64.0</td>\n",
       "      <td>22.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>0.0005</th>\n",
       "      <td>0.438234</td>\n",
       "      <td>0.630442</td>\n",
       "      <td>0.630335</td>\n",
       "      <td>0.631578</td>\n",
       "      <td>0.631582</td>\n",
       "      <td>0.207406</td>\n",
       "      <td>0.696323</td>\n",
       "      <td>0.652814</td>\n",
       "      <td>0.679568</td>\n",
       "      <td>0.650582</td>\n",
       "      <td>...</td>\n",
       "      <td>17.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>384.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>45.333333</td>\n",
       "      <td>2.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>64.0</td>\n",
       "      <td>23.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>0.0010</th>\n",
       "      <td>0.856663</td>\n",
       "      <td>0.603114</td>\n",
       "      <td>0.597925</td>\n",
       "      <td>0.616178</td>\n",
       "      <td>0.607765</td>\n",
       "      <td>0.220356</td>\n",
       "      <td>0.686833</td>\n",
       "      <td>0.656084</td>\n",
       "      <td>0.662340</td>\n",
       "      <td>0.654380</td>\n",
       "      <td>...</td>\n",
       "      <td>17.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>384.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>45.333333</td>\n",
       "      <td>2.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>64.0</td>\n",
       "      <td>21.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th rowspan=\"3\" valign=\"top\">0.5</th>\n",
       "      <th>0.0001</th>\n",
       "      <td>0.397297</td>\n",
       "      <td>0.622815</td>\n",
       "      <td>0.620360</td>\n",
       "      <td>0.633245</td>\n",
       "      <td>0.627093</td>\n",
       "      <td>0.225158</td>\n",
       "      <td>0.718861</td>\n",
       "      <td>0.679420</td>\n",
       "      <td>0.703125</td>\n",
       "      <td>0.673193</td>\n",
       "      <td>...</td>\n",
       "      <td>17.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>384.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>45.333333</td>\n",
       "      <td>2.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>64.0</td>\n",
       "      <td>19.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>0.0005</th>\n",
       "      <td>0.421027</td>\n",
       "      <td>0.631713</td>\n",
       "      <td>0.630469</td>\n",
       "      <td>0.636003</td>\n",
       "      <td>0.633689</td>\n",
       "      <td>0.203952</td>\n",
       "      <td>0.704626</td>\n",
       "      <td>0.663148</td>\n",
       "      <td>0.679613</td>\n",
       "      <td>0.657803</td>\n",
       "      <td>...</td>\n",
       "      <td>17.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>384.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>45.333333</td>\n",
       "      <td>2.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>64.0</td>\n",
       "      <td>20.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>0.0010</th>\n",
       "      <td>0.586376</td>\n",
       "      <td>0.611376</td>\n",
       "      <td>0.610659</td>\n",
       "      <td>0.614230</td>\n",
       "      <td>0.613248</td>\n",
       "      <td>0.198460</td>\n",
       "      <td>0.735469</td>\n",
       "      <td>0.702658</td>\n",
       "      <td>0.714960</td>\n",
       "      <td>0.697475</td>\n",
       "      <td>...</td>\n",
       "      <td>17.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>384.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>45.333333</td>\n",
       "      <td>2.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>64.0</td>\n",
       "      <td>18.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th rowspan=\"12\" valign=\"top\">12</th>\n",
       "      <th rowspan=\"12\" valign=\"top\">1</th>\n",
       "      <th rowspan=\"6\" valign=\"top\">(256, 256)</th>\n",
       "      <th rowspan=\"3\" valign=\"top\">0.1</th>\n",
       "      <th>0.0001</th>\n",
       "      <td>0.425550</td>\n",
       "      <td>0.614236</td>\n",
       "      <td>0.609736</td>\n",
       "      <td>0.619100</td>\n",
       "      <td>0.614196</td>\n",
       "      <td>0.226567</td>\n",
       "      <td>0.699881</td>\n",
       "      <td>0.641648</td>\n",
       "      <td>0.695839</td>\n",
       "      <td>0.638615</td>\n",
       "      <td>...</td>\n",
       "      <td>17.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>384.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>45.333333</td>\n",
       "      <td>2.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>64.0</td>\n",
       "      <td>28.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>0.0005</th>\n",
       "      <td>0.457671</td>\n",
       "      <td>0.627582</td>\n",
       "      <td>0.627257</td>\n",
       "      <td>0.627675</td>\n",
       "      <td>0.627809</td>\n",
       "      <td>0.205611</td>\n",
       "      <td>0.712930</td>\n",
       "      <td>0.680937</td>\n",
       "      <td>0.693701</td>\n",
       "      <td>0.677676</td>\n",
       "      <td>...</td>\n",
       "      <td>17.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>384.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>45.333333</td>\n",
       "      <td>2.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>64.0</td>\n",
       "      <td>29.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>0.0010</th>\n",
       "      <td>0.405572</td>\n",
       "      <td>0.606292</td>\n",
       "      <td>0.604768</td>\n",
       "      <td>0.608339</td>\n",
       "      <td>0.606963</td>\n",
       "      <td>0.198429</td>\n",
       "      <td>0.698695</td>\n",
       "      <td>0.665123</td>\n",
       "      <td>0.681167</td>\n",
       "      <td>0.665799</td>\n",
       "      <td>...</td>\n",
       "      <td>17.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>384.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>45.333333</td>\n",
       "      <td>2.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>64.0</td>\n",
       "      <td>27.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th rowspan=\"3\" valign=\"top\">0.5</th>\n",
       "      <th>0.0001</th>\n",
       "      <td>0.333581</td>\n",
       "      <td>0.626629</td>\n",
       "      <td>0.624724</td>\n",
       "      <td>0.634558</td>\n",
       "      <td>0.630111</td>\n",
       "      <td>0.229677</td>\n",
       "      <td>0.667853</td>\n",
       "      <td>0.620326</td>\n",
       "      <td>0.633220</td>\n",
       "      <td>0.617693</td>\n",
       "      <td>...</td>\n",
       "      <td>17.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>384.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>45.333333</td>\n",
       "      <td>2.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>64.0</td>\n",
       "      <td>25.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>0.0005</th>\n",
       "      <td>0.654582</td>\n",
       "      <td>0.621862</td>\n",
       "      <td>0.620417</td>\n",
       "      <td>0.622282</td>\n",
       "      <td>0.621333</td>\n",
       "      <td>0.199046</td>\n",
       "      <td>0.714116</td>\n",
       "      <td>0.674760</td>\n",
       "      <td>0.693291</td>\n",
       "      <td>0.668766</td>\n",
       "      <td>...</td>\n",
       "      <td>17.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>384.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>45.333333</td>\n",
       "      <td>2.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>64.0</td>\n",
       "      <td>26.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>0.0010</th>\n",
       "      <td>0.427511</td>\n",
       "      <td>0.637115</td>\n",
       "      <td>0.636970</td>\n",
       "      <td>0.637736</td>\n",
       "      <td>0.637868</td>\n",
       "      <td>0.190048</td>\n",
       "      <td>0.722420</td>\n",
       "      <td>0.686418</td>\n",
       "      <td>0.699569</td>\n",
       "      <td>0.680907</td>\n",
       "      <td>...</td>\n",
       "      <td>17.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>384.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>45.333333</td>\n",
       "      <td>2.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>64.0</td>\n",
       "      <td>24.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th rowspan=\"6\" valign=\"top\">(512, 512)</th>\n",
       "      <th rowspan=\"3\" valign=\"top\">0.1</th>\n",
       "      <th>0.0001</th>\n",
       "      <td>0.413396</td>\n",
       "      <td>0.608834</td>\n",
       "      <td>0.606072</td>\n",
       "      <td>0.617600</td>\n",
       "      <td>0.612039</td>\n",
       "      <td>0.204609</td>\n",
       "      <td>0.721234</td>\n",
       "      <td>0.683470</td>\n",
       "      <td>0.707994</td>\n",
       "      <td>0.679976</td>\n",
       "      <td>...</td>\n",
       "      <td>17.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>384.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>45.333333</td>\n",
       "      <td>2.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>64.0</td>\n",
       "      <td>34.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>0.0005</th>\n",
       "      <td>0.690202</td>\n",
       "      <td>0.634573</td>\n",
       "      <td>0.633398</td>\n",
       "      <td>0.641278</td>\n",
       "      <td>0.638266</td>\n",
       "      <td>0.234091</td>\n",
       "      <td>0.701068</td>\n",
       "      <td>0.658993</td>\n",
       "      <td>0.672415</td>\n",
       "      <td>0.657118</td>\n",
       "      <td>...</td>\n",
       "      <td>17.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>384.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>45.333333</td>\n",
       "      <td>2.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>64.0</td>\n",
       "      <td>35.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>0.0010</th>\n",
       "      <td>0.383327</td>\n",
       "      <td>0.636479</td>\n",
       "      <td>0.632168</td>\n",
       "      <td>0.650651</td>\n",
       "      <td>0.640950</td>\n",
       "      <td>0.204240</td>\n",
       "      <td>0.696323</td>\n",
       "      <td>0.652470</td>\n",
       "      <td>0.670571</td>\n",
       "      <td>0.648474</td>\n",
       "      <td>...</td>\n",
       "      <td>17.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>384.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>45.333333</td>\n",
       "      <td>2.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>64.0</td>\n",
       "      <td>33.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th rowspan=\"3\" valign=\"top\">0.5</th>\n",
       "      <th>0.0001</th>\n",
       "      <td>0.357123</td>\n",
       "      <td>0.636797</td>\n",
       "      <td>0.632918</td>\n",
       "      <td>0.648561</td>\n",
       "      <td>0.640391</td>\n",
       "      <td>0.229036</td>\n",
       "      <td>0.688019</td>\n",
       "      <td>0.644093</td>\n",
       "      <td>0.664583</td>\n",
       "      <td>0.639847</td>\n",
       "      <td>...</td>\n",
       "      <td>17.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>384.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>45.333333</td>\n",
       "      <td>2.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>64.0</td>\n",
       "      <td>31.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>0.0005</th>\n",
       "      <td>0.563043</td>\n",
       "      <td>0.626629</td>\n",
       "      <td>0.625977</td>\n",
       "      <td>0.629347</td>\n",
       "      <td>0.628267</td>\n",
       "      <td>0.210965</td>\n",
       "      <td>0.709371</td>\n",
       "      <td>0.674171</td>\n",
       "      <td>0.685253</td>\n",
       "      <td>0.669259</td>\n",
       "      <td>...</td>\n",
       "      <td>17.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>384.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>45.333333</td>\n",
       "      <td>2.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>64.0</td>\n",
       "      <td>32.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>0.0010</th>\n",
       "      <td>0.337940</td>\n",
       "      <td>0.625675</td>\n",
       "      <td>0.625217</td>\n",
       "      <td>0.628698</td>\n",
       "      <td>0.627564</td>\n",
       "      <td>0.193518</td>\n",
       "      <td>0.698695</td>\n",
       "      <td>0.650252</td>\n",
       "      <td>0.672456</td>\n",
       "      <td>0.646119</td>\n",
       "      <td>...</td>\n",
       "      <td>17.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>384.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>45.333333</td>\n",
       "      <td>2.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>64.0</td>\n",
       "      <td>30.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th rowspan=\"12\" valign=\"top\">12</th>\n",
       "      <th rowspan=\"12\" valign=\"top\">3</th>\n",
       "      <th rowspan=\"12\" valign=\"top\">10</th>\n",
       "      <th rowspan=\"12\" valign=\"top\">1</th>\n",
       "      <th rowspan=\"6\" valign=\"top\">(256, 256)</th>\n",
       "      <th rowspan=\"3\" valign=\"top\">0.1</th>\n",
       "      <th>0.0001</th>\n",
       "      <td>0.394287</td>\n",
       "      <td>0.604385</td>\n",
       "      <td>0.602615</td>\n",
       "      <td>0.610208</td>\n",
       "      <td>0.606897</td>\n",
       "      <td>0.231967</td>\n",
       "      <td>0.699881</td>\n",
       "      <td>0.660886</td>\n",
       "      <td>0.677639</td>\n",
       "      <td>0.656890</td>\n",
       "      <td>...</td>\n",
       "      <td>17.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>384.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>45.333333</td>\n",
       "      <td>2.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>64.0</td>\n",
       "      <td>4.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>0.0005</th>\n",
       "      <td>0.604171</td>\n",
       "      <td>0.626311</td>\n",
       "      <td>0.625423</td>\n",
       "      <td>0.628382</td>\n",
       "      <td>0.627160</td>\n",
       "      <td>0.223362</td>\n",
       "      <td>0.683274</td>\n",
       "      <td>0.620796</td>\n",
       "      <td>0.655091</td>\n",
       "      <td>0.618551</td>\n",
       "      <td>...</td>\n",
       "      <td>17.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>384.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>45.333333</td>\n",
       "      <td>2.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>64.0</td>\n",
       "      <td>5.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>0.0010</th>\n",
       "      <td>0.342548</td>\n",
       "      <td>0.632984</td>\n",
       "      <td>0.631617</td>\n",
       "      <td>0.635629</td>\n",
       "      <td>0.633713</td>\n",
       "      <td>0.197219</td>\n",
       "      <td>0.715303</td>\n",
       "      <td>0.657678</td>\n",
       "      <td>0.703630</td>\n",
       "      <td>0.651422</td>\n",
       "      <td>...</td>\n",
       "      <td>17.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>384.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>45.333333</td>\n",
       "      <td>2.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>64.0</td>\n",
       "      <td>3.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th rowspan=\"3\" valign=\"top\">0.5</th>\n",
       "      <th>0.0001</th>\n",
       "      <td>0.361919</td>\n",
       "      <td>0.612647</td>\n",
       "      <td>0.611713</td>\n",
       "      <td>0.615576</td>\n",
       "      <td>0.614046</td>\n",
       "      <td>0.212498</td>\n",
       "      <td>0.711744</td>\n",
       "      <td>0.665826</td>\n",
       "      <td>0.693873</td>\n",
       "      <td>0.662687</td>\n",
       "      <td>...</td>\n",
       "      <td>17.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>384.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>45.333333</td>\n",
       "      <td>2.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>64.0</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>0.0005</th>\n",
       "      <td>0.864935</td>\n",
       "      <td>0.615189</td>\n",
       "      <td>0.614900</td>\n",
       "      <td>0.617100</td>\n",
       "      <td>0.616743</td>\n",
       "      <td>0.345748</td>\n",
       "      <td>0.680902</td>\n",
       "      <td>0.645281</td>\n",
       "      <td>0.651805</td>\n",
       "      <td>0.642695</td>\n",
       "      <td>...</td>\n",
       "      <td>17.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>384.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>45.333333</td>\n",
       "      <td>2.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>64.0</td>\n",
       "      <td>2.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>0.0010</th>\n",
       "      <td>0.568580</td>\n",
       "      <td>0.600890</td>\n",
       "      <td>0.593914</td>\n",
       "      <td>0.611798</td>\n",
       "      <td>0.602605</td>\n",
       "      <td>0.208206</td>\n",
       "      <td>0.693950</td>\n",
       "      <td>0.670233</td>\n",
       "      <td>0.673361</td>\n",
       "      <td>0.669807</td>\n",
       "      <td>...</td>\n",
       "      <td>17.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>384.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>45.333333</td>\n",
       "      <td>2.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>64.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th rowspan=\"6\" valign=\"top\">(512, 512)</th>\n",
       "      <th rowspan=\"3\" valign=\"top\">0.1</th>\n",
       "      <th>0.0001</th>\n",
       "      <td>0.386000</td>\n",
       "      <td>0.609469</td>\n",
       "      <td>0.606123</td>\n",
       "      <td>0.622089</td>\n",
       "      <td>0.614521</td>\n",
       "      <td>0.240919</td>\n",
       "      <td>0.677343</td>\n",
       "      <td>0.647379</td>\n",
       "      <td>0.651878</td>\n",
       "      <td>0.646228</td>\n",
       "      <td>...</td>\n",
       "      <td>17.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>384.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>45.333333</td>\n",
       "      <td>2.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>64.0</td>\n",
       "      <td>10.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>0.0005</th>\n",
       "      <td>0.748276</td>\n",
       "      <td>0.630124</td>\n",
       "      <td>0.629621</td>\n",
       "      <td>0.630448</td>\n",
       "      <td>0.630327</td>\n",
       "      <td>0.214222</td>\n",
       "      <td>0.712930</td>\n",
       "      <td>0.671291</td>\n",
       "      <td>0.689902</td>\n",
       "      <td>0.666429</td>\n",
       "      <td>...</td>\n",
       "      <td>17.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>384.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>45.333333</td>\n",
       "      <td>2.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>64.0</td>\n",
       "      <td>11.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>0.0010</th>\n",
       "      <td>0.503538</td>\n",
       "      <td>0.630759</td>\n",
       "      <td>0.628516</td>\n",
       "      <td>0.634897</td>\n",
       "      <td>0.631440</td>\n",
       "      <td>0.184820</td>\n",
       "      <td>0.742586</td>\n",
       "      <td>0.714413</td>\n",
       "      <td>0.735213</td>\n",
       "      <td>0.714308</td>\n",
       "      <td>...</td>\n",
       "      <td>17.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>384.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>45.333333</td>\n",
       "      <td>2.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>64.0</td>\n",
       "      <td>9.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th rowspan=\"3\" valign=\"top\">0.5</th>\n",
       "      <th>0.0001</th>\n",
       "      <td>0.358638</td>\n",
       "      <td>0.629171</td>\n",
       "      <td>0.627040</td>\n",
       "      <td>0.639340</td>\n",
       "      <td>0.633998</td>\n",
       "      <td>0.221230</td>\n",
       "      <td>0.683274</td>\n",
       "      <td>0.643414</td>\n",
       "      <td>0.653418</td>\n",
       "      <td>0.640340</td>\n",
       "      <td>...</td>\n",
       "      <td>17.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>384.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>45.333333</td>\n",
       "      <td>2.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>64.0</td>\n",
       "      <td>7.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>0.0005</th>\n",
       "      <td>0.386564</td>\n",
       "      <td>0.629488</td>\n",
       "      <td>0.627214</td>\n",
       "      <td>0.637676</td>\n",
       "      <td>0.632665</td>\n",
       "      <td>0.199531</td>\n",
       "      <td>0.703440</td>\n",
       "      <td>0.661875</td>\n",
       "      <td>0.685768</td>\n",
       "      <td>0.656169</td>\n",
       "      <td>...</td>\n",
       "      <td>17.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>384.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>45.333333</td>\n",
       "      <td>2.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>64.0</td>\n",
       "      <td>8.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>0.0010</th>\n",
       "      <td>0.433459</td>\n",
       "      <td>0.624404</td>\n",
       "      <td>0.622128</td>\n",
       "      <td>0.623711</td>\n",
       "      <td>0.622423</td>\n",
       "      <td>0.182855</td>\n",
       "      <td>0.754448</td>\n",
       "      <td>0.703446</td>\n",
       "      <td>0.758766</td>\n",
       "      <td>0.692692</td>\n",
       "      <td>...</td>\n",
       "      <td>17.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>384.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>45.333333</td>\n",
       "      <td>2.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>64.0</td>\n",
       "      <td>6.0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>36 rows  21 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                                                                                                         loss  \\\n",
       "dimensions output_channels sig_depth num_heads num_layers ffn_hidden_dim dropout_rate learning_rate             \n",
       "15         8               4         6         1          (256, 256)     0.1          0.0001         0.437324   \n",
       "                                                                                      0.0005         0.497362   \n",
       "                                                                                      0.0010         0.479793   \n",
       "                                                                         0.5          0.0001         0.400435   \n",
       "                                                                                      0.0005         0.503324   \n",
       "                                                                                      0.0010         0.421962   \n",
       "                                                          (512, 512)     0.1          0.0001         0.397865   \n",
       "                                                                                      0.0005         0.438234   \n",
       "                                                                                      0.0010         0.856663   \n",
       "                                                                         0.5          0.0001         0.397297   \n",
       "                                                                                      0.0005         0.421027   \n",
       "                                                                                      0.0010         0.586376   \n",
       "                                     12        1          (256, 256)     0.1          0.0001         0.425550   \n",
       "                                                                                      0.0005         0.457671   \n",
       "                                                                                      0.0010         0.405572   \n",
       "                                                                         0.5          0.0001         0.333581   \n",
       "                                                                                      0.0005         0.654582   \n",
       "                                                                                      0.0010         0.427511   \n",
       "                                                          (512, 512)     0.1          0.0001         0.413396   \n",
       "                                                                                      0.0005         0.690202   \n",
       "                                                                                      0.0010         0.383327   \n",
       "                                                                         0.5          0.0001         0.357123   \n",
       "                                                                                      0.0005         0.563043   \n",
       "                                                                                      0.0010         0.337940   \n",
       "           12              3         10        1          (256, 256)     0.1          0.0001         0.394287   \n",
       "                                                                                      0.0005         0.604171   \n",
       "                                                                                      0.0010         0.342548   \n",
       "                                                                         0.5          0.0001         0.361919   \n",
       "                                                                                      0.0005         0.864935   \n",
       "                                                                                      0.0010         0.568580   \n",
       "                                                          (512, 512)     0.1          0.0001         0.386000   \n",
       "                                                                                      0.0005         0.748276   \n",
       "                                                                                      0.0010         0.503538   \n",
       "                                                                         0.5          0.0001         0.358638   \n",
       "                                                                                      0.0005         0.386564   \n",
       "                                                                                      0.0010         0.433459   \n",
       "\n",
       "                                                                                                     accuracy  \\\n",
       "dimensions output_channels sig_depth num_heads num_layers ffn_hidden_dim dropout_rate learning_rate             \n",
       "15         8               4         6         1          (256, 256)     0.1          0.0001         0.632031   \n",
       "                                                                                      0.0005         0.636479   \n",
       "                                                                                      0.0010         0.615825   \n",
       "                                                                         0.5          0.0001         0.620909   \n",
       "                                                                                      0.0005         0.629171   \n",
       "                                                                                      0.0010         0.628853   \n",
       "                                                          (512, 512)     0.1          0.0001         0.632348   \n",
       "                                                                                      0.0005         0.630442   \n",
       "                                                                                      0.0010         0.603114   \n",
       "                                                                         0.5          0.0001         0.622815   \n",
       "                                                                                      0.0005         0.631713   \n",
       "                                                                                      0.0010         0.611376   \n",
       "                                     12        1          (256, 256)     0.1          0.0001         0.614236   \n",
       "                                                                                      0.0005         0.627582   \n",
       "                                                                                      0.0010         0.606292   \n",
       "                                                                         0.5          0.0001         0.626629   \n",
       "                                                                                      0.0005         0.621862   \n",
       "                                                                                      0.0010         0.637115   \n",
       "                                                          (512, 512)     0.1          0.0001         0.608834   \n",
       "                                                                                      0.0005         0.634573   \n",
       "                                                                                      0.0010         0.636479   \n",
       "                                                                         0.5          0.0001         0.636797   \n",
       "                                                                                      0.0005         0.626629   \n",
       "                                                                                      0.0010         0.625675   \n",
       "           12              3         10        1          (256, 256)     0.1          0.0001         0.604385   \n",
       "                                                                                      0.0005         0.626311   \n",
       "                                                                                      0.0010         0.632984   \n",
       "                                                                         0.5          0.0001         0.612647   \n",
       "                                                                                      0.0005         0.615189   \n",
       "                                                                                      0.0010         0.600890   \n",
       "                                                          (512, 512)     0.1          0.0001         0.609469   \n",
       "                                                                                      0.0005         0.630124   \n",
       "                                                                                      0.0010         0.630759   \n",
       "                                                                         0.5          0.0001         0.629171   \n",
       "                                                                                      0.0005         0.629488   \n",
       "                                                                                      0.0010         0.624404   \n",
       "\n",
       "                                                                                                           f1  \\\n",
       "dimensions output_channels sig_depth num_heads num_layers ffn_hidden_dim dropout_rate learning_rate             \n",
       "15         8               4         6         1          (256, 256)     0.1          0.0001         0.631136   \n",
       "                                                                                      0.0005         0.633870   \n",
       "                                                                                      0.0010         0.608849   \n",
       "                                                                         0.5          0.0001         0.620536   \n",
       "                                                                                      0.0005         0.627057   \n",
       "                                                                                      0.0010         0.627584   \n",
       "                                                          (512, 512)     0.1          0.0001         0.628817   \n",
       "                                                                                      0.0005         0.630335   \n",
       "                                                                                      0.0010         0.597925   \n",
       "                                                                         0.5          0.0001         0.620360   \n",
       "                                                                                      0.0005         0.630469   \n",
       "                                                                                      0.0010         0.610659   \n",
       "                                     12        1          (256, 256)     0.1          0.0001         0.609736   \n",
       "                                                                                      0.0005         0.627257   \n",
       "                                                                                      0.0010         0.604768   \n",
       "                                                                         0.5          0.0001         0.624724   \n",
       "                                                                                      0.0005         0.620417   \n",
       "                                                                                      0.0010         0.636970   \n",
       "                                                          (512, 512)     0.1          0.0001         0.606072   \n",
       "                                                                                      0.0005         0.633398   \n",
       "                                                                                      0.0010         0.632168   \n",
       "                                                                         0.5          0.0001         0.632918   \n",
       "                                                                                      0.0005         0.625977   \n",
       "                                                                                      0.0010         0.625217   \n",
       "           12              3         10        1          (256, 256)     0.1          0.0001         0.602615   \n",
       "                                                                                      0.0005         0.625423   \n",
       "                                                                                      0.0010         0.631617   \n",
       "                                                                         0.5          0.0001         0.611713   \n",
       "                                                                                      0.0005         0.614900   \n",
       "                                                                                      0.0010         0.593914   \n",
       "                                                          (512, 512)     0.1          0.0001         0.606123   \n",
       "                                                                                      0.0005         0.629621   \n",
       "                                                                                      0.0010         0.628516   \n",
       "                                                                         0.5          0.0001         0.627040   \n",
       "                                                                                      0.0005         0.627214   \n",
       "                                                                                      0.0010         0.622128   \n",
       "\n",
       "                                                                                                     precision  \\\n",
       "dimensions output_channels sig_depth num_heads num_layers ffn_hidden_dim dropout_rate learning_rate              \n",
       "15         8               4         6         1          (256, 256)     0.1          0.0001          0.635017   \n",
       "                                                                                      0.0005          0.645095   \n",
       "                                                                                      0.0010          0.630976   \n",
       "                                                                         0.5          0.0001          0.620989   \n",
       "                                                                                      0.0005          0.634685   \n",
       "                                                                                      0.0010          0.628607   \n",
       "                                                          (512, 512)     0.1          0.0001          0.645633   \n",
       "                                                                                      0.0005          0.631578   \n",
       "                                                                                      0.0010          0.616178   \n",
       "                                                                         0.5          0.0001          0.633245   \n",
       "                                                                                      0.0005          0.636003   \n",
       "                                                                                      0.0010          0.614230   \n",
       "                                     12        1          (256, 256)     0.1          0.0001          0.619100   \n",
       "                                                                                      0.0005          0.627675   \n",
       "                                                                                      0.0010          0.608339   \n",
       "                                                                         0.5          0.0001          0.634558   \n",
       "                                                                                      0.0005          0.622282   \n",
       "                                                                                      0.0010          0.637736   \n",
       "                                                          (512, 512)     0.1          0.0001          0.617600   \n",
       "                                                                                      0.0005          0.641278   \n",
       "                                                                                      0.0010          0.650651   \n",
       "                                                                         0.5          0.0001          0.648561   \n",
       "                                                                                      0.0005          0.629347   \n",
       "                                                                                      0.0010          0.628698   \n",
       "           12              3         10        1          (256, 256)     0.1          0.0001          0.610208   \n",
       "                                                                                      0.0005          0.628382   \n",
       "                                                                                      0.0010          0.635629   \n",
       "                                                                         0.5          0.0001          0.615576   \n",
       "                                                                                      0.0005          0.617100   \n",
       "                                                                                      0.0010          0.611798   \n",
       "                                                          (512, 512)     0.1          0.0001          0.622089   \n",
       "                                                                                      0.0005          0.630448   \n",
       "                                                                                      0.0010          0.634897   \n",
       "                                                                         0.5          0.0001          0.639340   \n",
       "                                                                                      0.0005          0.637676   \n",
       "                                                                                      0.0010          0.623711   \n",
       "\n",
       "                                                                                                       recall  \\\n",
       "dimensions output_channels sig_depth num_heads num_layers ffn_hidden_dim dropout_rate learning_rate             \n",
       "15         8               4         6         1          (256, 256)     0.1          0.0001         0.633487   \n",
       "                                                                                      0.0005         0.639611   \n",
       "                                                                                      0.0010         0.620355   \n",
       "                                                                         0.5          0.0001         0.621106   \n",
       "                                                                                      0.0005         0.631350   \n",
       "                                                                                      0.0010         0.628041   \n",
       "                                                          (512, 512)     0.1          0.0001         0.637480   \n",
       "                                                                                      0.0005         0.631582   \n",
       "                                                                                      0.0010         0.607765   \n",
       "                                                                         0.5          0.0001         0.627093   \n",
       "                                                                                      0.0005         0.633689   \n",
       "                                                                                      0.0010         0.613248   \n",
       "                                     12        1          (256, 256)     0.1          0.0001         0.614196   \n",
       "                                                                                      0.0005         0.627809   \n",
       "                                                                                      0.0010         0.606963   \n",
       "                                                                         0.5          0.0001         0.630111   \n",
       "                                                                                      0.0005         0.621333   \n",
       "                                                                                      0.0010         0.637868   \n",
       "                                                          (512, 512)     0.1          0.0001         0.612039   \n",
       "                                                                                      0.0005         0.638266   \n",
       "                                                                                      0.0010         0.640950   \n",
       "                                                                         0.5          0.0001         0.640391   \n",
       "                                                                                      0.0005         0.628267   \n",
       "                                                                                      0.0010         0.627564   \n",
       "           12              3         10        1          (256, 256)     0.1          0.0001         0.606897   \n",
       "                                                                                      0.0005         0.627160   \n",
       "                                                                                      0.0010         0.633713   \n",
       "                                                                         0.5          0.0001         0.614046   \n",
       "                                                                                      0.0005         0.616743   \n",
       "                                                                                      0.0010         0.602605   \n",
       "                                                          (512, 512)     0.1          0.0001         0.614521   \n",
       "                                                                                      0.0005         0.630327   \n",
       "                                                                                      0.0010         0.631440   \n",
       "                                                                         0.5          0.0001         0.633998   \n",
       "                                                                                      0.0005         0.632665   \n",
       "                                                                                      0.0010         0.622423   \n",
       "\n",
       "                                                                                                     valid_loss  \\\n",
       "dimensions output_channels sig_depth num_heads num_layers ffn_hidden_dim dropout_rate learning_rate               \n",
       "15         8               4         6         1          (256, 256)     0.1          0.0001           0.286125   \n",
       "                                                                                      0.0005           0.203662   \n",
       "                                                                                      0.0010           0.222472   \n",
       "                                                                         0.5          0.0001           0.205582   \n",
       "                                                                                      0.0005           0.214372   \n",
       "                                                                                      0.0010           0.206338   \n",
       "                                                          (512, 512)     0.1          0.0001           0.219558   \n",
       "                                                                                      0.0005           0.207406   \n",
       "                                                                                      0.0010           0.220356   \n",
       "                                                                         0.5          0.0001           0.225158   \n",
       "                                                                                      0.0005           0.203952   \n",
       "                                                                                      0.0010           0.198460   \n",
       "                                     12        1          (256, 256)     0.1          0.0001           0.226567   \n",
       "                                                                                      0.0005           0.205611   \n",
       "                                                                                      0.0010           0.198429   \n",
       "                                                                         0.5          0.0001           0.229677   \n",
       "                                                                                      0.0005           0.199046   \n",
       "                                                                                      0.0010           0.190048   \n",
       "                                                          (512, 512)     0.1          0.0001           0.204609   \n",
       "                                                                                      0.0005           0.234091   \n",
       "                                                                                      0.0010           0.204240   \n",
       "                                                                         0.5          0.0001           0.229036   \n",
       "                                                                                      0.0005           0.210965   \n",
       "                                                                                      0.0010           0.193518   \n",
       "           12              3         10        1          (256, 256)     0.1          0.0001           0.231967   \n",
       "                                                                                      0.0005           0.223362   \n",
       "                                                                                      0.0010           0.197219   \n",
       "                                                                         0.5          0.0001           0.212498   \n",
       "                                                                                      0.0005           0.345748   \n",
       "                                                                                      0.0010           0.208206   \n",
       "                                                          (512, 512)     0.1          0.0001           0.240919   \n",
       "                                                                                      0.0005           0.214222   \n",
       "                                                                                      0.0010           0.184820   \n",
       "                                                                         0.5          0.0001           0.221230   \n",
       "                                                                                      0.0005           0.199531   \n",
       "                                                                                      0.0010           0.182855   \n",
       "\n",
       "                                                                                                     valid_accuracy  \\\n",
       "dimensions output_channels sig_depth num_heads num_layers ffn_hidden_dim dropout_rate learning_rate                   \n",
       "15         8               4         6         1          (256, 256)     0.1          0.0001               0.667853   \n",
       "                                                                                      0.0005               0.714116   \n",
       "                                                                                      0.0010               0.685646   \n",
       "                                                                         0.5          0.0001               0.718861   \n",
       "                                                                                      0.0005               0.715302   \n",
       "                                                                                      0.0010               0.704626   \n",
       "                                                          (512, 512)     0.1          0.0001               0.735469   \n",
       "                                                                                      0.0005               0.696323   \n",
       "                                                                                      0.0010               0.686833   \n",
       "                                                                         0.5          0.0001               0.718861   \n",
       "                                                                                      0.0005               0.704626   \n",
       "                                                                                      0.0010               0.735469   \n",
       "                                     12        1          (256, 256)     0.1          0.0001               0.699881   \n",
       "                                                                                      0.0005               0.712930   \n",
       "                                                                                      0.0010               0.698695   \n",
       "                                                                         0.5          0.0001               0.667853   \n",
       "                                                                                      0.0005               0.714116   \n",
       "                                                                                      0.0010               0.722420   \n",
       "                                                          (512, 512)     0.1          0.0001               0.721234   \n",
       "                                                                                      0.0005               0.701068   \n",
       "                                                                                      0.0010               0.696323   \n",
       "                                                                         0.5          0.0001               0.688019   \n",
       "                                                                                      0.0005               0.709371   \n",
       "                                                                                      0.0010               0.698695   \n",
       "           12              3         10        1          (256, 256)     0.1          0.0001               0.699881   \n",
       "                                                                                      0.0005               0.683274   \n",
       "                                                                                      0.0010               0.715303   \n",
       "                                                                         0.5          0.0001               0.711744   \n",
       "                                                                                      0.0005               0.680902   \n",
       "                                                                                      0.0010               0.693950   \n",
       "                                                          (512, 512)     0.1          0.0001               0.677343   \n",
       "                                                                                      0.0005               0.712930   \n",
       "                                                                                      0.0010               0.742586   \n",
       "                                                                         0.5          0.0001               0.683274   \n",
       "                                                                                      0.0005               0.703440   \n",
       "                                                                                      0.0010               0.754448   \n",
       "\n",
       "                                                                                                     valid_f1  \\\n",
       "dimensions output_channels sig_depth num_heads num_layers ffn_hidden_dim dropout_rate learning_rate             \n",
       "15         8               4         6         1          (256, 256)     0.1          0.0001         0.600958   \n",
       "                                                                                      0.0005         0.676161   \n",
       "                                                                                      0.0010         0.649962   \n",
       "                                                                         0.5          0.0001         0.666193   \n",
       "                                                                                      0.0005         0.686140   \n",
       "                                                                                      0.0010         0.640897   \n",
       "                                                          (512, 512)     0.1          0.0001         0.711003   \n",
       "                                                                                      0.0005         0.652814   \n",
       "                                                                                      0.0010         0.656084   \n",
       "                                                                         0.5          0.0001         0.679420   \n",
       "                                                                                      0.0005         0.663148   \n",
       "                                                                                      0.0010         0.702658   \n",
       "                                     12        1          (256, 256)     0.1          0.0001         0.641648   \n",
       "                                                                                      0.0005         0.680937   \n",
       "                                                                                      0.0010         0.665123   \n",
       "                                                                         0.5          0.0001         0.620326   \n",
       "                                                                                      0.0005         0.674760   \n",
       "                                                                                      0.0010         0.686418   \n",
       "                                                          (512, 512)     0.1          0.0001         0.683470   \n",
       "                                                                                      0.0005         0.658993   \n",
       "                                                                                      0.0010         0.652470   \n",
       "                                                                         0.5          0.0001         0.644093   \n",
       "                                                                                      0.0005         0.674171   \n",
       "                                                                                      0.0010         0.650252   \n",
       "           12              3         10        1          (256, 256)     0.1          0.0001         0.660886   \n",
       "                                                                                      0.0005         0.620796   \n",
       "                                                                                      0.0010         0.657678   \n",
       "                                                                         0.5          0.0001         0.665826   \n",
       "                                                                                      0.0005         0.645281   \n",
       "                                                                                      0.0010         0.670233   \n",
       "                                                          (512, 512)     0.1          0.0001         0.647379   \n",
       "                                                                                      0.0005         0.671291   \n",
       "                                                                                      0.0010         0.714413   \n",
       "                                                                         0.5          0.0001         0.643414   \n",
       "                                                                                      0.0005         0.661875   \n",
       "                                                                                      0.0010         0.703446   \n",
       "\n",
       "                                                                                                     valid_precision  \\\n",
       "dimensions output_channels sig_depth num_heads num_layers ffn_hidden_dim dropout_rate learning_rate                    \n",
       "15         8               4         6         1          (256, 256)     0.1          0.0001                0.639850   \n",
       "                                                                                      0.0005                0.693083   \n",
       "                                                                                      0.0010                0.659568   \n",
       "                                                                         0.5          0.0001                0.704705   \n",
       "                                                                                      0.0005                0.691222   \n",
       "                                                                                      0.0010                0.693559   \n",
       "                                                          (512, 512)     0.1          0.0001                0.717649   \n",
       "                                                                                      0.0005                0.679568   \n",
       "                                                                                      0.0010                0.662340   \n",
       "                                                                         0.5          0.0001                0.703125   \n",
       "                                                                                      0.0005                0.679613   \n",
       "                                                                                      0.0010                0.714960   \n",
       "                                     12        1          (256, 256)     0.1          0.0001                0.695839   \n",
       "                                                                                      0.0005                0.693701   \n",
       "                                                                                      0.0010                0.681167   \n",
       "                                                                         0.5          0.0001                0.633220   \n",
       "                                                                                      0.0005                0.693291   \n",
       "                                                                                      0.0010                0.699569   \n",
       "                                                          (512, 512)     0.1          0.0001                0.707994   \n",
       "                                                                                      0.0005                0.672415   \n",
       "                                                                                      0.0010                0.670571   \n",
       "                                                                         0.5          0.0001                0.664583   \n",
       "                                                                                      0.0005                0.685253   \n",
       "                                                                                      0.0010                0.672456   \n",
       "           12              3         10        1          (256, 256)     0.1          0.0001                0.677639   \n",
       "                                                                                      0.0005                0.655091   \n",
       "                                                                                      0.0010                0.703630   \n",
       "                                                                         0.5          0.0001                0.693873   \n",
       "                                                                                      0.0005                0.651805   \n",
       "                                                                                      0.0010                0.673361   \n",
       "                                                          (512, 512)     0.1          0.0001                0.651878   \n",
       "                                                                                      0.0005                0.689902   \n",
       "                                                                                      0.0010                0.735213   \n",
       "                                                                         0.5          0.0001                0.653418   \n",
       "                                                                                      0.0005                0.685768   \n",
       "                                                                                      0.0010                0.758766   \n",
       "\n",
       "                                                                                                     valid_recall  \\\n",
       "dimensions output_channels sig_depth num_heads num_layers ffn_hidden_dim dropout_rate learning_rate                 \n",
       "15         8               4         6         1          (256, 256)     0.1          0.0001             0.602229   \n",
       "                                                                                      0.0005             0.670172   \n",
       "                                                                                      0.0010             0.647123   \n",
       "                                                                         0.5          0.0001             0.665462   \n",
       "                                                                                      0.0005             0.683052   \n",
       "                                                                                      0.0010             0.640934   \n",
       "                                                          (512, 512)     0.1          0.0001             0.708721   \n",
       "                                                                                      0.0005             0.650582   \n",
       "                                                                                      0.0010             0.654380   \n",
       "                                                                         0.5          0.0001             0.673193   \n",
       "                                                                                      0.0005             0.657803   \n",
       "                                                                                      0.0010             0.697475   \n",
       "                                     12        1          (256, 256)     0.1          0.0001             0.638615   \n",
       "                                                                                      0.0005             0.677676   \n",
       "                                                                                      0.0010             0.665799   \n",
       "                                                                         0.5          0.0001             0.617693   \n",
       "                                                                                      0.0005             0.668766   \n",
       "                                                                                      0.0010             0.680907   \n",
       "                                                          (512, 512)     0.1          0.0001             0.679976   \n",
       "                                                                                      0.0005             0.657118   \n",
       "                                                                                      0.0010             0.648474   \n",
       "                                                                         0.5          0.0001             0.639847   \n",
       "                                                                                      0.0005             0.669259   \n",
       "                                                                                      0.0010             0.646119   \n",
       "           12              3         10        1          (256, 256)     0.1          0.0001             0.656890   \n",
       "                                                                                      0.0005             0.618551   \n",
       "                                                                                      0.0010             0.651422   \n",
       "                                                                         0.5          0.0001             0.662687   \n",
       "                                                                                      0.0005             0.642695   \n",
       "                                                                                      0.0010             0.669807   \n",
       "                                                          (512, 512)     0.1          0.0001             0.646228   \n",
       "                                                                                      0.0005             0.666429   \n",
       "                                                                                      0.0010             0.714308   \n",
       "                                                                         0.5          0.0001             0.640340   \n",
       "                                                                                      0.0005             0.656169   \n",
       "                                                                                      0.0010             0.692692   \n",
       "\n",
       "                                                                                                     ...  \\\n",
       "dimensions output_channels sig_depth num_heads num_layers ffn_hidden_dim dropout_rate learning_rate  ...   \n",
       "15         8               4         6         1          (256, 256)     0.1          0.0001         ...   \n",
       "                                                                                      0.0005         ...   \n",
       "                                                                                      0.0010         ...   \n",
       "                                                                         0.5          0.0001         ...   \n",
       "                                                                                      0.0005         ...   \n",
       "                                                                                      0.0010         ...   \n",
       "                                                          (512, 512)     0.1          0.0001         ...   \n",
       "                                                                                      0.0005         ...   \n",
       "                                                                                      0.0010         ...   \n",
       "                                                                         0.5          0.0001         ...   \n",
       "                                                                                      0.0005         ...   \n",
       "                                                                                      0.0010         ...   \n",
       "                                     12        1          (256, 256)     0.1          0.0001         ...   \n",
       "                                                                                      0.0005         ...   \n",
       "                                                                                      0.0010         ...   \n",
       "                                                                         0.5          0.0001         ...   \n",
       "                                                                                      0.0005         ...   \n",
       "                                                                                      0.0010         ...   \n",
       "                                                          (512, 512)     0.1          0.0001         ...   \n",
       "                                                                                      0.0005         ...   \n",
       "                                                                                      0.0010         ...   \n",
       "                                                                         0.5          0.0001         ...   \n",
       "                                                                                      0.0005         ...   \n",
       "                                                                                      0.0010         ...   \n",
       "           12              3         10        1          (256, 256)     0.1          0.0001         ...   \n",
       "                                                                                      0.0005         ...   \n",
       "                                                                                      0.0010         ...   \n",
       "                                                                         0.5          0.0001         ...   \n",
       "                                                                                      0.0005         ...   \n",
       "                                                                                      0.0010         ...   \n",
       "                                                          (512, 512)     0.1          0.0001         ...   \n",
       "                                                                                      0.0005         ...   \n",
       "                                                                                      0.0010         ...   \n",
       "                                                                         0.5          0.0001         ...   \n",
       "                                                                                      0.0005         ...   \n",
       "                                                                                      0.0010         ...   \n",
       "\n",
       "                                                                                                     input_channels  \\\n",
       "dimensions output_channels sig_depth num_heads num_layers ffn_hidden_dim dropout_rate learning_rate                   \n",
       "15         8               4         6         1          (256, 256)     0.1          0.0001                   17.0   \n",
       "                                                                                      0.0005                   17.0   \n",
       "                                                                                      0.0010                   17.0   \n",
       "                                                                         0.5          0.0001                   17.0   \n",
       "                                                                                      0.0005                   17.0   \n",
       "                                                                                      0.0010                   17.0   \n",
       "                                                          (512, 512)     0.1          0.0001                   17.0   \n",
       "                                                                                      0.0005                   17.0   \n",
       "                                                                                      0.0010                   17.0   \n",
       "                                                                         0.5          0.0001                   17.0   \n",
       "                                                                                      0.0005                   17.0   \n",
       "                                                                                      0.0010                   17.0   \n",
       "                                     12        1          (256, 256)     0.1          0.0001                   17.0   \n",
       "                                                                                      0.0005                   17.0   \n",
       "                                                                                      0.0010                   17.0   \n",
       "                                                                         0.5          0.0001                   17.0   \n",
       "                                                                                      0.0005                   17.0   \n",
       "                                                                                      0.0010                   17.0   \n",
       "                                                          (512, 512)     0.1          0.0001                   17.0   \n",
       "                                                                                      0.0005                   17.0   \n",
       "                                                                                      0.0010                   17.0   \n",
       "                                                                         0.5          0.0001                   17.0   \n",
       "                                                                                      0.0005                   17.0   \n",
       "                                                                                      0.0010                   17.0   \n",
       "           12              3         10        1          (256, 256)     0.1          0.0001                   17.0   \n",
       "                                                                                      0.0005                   17.0   \n",
       "                                                                                      0.0010                   17.0   \n",
       "                                                                         0.5          0.0001                   17.0   \n",
       "                                                                                      0.0005                   17.0   \n",
       "                                                                                      0.0010                   17.0   \n",
       "                                                          (512, 512)     0.1          0.0001                   17.0   \n",
       "                                                                                      0.0005                   17.0   \n",
       "                                                                                      0.0010                   17.0   \n",
       "                                                                         0.5          0.0001                   17.0   \n",
       "                                                                                      0.0005                   17.0   \n",
       "                                                                                      0.0010                   17.0   \n",
       "\n",
       "                                                                                                     add_time_in_path  \\\n",
       "dimensions output_channels sig_depth num_heads num_layers ffn_hidden_dim dropout_rate learning_rate                     \n",
       "15         8               4         6         1          (256, 256)     0.1          0.0001                      1.0   \n",
       "                                                                                      0.0005                      1.0   \n",
       "                                                                                      0.0010                      1.0   \n",
       "                                                                         0.5          0.0001                      1.0   \n",
       "                                                                                      0.0005                      1.0   \n",
       "                                                                                      0.0010                      1.0   \n",
       "                                                          (512, 512)     0.1          0.0001                      1.0   \n",
       "                                                                                      0.0005                      1.0   \n",
       "                                                                                      0.0010                      1.0   \n",
       "                                                                         0.5          0.0001                      1.0   \n",
       "                                                                                      0.0005                      1.0   \n",
       "                                                                                      0.0010                      1.0   \n",
       "                                     12        1          (256, 256)     0.1          0.0001                      1.0   \n",
       "                                                                                      0.0005                      1.0   \n",
       "                                                                                      0.0010                      1.0   \n",
       "                                                                         0.5          0.0001                      1.0   \n",
       "                                                                                      0.0005                      1.0   \n",
       "                                                                                      0.0010                      1.0   \n",
       "                                                          (512, 512)     0.1          0.0001                      1.0   \n",
       "                                                                                      0.0005                      1.0   \n",
       "                                                                                      0.0010                      1.0   \n",
       "                                                                         0.5          0.0001                      1.0   \n",
       "                                                                                      0.0005                      1.0   \n",
       "                                                                                      0.0010                      1.0   \n",
       "           12              3         10        1          (256, 256)     0.1          0.0001                      1.0   \n",
       "                                                                                      0.0005                      1.0   \n",
       "                                                                                      0.0010                      1.0   \n",
       "                                                                         0.5          0.0001                      1.0   \n",
       "                                                                                      0.0005                      1.0   \n",
       "                                                                                      0.0010                      1.0   \n",
       "                                                          (512, 512)     0.1          0.0001                      1.0   \n",
       "                                                                                      0.0005                      1.0   \n",
       "                                                                                      0.0010                      1.0   \n",
       "                                                                         0.5          0.0001                      1.0   \n",
       "                                                                                      0.0005                      1.0   \n",
       "                                                                                      0.0010                      1.0   \n",
       "\n",
       "                                                                                                     num_features  \\\n",
       "dimensions output_channels sig_depth num_heads num_layers ffn_hidden_dim dropout_rate learning_rate                 \n",
       "15         8               4         6         1          (256, 256)     0.1          0.0001                  2.0   \n",
       "                                                                                      0.0005                  2.0   \n",
       "                                                                                      0.0010                  2.0   \n",
       "                                                                         0.5          0.0001                  2.0   \n",
       "                                                                                      0.0005                  2.0   \n",
       "                                                                                      0.0010                  2.0   \n",
       "                                                          (512, 512)     0.1          0.0001                  2.0   \n",
       "                                                                                      0.0005                  2.0   \n",
       "                                                                                      0.0010                  2.0   \n",
       "                                                                         0.5          0.0001                  2.0   \n",
       "                                                                                      0.0005                  2.0   \n",
       "                                                                                      0.0010                  2.0   \n",
       "                                     12        1          (256, 256)     0.1          0.0001                  2.0   \n",
       "                                                                                      0.0005                  2.0   \n",
       "                                                                                      0.0010                  2.0   \n",
       "                                                                         0.5          0.0001                  2.0   \n",
       "                                                                                      0.0005                  2.0   \n",
       "                                                                                      0.0010                  2.0   \n",
       "                                                          (512, 512)     0.1          0.0001                  2.0   \n",
       "                                                                                      0.0005                  2.0   \n",
       "                                                                                      0.0010                  2.0   \n",
       "                                                                         0.5          0.0001                  2.0   \n",
       "                                                                                      0.0005                  2.0   \n",
       "                                                                                      0.0010                  2.0   \n",
       "           12              3         10        1          (256, 256)     0.1          0.0001                  2.0   \n",
       "                                                                                      0.0005                  2.0   \n",
       "                                                                                      0.0010                  2.0   \n",
       "                                                                         0.5          0.0001                  2.0   \n",
       "                                                                                      0.0005                  2.0   \n",
       "                                                                                      0.0010                  2.0   \n",
       "                                                          (512, 512)     0.1          0.0001                  2.0   \n",
       "                                                                                      0.0005                  2.0   \n",
       "                                                                                      0.0010                  2.0   \n",
       "                                                                         0.5          0.0001                  2.0   \n",
       "                                                                                      0.0005                  2.0   \n",
       "                                                                                      0.0010                  2.0   \n",
       "\n",
       "                                                                                                     embedding_dim  \\\n",
       "dimensions output_channels sig_depth num_heads num_layers ffn_hidden_dim dropout_rate learning_rate                  \n",
       "15         8               4         6         1          (256, 256)     0.1          0.0001                 384.0   \n",
       "                                                                                      0.0005                 384.0   \n",
       "                                                                                      0.0010                 384.0   \n",
       "                                                                         0.5          0.0001                 384.0   \n",
       "                                                                                      0.0005                 384.0   \n",
       "                                                                                      0.0010                 384.0   \n",
       "                                                          (512, 512)     0.1          0.0001                 384.0   \n",
       "                                                                                      0.0005                 384.0   \n",
       "                                                                                      0.0010                 384.0   \n",
       "                                                                         0.5          0.0001                 384.0   \n",
       "                                                                                      0.0005                 384.0   \n",
       "                                                                                      0.0010                 384.0   \n",
       "                                     12        1          (256, 256)     0.1          0.0001                 384.0   \n",
       "                                                                                      0.0005                 384.0   \n",
       "                                                                                      0.0010                 384.0   \n",
       "                                                                         0.5          0.0001                 384.0   \n",
       "                                                                                      0.0005                 384.0   \n",
       "                                                                                      0.0010                 384.0   \n",
       "                                                          (512, 512)     0.1          0.0001                 384.0   \n",
       "                                                                                      0.0005                 384.0   \n",
       "                                                                                      0.0010                 384.0   \n",
       "                                                                         0.5          0.0001                 384.0   \n",
       "                                                                                      0.0005                 384.0   \n",
       "                                                                                      0.0010                 384.0   \n",
       "           12              3         10        1          (256, 256)     0.1          0.0001                 384.0   \n",
       "                                                                                      0.0005                 384.0   \n",
       "                                                                                      0.0010                 384.0   \n",
       "                                                                         0.5          0.0001                 384.0   \n",
       "                                                                                      0.0005                 384.0   \n",
       "                                                                                      0.0010                 384.0   \n",
       "                                                          (512, 512)     0.1          0.0001                 384.0   \n",
       "                                                                                      0.0005                 384.0   \n",
       "                                                                                      0.0010                 384.0   \n",
       "                                                                         0.5          0.0001                 384.0   \n",
       "                                                                                      0.0005                 384.0   \n",
       "                                                                                      0.0010                 384.0   \n",
       "\n",
       "                                                                                                     log_signature  \\\n",
       "dimensions output_channels sig_depth num_heads num_layers ffn_hidden_dim dropout_rate learning_rate                  \n",
       "15         8               4         6         1          (256, 256)     0.1          0.0001                   1.0   \n",
       "                                                                                      0.0005                   1.0   \n",
       "                                                                                      0.0010                   1.0   \n",
       "                                                                         0.5          0.0001                   1.0   \n",
       "                                                                                      0.0005                   1.0   \n",
       "                                                                                      0.0010                   1.0   \n",
       "                                                          (512, 512)     0.1          0.0001                   1.0   \n",
       "                                                                                      0.0005                   1.0   \n",
       "                                                                                      0.0010                   1.0   \n",
       "                                                                         0.5          0.0001                   1.0   \n",
       "                                                                                      0.0005                   1.0   \n",
       "                                                                                      0.0010                   1.0   \n",
       "                                     12        1          (256, 256)     0.1          0.0001                   1.0   \n",
       "                                                                                      0.0005                   1.0   \n",
       "                                                                                      0.0010                   1.0   \n",
       "                                                                         0.5          0.0001                   1.0   \n",
       "                                                                                      0.0005                   1.0   \n",
       "                                                                                      0.0010                   1.0   \n",
       "                                                          (512, 512)     0.1          0.0001                   1.0   \n",
       "                                                                                      0.0005                   1.0   \n",
       "                                                                                      0.0010                   1.0   \n",
       "                                                                         0.5          0.0001                   1.0   \n",
       "                                                                                      0.0005                   1.0   \n",
       "                                                                                      0.0010                   1.0   \n",
       "           12              3         10        1          (256, 256)     0.1          0.0001                   1.0   \n",
       "                                                                                      0.0005                   1.0   \n",
       "                                                                                      0.0010                   1.0   \n",
       "                                                                         0.5          0.0001                   1.0   \n",
       "                                                                                      0.0005                   1.0   \n",
       "                                                                                      0.0010                   1.0   \n",
       "                                                          (512, 512)     0.1          0.0001                   1.0   \n",
       "                                                                                      0.0005                   1.0   \n",
       "                                                                                      0.0010                   1.0   \n",
       "                                                                         0.5          0.0001                   1.0   \n",
       "                                                                                      0.0005                   1.0   \n",
       "                                                                                      0.0010                   1.0   \n",
       "\n",
       "                                                                                                          seed  \\\n",
       "dimensions output_channels sig_depth num_heads num_layers ffn_hidden_dim dropout_rate learning_rate              \n",
       "15         8               4         6         1          (256, 256)     0.1          0.0001         45.333333   \n",
       "                                                                                      0.0005         45.333333   \n",
       "                                                                                      0.0010         45.333333   \n",
       "                                                                         0.5          0.0001         45.333333   \n",
       "                                                                                      0.0005         45.333333   \n",
       "                                                                                      0.0010         45.333333   \n",
       "                                                          (512, 512)     0.1          0.0001         45.333333   \n",
       "                                                                                      0.0005         45.333333   \n",
       "                                                                                      0.0010         45.333333   \n",
       "                                                                         0.5          0.0001         45.333333   \n",
       "                                                                                      0.0005         45.333333   \n",
       "                                                                                      0.0010         45.333333   \n",
       "                                     12        1          (256, 256)     0.1          0.0001         45.333333   \n",
       "                                                                                      0.0005         45.333333   \n",
       "                                                                                      0.0010         45.333333   \n",
       "                                                                         0.5          0.0001         45.333333   \n",
       "                                                                                      0.0005         45.333333   \n",
       "                                                                                      0.0010         45.333333   \n",
       "                                                          (512, 512)     0.1          0.0001         45.333333   \n",
       "                                                                                      0.0005         45.333333   \n",
       "                                                                                      0.0010         45.333333   \n",
       "                                                                         0.5          0.0001         45.333333   \n",
       "                                                                                      0.0005         45.333333   \n",
       "                                                                                      0.0010         45.333333   \n",
       "           12              3         10        1          (256, 256)     0.1          0.0001         45.333333   \n",
       "                                                                                      0.0005         45.333333   \n",
       "                                                                                      0.0010         45.333333   \n",
       "                                                                         0.5          0.0001         45.333333   \n",
       "                                                                                      0.0005         45.333333   \n",
       "                                                                                      0.0010         45.333333   \n",
       "                                                          (512, 512)     0.1          0.0001         45.333333   \n",
       "                                                                                      0.0005         45.333333   \n",
       "                                                                                      0.0010         45.333333   \n",
       "                                                                         0.5          0.0001         45.333333   \n",
       "                                                                                      0.0005         45.333333   \n",
       "                                                                                      0.0010         45.333333   \n",
       "\n",
       "                                                                                                     gamma  \\\n",
       "dimensions output_channels sig_depth num_heads num_layers ffn_hidden_dim dropout_rate learning_rate          \n",
       "15         8               4         6         1          (256, 256)     0.1          0.0001           2.0   \n",
       "                                                                                      0.0005           2.0   \n",
       "                                                                                      0.0010           2.0   \n",
       "                                                                         0.5          0.0001           2.0   \n",
       "                                                                                      0.0005           2.0   \n",
       "                                                                                      0.0010           2.0   \n",
       "                                                          (512, 512)     0.1          0.0001           2.0   \n",
       "                                                                                      0.0005           2.0   \n",
       "                                                                                      0.0010           2.0   \n",
       "                                                                         0.5          0.0001           2.0   \n",
       "                                                                                      0.0005           2.0   \n",
       "                                                                                      0.0010           2.0   \n",
       "                                     12        1          (256, 256)     0.1          0.0001           2.0   \n",
       "                                                                                      0.0005           2.0   \n",
       "                                                                                      0.0010           2.0   \n",
       "                                                                         0.5          0.0001           2.0   \n",
       "                                                                                      0.0005           2.0   \n",
       "                                                                                      0.0010           2.0   \n",
       "                                                          (512, 512)     0.1          0.0001           2.0   \n",
       "                                                                                      0.0005           2.0   \n",
       "                                                                                      0.0010           2.0   \n",
       "                                                                         0.5          0.0001           2.0   \n",
       "                                                                                      0.0005           2.0   \n",
       "                                                                                      0.0010           2.0   \n",
       "           12              3         10        1          (256, 256)     0.1          0.0001           2.0   \n",
       "                                                                                      0.0005           2.0   \n",
       "                                                                                      0.0010           2.0   \n",
       "                                                                         0.5          0.0001           2.0   \n",
       "                                                                                      0.0005           2.0   \n",
       "                                                                                      0.0010           2.0   \n",
       "                                                          (512, 512)     0.1          0.0001           2.0   \n",
       "                                                                                      0.0005           2.0   \n",
       "                                                                                      0.0010           2.0   \n",
       "                                                                         0.5          0.0001           2.0   \n",
       "                                                                                      0.0005           2.0   \n",
       "                                                                                      0.0010           2.0   \n",
       "\n",
       "                                                                                                     k_fold  \\\n",
       "dimensions output_channels sig_depth num_heads num_layers ffn_hidden_dim dropout_rate learning_rate           \n",
       "15         8               4         6         1          (256, 256)     0.1          0.0001            0.0   \n",
       "                                                                                      0.0005            0.0   \n",
       "                                                                                      0.0010            0.0   \n",
       "                                                                         0.5          0.0001            0.0   \n",
       "                                                                                      0.0005            0.0   \n",
       "                                                                                      0.0010            0.0   \n",
       "                                                          (512, 512)     0.1          0.0001            0.0   \n",
       "                                                                                      0.0005            0.0   \n",
       "                                                                                      0.0010            0.0   \n",
       "                                                                         0.5          0.0001            0.0   \n",
       "                                                                                      0.0005            0.0   \n",
       "                                                                                      0.0010            0.0   \n",
       "                                     12        1          (256, 256)     0.1          0.0001            0.0   \n",
       "                                                                                      0.0005            0.0   \n",
       "                                                                                      0.0010            0.0   \n",
       "                                                                         0.5          0.0001            0.0   \n",
       "                                                                                      0.0005            0.0   \n",
       "                                                                                      0.0010            0.0   \n",
       "                                                          (512, 512)     0.1          0.0001            0.0   \n",
       "                                                                                      0.0005            0.0   \n",
       "                                                                                      0.0010            0.0   \n",
       "                                                                         0.5          0.0001            0.0   \n",
       "                                                                                      0.0005            0.0   \n",
       "                                                                                      0.0010            0.0   \n",
       "           12              3         10        1          (256, 256)     0.1          0.0001            0.0   \n",
       "                                                                                      0.0005            0.0   \n",
       "                                                                                      0.0010            0.0   \n",
       "                                                                         0.5          0.0001            0.0   \n",
       "                                                                                      0.0005            0.0   \n",
       "                                                                                      0.0010            0.0   \n",
       "                                                          (512, 512)     0.1          0.0001            0.0   \n",
       "                                                                                      0.0005            0.0   \n",
       "                                                                                      0.0010            0.0   \n",
       "                                                                         0.5          0.0001            0.0   \n",
       "                                                                                      0.0005            0.0   \n",
       "                                                                                      0.0010            0.0   \n",
       "\n",
       "                                                                                                     batch_size  \\\n",
       "dimensions output_channels sig_depth num_heads num_layers ffn_hidden_dim dropout_rate learning_rate               \n",
       "15         8               4         6         1          (256, 256)     0.1          0.0001               64.0   \n",
       "                                                                                      0.0005               64.0   \n",
       "                                                                                      0.0010               64.0   \n",
       "                                                                         0.5          0.0001               64.0   \n",
       "                                                                                      0.0005               64.0   \n",
       "                                                                                      0.0010               64.0   \n",
       "                                                          (512, 512)     0.1          0.0001               64.0   \n",
       "                                                                                      0.0005               64.0   \n",
       "                                                                                      0.0010               64.0   \n",
       "                                                                         0.5          0.0001               64.0   \n",
       "                                                                                      0.0005               64.0   \n",
       "                                                                                      0.0010               64.0   \n",
       "                                     12        1          (256, 256)     0.1          0.0001               64.0   \n",
       "                                                                                      0.0005               64.0   \n",
       "                                                                                      0.0010               64.0   \n",
       "                                                                         0.5          0.0001               64.0   \n",
       "                                                                                      0.0005               64.0   \n",
       "                                                                                      0.0010               64.0   \n",
       "                                                          (512, 512)     0.1          0.0001               64.0   \n",
       "                                                                                      0.0005               64.0   \n",
       "                                                                                      0.0010               64.0   \n",
       "                                                                         0.5          0.0001               64.0   \n",
       "                                                                                      0.0005               64.0   \n",
       "                                                                                      0.0010               64.0   \n",
       "           12              3         10        1          (256, 256)     0.1          0.0001               64.0   \n",
       "                                                                                      0.0005               64.0   \n",
       "                                                                                      0.0010               64.0   \n",
       "                                                                         0.5          0.0001               64.0   \n",
       "                                                                                      0.0005               64.0   \n",
       "                                                                                      0.0010               64.0   \n",
       "                                                          (512, 512)     0.1          0.0001               64.0   \n",
       "                                                                                      0.0005               64.0   \n",
       "                                                                                      0.0010               64.0   \n",
       "                                                                         0.5          0.0001               64.0   \n",
       "                                                                                      0.0005               64.0   \n",
       "                                                                                      0.0010               64.0   \n",
       "\n",
       "                                                                                                     model_id  \n",
       "dimensions output_channels sig_depth num_heads num_layers ffn_hidden_dim dropout_rate learning_rate            \n",
       "15         8               4         6         1          (256, 256)     0.1          0.0001             16.0  \n",
       "                                                                                      0.0005             17.0  \n",
       "                                                                                      0.0010             15.0  \n",
       "                                                                         0.5          0.0001             13.0  \n",
       "                                                                                      0.0005             14.0  \n",
       "                                                                                      0.0010             12.0  \n",
       "                                                          (512, 512)     0.1          0.0001             22.0  \n",
       "                                                                                      0.0005             23.0  \n",
       "                                                                                      0.0010             21.0  \n",
       "                                                                         0.5          0.0001             19.0  \n",
       "                                                                                      0.0005             20.0  \n",
       "                                                                                      0.0010             18.0  \n",
       "                                     12        1          (256, 256)     0.1          0.0001             28.0  \n",
       "                                                                                      0.0005             29.0  \n",
       "                                                                                      0.0010             27.0  \n",
       "                                                                         0.5          0.0001             25.0  \n",
       "                                                                                      0.0005             26.0  \n",
       "                                                                                      0.0010             24.0  \n",
       "                                                          (512, 512)     0.1          0.0001             34.0  \n",
       "                                                                                      0.0005             35.0  \n",
       "                                                                                      0.0010             33.0  \n",
       "                                                                         0.5          0.0001             31.0  \n",
       "                                                                                      0.0005             32.0  \n",
       "                                                                                      0.0010             30.0  \n",
       "           12              3         10        1          (256, 256)     0.1          0.0001              4.0  \n",
       "                                                                                      0.0005              5.0  \n",
       "                                                                                      0.0010              3.0  \n",
       "                                                                         0.5          0.0001              1.0  \n",
       "                                                                                      0.0005              2.0  \n",
       "                                                                                      0.0010              0.0  \n",
       "                                                          (512, 512)     0.1          0.0001             10.0  \n",
       "                                                                                      0.0005             11.0  \n",
       "                                                                                      0.0010              9.0  \n",
       "                                                                         0.5          0.0001              7.0  \n",
       "                                                                                      0.0005              8.0  \n",
       "                                                                                      0.0010              6.0  \n",
       "\n",
       "[36 rows x 21 columns]"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "swmhau_network_grp.groupby([\"dimensions\",\n",
    "                            \"output_channels\",\n",
    "                            \"sig_depth\",\n",
    "                            \"num_heads\",\n",
    "                            \"num_layers\",\n",
    "                            \"ffn_hidden_dim\",\n",
    "                            \"dropout_rate\",\n",
    "                            \"learning_rate\"]).mean()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "603dee18",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>loss</th>\n",
       "      <th>accuracy</th>\n",
       "      <th>f1</th>\n",
       "      <th>f1_scores</th>\n",
       "      <th>precision</th>\n",
       "      <th>precision_scores</th>\n",
       "      <th>recall</th>\n",
       "      <th>recall_scores</th>\n",
       "      <th>valid_loss</th>\n",
       "      <th>valid_accuracy</th>\n",
       "      <th>...</th>\n",
       "      <th>learning_rate</th>\n",
       "      <th>seed</th>\n",
       "      <th>loss_function</th>\n",
       "      <th>gamma</th>\n",
       "      <th>k_fold</th>\n",
       "      <th>n_splits</th>\n",
       "      <th>augmentation_type</th>\n",
       "      <th>hidden_dim_aug</th>\n",
       "      <th>comb_method</th>\n",
       "      <th>batch_size</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0.388765</td>\n",
       "      <td>0.634890</td>\n",
       "      <td>0.633350</td>\n",
       "      <td>[0.657117278424351, 0.6095820591233435]</td>\n",
       "      <td>0.633874</td>\n",
       "      <td>[0.6461267605633803, 0.6216216216216216]</td>\n",
       "      <td>0.633244</td>\n",
       "      <td>[0.668488160291439, 0.598]</td>\n",
       "      <td>0.187115</td>\n",
       "      <td>0.747331</td>\n",
       "      <td>...</td>\n",
       "      <td>0.001</td>\n",
       "      <td>1</td>\n",
       "      <td>focal</td>\n",
       "      <td>2</td>\n",
       "      <td>False</td>\n",
       "      <td>None</td>\n",
       "      <td>Conv1d</td>\n",
       "      <td>None</td>\n",
       "      <td>concatenation</td>\n",
       "      <td>64</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0.796810</td>\n",
       "      <td>0.601525</td>\n",
       "      <td>0.599367</td>\n",
       "      <td>[0.6287744227353464, 0.5699588477366254]</td>\n",
       "      <td>0.600191</td>\n",
       "      <td>[0.6135181975736569, 0.586864406779661]</td>\n",
       "      <td>0.599404</td>\n",
       "      <td>[0.644808743169399, 0.554]</td>\n",
       "      <td>0.164889</td>\n",
       "      <td>0.786477</td>\n",
       "      <td>...</td>\n",
       "      <td>0.001</td>\n",
       "      <td>12</td>\n",
       "      <td>focal</td>\n",
       "      <td>2</td>\n",
       "      <td>False</td>\n",
       "      <td>None</td>\n",
       "      <td>Conv1d</td>\n",
       "      <td>None</td>\n",
       "      <td>concatenation</td>\n",
       "      <td>64</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0.325039</td>\n",
       "      <td>0.655863</td>\n",
       "      <td>0.652833</td>\n",
       "      <td>[0.6203995793901157, 0.6852659110723627]</td>\n",
       "      <td>0.670625</td>\n",
       "      <td>[0.7338308457711443, 0.60741885625966]</td>\n",
       "      <td>0.661670</td>\n",
       "      <td>[0.5373406193078324, 0.786]</td>\n",
       "      <td>0.202457</td>\n",
       "      <td>0.693950</td>\n",
       "      <td>...</td>\n",
       "      <td>0.001</td>\n",
       "      <td>123</td>\n",
       "      <td>focal</td>\n",
       "      <td>2</td>\n",
       "      <td>False</td>\n",
       "      <td>None</td>\n",
       "      <td>Conv1d</td>\n",
       "      <td>None</td>\n",
       "      <td>concatenation</td>\n",
       "      <td>64</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>3 rows  42 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "       loss  accuracy        f1                                 f1_scores  \\\n",
       "0  0.388765  0.634890  0.633350   [0.657117278424351, 0.6095820591233435]   \n",
       "0  0.796810  0.601525  0.599367  [0.6287744227353464, 0.5699588477366254]   \n",
       "0  0.325039  0.655863  0.652833  [0.6203995793901157, 0.6852659110723627]   \n",
       "\n",
       "   precision                          precision_scores    recall  \\\n",
       "0   0.633874  [0.6461267605633803, 0.6216216216216216]  0.633244   \n",
       "0   0.600191   [0.6135181975736569, 0.586864406779661]  0.599404   \n",
       "0   0.670625    [0.7338308457711443, 0.60741885625966]  0.661670   \n",
       "\n",
       "                 recall_scores  valid_loss  valid_accuracy  ...  \\\n",
       "0   [0.668488160291439, 0.598]    0.187115        0.747331  ...   \n",
       "0   [0.644808743169399, 0.554]    0.164889        0.786477  ...   \n",
       "0  [0.5373406193078324, 0.786]    0.202457        0.693950  ...   \n",
       "\n",
       "   learning_rate seed  loss_function gamma  k_fold n_splits  \\\n",
       "0          0.001    1          focal     2   False     None   \n",
       "0          0.001   12          focal     2   False     None   \n",
       "0          0.001  123          focal     2   False     None   \n",
       "\n",
       "   augmentation_type  hidden_dim_aug    comb_method batch_size  \n",
       "0             Conv1d            None  concatenation         64  \n",
       "0             Conv1d            None  concatenation         64  \n",
       "0             Conv1d            None  concatenation         64  \n",
       "\n",
       "[3 rows x 42 columns]"
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "best_swmhau_network_grp"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a7a3e5b1-4130-4b3f-a15e-57353492f1d4",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Index(['loss', 'accuracy', 'f1', 'f1_scores', 'precision', 'precision_scores',\n",
       "       'recall', 'recall_scores', 'valid_loss', 'valid_accuracy', 'valid_f1',\n",
       "       'valid_f1_scores', 'valid_precision', 'valid_precision_scores',\n",
       "       'valid_recall', 'valid_recall_scores', 'k', 'dimensions', 'sig_depth',\n",
       "       'method', 'input_channels', 'output_channels', 'features',\n",
       "       'standardise_method', 'add_time_in_path', 'num_features',\n",
       "       'embedding_dim', 'log_signature', 'num_heads', 'num_layers',\n",
       "       'ffn_hidden_dim', 'dropout_rate', 'learning_rate', 'seed',\n",
       "       'loss_function', 'gamma', 'k_fold', 'n_splits', 'augmentation_type',\n",
       "       'hidden_dim_aug', 'comb_method', 'batch_size'],\n",
       "      dtype='object')"
      ]
     },
     "execution_count": 32,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "best_swmhau_network_grp.columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "id": "e706aad7-e55f-4402-9df8-4e2cb0a0eb82",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>dimensions</th>\n",
       "      <th>output_channels</th>\n",
       "      <th>sig_depth</th>\n",
       "      <th>num_heads</th>\n",
       "      <th>num_layers</th>\n",
       "      <th>ffn_hidden_dim</th>\n",
       "      <th>dropout_rate</th>\n",
       "      <th>learning_rate</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>15</td>\n",
       "      <td>12</td>\n",
       "      <td>3</td>\n",
       "      <td>10</td>\n",
       "      <td>1</td>\n",
       "      <td>(512, 512)</td>\n",
       "      <td>0.1</td>\n",
       "      <td>0.001</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>15</td>\n",
       "      <td>12</td>\n",
       "      <td>3</td>\n",
       "      <td>10</td>\n",
       "      <td>1</td>\n",
       "      <td>(512, 512)</td>\n",
       "      <td>0.1</td>\n",
       "      <td>0.001</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>15</td>\n",
       "      <td>12</td>\n",
       "      <td>3</td>\n",
       "      <td>10</td>\n",
       "      <td>1</td>\n",
       "      <td>(512, 512)</td>\n",
       "      <td>0.1</td>\n",
       "      <td>0.001</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   dimensions  output_channels  sig_depth  num_heads  num_layers  \\\n",
       "0          15               12          3         10           1   \n",
       "0          15               12          3         10           1   \n",
       "0          15               12          3         10           1   \n",
       "\n",
       "  ffn_hidden_dim  dropout_rate  learning_rate  \n",
       "0     (512, 512)           0.1          0.001  \n",
       "0     (512, 512)           0.1          0.001  \n",
       "0     (512, 512)           0.1          0.001  "
      ]
     },
     "execution_count": 35,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "best_swmhau_network_grp[[\"dimensions\",\n",
    "                         \"output_channels\",\n",
    "                         \"sig_depth\",\n",
    "                         \"num_heads\",\n",
    "                         \"num_layers\",\n",
    "                         \"ffn_hidden_dim\",\n",
    "                         \"dropout_rate\",\n",
    "                         \"learning_rate\"]]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "e9d503c3",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.6285163497470242"
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "best_swmhau_network_grp[\"f1\"].mean()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "f3079077",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.6348967814281874"
      ]
     },
     "execution_count": 22,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "best_swmhau_network_grp[\"precision\"].mean()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "eb2894ed",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.6314395871281118"
      ]
     },
     "execution_count": 23,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "best_swmhau_network_grp[\"recall\"].mean()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "a3e8bbc5",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([0.63543043, 0.62160227])"
      ]
     },
     "execution_count": 24,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "np.stack(best_swmhau_network_grp[\"f1_scores\"]).mean(axis=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "4601b7f2",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([0.66449193, 0.60530163])"
      ]
     },
     "execution_count": 25,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "np.stack(best_swmhau_network_grp[\"precision_scores\"]).mean(axis=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "a3201dd5",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([0.61687917, 0.646     ])"
      ]
     },
     "execution_count": 26,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "np.stack(best_swmhau_network_grp[\"recall_scores\"]).mean(axis=0)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "nlpsig-networks (Conda)",
   "language": "python",
   "name": "sys_nlpsig-networks"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.17"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
