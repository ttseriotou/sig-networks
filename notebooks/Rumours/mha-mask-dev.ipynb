{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "2a2ab372-fcac-4506-add6-2cfc51d61ab8",
   "metadata": {},
   "outputs": [],
   "source": [
    "seed = 2023\n",
    "from nlpsig_networks.scripts.swnu_network_functions import (\n",
    "    obtain_SWNUNetwork_input\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4e0ad91f-9f08-419e-8119-c93715159d28",
   "metadata": {},
   "source": [
    "## Rumours"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 275,
   "id": "c89e7b21",
   "metadata": {},
   "outputs": [],
   "source": [
    "from __future__ import annotations\n",
    "\n",
    "import nlpsig\n",
    "from nlpsig_networks.pytorch_utils import _get_timestamp, SaveBestModel, set_seed\n",
    "from nlpsig_networks.swnu_network import SWNUNetwork\n",
    "from nlpsig_networks.scripts.implement_model import implement_model\n",
    "from typing import Iterable\n",
    "import torch\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "from tqdm.auto import tqdm\n",
    "import os\n",
    "\n",
    "\n",
    "def obtain_SWNUNetwork_input(\n",
    "    method: str,\n",
    "    dimension: int,\n",
    "    df: pd.DataFrame,\n",
    "    id_column: str,\n",
    "    label_column: str,\n",
    "    embeddings: np.array,\n",
    "    k: int,\n",
    "    features: list[str] | str | None = None,\n",
    "    standardise_method: list[str] | str | None = None,\n",
    "    include_features_in_path: bool = False,\n",
    "    seed: int = 42,\n",
    "    path_indices : list | np.array | None = None\n",
    ") -> dict[str, torch.tensor | int]:\n",
    "    # use nlpsig to construct the path as a numpy array\n",
    "    # first define how we construct the path\n",
    "    # i.e. padding by history for the last k posts,\n",
    "    # include features and apply requested standardisation\n",
    "    # construct the path using dimension reduced embeddings \n",
    "    # and include the currrent embedding in the path\n",
    "    path_specifics = {\"pad_by\": \"history\",\n",
    "                      \"zero_padding\": True,\n",
    "                      \"method\": \"k_last\",\n",
    "                      \"k\": k,\n",
    "                      \"features\": features,\n",
    "                      \"standardise_method\": standardise_method,\n",
    "                      \"embeddings\": \"dim_reduced\",\n",
    "                      \"include_current_embedding\": True}\n",
    "    \n",
    "    # first perform dimension reduction on embeddings\n",
    "    if dimension == embeddings.shape[1]:\n",
    "        # no need to perform dimensionality reduction\n",
    "        embeddings_reduced = embeddings\n",
    "    else:\n",
    "        reduction = nlpsig.DimReduce(method=method,\n",
    "                                     n_components=dimension)\n",
    "        embeddings_reduced = reduction.fit_transform(embeddings,\n",
    "                                                     random_state=seed)\n",
    "    \n",
    "    # obtain path by using PrepareData class and .pad method\n",
    "    paths = nlpsig.PrepareData(df,\n",
    "                               id_column=id_column,\n",
    "                               label_column=label_column,\n",
    "                               embeddings=embeddings,\n",
    "                               embeddings_reduced=embeddings_reduced)\n",
    "    paths.pad(**path_specifics)\n",
    "    \n",
    "    # slice the path in specified way\n",
    "    if path_indices is not None:\n",
    "        paths.array_padded = paths.array_padded[path_indices]\n",
    "        paths.embeddings = paths.embeddings[path_indices]\n",
    "        paths.embeddings_reduced = paths.embeddings_reduced[path_indices]\n",
    "    \n",
    "    # construct path for SWNUNetwork which is given as a dictionary with keys\n",
    "    # \"x_data\", \"input_channels\" and \"num_features\"\n",
    "    # include features and (full, not dimension reduced) embeddings in the FFN input\n",
    "    return paths.get_torch_path_for_SWNUNetwork(\n",
    "        include_features_in_path=include_features_in_path,\n",
    "        include_features_in_input=True,\n",
    "        include_embedding_in_input=True,\n",
    "        reduced_embeddings=False\n",
    "    )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 276,
   "id": "dff20ec3-c34b-4058-8ec5-ddf94d63e348",
   "metadata": {},
   "outputs": [],
   "source": [
    "%run load_sbert-embeddings.py"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 277,
   "id": "24fadcec-ab8d-4a2b-b7f5-e746c4ee1f8c",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>id</th>\n",
       "      <th>label</th>\n",
       "      <th>datetime</th>\n",
       "      <th>text</th>\n",
       "      <th>timeline_id</th>\n",
       "      <th>set</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>5.249902e+17</td>\n",
       "      <td>0</td>\n",
       "      <td>2014-10-22 18:26:23</td>\n",
       "      <td>Police have clarified that there were two shoo...</td>\n",
       "      <td>0</td>\n",
       "      <td>train</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>5.249906e+17</td>\n",
       "      <td>0</td>\n",
       "      <td>2014-10-22 18:27:58</td>\n",
       "      <td>@CTVNews you guys \"confirmed\" there were 3 sho...</td>\n",
       "      <td>0</td>\n",
       "      <td>train</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>5.249908e+17</td>\n",
       "      <td>1</td>\n",
       "      <td>2014-10-22 18:28:46</td>\n",
       "      <td>@CTVNews get it right. http://t.co/GHYxMuzPG9</td>\n",
       "      <td>0</td>\n",
       "      <td>train</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>5.249927e+17</td>\n",
       "      <td>1</td>\n",
       "      <td>2014-10-22 18:36:29</td>\n",
       "      <td>RT @CTVNews Police have clarified that there w...</td>\n",
       "      <td>0</td>\n",
       "      <td>train</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>5.250038e+17</td>\n",
       "      <td>1</td>\n",
       "      <td>2014-10-22 19:20:41</td>\n",
       "      <td>@CTVNews @ctvsaskatoon so what happened at Rid...</td>\n",
       "      <td>0</td>\n",
       "      <td>train</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "             id label            datetime  \\\n",
       "0  5.249902e+17     0 2014-10-22 18:26:23   \n",
       "1  5.249906e+17     0 2014-10-22 18:27:58   \n",
       "2  5.249908e+17     1 2014-10-22 18:28:46   \n",
       "3  5.249927e+17     1 2014-10-22 18:36:29   \n",
       "4  5.250038e+17     1 2014-10-22 19:20:41   \n",
       "\n",
       "                                                text timeline_id    set  \n",
       "0  Police have clarified that there were two shoo...           0  train  \n",
       "1  @CTVNews you guys \"confirmed\" there were 3 sho...           0  train  \n",
       "2      @CTVNews get it right. http://t.co/GHYxMuzPG9           0  train  \n",
       "3  RT @CTVNews Police have clarified that there w...           0  train  \n",
       "4  @CTVNews @ctvsaskatoon so what happened at Rid...           0  train  "
      ]
     },
     "execution_count": 277,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_rumours.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 278,
   "id": "cd2259de",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "5568"
      ]
     },
     "execution_count": 278,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(df_rumours)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 279,
   "id": "28f2730f",
   "metadata": {},
   "outputs": [],
   "source": [
    "import signatory"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 280,
   "id": "e1908cc0-4b2b-4c1d-8b17-6c237ed1849a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[INFO] Concatenating the embeddings to the dataframe...\n",
      "[INFO] - columns beginning with 'e' denote the full embddings.\n",
      "[INFO] - columns beginning with 'd' denote the dimension reduced embeddings.\n",
      "[INFO] Adding time feature columns into dataframe in `.df`.\n",
      "[INFO] Adding 'time_encoding' feature...\n",
      "[INFO] Adding 'time_diff' feature...\n",
      "[INFO] Adding 'timeline_index' feature...\n",
      "[INFO] Padding ids and storing in `.df_padded` and `.array_padded` attributes.\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "1cc99ea6238549b593ff74cbe0f33754",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/5568 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[INFO] The path was created for each item in the dataframe, by looking at its history, so to include embeddings in the FFN input, we concatenate the embeddings for each sentence / text.\n"
     ]
    }
   ],
   "source": [
    "x_data = obtain_SWNUNetwork_input(\n",
    "    method=\"umap\",\n",
    "    dimension=3,\n",
    "    df=df_rumours,\n",
    "    id_column='timeline_id',\n",
    "    label_column='label',\n",
    "    embeddings=sbert_embeddings,\n",
    "    k=10,\n",
    "    features=['time_encoding', 'timeline_index'],\n",
    "    standardise_method=None,\n",
    "    include_features_in_path=True,\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 281,
   "id": "57dc8fb5",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "dict_keys(['x_data', 'input_channels', 'num_features'])"
      ]
     },
     "execution_count": 281,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "x_data.keys()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 282,
   "id": "2abd7518",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([5568, 10, 5])"
      ]
     },
     "execution_count": 282,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "x_data[\"x_data\"][\"path\"].shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 283,
   "id": "cdee30cb",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([5568, 386])"
      ]
     },
     "execution_count": 283,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "x_data[\"x_data\"][\"features\"].shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 284,
   "id": "65c266e5",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "5"
      ]
     },
     "execution_count": 284,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "x_data[\"input_channels\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 285,
   "id": "297955c3",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "386"
      ]
     },
     "execution_count": 285,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "x_data[\"num_features\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 286,
   "id": "f0b55c30-40af-42b9-9325-a0fcd3547ec0",
   "metadata": {},
   "outputs": [],
   "source": [
    "path = x_data[\"x_data\"][\"path\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 287,
   "id": "155810f6-0e44-4d7d-a379-fd75d373b5ea",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([5568, 10, 5])"
      ]
     },
     "execution_count": 287,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "path.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 288,
   "id": "954679b6",
   "metadata": {},
   "outputs": [],
   "source": [
    "signatures = signatory.logsignature(path, 2, stream=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 289,
   "id": "f3f200f3",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([5568, 9, 15])"
      ]
     },
     "execution_count": 289,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "signatures.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "562717e3",
   "metadata": {},
   "source": [
    "Apply convolution to this path."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 290,
   "id": "76e463b6",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[ 2.0148e+03,  1.0000e+00, -7.2296e+00,  2.7356e+00,  8.0972e+00],\n",
       "        [ 0.0000e+00,  0.0000e+00,  0.0000e+00,  0.0000e+00,  0.0000e+00],\n",
       "        [ 0.0000e+00,  0.0000e+00,  0.0000e+00,  0.0000e+00,  0.0000e+00],\n",
       "        [ 0.0000e+00,  0.0000e+00,  0.0000e+00,  0.0000e+00,  0.0000e+00],\n",
       "        [ 0.0000e+00,  0.0000e+00,  0.0000e+00,  0.0000e+00,  0.0000e+00],\n",
       "        [ 0.0000e+00,  0.0000e+00,  0.0000e+00,  0.0000e+00,  0.0000e+00],\n",
       "        [ 0.0000e+00,  0.0000e+00,  0.0000e+00,  0.0000e+00,  0.0000e+00],\n",
       "        [ 0.0000e+00,  0.0000e+00,  0.0000e+00,  0.0000e+00,  0.0000e+00],\n",
       "        [ 0.0000e+00,  0.0000e+00,  0.0000e+00,  0.0000e+00,  0.0000e+00],\n",
       "        [ 0.0000e+00,  0.0000e+00,  0.0000e+00,  0.0000e+00,  0.0000e+00]],\n",
       "       dtype=torch.float64)"
      ]
     },
     "execution_count": 290,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "path[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 291,
   "id": "81a60c69",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[-2.0148e+03, -1.0000e+00,  7.2296e+00, -2.7356e+00, -8.0972e+00,\n",
       "          0.0000e+00,  0.0000e+00,  0.0000e+00,  0.0000e+00,  0.0000e+00,\n",
       "          0.0000e+00,  0.0000e+00,  0.0000e+00,  0.0000e+00,  0.0000e+00],\n",
       "        [-2.0148e+03, -1.0000e+00,  7.2296e+00, -2.7356e+00, -8.0972e+00,\n",
       "          0.0000e+00,  0.0000e+00,  0.0000e+00,  0.0000e+00,  0.0000e+00,\n",
       "          0.0000e+00,  0.0000e+00,  0.0000e+00,  0.0000e+00,  0.0000e+00],\n",
       "        [-2.0148e+03, -1.0000e+00,  7.2296e+00, -2.7356e+00, -8.0972e+00,\n",
       "          0.0000e+00,  0.0000e+00,  0.0000e+00,  0.0000e+00,  0.0000e+00,\n",
       "          0.0000e+00,  0.0000e+00,  0.0000e+00,  0.0000e+00,  0.0000e+00],\n",
       "        [-2.0148e+03, -1.0000e+00,  7.2296e+00, -2.7356e+00, -8.0972e+00,\n",
       "          0.0000e+00,  0.0000e+00,  0.0000e+00,  0.0000e+00,  0.0000e+00,\n",
       "          0.0000e+00,  0.0000e+00,  0.0000e+00,  0.0000e+00,  0.0000e+00],\n",
       "        [-2.0148e+03, -1.0000e+00,  7.2296e+00, -2.7356e+00, -8.0972e+00,\n",
       "          0.0000e+00,  0.0000e+00,  0.0000e+00,  0.0000e+00,  0.0000e+00,\n",
       "          0.0000e+00,  0.0000e+00,  0.0000e+00,  0.0000e+00,  0.0000e+00],\n",
       "        [-2.0148e+03, -1.0000e+00,  7.2296e+00, -2.7356e+00, -8.0972e+00,\n",
       "          0.0000e+00,  0.0000e+00,  0.0000e+00,  0.0000e+00,  0.0000e+00,\n",
       "          0.0000e+00,  0.0000e+00,  0.0000e+00,  0.0000e+00,  0.0000e+00],\n",
       "        [-2.0148e+03, -1.0000e+00,  7.2296e+00, -2.7356e+00, -8.0972e+00,\n",
       "          0.0000e+00,  0.0000e+00,  0.0000e+00,  0.0000e+00,  0.0000e+00,\n",
       "          0.0000e+00,  0.0000e+00,  0.0000e+00,  0.0000e+00,  0.0000e+00],\n",
       "        [-2.0148e+03, -1.0000e+00,  7.2296e+00, -2.7356e+00, -8.0972e+00,\n",
       "          0.0000e+00,  0.0000e+00,  0.0000e+00,  0.0000e+00,  0.0000e+00,\n",
       "          0.0000e+00,  0.0000e+00,  0.0000e+00,  0.0000e+00,  0.0000e+00],\n",
       "        [-2.0148e+03, -1.0000e+00,  7.2296e+00, -2.7356e+00, -8.0972e+00,\n",
       "          0.0000e+00,  0.0000e+00,  0.0000e+00,  0.0000e+00,  0.0000e+00,\n",
       "          0.0000e+00,  0.0000e+00,  0.0000e+00,  0.0000e+00,  0.0000e+00]],\n",
       "       dtype=torch.float64)"
      ]
     },
     "execution_count": 291,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "signatures[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 292,
   "id": "f91b75ed",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[ 2.0148e+03,  1.0000e+00, -7.2296e+00,  2.7356e+00,  8.0972e+00],\n",
       "        [ 2.0148e+03,  2.0000e+00, -7.4468e+00,  3.6928e+00,  9.9551e+00],\n",
       "        [ 2.0148e+03,  3.0000e+00, -9.0931e+00,  1.2844e+01,  9.0442e+00],\n",
       "        [ 0.0000e+00,  0.0000e+00,  0.0000e+00,  0.0000e+00,  0.0000e+00],\n",
       "        [ 0.0000e+00,  0.0000e+00,  0.0000e+00,  0.0000e+00,  0.0000e+00],\n",
       "        [ 0.0000e+00,  0.0000e+00,  0.0000e+00,  0.0000e+00,  0.0000e+00],\n",
       "        [ 0.0000e+00,  0.0000e+00,  0.0000e+00,  0.0000e+00,  0.0000e+00],\n",
       "        [ 0.0000e+00,  0.0000e+00,  0.0000e+00,  0.0000e+00,  0.0000e+00],\n",
       "        [ 0.0000e+00,  0.0000e+00,  0.0000e+00,  0.0000e+00,  0.0000e+00],\n",
       "        [ 0.0000e+00,  0.0000e+00,  0.0000e+00,  0.0000e+00,  0.0000e+00]],\n",
       "       dtype=torch.float64)"
      ]
     },
     "execution_count": 292,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "path[2]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 293,
   "id": "0fd09d2d",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[ 3.0124e-06,  1.0000e+00, -2.1716e-01,  9.5729e-01,  1.8579e+00,\n",
       "          0.0000e+00,  0.0000e+00,  0.0000e+00,  0.0000e+00,  0.0000e+00,\n",
       "          0.0000e+00,  0.0000e+00,  0.0000e+00,  0.0000e+00,  0.0000e+00],\n",
       "        [ 4.5345e-06,  2.0000e+00, -1.8635e+00,  1.0108e+01,  9.4692e-01,\n",
       "          7.4518e-07, -2.3145e-06,  1.3055e-05, -2.7860e-06, -7.1461e-01,\n",
       "          4.0969e+00, -1.3844e+00, -2.0557e-01,  1.6283e+00, -8.9369e+00],\n",
       "        [-2.0148e+03, -1.0000e+00,  7.2296e+00, -2.7356e+00, -8.0972e+00,\n",
       "          2.0148e+03, -1.8773e+03,  1.0183e+04,  9.5393e+02,  5.5832e+00,\n",
       "          6.4156e+00, -9.0082e+00, -3.4197e+01,  5.7501e+00, -4.8567e+01],\n",
       "        [-2.0148e+03, -1.0000e+00,  7.2296e+00, -2.7356e+00, -8.0972e+00,\n",
       "          2.0148e+03, -1.8773e+03,  1.0183e+04,  9.5393e+02,  5.5832e+00,\n",
       "          6.4156e+00, -9.0082e+00, -3.4197e+01,  5.7501e+00, -4.8567e+01],\n",
       "        [-2.0148e+03, -1.0000e+00,  7.2296e+00, -2.7356e+00, -8.0972e+00,\n",
       "          2.0148e+03, -1.8773e+03,  1.0183e+04,  9.5393e+02,  5.5832e+00,\n",
       "          6.4156e+00, -9.0082e+00, -3.4197e+01,  5.7501e+00, -4.8567e+01],\n",
       "        [-2.0148e+03, -1.0000e+00,  7.2296e+00, -2.7356e+00, -8.0972e+00,\n",
       "          2.0148e+03, -1.8773e+03,  1.0183e+04,  9.5393e+02,  5.5832e+00,\n",
       "          6.4156e+00, -9.0082e+00, -3.4197e+01,  5.7501e+00, -4.8567e+01],\n",
       "        [-2.0148e+03, -1.0000e+00,  7.2296e+00, -2.7356e+00, -8.0972e+00,\n",
       "          2.0148e+03, -1.8773e+03,  1.0183e+04,  9.5393e+02,  5.5832e+00,\n",
       "          6.4156e+00, -9.0082e+00, -3.4197e+01,  5.7501e+00, -4.8567e+01],\n",
       "        [-2.0148e+03, -1.0000e+00,  7.2296e+00, -2.7356e+00, -8.0972e+00,\n",
       "          2.0148e+03, -1.8773e+03,  1.0183e+04,  9.5393e+02,  5.5832e+00,\n",
       "          6.4156e+00, -9.0082e+00, -3.4197e+01,  5.7501e+00, -4.8567e+01],\n",
       "        [-2.0148e+03, -1.0000e+00,  7.2296e+00, -2.7356e+00, -8.0972e+00,\n",
       "          2.0148e+03, -1.8773e+03,  1.0183e+04,  9.5393e+02,  5.5832e+00,\n",
       "          6.4156e+00, -9.0082e+00, -3.4197e+01,  5.7501e+00, -4.8567e+01]],\n",
       "       dtype=torch.float64)"
      ]
     },
     "execution_count": 293,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "signatures[2]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9760fab0-d2c8-4651-b95e-fdfaf755fedb",
   "metadata": {},
   "source": [
    "`True` values in the mask are the ones that indicate to MultiheadAttention to ignore in attention calculation."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 294,
   "id": "d0c3a2fc",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([8, 15])"
      ]
     },
     "execution_count": 294,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "signatures[0][1:].shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 295,
   "id": "c88bcf2f",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([8, 15])"
      ]
     },
     "execution_count": 295,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "signatures[0][:-1].shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 296,
   "id": "7119c972",
   "metadata": {},
   "outputs": [],
   "source": [
    "def obtain_signatures_mask(signatures: torch.tensor) -> torch.tensor:\n",
    "    # assuming that padding was applied from below\n",
    "    # signatures has dimensions [batch, length, channels]\n",
    "    # compare each row with the row above it (for each batch)\n",
    "    equal_to_previous = torch.eq(signatures[:,1:], signatures[:,:-1])\n",
    "    # look for cases when the entire row is equal to the previous row\n",
    "    equal_to_previous_row = torch.all(equal_to_previous, dim=2)\n",
    "    false_tensor = torch.full((signatures.shape[0],1), False, dtype=torch.bool)\n",
    "    # return bool tensor of dimension [batch, length]\n",
    "    return torch.cat((false_tensor, equal_to_previous_row), dim=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 297,
   "id": "d8fa2aa6",
   "metadata": {},
   "outputs": [],
   "source": [
    "mask = obtain_signatures_mask(signatures)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 298,
   "id": "0953a867",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([False,  True,  True,  True,  True,  True,  True,  True,  True])"
      ]
     },
     "execution_count": 298,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "mask[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 299,
   "id": "8e66ca63",
   "metadata": {},
   "outputs": [],
   "source": [
    "mask_ = (torch.sum(path, 2) == 0)[:,:-1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 300,
   "id": "61860126",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([False,  True,  True,  True,  True,  True,  True,  True,  True])"
      ]
     },
     "execution_count": 300,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "mask_[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 301,
   "id": "23f6353a",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 301,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "torch.equal(mask, mask_)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 147,
   "id": "cbbe03bf",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.bool"
      ]
     },
     "execution_count": 147,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "mask.dtype"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 148,
   "id": "0c1021a6",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([5568, 9])"
      ]
     },
     "execution_count": 148,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "mask.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 149,
   "id": "c5bdbf15-52da-4cb6-822e-a58dd52ec239",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[ 2.0148e+03,  1.0000e+00, -7.2296e+00,  2.7356e+00,  8.0972e+00],\n",
       "        [ 0.0000e+00,  0.0000e+00,  0.0000e+00,  0.0000e+00,  0.0000e+00],\n",
       "        [ 0.0000e+00,  0.0000e+00,  0.0000e+00,  0.0000e+00,  0.0000e+00],\n",
       "        [ 0.0000e+00,  0.0000e+00,  0.0000e+00,  0.0000e+00,  0.0000e+00],\n",
       "        [ 0.0000e+00,  0.0000e+00,  0.0000e+00,  0.0000e+00,  0.0000e+00],\n",
       "        [ 0.0000e+00,  0.0000e+00,  0.0000e+00,  0.0000e+00,  0.0000e+00],\n",
       "        [ 0.0000e+00,  0.0000e+00,  0.0000e+00,  0.0000e+00,  0.0000e+00],\n",
       "        [ 0.0000e+00,  0.0000e+00,  0.0000e+00,  0.0000e+00,  0.0000e+00],\n",
       "        [ 0.0000e+00,  0.0000e+00,  0.0000e+00,  0.0000e+00,  0.0000e+00],\n",
       "        [ 0.0000e+00,  0.0000e+00,  0.0000e+00,  0.0000e+00,  0.0000e+00]],\n",
       "       dtype=torch.float64)"
      ]
     },
     "execution_count": 149,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "path[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 150,
   "id": "6a95f265",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[-2.0148e+03, -1.0000e+00,  7.2296e+00, -2.7356e+00, -8.0972e+00,\n",
       "          0.0000e+00,  0.0000e+00,  0.0000e+00,  0.0000e+00,  0.0000e+00,\n",
       "          0.0000e+00,  0.0000e+00,  0.0000e+00,  0.0000e+00,  0.0000e+00],\n",
       "        [-2.0148e+03, -1.0000e+00,  7.2296e+00, -2.7356e+00, -8.0972e+00,\n",
       "          0.0000e+00,  0.0000e+00,  0.0000e+00,  0.0000e+00,  0.0000e+00,\n",
       "          0.0000e+00,  0.0000e+00,  0.0000e+00,  0.0000e+00,  0.0000e+00],\n",
       "        [-2.0148e+03, -1.0000e+00,  7.2296e+00, -2.7356e+00, -8.0972e+00,\n",
       "          0.0000e+00,  0.0000e+00,  0.0000e+00,  0.0000e+00,  0.0000e+00,\n",
       "          0.0000e+00,  0.0000e+00,  0.0000e+00,  0.0000e+00,  0.0000e+00],\n",
       "        [-2.0148e+03, -1.0000e+00,  7.2296e+00, -2.7356e+00, -8.0972e+00,\n",
       "          0.0000e+00,  0.0000e+00,  0.0000e+00,  0.0000e+00,  0.0000e+00,\n",
       "          0.0000e+00,  0.0000e+00,  0.0000e+00,  0.0000e+00,  0.0000e+00],\n",
       "        [-2.0148e+03, -1.0000e+00,  7.2296e+00, -2.7356e+00, -8.0972e+00,\n",
       "          0.0000e+00,  0.0000e+00,  0.0000e+00,  0.0000e+00,  0.0000e+00,\n",
       "          0.0000e+00,  0.0000e+00,  0.0000e+00,  0.0000e+00,  0.0000e+00],\n",
       "        [-2.0148e+03, -1.0000e+00,  7.2296e+00, -2.7356e+00, -8.0972e+00,\n",
       "          0.0000e+00,  0.0000e+00,  0.0000e+00,  0.0000e+00,  0.0000e+00,\n",
       "          0.0000e+00,  0.0000e+00,  0.0000e+00,  0.0000e+00,  0.0000e+00],\n",
       "        [-2.0148e+03, -1.0000e+00,  7.2296e+00, -2.7356e+00, -8.0972e+00,\n",
       "          0.0000e+00,  0.0000e+00,  0.0000e+00,  0.0000e+00,  0.0000e+00,\n",
       "          0.0000e+00,  0.0000e+00,  0.0000e+00,  0.0000e+00,  0.0000e+00],\n",
       "        [-2.0148e+03, -1.0000e+00,  7.2296e+00, -2.7356e+00, -8.0972e+00,\n",
       "          0.0000e+00,  0.0000e+00,  0.0000e+00,  0.0000e+00,  0.0000e+00,\n",
       "          0.0000e+00,  0.0000e+00,  0.0000e+00,  0.0000e+00,  0.0000e+00],\n",
       "        [-2.0148e+03, -1.0000e+00,  7.2296e+00, -2.7356e+00, -8.0972e+00,\n",
       "          0.0000e+00,  0.0000e+00,  0.0000e+00,  0.0000e+00,  0.0000e+00,\n",
       "          0.0000e+00,  0.0000e+00,  0.0000e+00,  0.0000e+00,  0.0000e+00]],\n",
       "       dtype=torch.float64)"
      ]
     },
     "execution_count": 150,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "signatures[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 151,
   "id": "c69488a9-dec3-46ca-ade8-11c64324186e",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([False,  True,  True,  True,  True,  True,  True,  True,  True])"
      ]
     },
     "execution_count": 151,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "mask[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 108,
   "id": "1a3c253c-4385-4dcc-b67f-8d4ed77de2fb",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[ 2.0148e+03,  1.0000e+00, -7.2296e+00,  2.7356e+00,  8.0972e+00],\n",
       "        [ 2.0148e+03,  2.0000e+00, -7.4468e+00,  3.6928e+00,  9.9551e+00],\n",
       "        [ 0.0000e+00,  0.0000e+00,  0.0000e+00,  0.0000e+00,  0.0000e+00],\n",
       "        [ 0.0000e+00,  0.0000e+00,  0.0000e+00,  0.0000e+00,  0.0000e+00],\n",
       "        [ 0.0000e+00,  0.0000e+00,  0.0000e+00,  0.0000e+00,  0.0000e+00],\n",
       "        [ 0.0000e+00,  0.0000e+00,  0.0000e+00,  0.0000e+00,  0.0000e+00],\n",
       "        [ 0.0000e+00,  0.0000e+00,  0.0000e+00,  0.0000e+00,  0.0000e+00],\n",
       "        [ 0.0000e+00,  0.0000e+00,  0.0000e+00,  0.0000e+00,  0.0000e+00],\n",
       "        [ 0.0000e+00,  0.0000e+00,  0.0000e+00,  0.0000e+00,  0.0000e+00],\n",
       "        [ 0.0000e+00,  0.0000e+00,  0.0000e+00,  0.0000e+00,  0.0000e+00]],\n",
       "       dtype=torch.float64)"
      ]
     },
     "execution_count": 108,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "path[1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 152,
   "id": "0635f215",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[ 3.0124e-06,  1.0000e+00, -2.1716e-01,  9.5729e-01,  1.8579e+00,\n",
       "          0.0000e+00,  0.0000e+00,  0.0000e+00,  0.0000e+00,  0.0000e+00,\n",
       "          0.0000e+00,  0.0000e+00,  0.0000e+00,  0.0000e+00,  0.0000e+00],\n",
       "        [-2.0148e+03, -1.0000e+00,  7.2296e+00, -2.7356e+00, -8.0972e+00,\n",
       "          1.0074e+03, -2.1876e+02,  9.6438e+02,  1.8716e+03,  3.5062e+00,\n",
       "         -8.8913e-01, -3.1197e+00, -3.1634e+00, -5.8367e+00, -1.3345e+00],\n",
       "        [-2.0148e+03, -1.0000e+00,  7.2296e+00, -2.7356e+00, -8.0972e+00,\n",
       "          1.0074e+03, -2.1876e+02,  9.6438e+02,  1.8716e+03,  3.5062e+00,\n",
       "         -8.8913e-01, -3.1197e+00, -3.1634e+00, -5.8367e+00, -1.3345e+00],\n",
       "        [-2.0148e+03, -1.0000e+00,  7.2296e+00, -2.7356e+00, -8.0972e+00,\n",
       "          1.0074e+03, -2.1876e+02,  9.6438e+02,  1.8716e+03,  3.5062e+00,\n",
       "         -8.8913e-01, -3.1197e+00, -3.1634e+00, -5.8367e+00, -1.3345e+00],\n",
       "        [-2.0148e+03, -1.0000e+00,  7.2296e+00, -2.7356e+00, -8.0972e+00,\n",
       "          1.0074e+03, -2.1876e+02,  9.6438e+02,  1.8716e+03,  3.5062e+00,\n",
       "         -8.8913e-01, -3.1197e+00, -3.1634e+00, -5.8367e+00, -1.3345e+00],\n",
       "        [-2.0148e+03, -1.0000e+00,  7.2296e+00, -2.7356e+00, -8.0972e+00,\n",
       "          1.0074e+03, -2.1876e+02,  9.6438e+02,  1.8716e+03,  3.5062e+00,\n",
       "         -8.8913e-01, -3.1197e+00, -3.1634e+00, -5.8367e+00, -1.3345e+00],\n",
       "        [-2.0148e+03, -1.0000e+00,  7.2296e+00, -2.7356e+00, -8.0972e+00,\n",
       "          1.0074e+03, -2.1876e+02,  9.6438e+02,  1.8716e+03,  3.5062e+00,\n",
       "         -8.8913e-01, -3.1197e+00, -3.1634e+00, -5.8367e+00, -1.3345e+00],\n",
       "        [-2.0148e+03, -1.0000e+00,  7.2296e+00, -2.7356e+00, -8.0972e+00,\n",
       "          1.0074e+03, -2.1876e+02,  9.6438e+02,  1.8716e+03,  3.5062e+00,\n",
       "         -8.8913e-01, -3.1197e+00, -3.1634e+00, -5.8367e+00, -1.3345e+00],\n",
       "        [-2.0148e+03, -1.0000e+00,  7.2296e+00, -2.7356e+00, -8.0972e+00,\n",
       "          1.0074e+03, -2.1876e+02,  9.6438e+02,  1.8716e+03,  3.5062e+00,\n",
       "         -8.8913e-01, -3.1197e+00, -3.1634e+00, -5.8367e+00, -1.3345e+00]],\n",
       "       dtype=torch.float64)"
      ]
     },
     "execution_count": 152,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "signatures[1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 153,
   "id": "fff7e21c-6344-4948-b1b7-0fb234e3fee9",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([False, False,  True,  True,  True,  True,  True,  True,  True])"
      ]
     },
     "execution_count": 153,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "mask[1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 156,
   "id": "6f3d090f",
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch.nn as nn\n",
    "mha = nn.MultiheadAttention(\n",
    "    embed_dim=15,\n",
    "    num_heads=1,\n",
    "    batch_first=True,\n",
    ").double()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 157,
   "id": "11f2d8a1",
   "metadata": {},
   "outputs": [],
   "source": [
    "attn_output, attn_output_weights = mha(signatures.double(), signatures.double(), signatures.double(), key_padding_mask=mask)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 158,
   "id": "5744ef37",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([[-2.0148e+03, -1.0000e+00,  7.2296e+00, -2.7356e+00, -8.0972e+00,\n",
      "          0.0000e+00,  0.0000e+00,  0.0000e+00,  0.0000e+00,  0.0000e+00,\n",
      "          0.0000e+00,  0.0000e+00,  0.0000e+00,  0.0000e+00,  0.0000e+00],\n",
      "        [-2.0148e+03, -1.0000e+00,  7.2296e+00, -2.7356e+00, -8.0972e+00,\n",
      "          0.0000e+00,  0.0000e+00,  0.0000e+00,  0.0000e+00,  0.0000e+00,\n",
      "          0.0000e+00,  0.0000e+00,  0.0000e+00,  0.0000e+00,  0.0000e+00],\n",
      "        [-2.0148e+03, -1.0000e+00,  7.2296e+00, -2.7356e+00, -8.0972e+00,\n",
      "          0.0000e+00,  0.0000e+00,  0.0000e+00,  0.0000e+00,  0.0000e+00,\n",
      "          0.0000e+00,  0.0000e+00,  0.0000e+00,  0.0000e+00,  0.0000e+00],\n",
      "        [-2.0148e+03, -1.0000e+00,  7.2296e+00, -2.7356e+00, -8.0972e+00,\n",
      "          0.0000e+00,  0.0000e+00,  0.0000e+00,  0.0000e+00,  0.0000e+00,\n",
      "          0.0000e+00,  0.0000e+00,  0.0000e+00,  0.0000e+00,  0.0000e+00],\n",
      "        [-2.0148e+03, -1.0000e+00,  7.2296e+00, -2.7356e+00, -8.0972e+00,\n",
      "          0.0000e+00,  0.0000e+00,  0.0000e+00,  0.0000e+00,  0.0000e+00,\n",
      "          0.0000e+00,  0.0000e+00,  0.0000e+00,  0.0000e+00,  0.0000e+00],\n",
      "        [-2.0148e+03, -1.0000e+00,  7.2296e+00, -2.7356e+00, -8.0972e+00,\n",
      "          0.0000e+00,  0.0000e+00,  0.0000e+00,  0.0000e+00,  0.0000e+00,\n",
      "          0.0000e+00,  0.0000e+00,  0.0000e+00,  0.0000e+00,  0.0000e+00],\n",
      "        [-2.0148e+03, -1.0000e+00,  7.2296e+00, -2.7356e+00, -8.0972e+00,\n",
      "          0.0000e+00,  0.0000e+00,  0.0000e+00,  0.0000e+00,  0.0000e+00,\n",
      "          0.0000e+00,  0.0000e+00,  0.0000e+00,  0.0000e+00,  0.0000e+00],\n",
      "        [-2.0148e+03, -1.0000e+00,  7.2296e+00, -2.7356e+00, -8.0972e+00,\n",
      "          0.0000e+00,  0.0000e+00,  0.0000e+00,  0.0000e+00,  0.0000e+00,\n",
      "          0.0000e+00,  0.0000e+00,  0.0000e+00,  0.0000e+00,  0.0000e+00],\n",
      "        [-2.0148e+03, -1.0000e+00,  7.2296e+00, -2.7356e+00, -8.0972e+00,\n",
      "          0.0000e+00,  0.0000e+00,  0.0000e+00,  0.0000e+00,  0.0000e+00,\n",
      "          0.0000e+00,  0.0000e+00,  0.0000e+00,  0.0000e+00,  0.0000e+00]],\n",
      "       dtype=torch.float64)\n",
      "tensor([[ -39.0876,  -44.8515,  -32.2904,  -72.6063,   35.8824,  270.9407,\n",
      "         -285.3095,  147.0201,    2.5943,    9.1322,   66.5264,  215.1106,\n",
      "           63.0014,  396.8490,   49.1461],\n",
      "        [ -39.0876,  -44.8515,  -32.2904,  -72.6063,   35.8824,  270.9407,\n",
      "         -285.3095,  147.0201,    2.5943,    9.1322,   66.5264,  215.1106,\n",
      "           63.0014,  396.8490,   49.1461],\n",
      "        [ -39.0876,  -44.8515,  -32.2904,  -72.6063,   35.8824,  270.9407,\n",
      "         -285.3095,  147.0201,    2.5943,    9.1322,   66.5264,  215.1106,\n",
      "           63.0014,  396.8490,   49.1461],\n",
      "        [ -39.0876,  -44.8515,  -32.2904,  -72.6063,   35.8824,  270.9407,\n",
      "         -285.3095,  147.0201,    2.5943,    9.1322,   66.5264,  215.1106,\n",
      "           63.0014,  396.8490,   49.1461],\n",
      "        [ -39.0876,  -44.8515,  -32.2904,  -72.6063,   35.8824,  270.9407,\n",
      "         -285.3095,  147.0201,    2.5943,    9.1322,   66.5264,  215.1106,\n",
      "           63.0014,  396.8490,   49.1461],\n",
      "        [ -39.0876,  -44.8515,  -32.2904,  -72.6063,   35.8824,  270.9407,\n",
      "         -285.3095,  147.0201,    2.5943,    9.1322,   66.5264,  215.1106,\n",
      "           63.0014,  396.8490,   49.1461],\n",
      "        [ -39.0876,  -44.8515,  -32.2904,  -72.6063,   35.8824,  270.9407,\n",
      "         -285.3095,  147.0201,    2.5943,    9.1322,   66.5264,  215.1106,\n",
      "           63.0014,  396.8490,   49.1461],\n",
      "        [ -39.0876,  -44.8515,  -32.2904,  -72.6063,   35.8824,  270.9407,\n",
      "         -285.3095,  147.0201,    2.5943,    9.1322,   66.5264,  215.1106,\n",
      "           63.0014,  396.8490,   49.1461],\n",
      "        [ -39.0876,  -44.8515,  -32.2904,  -72.6063,   35.8824,  270.9407,\n",
      "         -285.3095,  147.0201,    2.5943,    9.1322,   66.5264,  215.1106,\n",
      "           63.0014,  396.8490,   49.1461]], dtype=torch.float64,\n",
      "       grad_fn=<SelectBackward>)\n"
     ]
    }
   ],
   "source": [
    "i=0\n",
    "print(signatures[i])\n",
    "# print(mask[i])\n",
    "print(attn_output[i])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 160,
   "id": "0730f67d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([[ 3.0124e-06,  1.0000e+00, -2.1716e-01,  9.5729e-01,  1.8579e+00,\n",
      "          0.0000e+00,  0.0000e+00,  0.0000e+00,  0.0000e+00,  0.0000e+00,\n",
      "          0.0000e+00,  0.0000e+00,  0.0000e+00,  0.0000e+00,  0.0000e+00],\n",
      "        [-2.0148e+03, -1.0000e+00,  7.2296e+00, -2.7356e+00, -8.0972e+00,\n",
      "          1.0074e+03, -2.1876e+02,  9.6438e+02,  1.8716e+03,  3.5062e+00,\n",
      "         -8.8913e-01, -3.1197e+00, -3.1634e+00, -5.8367e+00, -1.3345e+00],\n",
      "        [-2.0148e+03, -1.0000e+00,  7.2296e+00, -2.7356e+00, -8.0972e+00,\n",
      "          1.0074e+03, -2.1876e+02,  9.6438e+02,  1.8716e+03,  3.5062e+00,\n",
      "         -8.8913e-01, -3.1197e+00, -3.1634e+00, -5.8367e+00, -1.3345e+00],\n",
      "        [-2.0148e+03, -1.0000e+00,  7.2296e+00, -2.7356e+00, -8.0972e+00,\n",
      "          1.0074e+03, -2.1876e+02,  9.6438e+02,  1.8716e+03,  3.5062e+00,\n",
      "         -8.8913e-01, -3.1197e+00, -3.1634e+00, -5.8367e+00, -1.3345e+00],\n",
      "        [-2.0148e+03, -1.0000e+00,  7.2296e+00, -2.7356e+00, -8.0972e+00,\n",
      "          1.0074e+03, -2.1876e+02,  9.6438e+02,  1.8716e+03,  3.5062e+00,\n",
      "         -8.8913e-01, -3.1197e+00, -3.1634e+00, -5.8367e+00, -1.3345e+00],\n",
      "        [-2.0148e+03, -1.0000e+00,  7.2296e+00, -2.7356e+00, -8.0972e+00,\n",
      "          1.0074e+03, -2.1876e+02,  9.6438e+02,  1.8716e+03,  3.5062e+00,\n",
      "         -8.8913e-01, -3.1197e+00, -3.1634e+00, -5.8367e+00, -1.3345e+00],\n",
      "        [-2.0148e+03, -1.0000e+00,  7.2296e+00, -2.7356e+00, -8.0972e+00,\n",
      "          1.0074e+03, -2.1876e+02,  9.6438e+02,  1.8716e+03,  3.5062e+00,\n",
      "         -8.8913e-01, -3.1197e+00, -3.1634e+00, -5.8367e+00, -1.3345e+00],\n",
      "        [-2.0148e+03, -1.0000e+00,  7.2296e+00, -2.7356e+00, -8.0972e+00,\n",
      "          1.0074e+03, -2.1876e+02,  9.6438e+02,  1.8716e+03,  3.5062e+00,\n",
      "         -8.8913e-01, -3.1197e+00, -3.1634e+00, -5.8367e+00, -1.3345e+00],\n",
      "        [-2.0148e+03, -1.0000e+00,  7.2296e+00, -2.7356e+00, -8.0972e+00,\n",
      "          1.0074e+03, -2.1876e+02,  9.6438e+02,  1.8716e+03,  3.5062e+00,\n",
      "         -8.8913e-01, -3.1197e+00, -3.1634e+00, -5.8367e+00, -1.3345e+00]],\n",
      "       dtype=torch.float64)\n",
      "tensor([False, False,  True,  True,  True,  True,  True,  True,  True])\n",
      "tensor([[ 131.6951, -309.7222,  160.0019,  -32.8303, -158.4175,  534.9648,\n",
      "         -377.3273,  420.1287, -223.1454,  697.8203,  106.0938,  110.9961,\n",
      "          294.2986,  407.1962,  108.3683],\n",
      "        [ 131.6951, -309.7222,  160.0019,  -32.8303, -158.4175,  534.9648,\n",
      "         -377.3273,  420.1287, -223.1454,  697.8203,  106.0938,  110.9961,\n",
      "          294.2986,  407.1962,  108.3683],\n",
      "        [ 131.6951, -309.7222,  160.0019,  -32.8303, -158.4175,  534.9648,\n",
      "         -377.3273,  420.1287, -223.1454,  697.8203,  106.0938,  110.9961,\n",
      "          294.2986,  407.1962,  108.3683],\n",
      "        [ 131.6951, -309.7222,  160.0019,  -32.8303, -158.4175,  534.9648,\n",
      "         -377.3273,  420.1287, -223.1454,  697.8203,  106.0938,  110.9961,\n",
      "          294.2986,  407.1962,  108.3683],\n",
      "        [ 131.6951, -309.7222,  160.0019,  -32.8303, -158.4175,  534.9648,\n",
      "         -377.3273,  420.1287, -223.1454,  697.8203,  106.0938,  110.9961,\n",
      "          294.2986,  407.1962,  108.3683],\n",
      "        [ 131.6951, -309.7222,  160.0019,  -32.8303, -158.4175,  534.9648,\n",
      "         -377.3273,  420.1287, -223.1454,  697.8203,  106.0938,  110.9961,\n",
      "          294.2986,  407.1962,  108.3683],\n",
      "        [ 131.6951, -309.7222,  160.0019,  -32.8303, -158.4175,  534.9648,\n",
      "         -377.3273,  420.1287, -223.1454,  697.8203,  106.0938,  110.9961,\n",
      "          294.2986,  407.1962,  108.3683],\n",
      "        [ 131.6951, -309.7222,  160.0019,  -32.8303, -158.4175,  534.9648,\n",
      "         -377.3273,  420.1287, -223.1454,  697.8203,  106.0938,  110.9961,\n",
      "          294.2986,  407.1962,  108.3683],\n",
      "        [ 131.6951, -309.7222,  160.0019,  -32.8303, -158.4175,  534.9648,\n",
      "         -377.3273,  420.1287, -223.1454,  697.8203,  106.0938,  110.9961,\n",
      "          294.2986,  407.1962,  108.3683]], dtype=torch.float64,\n",
      "       grad_fn=<SelectBackward>)\n"
     ]
    }
   ],
   "source": [
    "i=1\n",
    "print(signatures[i])\n",
    "print(mask[i])\n",
    "print(attn_output[i])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 118,
   "id": "5047cb56",
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([[ 2.0148e+03,  1.0000e+00, -7.2296e+00,  2.7356e+00,  8.0972e+00],\n",
      "        [ 2.0148e+03,  2.0000e+00, -7.4468e+00,  3.6928e+00,  9.9551e+00],\n",
      "        [ 2.0148e+03,  3.0000e+00, -9.0931e+00,  1.2844e+01,  9.0442e+00],\n",
      "        [ 0.0000e+00,  0.0000e+00,  0.0000e+00,  0.0000e+00,  0.0000e+00],\n",
      "        [ 0.0000e+00,  0.0000e+00,  0.0000e+00,  0.0000e+00,  0.0000e+00],\n",
      "        [ 0.0000e+00,  0.0000e+00,  0.0000e+00,  0.0000e+00,  0.0000e+00],\n",
      "        [ 0.0000e+00,  0.0000e+00,  0.0000e+00,  0.0000e+00,  0.0000e+00],\n",
      "        [ 0.0000e+00,  0.0000e+00,  0.0000e+00,  0.0000e+00,  0.0000e+00],\n",
      "        [ 0.0000e+00,  0.0000e+00,  0.0000e+00,  0.0000e+00,  0.0000e+00],\n",
      "        [ 0.0000e+00,  0.0000e+00,  0.0000e+00,  0.0000e+00,  0.0000e+00]],\n",
      "       dtype=torch.float64)\n",
      "tensor([False, False, False,  True,  True,  True,  True,  True,  True,  True])\n",
      "tensor([[ 369.3173,  610.7261, -434.8319,  221.3471,  672.8438],\n",
      "        [ 369.3173,  610.7261, -434.8319,  221.3471,  672.8438],\n",
      "        [ 369.3173,  610.7261, -434.8319,  221.3471,  672.8438],\n",
      "        [ 370.1490,  610.5764, -434.6239,  222.5560,  673.5063],\n",
      "        [ 370.1490,  610.5764, -434.6239,  222.5560,  673.5063],\n",
      "        [ 370.1490,  610.5764, -434.6239,  222.5560,  673.5063],\n",
      "        [ 370.1490,  610.5764, -434.6239,  222.5560,  673.5063],\n",
      "        [ 370.1490,  610.5764, -434.6239,  222.5560,  673.5063],\n",
      "        [ 370.1490,  610.5764, -434.6239,  222.5560,  673.5063],\n",
      "        [ 370.1490,  610.5764, -434.6239,  222.5560,  673.5063]],\n",
      "       dtype=torch.float64, grad_fn=<SelectBackward>)\n"
     ]
    }
   ],
   "source": [
    "i=2\n",
    "print(path[i])\n",
    "print(mask[i])\n",
    "print(attn_output[i])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 119,
   "id": "cb5d7f57",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([[ 2.0148e+03,  1.0000e+00, -7.2296e+00,  2.7356e+00,  8.0972e+00],\n",
      "        [ 2.0148e+03,  2.0000e+00, -7.4468e+00,  3.6928e+00,  9.9551e+00],\n",
      "        [ 2.0148e+03,  3.0000e+00, -9.0931e+00,  1.2844e+01,  9.0442e+00],\n",
      "        [ 2.0148e+03,  4.0000e+00, -6.7662e+00,  2.6486e+00,  8.3875e+00],\n",
      "        [ 2.0148e+03,  5.0000e+00, -5.3710e+00,  7.5870e+00,  1.2499e+01],\n",
      "        [ 0.0000e+00,  0.0000e+00,  0.0000e+00,  0.0000e+00,  0.0000e+00],\n",
      "        [ 0.0000e+00,  0.0000e+00,  0.0000e+00,  0.0000e+00,  0.0000e+00],\n",
      "        [ 0.0000e+00,  0.0000e+00,  0.0000e+00,  0.0000e+00,  0.0000e+00],\n",
      "        [ 0.0000e+00,  0.0000e+00,  0.0000e+00,  0.0000e+00,  0.0000e+00],\n",
      "        [ 0.0000e+00,  0.0000e+00,  0.0000e+00,  0.0000e+00,  0.0000e+00]],\n",
      "       dtype=torch.float64)\n",
      "tensor([False, False, False, False, False,  True,  True,  True,  True,  True])\n",
      "tensor([[ 369.3173,  610.7261, -434.8319,  221.3471,  672.8438],\n",
      "        [ 369.3173,  610.7261, -434.8319,  221.3471,  672.8438],\n",
      "        [ 369.3173,  610.7261, -434.8319,  221.3471,  672.8438],\n",
      "        [ 369.3173,  610.7261, -434.8319,  221.3471,  672.8438],\n",
      "        [ 369.3173,  610.7261, -434.8319,  221.3471,  672.8438],\n",
      "        [ 369.8181,  610.8782, -434.4502,  222.4964,  673.5971],\n",
      "        [ 369.8181,  610.8782, -434.4502,  222.4964,  673.5971],\n",
      "        [ 369.8181,  610.8782, -434.4502,  222.4964,  673.5971],\n",
      "        [ 369.8181,  610.8782, -434.4502,  222.4964,  673.5971],\n",
      "        [ 369.8181,  610.8782, -434.4502,  222.4964,  673.5971]],\n",
      "       dtype=torch.float64, grad_fn=<SelectBackward>)\n"
     ]
    }
   ],
   "source": [
    "i=4\n",
    "print(path[i])\n",
    "print(mask[i])\n",
    "print(attn_output[i])"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "nlpsig-networks",
   "language": "python",
   "name": "nlpsig-networks"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.16"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
