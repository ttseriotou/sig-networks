{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "a983a5e8",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pickle\n",
    "import os\n",
    "\n",
    "seed = 2023"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "a4b2805b-1454-407d-9a0a-740341ebfd3c",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "device(type='cuda')"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import torch\n",
    "\n",
    "# set device\n",
    "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "device"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "e4e666cc",
   "metadata": {},
   "outputs": [],
   "source": [
    "from nlpsig_networks.scripts.seqsignet_attention_functions import (\n",
    "    seqsignet_attention_hyperparameter_search,\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "6e918dde",
   "metadata": {},
   "outputs": [],
   "source": [
    "output_dir = \"rumours_output\"\n",
    "if not os.path.isdir(output_dir):\n",
    "    os.makedirs(output_dir)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f7409a03",
   "metadata": {},
   "source": [
    "## Rumours"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "f00bb922",
   "metadata": {},
   "outputs": [],
   "source": [
    "%run load_sbert-embeddings.py"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "720d820f",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>id</th>\n",
       "      <th>label</th>\n",
       "      <th>datetime</th>\n",
       "      <th>text</th>\n",
       "      <th>timeline_id</th>\n",
       "      <th>set</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>5.249902e+17</td>\n",
       "      <td>0</td>\n",
       "      <td>2014-10-22 18:26:23</td>\n",
       "      <td>Police have clarified that there were two shoo...</td>\n",
       "      <td>0</td>\n",
       "      <td>train</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>5.249906e+17</td>\n",
       "      <td>0</td>\n",
       "      <td>2014-10-22 18:27:58</td>\n",
       "      <td>@CTVNews you guys \"confirmed\" there were 3 sho...</td>\n",
       "      <td>0</td>\n",
       "      <td>train</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>5.249908e+17</td>\n",
       "      <td>1</td>\n",
       "      <td>2014-10-22 18:28:46</td>\n",
       "      <td>@CTVNews get it right. http://t.co/GHYxMuzPG9</td>\n",
       "      <td>0</td>\n",
       "      <td>train</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>5.249927e+17</td>\n",
       "      <td>1</td>\n",
       "      <td>2014-10-22 18:36:29</td>\n",
       "      <td>RT @CTVNews Police have clarified that there w...</td>\n",
       "      <td>0</td>\n",
       "      <td>train</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>5.250038e+17</td>\n",
       "      <td>1</td>\n",
       "      <td>2014-10-22 19:20:41</td>\n",
       "      <td>@CTVNews @ctvsaskatoon so what happened at Rid...</td>\n",
       "      <td>0</td>\n",
       "      <td>train</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "             id label            datetime  \\\n",
       "0  5.249902e+17     0 2014-10-22 18:26:23   \n",
       "1  5.249906e+17     0 2014-10-22 18:27:58   \n",
       "2  5.249908e+17     1 2014-10-22 18:28:46   \n",
       "3  5.249927e+17     1 2014-10-22 18:36:29   \n",
       "4  5.250038e+17     1 2014-10-22 19:20:41   \n",
       "\n",
       "                                                text timeline_id    set  \n",
       "0  Police have clarified that there were two shoo...           0  train  \n",
       "1  @CTVNews you guys \"confirmed\" there were 3 sho...           0  train  \n",
       "2      @CTVNews get it right. http://t.co/GHYxMuzPG9           0  train  \n",
       "3  RT @CTVNews Police have clarified that there w...           0  train  \n",
       "4  @CTVNews @ctvsaskatoon so what happened at Rid...           0  train  "
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_rumours.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "da4ff92d",
   "metadata": {},
   "source": [
    "# SeqSigNet with Attention Network"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "90bfd87c",
   "metadata": {},
   "outputs": [],
   "source": [
    "features = [\"time_encoding\", \"timeline_index\"]\n",
    "standardise_method = [\"z_score\", None]\n",
    "include_features_in_path = True\n",
    "include_features_in_input = False"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "2a6b9a8c-ded5-44da-a451-77f363d394ee",
   "metadata": {},
   "outputs": [],
   "source": [
    "split_ids = torch.tensor(df_rumours['timeline_id'].astype(int))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "9e9bee3b",
   "metadata": {},
   "outputs": [],
   "source": [
    "num_epochs = 100\n",
    "dimensions = [15]  # [50, 15]\n",
    "# define swmhau parameters: (output_channels, sig_depth, num_heads)\n",
    "swmhau_parameters = [(12, 3, 10), (8, 4, 6)]#, (8, 4, 12)]\n",
    "num_layers = [1]\n",
    "lstm_hidden_dim_sizes = [384]\n",
    "ffn_hidden_dim_sizes = [[256,256],[512,512]]\n",
    "dropout_rates = [0.1, 0.2]\n",
    "learning_rates = [1e-3, 1e-4, 5e-4]\n",
    "seeds = [1, 12, 123]\n",
    "loss = \"focal\"\n",
    "gamma = 2\n",
    "validation_metric = \"f1\"\n",
    "patience = 5"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c065cd69-a3c1-4fbc-b72a-9555601c58de",
   "metadata": {
    "tags": []
   },
   "source": [
    "# history_length=11"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "9bbec9ab-4add-477f-8950-8123ce70766b",
   "metadata": {},
   "outputs": [],
   "source": [
    "shift = 3\n",
    "window_size = 5\n",
    "n = 3"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "89a4bcc6-f9e4-4763-9bdf-b21003d5d257",
   "metadata": {},
   "source": [
    "## UMAP"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "3739e09a",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "9c95db7bd8764880abf771e989bf7a3c",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/1 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "5c43f59e4d194defa4f30810f6567b5f",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/1 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "##################################################\n",
      "dimension: 15 | method: umap\n",
      "given shift 3, window size 5 and n 3: history length = 11\n",
      "[INFO] Concatenating the embeddings to the dataframe...\n",
      "[INFO] - columns beginning with 'e' denote the full embddings.\n",
      "[INFO] - columns beginning with 'd' denote the dimension reduced embeddings.\n",
      "[INFO] Adding time feature columns into dataframe in `.df`.\n",
      "[INFO] Adding 'time_encoding' feature...\n",
      "[INFO] Adding 'time_diff' feature...\n",
      "[INFO] Adding 'timeline_index' feature...\n",
      "[INFO] Padding ids and storing in `.df_padded` and `.array_padded` attributes.\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "e04b2598b2864e0eb3cedd0090b1fa8d",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/5568 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[INFO] The path was created for each item in the dataframe, by looking at its history, so to include embeddings in the FFN input, we concatenate the embeddings for each sentence / text.\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "ed9f013ffbff4e1180f135417f650a05",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/2 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "fa7f59b9108b4ed2829f97afde2ab86a",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/1 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "8397862628a94f85af5de1ee2de8c30d",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/1 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "f636e54ab1cc4fb59d209492eb2e8e08",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/2 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "be0ccef572414093a2bdc0b2f72ec692",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/2 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "5fcc2ddb2b474af690b06a9cbf1d0a44",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/3 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " ** On entry to SGEMM  parameter number 10 had an illegal value\n"
     ]
    },
    {
     "ename": "RuntimeError",
     "evalue": "CUDA error: CUBLAS_STATUS_INVALID_VALUE when calling `cublasSgemm( handle, opa, opb, m, n, k, &alpha, a, lda, b, ldb, &beta, c, ldc)`",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mRuntimeError\u001b[0m                              Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[11], line 6\u001b[0m\n\u001b[1;32m      1\u001b[0m (\n\u001b[1;32m      2\u001b[0m     seqsignet_attention_umap_11,\n\u001b[1;32m      3\u001b[0m     best_seqsignet_attention_umap_11,\n\u001b[1;32m      4\u001b[0m     _,\n\u001b[1;32m      5\u001b[0m     __,\n\u001b[0;32m----> 6\u001b[0m ) \u001b[38;5;241m=\u001b[39m \u001b[43mseqsignet_attention_hyperparameter_search\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m      7\u001b[0m \u001b[43m    \u001b[49m\u001b[43mnum_epochs\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mnum_epochs\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m      8\u001b[0m \u001b[43m    \u001b[49m\u001b[43mdf\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mdf_rumours\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m      9\u001b[0m \u001b[43m    \u001b[49m\u001b[43mid_column\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mtimeline_id\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m,\u001b[49m\n\u001b[1;32m     10\u001b[0m \u001b[43m    \u001b[49m\u001b[43mlabel_column\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mlabel\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m,\u001b[49m\n\u001b[1;32m     11\u001b[0m \u001b[43m    \u001b[49m\u001b[43membeddings\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43msbert_embeddings\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m     12\u001b[0m \u001b[43m    \u001b[49m\u001b[43my_data\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43my_data\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m     13\u001b[0m \u001b[43m    \u001b[49m\u001b[43moutput_dim\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43moutput_dim\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m     14\u001b[0m \u001b[43m    \u001b[49m\u001b[43mshift\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mshift\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m     15\u001b[0m \u001b[43m    \u001b[49m\u001b[43mwindow_size\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mwindow_size\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m     16\u001b[0m \u001b[43m    \u001b[49m\u001b[43mn\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mn\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m     17\u001b[0m \u001b[43m    \u001b[49m\u001b[43mdim_reduce_methods\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43m[\u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mumap\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m]\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m     18\u001b[0m \u001b[43m    \u001b[49m\u001b[43mdimensions\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mdimensions\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m     19\u001b[0m \u001b[43m    \u001b[49m\u001b[43mlog_signature\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43;01mTrue\u001b[39;49;00m\u001b[43m,\u001b[49m\n\u001b[1;32m     20\u001b[0m \u001b[43m    \u001b[49m\u001b[43mswmhau_parameters\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mswmhau_parameters\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m     21\u001b[0m \u001b[43m    \u001b[49m\u001b[43mnum_layers\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mnum_layers\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m     22\u001b[0m \u001b[43m    \u001b[49m\u001b[43mlstm_hidden_dim_sizes\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mlstm_hidden_dim_sizes\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m     23\u001b[0m \u001b[43m    \u001b[49m\u001b[43mffn_hidden_dim_sizes\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mffn_hidden_dim_sizes\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m     24\u001b[0m \u001b[43m    \u001b[49m\u001b[43mdropout_rates\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mdropout_rates\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m     25\u001b[0m \u001b[43m    \u001b[49m\u001b[43mlearning_rates\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mlearning_rates\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m     26\u001b[0m \u001b[43m    \u001b[49m\u001b[43mseeds\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mseeds\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m     27\u001b[0m \u001b[43m    \u001b[49m\u001b[43mloss\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mloss\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m     28\u001b[0m \u001b[43m    \u001b[49m\u001b[43mgamma\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mgamma\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m     29\u001b[0m \u001b[43m    \u001b[49m\u001b[43mdevice\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mdevice\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m     30\u001b[0m \u001b[43m    \u001b[49m\u001b[43msplit_ids\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43msplit_ids\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m     31\u001b[0m \u001b[43m    \u001b[49m\u001b[43mk_fold\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43;01mTrue\u001b[39;49;00m\u001b[43m,\u001b[49m\n\u001b[1;32m     32\u001b[0m \u001b[43m    \u001b[49m\u001b[43mfeatures\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mfeatures\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m     33\u001b[0m \u001b[43m    \u001b[49m\u001b[43mstandardise_method\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mstandardise_method\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m     34\u001b[0m \u001b[43m    \u001b[49m\u001b[43minclude_features_in_path\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43minclude_features_in_path\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m     35\u001b[0m \u001b[43m    \u001b[49m\u001b[43mpatience\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mpatience\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m     36\u001b[0m \u001b[43m    \u001b[49m\u001b[43mvalidation_metric\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mvalidation_metric\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m     37\u001b[0m \u001b[43m    \u001b[49m\u001b[43mresults_output\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;124;43mf\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;132;43;01m{\u001b[39;49;00m\u001b[43moutput_dir\u001b[49m\u001b[38;5;132;43;01m}\u001b[39;49;00m\u001b[38;5;124;43m/seqsignet_attention_umap_focal_\u001b[39;49m\u001b[38;5;132;43;01m{\u001b[39;49;00m\u001b[43mgamma\u001b[49m\u001b[38;5;132;43;01m}\u001b[39;49;00m\u001b[38;5;124;43m_\u001b[39;49m\u001b[38;5;132;43;01m{\u001b[39;49;00m\u001b[43mshift\u001b[49m\u001b[38;5;132;43;01m}\u001b[39;49;00m\u001b[38;5;124;43m_\u001b[39;49m\u001b[38;5;132;43;01m{\u001b[39;49;00m\u001b[43mwindow_size\u001b[49m\u001b[38;5;132;43;01m}\u001b[39;49;00m\u001b[38;5;124;43m_\u001b[39;49m\u001b[38;5;132;43;01m{\u001b[39;49;00m\u001b[43mn\u001b[49m\u001b[38;5;132;43;01m}\u001b[39;49;00m\u001b[38;5;124;43m_kfold.csv\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m,\u001b[49m\n\u001b[1;32m     38\u001b[0m \u001b[43m    \u001b[49m\u001b[43mverbose\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43;01mFalse\u001b[39;49;00m\u001b[43m,\u001b[49m\n\u001b[1;32m     39\u001b[0m \u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m/bask/projects/v/vjgo8416-rough-paths/nlpsig-networks/nlpsig_networks/scripts/seqsignet_attention_functions.py:224\u001b[0m, in \u001b[0;36mseqsignet_attention_hyperparameter_search\u001b[0;34m(num_epochs, df, id_column, label_column, embeddings, y_data, output_dim, shift, window_size, n, dim_reduce_methods, dimensions, log_signature, swmhau_parameters, num_layers, lstm_hidden_dim_sizes, ffn_hidden_dim_sizes, dropout_rates, learning_rates, seeds, loss, gamma, device, batch_size, features, standardise_method, include_features_in_path, include_features_in_input, augmentation_type, hidden_dim_aug, comb_method, path_indices, data_split_seed, split_ids, split_indices, k_fold, n_splits, patience, validation_metric, results_output, verbose)\u001b[0m\n\u001b[1;32m    222\u001b[0m verbose_model \u001b[38;5;241m=\u001b[39m verbose\n\u001b[1;32m    223\u001b[0m \u001b[38;5;28;01mfor\u001b[39;00m seed \u001b[38;5;129;01min\u001b[39;00m seeds:\n\u001b[0;32m--> 224\u001b[0m     _, results \u001b[38;5;241m=\u001b[39m \u001b[43mimplement_seqsignet_attention\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m    225\u001b[0m \u001b[43m        \u001b[49m\u001b[43mnum_epochs\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mnum_epochs\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    226\u001b[0m \u001b[43m        \u001b[49m\u001b[43mx_data\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43minput\u001b[39;49m\u001b[43m[\u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mx_data\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m]\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    227\u001b[0m \u001b[43m        \u001b[49m\u001b[43my_data\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43my_data\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    228\u001b[0m \u001b[43m        \u001b[49m\u001b[43minput_channels\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43minput\u001b[39;49m\u001b[43m[\u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43minput_channels\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m]\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    229\u001b[0m \u001b[43m        \u001b[49m\u001b[43moutput_channels\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43moutput_channels\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    230\u001b[0m \u001b[43m        \u001b[49m\u001b[43membedding_dim\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43minput\u001b[39;49m\u001b[43m[\u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43membedding_dim\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m]\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    231\u001b[0m \u001b[43m        \u001b[49m\u001b[43mnum_features\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43minput\u001b[39;49m\u001b[43m[\u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mnum_features\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m]\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    232\u001b[0m \u001b[43m        \u001b[49m\u001b[43mlog_signature\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mlog_signature\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    233\u001b[0m \u001b[43m        \u001b[49m\u001b[43msig_depth\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43msig_depth\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    234\u001b[0m \u001b[43m        \u001b[49m\u001b[43mnum_heads\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mnum_heads\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    235\u001b[0m \u001b[43m        \u001b[49m\u001b[43mnum_layers\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mn_layers\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    236\u001b[0m \u001b[43m        \u001b[49m\u001b[43mlstm_hidden_dim\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mlstm_hidden_dim\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    237\u001b[0m \u001b[43m        \u001b[49m\u001b[43mffn_hidden_dim\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mffn_hidden_dim\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    238\u001b[0m \u001b[43m        \u001b[49m\u001b[43moutput_dim\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43moutput_dim\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    239\u001b[0m \u001b[43m        \u001b[49m\u001b[43mdropout_rate\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mdropout\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    240\u001b[0m \u001b[43m        \u001b[49m\u001b[43mlearning_rate\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mlr\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    241\u001b[0m \u001b[43m        \u001b[49m\u001b[43mseed\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mseed\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    242\u001b[0m \u001b[43m        \u001b[49m\u001b[43mloss\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mloss\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    243\u001b[0m \u001b[43m        \u001b[49m\u001b[43mgamma\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mgamma\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    244\u001b[0m \u001b[43m        \u001b[49m\u001b[43mdevice\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mdevice\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    245\u001b[0m \u001b[43m        \u001b[49m\u001b[43mbatch_size\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mbatch_size\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    246\u001b[0m \u001b[43m        \u001b[49m\u001b[43maugmentation_type\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43maugmentation_type\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    247\u001b[0m \u001b[43m        \u001b[49m\u001b[43mhidden_dim_aug\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mhidden_dim_aug\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    248\u001b[0m \u001b[43m        \u001b[49m\u001b[43mcomb_method\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mcomb_method\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    249\u001b[0m \u001b[43m        \u001b[49m\u001b[43mdata_split_seed\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mdata_split_seed\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    250\u001b[0m \u001b[43m        \u001b[49m\u001b[43msplit_ids\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43msplit_ids\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    251\u001b[0m \u001b[43m        \u001b[49m\u001b[43msplit_indices\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43msplit_indices\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    252\u001b[0m \u001b[43m        \u001b[49m\u001b[43mk_fold\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mk_fold\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    253\u001b[0m \u001b[43m        \u001b[49m\u001b[43mn_splits\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mn_splits\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    254\u001b[0m \u001b[43m        \u001b[49m\u001b[43mpatience\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mpatience\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    255\u001b[0m \u001b[43m        \u001b[49m\u001b[43mverbose_training\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43;01mFalse\u001b[39;49;00m\u001b[43m,\u001b[49m\n\u001b[1;32m    256\u001b[0m \u001b[43m        \u001b[49m\u001b[43mverbose_results\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mverbose\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    257\u001b[0m \u001b[43m        \u001b[49m\u001b[43mverbose_model\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mverbose_model\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    258\u001b[0m \u001b[43m    \u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    259\u001b[0m     \u001b[38;5;66;03m# save metric that we want to validate on\u001b[39;00m\n\u001b[1;32m    260\u001b[0m     \u001b[38;5;66;03m# take mean of performance on the folds\u001b[39;00m\n\u001b[1;32m    261\u001b[0m     \u001b[38;5;66;03m# if k_fold=False, return performance for seed\u001b[39;00m\n\u001b[1;32m    262\u001b[0m     scores\u001b[38;5;241m.\u001b[39mappend(\n\u001b[1;32m    263\u001b[0m         results[\u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mvalid_\u001b[39m\u001b[38;5;132;01m{\u001b[39;00mvalidation_metric\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m\"\u001b[39m]\u001b[38;5;241m.\u001b[39mmean()\n\u001b[1;32m    264\u001b[0m     )\n",
      "File \u001b[0;32m/bask/projects/v/vjgo8416-rough-paths/nlpsig-networks/nlpsig_networks/scripts/seqsignet_attention_functions.py:94\u001b[0m, in \u001b[0;36mimplement_seqsignet_attention\u001b[0;34m(num_epochs, x_data, y_data, input_channels, output_channels, num_features, embedding_dim, log_signature, sig_depth, num_heads, num_layers, lstm_hidden_dim, ffn_hidden_dim, output_dim, dropout_rate, learning_rate, seed, loss, gamma, device, batch_size, augmentation_type, hidden_dim_aug, comb_method, data_split_seed, split_ids, split_indices, k_fold, n_splits, patience, verbose_training, verbose_results, verbose_model)\u001b[0m\n\u001b[1;32m     91\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28misinstance\u001b[39m(y_data, torch\u001b[38;5;241m.\u001b[39mTensor):\n\u001b[1;32m     92\u001b[0m     y_data \u001b[38;5;241m=\u001b[39m torch\u001b[38;5;241m.\u001b[39mtensor(y_data)\n\u001b[0;32m---> 94\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mimplement_model\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m     95\u001b[0m \u001b[43m    \u001b[49m\u001b[43mmodel\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mseqsignet_attention_model\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m     96\u001b[0m \u001b[43m    \u001b[49m\u001b[43mnum_epochs\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mnum_epochs\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m     97\u001b[0m \u001b[43m    \u001b[49m\u001b[43mx_data\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mx_data\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m     98\u001b[0m \u001b[43m    \u001b[49m\u001b[43my_data\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43my_data\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m     99\u001b[0m \u001b[43m    \u001b[49m\u001b[43mlearning_rate\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mlearning_rate\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    100\u001b[0m \u001b[43m    \u001b[49m\u001b[43mseed\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mseed\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    101\u001b[0m \u001b[43m    \u001b[49m\u001b[43mloss\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mloss\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    102\u001b[0m \u001b[43m    \u001b[49m\u001b[43mgamma\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mgamma\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    103\u001b[0m \u001b[43m    \u001b[49m\u001b[43mdevice\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mdevice\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    104\u001b[0m \u001b[43m    \u001b[49m\u001b[43mbatch_size\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mbatch_size\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    105\u001b[0m \u001b[43m    \u001b[49m\u001b[43mdata_split_seed\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mdata_split_seed\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    106\u001b[0m \u001b[43m    \u001b[49m\u001b[43msplit_ids\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43msplit_ids\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    107\u001b[0m \u001b[43m    \u001b[49m\u001b[43msplit_indices\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43msplit_indices\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    108\u001b[0m \u001b[43m    \u001b[49m\u001b[43mk_fold\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mk_fold\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    109\u001b[0m \u001b[43m    \u001b[49m\u001b[43mn_splits\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mn_splits\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    110\u001b[0m \u001b[43m    \u001b[49m\u001b[43mpatience\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mpatience\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    111\u001b[0m \u001b[43m    \u001b[49m\u001b[43mverbose_training\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mverbose_training\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    112\u001b[0m \u001b[43m    \u001b[49m\u001b[43mverbose_results\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mverbose_results\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    113\u001b[0m \u001b[43m\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m/bask/projects/v/vjgo8416-rough-paths/nlpsig-networks/nlpsig_networks/scripts/implement_model.py:106\u001b[0m, in \u001b[0;36mimplement_model\u001b[0;34m(model, num_epochs, x_data, y_data, learning_rate, seed, loss, gamma, device, batch_size, data_split_seed, split_ids, split_indices, k_fold, n_splits, patience, verbose_training, verbose_results)\u001b[0m\n\u001b[1;32m     99\u001b[0m     optimizer \u001b[38;5;241m=\u001b[39m torch\u001b[38;5;241m.\u001b[39moptim\u001b[38;5;241m.\u001b[39mAdam(\n\u001b[1;32m    100\u001b[0m         model\u001b[38;5;241m.\u001b[39mparameters(), lr\u001b[38;5;241m=\u001b[39mlearning_rate, weight_decay\u001b[38;5;241m=\u001b[39mweight_decay_adam\n\u001b[1;32m    101\u001b[0m     )\n\u001b[1;32m    103\u001b[0m     \u001b[38;5;66;03m# perform k-fold evaluation which returns a dataframe with columns for the\u001b[39;00m\n\u001b[1;32m    104\u001b[0m     \u001b[38;5;66;03m# loss, accuracy, f1 (macro) and individual f1-scores for each fold\u001b[39;00m\n\u001b[1;32m    105\u001b[0m     \u001b[38;5;66;03m# (for both validation and test set)\u001b[39;00m\n\u001b[0;32m--> 106\u001b[0m     results \u001b[38;5;241m=\u001b[39m \u001b[43mKFold_pytorch\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m    107\u001b[0m \u001b[43m        \u001b[49m\u001b[43mfolds\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mfolds\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    108\u001b[0m \u001b[43m        \u001b[49m\u001b[43mmodel\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mmodel\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    109\u001b[0m \u001b[43m        \u001b[49m\u001b[43mcriterion\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mcriterion\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    110\u001b[0m \u001b[43m        \u001b[49m\u001b[43moptimizer\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43moptimizer\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    111\u001b[0m \u001b[43m        \u001b[49m\u001b[43mnum_epochs\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mnum_epochs\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    112\u001b[0m \u001b[43m        \u001b[49m\u001b[43mbatch_size\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mbatch_size\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    113\u001b[0m \u001b[43m        \u001b[49m\u001b[43mseed\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mseed\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    114\u001b[0m \u001b[43m        \u001b[49m\u001b[43mreturn_best\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mreturn_best\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    115\u001b[0m \u001b[43m        \u001b[49m\u001b[43mearly_stopping\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mearly_stopping\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    116\u001b[0m \u001b[43m        \u001b[49m\u001b[43mpatience\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mpatience\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    117\u001b[0m \u001b[43m        \u001b[49m\u001b[43mdevice\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mdevice\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    118\u001b[0m \u001b[43m        \u001b[49m\u001b[43mverbose\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mverbose_training\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    119\u001b[0m \u001b[43m    \u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    120\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[1;32m    121\u001b[0m     \u001b[38;5;66;03m# split dataset\u001b[39;00m\n\u001b[1;32m    122\u001b[0m     data_loader_args \u001b[38;5;241m=\u001b[39m {\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mbatch_size\u001b[39m\u001b[38;5;124m\"\u001b[39m: batch_size, \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mshuffle\u001b[39m\u001b[38;5;124m\"\u001b[39m: \u001b[38;5;28;01mTrue\u001b[39;00m}\n",
      "File \u001b[0;32m/bask/projects/v/vjgo8416-rough-paths/nlpsig-networks/nlpsig_networks/pytorch_utils.py:789\u001b[0m, in \u001b[0;36mKFold_pytorch\u001b[0;34m(folds, model, criterion, optimizer, num_epochs, batch_size, return_metric_for_each_fold, seed, return_best, early_stopping, patience, device, verbose, verbose_epoch)\u001b[0m\n\u001b[1;32m    784\u001b[0m train, valid, test \u001b[38;5;241m=\u001b[39m folds\u001b[38;5;241m.\u001b[39mget_splits(\n\u001b[1;32m    785\u001b[0m     fold_index\u001b[38;5;241m=\u001b[39mfold, as_DataLoader\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mTrue\u001b[39;00m, data_loader_args\u001b[38;5;241m=\u001b[39mdata_loader_args\n\u001b[1;32m    786\u001b[0m )\n\u001b[1;32m    788\u001b[0m \u001b[38;5;66;03m# train pytorch model\u001b[39;00m\n\u001b[0;32m--> 789\u001b[0m model \u001b[38;5;241m=\u001b[39m \u001b[43mtraining_pytorch\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m    790\u001b[0m \u001b[43m    \u001b[49m\u001b[43mmodel\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mmodel\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    791\u001b[0m \u001b[43m    \u001b[49m\u001b[43mtrain_loader\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mtrain\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    792\u001b[0m \u001b[43m    \u001b[49m\u001b[43mvalid_loader\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mvalid\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    793\u001b[0m \u001b[43m    \u001b[49m\u001b[43mcriterion\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mcriterion\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    794\u001b[0m \u001b[43m    \u001b[49m\u001b[43moptimizer\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43moptimizer\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    795\u001b[0m \u001b[43m    \u001b[49m\u001b[43mnum_epochs\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mnum_epochs\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    796\u001b[0m \u001b[43m    \u001b[49m\u001b[43mseed\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mseed\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    797\u001b[0m \u001b[43m    \u001b[49m\u001b[43mreturn_best\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mreturn_best\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    798\u001b[0m \u001b[43m    \u001b[49m\u001b[43msave_best\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43;01mFalse\u001b[39;49;00m\u001b[43m,\u001b[49m\n\u001b[1;32m    799\u001b[0m \u001b[43m    \u001b[49m\u001b[43mearly_stopping\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mearly_stopping\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    800\u001b[0m \u001b[43m    \u001b[49m\u001b[43mpatience\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mpatience\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    801\u001b[0m \u001b[43m    \u001b[49m\u001b[43mdevice\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mdevice\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    802\u001b[0m \u001b[43m    \u001b[49m\u001b[43mverbose\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mverbose\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    803\u001b[0m \u001b[43m    \u001b[49m\u001b[43mverbose_epoch\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mverbose_epoch\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    804\u001b[0m \u001b[43m\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    806\u001b[0m \u001b[38;5;66;03m# test model\u001b[39;00m\n\u001b[1;32m    807\u001b[0m test_results \u001b[38;5;241m=\u001b[39m testing_pytorch(\n\u001b[1;32m    808\u001b[0m     model\u001b[38;5;241m=\u001b[39mmodel,\n\u001b[1;32m    809\u001b[0m     test_loader\u001b[38;5;241m=\u001b[39mtest,\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m    812\u001b[0m     verbose\u001b[38;5;241m=\u001b[39mverbose,\n\u001b[1;32m    813\u001b[0m )\n",
      "File \u001b[0;32m/bask/projects/v/vjgo8416-rough-paths/nlpsig-networks/nlpsig_networks/pytorch_utils.py:476\u001b[0m, in \u001b[0;36mtraining_pytorch\u001b[0;34m(model, train_loader, criterion, optimizer, num_epochs, scheduler, valid_loader, seed, return_best, save_best, output, early_stopping, validation_metric, patience, device, verbose, verbose_epoch)\u001b[0m\n\u001b[1;32m    474\u001b[0m \u001b[38;5;66;03m# perform training by performing forward and backward passes\u001b[39;00m\n\u001b[1;32m    475\u001b[0m optimizer\u001b[38;5;241m.\u001b[39mzero_grad()\n\u001b[0;32m--> 476\u001b[0m model_output \u001b[38;5;241m=\u001b[39m \u001b[43mmodel\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mbatch_inputs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    477\u001b[0m loss \u001b[38;5;241m=\u001b[39m criterion(model_output, batch_labels)\n\u001b[1;32m    478\u001b[0m loss\u001b[38;5;241m.\u001b[39mbackward()\n",
      "File \u001b[0;32m/bask/projects/v/vjgo8416-rough-paths/envs/nlpsig-networks/lib/python3.8/site-packages/torch/nn/modules/module.py:1051\u001b[0m, in \u001b[0;36mModule._call_impl\u001b[0;34m(self, *input, **kwargs)\u001b[0m\n\u001b[1;32m   1047\u001b[0m \u001b[38;5;66;03m# If we don't have any hooks, we want to skip the rest of the logic in\u001b[39;00m\n\u001b[1;32m   1048\u001b[0m \u001b[38;5;66;03m# this function, and just call forward.\u001b[39;00m\n\u001b[1;32m   1049\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m (\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_backward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_forward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_backward_hooks\n\u001b[1;32m   1050\u001b[0m         \u001b[38;5;129;01mor\u001b[39;00m _global_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_forward_pre_hooks):\n\u001b[0;32m-> 1051\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mforward_call\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;28;43minput\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m   1052\u001b[0m \u001b[38;5;66;03m# Do not call functions when jit is used\u001b[39;00m\n\u001b[1;32m   1053\u001b[0m full_backward_hooks, non_full_backward_hooks \u001b[38;5;241m=\u001b[39m [], []\n",
      "File \u001b[0;32m/bask/projects/v/vjgo8416-rough-paths/nlpsig-networks/nlpsig_networks/seqsignet_attention.py:178\u001b[0m, in \u001b[0;36mSeqSigNetAttention.forward\u001b[0;34m(self, path, features)\u001b[0m\n\u001b[1;32m    175\u001b[0m out \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mfeature_concat(out, features)\n\u001b[1;32m    177\u001b[0m \u001b[38;5;66;03m# FFN\u001b[39;00m\n\u001b[0;32m--> 178\u001b[0m out \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mffn\u001b[49m\u001b[43m(\u001b[49m\u001b[43mout\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mfloat\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    180\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m out\n",
      "File \u001b[0;32m/bask/projects/v/vjgo8416-rough-paths/envs/nlpsig-networks/lib/python3.8/site-packages/torch/nn/modules/module.py:1051\u001b[0m, in \u001b[0;36mModule._call_impl\u001b[0;34m(self, *input, **kwargs)\u001b[0m\n\u001b[1;32m   1047\u001b[0m \u001b[38;5;66;03m# If we don't have any hooks, we want to skip the rest of the logic in\u001b[39;00m\n\u001b[1;32m   1048\u001b[0m \u001b[38;5;66;03m# this function, and just call forward.\u001b[39;00m\n\u001b[1;32m   1049\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m (\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_backward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_forward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_backward_hooks\n\u001b[1;32m   1050\u001b[0m         \u001b[38;5;129;01mor\u001b[39;00m _global_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_forward_pre_hooks):\n\u001b[0;32m-> 1051\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mforward_call\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;28;43minput\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m   1052\u001b[0m \u001b[38;5;66;03m# Do not call functions when jit is used\u001b[39;00m\n\u001b[1;32m   1053\u001b[0m full_backward_hooks, non_full_backward_hooks \u001b[38;5;241m=\u001b[39m [], []\n",
      "File \u001b[0;32m/bask/projects/v/vjgo8416-rough-paths/nlpsig-networks/nlpsig_networks/ffn_baseline.py:66\u001b[0m, in \u001b[0;36mFeedforwardNeuralNetModel.forward\u001b[0;34m(self, x)\u001b[0m\n\u001b[1;32m     64\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mforward\u001b[39m(\u001b[38;5;28mself\u001b[39m, x: torch\u001b[38;5;241m.\u001b[39mTensor):\n\u001b[1;32m     65\u001b[0m     \u001b[38;5;66;03m# FFN: input layer\u001b[39;00m\n\u001b[0;32m---> 66\u001b[0m     out \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43minput_layer\u001b[49m\u001b[43m(\u001b[49m\u001b[43mx\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m     67\u001b[0m     out \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mrelu(out)\n\u001b[1;32m     68\u001b[0m     out \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mdropout(out)\n",
      "File \u001b[0;32m/bask/projects/v/vjgo8416-rough-paths/envs/nlpsig-networks/lib/python3.8/site-packages/torch/nn/modules/module.py:1051\u001b[0m, in \u001b[0;36mModule._call_impl\u001b[0;34m(self, *input, **kwargs)\u001b[0m\n\u001b[1;32m   1047\u001b[0m \u001b[38;5;66;03m# If we don't have any hooks, we want to skip the rest of the logic in\u001b[39;00m\n\u001b[1;32m   1048\u001b[0m \u001b[38;5;66;03m# this function, and just call forward.\u001b[39;00m\n\u001b[1;32m   1049\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m (\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_backward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_forward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_backward_hooks\n\u001b[1;32m   1050\u001b[0m         \u001b[38;5;129;01mor\u001b[39;00m _global_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_forward_pre_hooks):\n\u001b[0;32m-> 1051\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mforward_call\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;28;43minput\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m   1052\u001b[0m \u001b[38;5;66;03m# Do not call functions when jit is used\u001b[39;00m\n\u001b[1;32m   1053\u001b[0m full_backward_hooks, non_full_backward_hooks \u001b[38;5;241m=\u001b[39m [], []\n",
      "File \u001b[0;32m/bask/projects/v/vjgo8416-rough-paths/envs/nlpsig-networks/lib/python3.8/site-packages/torch/nn/modules/linear.py:96\u001b[0m, in \u001b[0;36mLinear.forward\u001b[0;34m(self, input)\u001b[0m\n\u001b[1;32m     95\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mforward\u001b[39m(\u001b[38;5;28mself\u001b[39m, \u001b[38;5;28minput\u001b[39m: Tensor) \u001b[38;5;241m-\u001b[39m\u001b[38;5;241m>\u001b[39m Tensor:\n\u001b[0;32m---> 96\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mF\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mlinear\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;28;43minput\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mweight\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mbias\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m/bask/projects/v/vjgo8416-rough-paths/envs/nlpsig-networks/lib/python3.8/site-packages/torch/nn/functional.py:1847\u001b[0m, in \u001b[0;36mlinear\u001b[0;34m(input, weight, bias)\u001b[0m\n\u001b[1;32m   1845\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m has_torch_function_variadic(\u001b[38;5;28minput\u001b[39m, weight):\n\u001b[1;32m   1846\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m handle_torch_function(linear, (\u001b[38;5;28minput\u001b[39m, weight), \u001b[38;5;28minput\u001b[39m, weight, bias\u001b[38;5;241m=\u001b[39mbias)\n\u001b[0;32m-> 1847\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mtorch\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_C\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_nn\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mlinear\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;28;43minput\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mweight\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mbias\u001b[49m\u001b[43m)\u001b[49m\n",
      "\u001b[0;31mRuntimeError\u001b[0m: CUDA error: CUBLAS_STATUS_INVALID_VALUE when calling `cublasSgemm( handle, opa, opb, m, n, k, &alpha, a, lda, b, ldb, &beta, c, ldc)`"
     ]
    }
   ],
   "source": [
    "(\n",
    "    seqsignet_attention_umap_11,\n",
    "    best_seqsignet_attention_umap_11,\n",
    "    _,\n",
    "    __,\n",
    ") = seqsignet_attention_hyperparameter_search(\n",
    "    num_epochs=num_epochs,\n",
    "    df=df_rumours,\n",
    "    id_column=\"timeline_id\",\n",
    "    label_column=\"label\",\n",
    "    embeddings=sbert_embeddings,\n",
    "    y_data=y_data,\n",
    "    output_dim=output_dim,\n",
    "    shift=shift,\n",
    "    window_size=window_size,\n",
    "    n=n,\n",
    "    dim_reduce_methods=[\"umap\"],\n",
    "    dimensions=dimensions,\n",
    "    log_signature=True,\n",
    "    swmhau_parameters=swmhau_parameters,\n",
    "    num_layers=num_layers,\n",
    "    lstm_hidden_dim_sizes=lstm_hidden_dim_sizes,\n",
    "    ffn_hidden_dim_sizes=ffn_hidden_dim_sizes,\n",
    "    dropout_rates=dropout_rates,\n",
    "    learning_rates=learning_rates,\n",
    "    seeds=seeds,\n",
    "    loss=loss,\n",
    "    gamma=gamma,\n",
    "    device=device,\n",
    "    split_ids=split_ids,\n",
    "    k_fold=True,\n",
    "    features=features,\n",
    "    standardise_method=standardise_method,\n",
    "    include_features_in_path=include_features_in_path,\n",
    "    patience=patience,\n",
    "    validation_metric=validation_metric,\n",
    "    results_output=f\"{output_dir}/seqsignet_attention_umap_focal_{gamma}_{shift}_{window_size}_{n}_kfold.csv\",\n",
    "    verbose=False,\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "db912cd7-e74a-4893-987b-037b69c1fec8",
   "metadata": {},
   "outputs": [],
   "source": [
    "seqsignet_attention_umap_11.groupby(\n",
    "    [\n",
    "        \"dimensions\",\n",
    "        \"output_channels\",\n",
    "        \"sig_depth\",\n",
    "        \"num_heads\",\n",
    "        \"num_layers\",\n",
    "        \"ffn_hidden_dim\",\n",
    "        \"learning_rate\",\n",
    "    ]\n",
    ").mean()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "089e89fa-e2bc-4bd2-a063-d9c7d35ba390",
   "metadata": {},
   "outputs": [],
   "source": [
    "best_seqsignet_attention_umap_11"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "978d2bdc-9e44-49ac-a88c-71540aa34777",
   "metadata": {},
   "outputs": [],
   "source": [
    "best_seqsignet_attention_umap_11[\n",
    "    [\n",
    "        \"dimensions\",\n",
    "        \"output_channels\",\n",
    "        \"sig_depth\",\n",
    "        \"num_heads\",\n",
    "        \"num_layers\",\n",
    "        \"ffn_hidden_dim\",\n",
    "        \"dropout_rate\",\n",
    "        \"learning_rate\",\n",
    "    ]\n",
    "]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "78b1127f-0371-40b9-a521-14f6f38f150f",
   "metadata": {},
   "outputs": [],
   "source": [
    "best_seqsignet_attention_umap_11[\"f1\"].mean()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "500a7f96-d4df-44c0-93dc-60e3f38b5e7e",
   "metadata": {},
   "outputs": [],
   "source": [
    "best_seqsignet_attention_umap_11[\"precision\"].mean()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "eb46a36b-60fd-4ff8-9c44-301db7b1c806",
   "metadata": {},
   "outputs": [],
   "source": [
    "best_seqsignet_attention_umap_11[\"recall\"].mean()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "088a2cba-e1ee-45f3-9ebf-950d6828c9b6",
   "metadata": {},
   "outputs": [],
   "source": [
    "np.stack(best_seqsignet_attention_umap_11[\"f1_scores\"]).mean(axis=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7fe395fe-9dfe-441c-bda8-e2304f3710db",
   "metadata": {},
   "outputs": [],
   "source": [
    "np.stack(best_seqsignet_attention_umap_11[\"precision_scores\"]).mean(axis=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6a62f0f1-1ba4-432e-a9c5-537150ea3a59",
   "metadata": {},
   "outputs": [],
   "source": [
    "np.stack(best_seqsignet_attention_umap_11[\"recall_scores\"]).mean(axis=0)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f0787150-8266-48ee-97f5-5f711ce899c7",
   "metadata": {},
   "source": [
    "## Random Projections"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "13a67a66",
   "metadata": {},
   "outputs": [],
   "source": [
    "(\n",
    "    seqsignet_attention_grp_11,\n",
    "    best_seqsignet_attention_grp_11,\n",
    "    _,\n",
    "    __,\n",
    ") = seqsignet_attention_hyperparameter_search(\n",
    "    num_epochs=num_epochs,\n",
    "    df=df_rumours,\n",
    "    id_column=\"timeline_id\",\n",
    "    label_column=\"label\",\n",
    "    embeddings=sbert_embeddings,\n",
    "    y_data=y_data,\n",
    "    output_dim=output_dim,\n",
    "    shift=shift,\n",
    "    window_size=window_size,\n",
    "    n=n,\n",
    "    dim_reduce_methods=[\"gaussian_random_projection\"],\n",
    "    dimensions=dimensions,\n",
    "    log_signature=True,\n",
    "    swmhau_parameters=swmhau_parameters,\n",
    "    num_layers=num_layers,\n",
    "    lstm_hidden_dim_sizes=lstm_hidden_dim_sizes,\n",
    "    ffn_hidden_dim_sizes=ffn_hidden_dim_sizes,\n",
    "    dropout_rates=dropout_rates,\n",
    "    learning_rates=learning_rates,\n",
    "    seeds=seeds,\n",
    "    loss=loss,\n",
    "    gamma=gamma,\n",
    "    device=device,\n",
    "    split_ids=split_ids,\n",
    "    k_fold=True,\n",
    "    features=features,\n",
    "    standardise_method=standardise_method,\n",
    "    include_features_in_path=include_features_in_path,\n",
    "    patience=patience,\n",
    "    validation_metric=validation_metric,\n",
    "    results_output=f\"{output_dir}/seqsignet_attention_grp_focal_{gamma}_{shift}_{window_size}_{n}_kfold.csv\",\n",
    "    verbose=False,\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0ec7c660",
   "metadata": {},
   "outputs": [],
   "source": [
    "seqsignet_attention_grp_11.groupby(\n",
    "    [\n",
    "        \"dimensions\",\n",
    "        \"output_channels\",\n",
    "        \"sig_depth\",\n",
    "        \"num_heads\",\n",
    "        \"num_layers\",\n",
    "        \"ffn_hidden_dim\",\n",
    "        \"dropout_rate\",\n",
    "        \"learning_rate\",\n",
    "    ]\n",
    ").mean()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "603dee18",
   "metadata": {},
   "outputs": [],
   "source": [
    "best_seqsignet_attention_grp_11"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a7a3e5b1-4130-4b3f-a15e-57353492f1d4",
   "metadata": {},
   "outputs": [],
   "source": [
    "best_seqsignet_attention_grp_11.columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e706aad7-e55f-4402-9df8-4e2cb0a0eb82",
   "metadata": {},
   "outputs": [],
   "source": [
    "best_seqsignet_attention_grp_11[\n",
    "    [\n",
    "        \"dimensions\",\n",
    "        \"output_channels\",\n",
    "        \"sig_depth\",\n",
    "        \"num_heads\",\n",
    "        \"num_layers\",\n",
    "        \"ffn_hidden_dim\",\n",
    "        \"dropout_rate\",\n",
    "        \"learning_rate\",\n",
    "    ]\n",
    "]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e9d503c3",
   "metadata": {},
   "outputs": [],
   "source": [
    "best_seqsignet_attention_grp_11[\"f1\"].mean()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f3079077",
   "metadata": {},
   "outputs": [],
   "source": [
    "best_seqsignet_attention_grp_11[\"precision\"].mean()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "eb2894ed",
   "metadata": {},
   "outputs": [],
   "source": [
    "best_seqsignet_attention_grp_11[\"recall\"].mean()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a3e8bbc5",
   "metadata": {},
   "outputs": [],
   "source": [
    "np.stack(best_seqsignet_attention_grp_11[\"f1_scores\"]).mean(axis=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4601b7f2",
   "metadata": {},
   "outputs": [],
   "source": [
    "np.stack(best_seqsignet_attention_grp_11[\"precision_scores\"]).mean(axis=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a3201dd5",
   "metadata": {},
   "outputs": [],
   "source": [
    "np.stack(best_seqsignet_attention_grp_11[\"recall_scores\"]).mean(axis=0)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c81803c8-98e4-4c83-bd10-20aa615443d4",
   "metadata": {
    "tags": []
   },
   "source": [
    "# history_length=20"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "965d96c4-206b-4842-b54e-164ab1e62ba0",
   "metadata": {},
   "outputs": [],
   "source": [
    "shift = 3\n",
    "window_size = 5\n",
    "n = 6"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cf521bdb-e66a-44f1-ab0e-e75cec3b6688",
   "metadata": {},
   "source": [
    "## UMAP"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cbad258f-49e3-48c0-8018-d79157089662",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "(\n",
    "    seqsignet_attention_umap_20,\n",
    "    best_seqsignet_attention_umap_20,\n",
    "    _,\n",
    "    __,\n",
    ") = seqsignet_attention_hyperparameter_search(\n",
    "    num_epochs=num_epochs,\n",
    "    df=df_rumours,\n",
    "    id_column=\"timeline_id\",\n",
    "    label_column=\"label\",\n",
    "    embeddings=sbert_embeddings,\n",
    "    y_data=y_data,\n",
    "    output_dim=output_dim,\n",
    "    shift=shift,\n",
    "    window_size=window_size,\n",
    "    n=n,\n",
    "    dim_reduce_methods=[\"umap\"],\n",
    "    dimensions=dimensions,\n",
    "    log_signature=True,\n",
    "    swmhau_parameters=swmhau_parameters,\n",
    "    num_layers=num_layers,\n",
    "    lstm_hidden_dim_sizes=lstm_hidden_dim_sizes,\n",
    "    ffn_hidden_dim_sizes=ffn_hidden_dim_sizes,\n",
    "    dropout_rates=dropout_rates,\n",
    "    learning_rates=learning_rates,\n",
    "    seeds=seeds,\n",
    "    loss=loss,\n",
    "    gamma=gamma,\n",
    "    device=device,\n",
    "    split_ids=split_ids,\n",
    "    k_fold=True,\n",
    "    features=features,\n",
    "    standardise_method=standardise_method,\n",
    "    include_features_in_path=include_features_in_path,\n",
    "    patience=patience,\n",
    "    validation_metric=validation_metric,\n",
    "    results_output=f\"{output_dir}/seqsignet_attention_umap_focal_{gamma}_{shift}_{window_size}_{n}_kfold.csv\",\n",
    "    verbose=False,\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0e4d99bd-a91d-4d35-9037-3105029b79c2",
   "metadata": {},
   "outputs": [],
   "source": [
    "seqsignet_attention_umap_20.groupby(\n",
    "    [\n",
    "        \"dimensions\",\n",
    "        \"output_channels\",\n",
    "        \"sig_depth\",\n",
    "        \"num_heads\",\n",
    "        \"num_layers\",\n",
    "        \"ffn_hidden_dim\",\n",
    "        \"learning_rate\",\n",
    "    ]\n",
    ").mean()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b12e1066-9535-41e2-920c-a4abc6e81c45",
   "metadata": {},
   "outputs": [],
   "source": [
    "best_seqsignet_attention_umap_20"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7c9b5b77-ffa2-43e3-8779-9d09f82d66f0",
   "metadata": {},
   "outputs": [],
   "source": [
    "best_seqsignet_attention_umap_20[\n",
    "    [\n",
    "        \"dimensions\",\n",
    "        \"output_channels\",\n",
    "        \"sig_depth\",\n",
    "        \"num_heads\",\n",
    "        \"num_layers\",\n",
    "        \"ffn_hidden_dim\",\n",
    "        \"dropout_rate\",\n",
    "        \"learning_rate\",\n",
    "    ]\n",
    "]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3dc123cb-a317-4465-bc8d-bc4f39e0fac0",
   "metadata": {},
   "outputs": [],
   "source": [
    "best_seqsignet_attention_umap_20[\"f1\"].mean()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9800c8d3-7916-4599-899a-80c6e3c82922",
   "metadata": {},
   "outputs": [],
   "source": [
    "best_seqsignet_attention_umap_20[\"precision\"].mean()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "993b65a2-ffbc-42dc-80a3-3cae72f6f048",
   "metadata": {},
   "outputs": [],
   "source": [
    "best_seqsignet_attention_umap_20[\"recall\"].mean()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "518378e7-c54b-4a62-9311-b72c4048a46b",
   "metadata": {},
   "outputs": [],
   "source": [
    "np.stack(best_seqsignet_attention_umap_20[\"f1_scores\"]).mean(axis=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "072e1e50-94f6-45f7-a42d-5dfcc600811b",
   "metadata": {},
   "outputs": [],
   "source": [
    "np.stack(best_seqsignet_attention_umap_20[\"precision_scores\"]).mean(axis=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f0f37b83-22c7-4d02-bced-f8619d594716",
   "metadata": {},
   "outputs": [],
   "source": [
    "np.stack(best_seqsignet_attention_umap_20[\"recall_scores\"]).mean(axis=0)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "dbd41486-2ef0-4663-9eb9-fae32edab339",
   "metadata": {},
   "source": [
    "## Random Projections"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a632f791-38ff-49f2-bce1-1b3453d67c15",
   "metadata": {},
   "outputs": [],
   "source": [
    "(\n",
    "    seqsignet_attention_grp_20,\n",
    "    best_seqsignet_attention_grp_20,\n",
    "    _,\n",
    "    __,\n",
    ") = seqsignet_attention_hyperparameter_search(\n",
    "    num_epochs=num_epochs,\n",
    "    df=df_rumours,\n",
    "    id_column=\"timeline_id\",\n",
    "    label_column=\"label\",\n",
    "    embeddings=sbert_embeddings,\n",
    "    y_data=y_data,\n",
    "    output_dim=output_dim,\n",
    "    shift=shift,\n",
    "    window_size=window_size,\n",
    "    n=n,\n",
    "    dim_reduce_methods=[\"gaussian_random_projection\"],\n",
    "    dimensions=dimensions,\n",
    "    log_signature=True,\n",
    "    swmhau_parameters=swmhau_parameters,\n",
    "    num_layers=num_layers,\n",
    "    lstm_hidden_dim_sizes=lstm_hidden_dim_sizes,\n",
    "    ffn_hidden_dim_sizes=ffn_hidden_dim_sizes,\n",
    "    dropout_rates=dropout_rates,\n",
    "    learning_rates=learning_rates,\n",
    "    seeds=seeds,\n",
    "    loss=loss,\n",
    "    gamma=gamma,\n",
    "    device=device,\n",
    "    split_ids=split_ids,\n",
    "    k_fold=True,\n",
    "    features=features,\n",
    "    standardise_method=standardise_method,\n",
    "    include_features_in_path=include_features_in_path,\n",
    "    patience=patience,\n",
    "    validation_metric=validation_metric,\n",
    "    results_output=f\"{output_dir}/seqsignet_attention_grp_focal_{gamma}_{shift}_{window_size}_{n}_kfold.csv\",\n",
    "    verbose=False,\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d1d73e6e-2903-454f-ad50-1be853de1898",
   "metadata": {},
   "outputs": [],
   "source": [
    "seqsignet_attention_grp_20.groupby(\n",
    "    [\n",
    "        \"dimensions\",\n",
    "        \"output_channels\",\n",
    "        \"sig_depth\",\n",
    "        \"num_heads\",\n",
    "        \"num_layers\",\n",
    "        \"ffn_hidden_dim\",\n",
    "        \"dropout_rate\",\n",
    "        \"learning_rate\",\n",
    "    ]\n",
    ").mean()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "005101e0-df1f-4f29-82ba-4b18e04169a0",
   "metadata": {},
   "outputs": [],
   "source": [
    "best_seqsignet_attention_grp_20"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "034669d5-7cdb-4ed6-9929-82cd4ca25893",
   "metadata": {},
   "outputs": [],
   "source": [
    "best_seqsignet_attention_grp_20.columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "479f5418-79e4-4c42-a72a-67253f34ef88",
   "metadata": {},
   "outputs": [],
   "source": [
    "best_seqsignet_attention_grp_20[\n",
    "    [\n",
    "        \"dimensions\",\n",
    "        \"output_channels\",\n",
    "        \"sig_depth\",\n",
    "        \"num_heads\",\n",
    "        \"num_layers\",\n",
    "        \"ffn_hidden_dim\",\n",
    "        \"dropout_rate\",\n",
    "        \"learning_rate\",\n",
    "    ]\n",
    "]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "05e0364c-531c-4548-b706-301d852e11ca",
   "metadata": {},
   "outputs": [],
   "source": [
    "best_seqsignet_attention_grp_20[\"f1\"].mean()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5b5062e0-1005-456f-a78d-49a2d9c6dc60",
   "metadata": {},
   "outputs": [],
   "source": [
    "best_seqsignet_attention_grp_20[\"precision\"].mean()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1e4f9590-2916-4b2d-966f-e224cbc7175e",
   "metadata": {},
   "outputs": [],
   "source": [
    "best_seqsignet_attention_grp_20[\"recall\"].mean()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e2eec31c-c0b5-4a51-9277-973de3223f1c",
   "metadata": {},
   "outputs": [],
   "source": [
    "np.stack(best_seqsignet_attention_grp_20[\"f1_scores\"]).mean(axis=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fe7f5668-f54b-49ee-836d-2c016de127f1",
   "metadata": {},
   "outputs": [],
   "source": [
    "np.stack(best_seqsignet_attention_grp_20[\"precision_scores\"]).mean(axis=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b94b26ce-ff9b-4215-afc4-72b656a31eea",
   "metadata": {},
   "outputs": [],
   "source": [
    "np.stack(best_seqsignet_attention_grp_20[\"recall_scores\"]).mean(axis=0)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e7ef749b-d4b3-4ade-9e94-0235d7580cfd",
   "metadata": {
    "tags": []
   },
   "source": [
    "# history_length=35"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8d5cfef8-0d7b-4324-8cd7-29bb95e3c77a",
   "metadata": {},
   "outputs": [],
   "source": [
    "shift = 3\n",
    "window_size = 5\n",
    "n = 11"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b604e467-1c61-4037-bc7c-46bef7f3eb52",
   "metadata": {},
   "source": [
    "## UMAP"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "164fceff-7055-41a4-9bad-f00224dc8457",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "(\n",
    "    seqsignet_attention_umap_35,\n",
    "    best_seqsignet_attention_umap_35,\n",
    "    _,\n",
    "    __,\n",
    ") = seqsignet_attention_hyperparameter_search(\n",
    "    num_epochs=num_epochs,\n",
    "    df=df_rumours,\n",
    "    id_column=\"timeline_id\",\n",
    "    label_column=\"label\",\n",
    "    embeddings=sbert_embeddings,\n",
    "    y_data=y_data,\n",
    "    output_dim=output_dim,\n",
    "    shift=shift,\n",
    "    window_size=window_size,\n",
    "    n=n,\n",
    "    dim_reduce_methods=[\"umap\"],\n",
    "    dimensions=dimensions,\n",
    "    log_signature=True,\n",
    "    swmhau_parameters=swmhau_parameters,\n",
    "    num_layers=num_layers,\n",
    "    lstm_hidden_dim_sizes=lstm_hidden_dim_sizes,\n",
    "    ffn_hidden_dim_sizes=ffn_hidden_dim_sizes,\n",
    "    dropout_rates=dropout_rates,\n",
    "    learning_rates=learning_rates,\n",
    "    seeds=seeds,\n",
    "    loss=loss,\n",
    "    gamma=gamma,\n",
    "    device=device,\n",
    "    split_ids=split_ids,\n",
    "    k_fold=True,\n",
    "    features=features,\n",
    "    standardise_method=standardise_method,\n",
    "    include_features_in_path=include_features_in_path,\n",
    "    patience=patience,\n",
    "    validation_metric=validation_metric,\n",
    "    results_output=f\"{output_dir}/seqsignet_attention_umap_focal_{gamma}_{shift}_{window_size}_{n}_kfold.csv\",\n",
    "    verbose=False,\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b9cba4a4-da68-4185-b139-c137557be7d7",
   "metadata": {},
   "outputs": [],
   "source": [
    "seqsignet_attention_umap_35.groupby(\n",
    "    [\n",
    "        \"dimensions\",\n",
    "        \"output_channels\",\n",
    "        \"sig_depth\",\n",
    "        \"num_heads\",\n",
    "        \"num_layers\",\n",
    "        \"ffn_hidden_dim\",\n",
    "        \"learning_rate\",\n",
    "    ]\n",
    ").mean()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "af0a3959-647d-4b9a-982b-ec369551c705",
   "metadata": {},
   "outputs": [],
   "source": [
    "best_seqsignet_attention_umap_35"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "36f776fa-778c-4407-83c5-f8d3f915ed8a",
   "metadata": {},
   "outputs": [],
   "source": [
    "best_seqsignet_attention_umap_35[\n",
    "    [\n",
    "        \"dimensions\",\n",
    "        \"output_channels\",\n",
    "        \"sig_depth\",\n",
    "        \"num_heads\",\n",
    "        \"num_layers\",\n",
    "        \"ffn_hidden_dim\",\n",
    "        \"dropout_rate\",\n",
    "        \"learning_rate\",\n",
    "    ]\n",
    "]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e34db780-67b5-41a1-be6d-777c5767e052",
   "metadata": {},
   "outputs": [],
   "source": [
    "best_seqsignet_attention_umap_35[\"f1\"].mean()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "192cbd3a-2a7a-4794-9757-17529454787a",
   "metadata": {},
   "outputs": [],
   "source": [
    "best_seqsignet_attention_umap_35[\"precision\"].mean()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "389d80c2-2d3c-434b-b27c-47806b952a4a",
   "metadata": {},
   "outputs": [],
   "source": [
    "best_seqsignet_attention_umap_35[\"recall\"].mean()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5fd9f864-1b9c-4d53-875c-457dc73bab6e",
   "metadata": {},
   "outputs": [],
   "source": [
    "np.stack(best_seqsignet_attention_umap_35[\"f1_scores\"]).mean(axis=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8d14fa50-74b3-4195-a530-c62487b65749",
   "metadata": {},
   "outputs": [],
   "source": [
    "np.stack(best_seqsignet_attention_umap_35[\"precision_scores\"]).mean(axis=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9514df33-20b7-49c2-a9f6-13abf8f7725a",
   "metadata": {},
   "outputs": [],
   "source": [
    "np.stack(best_seqsignet_attention_umap_35[\"recall_scores\"]).mean(axis=0)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c6d834fa-f3c7-4c78-9ce4-717f573e0af4",
   "metadata": {},
   "source": [
    "## Random Projections"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "63265bf4-3fde-4328-b234-1b955dc0b2fb",
   "metadata": {},
   "outputs": [],
   "source": [
    "(\n",
    "    seqsignet_attention_grp_35,\n",
    "    best_seqsignet_attention_grp_35,\n",
    "    _,\n",
    "    __,\n",
    ") = seqsignet_attention_hyperparameter_search(\n",
    "    num_epochs=num_epochs,\n",
    "    df=df_rumours,\n",
    "    id_column=\"timeline_id\",\n",
    "    label_column=\"label\",\n",
    "    embeddings=sbert_embeddings,\n",
    "    y_data=y_data,\n",
    "    output_dim=output_dim,\n",
    "    shift=shift,\n",
    "    window_size=window_size,\n",
    "    n=n,\n",
    "    dim_reduce_methods=[\"gaussian_random_projection\"],\n",
    "    dimensions=dimensions,\n",
    "    log_signature=True,\n",
    "    swmhau_parameters=swmhau_parameters,\n",
    "    num_layers=num_layers,\n",
    "    lstm_hidden_dim_sizes=lstm_hidden_dim_sizes,\n",
    "    ffn_hidden_dim_sizes=ffn_hidden_dim_sizes,\n",
    "    dropout_rates=dropout_rates,\n",
    "    learning_rates=learning_rates,\n",
    "    seeds=seeds,\n",
    "    loss=loss,\n",
    "    gamma=gamma,\n",
    "    device=device,\n",
    "    split_ids=split_ids,\n",
    "    k_fold=True,\n",
    "    features=features,\n",
    "    standardise_method=standardise_method,\n",
    "    include_features_in_path=include_features_in_path,\n",
    "    patience=patience,\n",
    "    validation_metric=validation_metric,\n",
    "    results_output=f\"{output_dir}/seqsignet_attention_grp_focal_{gamma}_{shift}_{window_size}_{n}_kfold.csv\",\n",
    "    verbose=False,\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6359db47-ec12-4a44-9566-2b1dbefbe0f2",
   "metadata": {},
   "outputs": [],
   "source": [
    "seqsignet_attention_grp_35.groupby(\n",
    "    [\n",
    "        \"dimensions\",\n",
    "        \"output_channels\",\n",
    "        \"sig_depth\",\n",
    "        \"num_heads\",\n",
    "        \"num_layers\",\n",
    "        \"ffn_hidden_dim\",\n",
    "        \"dropout_rate\",\n",
    "        \"learning_rate\",\n",
    "    ]\n",
    ").mean()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "080d2396-26c9-4de8-b527-01d065cb37ff",
   "metadata": {},
   "outputs": [],
   "source": [
    "best_seqsignet_attention_grp_35"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2cca028e-a673-437c-9b51-60965630c67d",
   "metadata": {},
   "outputs": [],
   "source": [
    "best_seqsignet_attention_grp_35.columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "dc373678-f928-445c-b257-d23883eb1be6",
   "metadata": {},
   "outputs": [],
   "source": [
    "best_seqsignet_attention_grp_35[\n",
    "    [\n",
    "        \"dimensions\",\n",
    "        \"output_channels\",\n",
    "        \"sig_depth\",\n",
    "        \"num_heads\",\n",
    "        \"num_layers\",\n",
    "        \"ffn_hidden_dim\",\n",
    "        \"dropout_rate\",\n",
    "        \"learning_rate\",\n",
    "    ]\n",
    "]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "efb8e85b-e9f7-4640-a709-afc118c14e98",
   "metadata": {},
   "outputs": [],
   "source": [
    "best_seqsignet_attention_grp_35[\"f1\"].mean()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cacb1afc-22e1-4b2e-a209-d2e76954f0d9",
   "metadata": {},
   "outputs": [],
   "source": [
    "best_seqsignet_attention_grp_35[\"precision\"].mean()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7df27a7e-285f-4a53-ac59-74def9f4e49f",
   "metadata": {},
   "outputs": [],
   "source": [
    "best_seqsignet_attention_grp_35[\"recall\"].mean()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ebdf81d9-3301-4f3b-aa88-5c09d4b2490b",
   "metadata": {},
   "outputs": [],
   "source": [
    "np.stack(best_seqsignet_attention_grp_35[\"f1_scores\"]).mean(axis=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9b22b04c-ccd0-4fb7-9da4-bd3131ace666",
   "metadata": {},
   "outputs": [],
   "source": [
    "np.stack(best_seqsignet_attention_grp_35[\"precision_scores\"]).mean(axis=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "eca96477-2f59-40eb-8732-8ad023be37f1",
   "metadata": {},
   "outputs": [],
   "source": [
    "np.stack(best_seqsignet_attention_grp_35[\"recall_scores\"]).mean(axis=0)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e224d684-9ff0-459a-ba03-8e8853fb50de",
   "metadata": {
    "tags": []
   },
   "source": [
    "# history_length=80"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f7802347-e3fd-4898-8a6c-ccbbe6120dfe",
   "metadata": {},
   "outputs": [],
   "source": [
    "shift = 3\n",
    "window_size = 5\n",
    "n = 26"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f48541cb-6ef2-47da-95ac-1156ca2b2195",
   "metadata": {},
   "source": [
    "## UMAP"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "44da905a-8a16-419a-be32-000de8a57810",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "(\n",
    "    seqsignet_attention_umap_80,\n",
    "    best_seqsignet_attention_umap_80,\n",
    "    _,\n",
    "    __,\n",
    ") = seqsignet_attention_hyperparameter_search(\n",
    "    num_epochs=num_epochs,\n",
    "    df=df_rumours,\n",
    "    id_column=\"timeline_id\",\n",
    "    label_column=\"label\",\n",
    "    embeddings=sbert_embeddings,\n",
    "    y_data=y_data,\n",
    "    output_dim=output_dim,\n",
    "    shift=shift,\n",
    "    window_size=window_size,\n",
    "    n=n,\n",
    "    dim_reduce_methods=[\"umap\"],\n",
    "    dimensions=dimensions,\n",
    "    log_signature=True,\n",
    "    swmhau_parameters=swmhau_parameters,\n",
    "    num_layers=num_layers,\n",
    "    lstm_hidden_dim_sizes=lstm_hidden_dim_sizes,\n",
    "    ffn_hidden_dim_sizes=ffn_hidden_dim_sizes,\n",
    "    dropout_rates=dropout_rates,\n",
    "    learning_rates=learning_rates,\n",
    "    seeds=seeds,\n",
    "    loss=loss,\n",
    "    gamma=gamma,\n",
    "    device=device,\n",
    "    split_ids=split_ids,\n",
    "    k_fold=True,\n",
    "    features=features,\n",
    "    standardise_method=standardise_method,\n",
    "    include_features_in_path=include_features_in_path,\n",
    "    patience=patience,\n",
    "    validation_metric=validation_metric,\n",
    "    results_output=f\"{output_dir}/seqsignet_attention_umap_focal_{gamma}_{shift}_{window_size}_{n}_kfold.csv\",\n",
    "    verbose=False,\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "54b5a51b-bafc-4fbe-a62d-b5b43fa55c1e",
   "metadata": {},
   "outputs": [],
   "source": [
    "seqsignet_attention_umap_80.groupby(\n",
    "    [\n",
    "        \"dimensions\",\n",
    "        \"output_channels\",\n",
    "        \"sig_depth\",\n",
    "        \"num_heads\",\n",
    "        \"num_layers\",\n",
    "        \"ffn_hidden_dim\",\n",
    "        \"learning_rate\",\n",
    "    ]\n",
    ").mean()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cb239104-e394-4fc4-8efe-e6c17ed97400",
   "metadata": {},
   "outputs": [],
   "source": [
    "best_seqsignet_attention_umap_80"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0326ade1-36a6-48c8-926e-6f8a1f52f685",
   "metadata": {},
   "outputs": [],
   "source": [
    "best_seqsignet_attention_umap_80[\n",
    "    [\n",
    "        \"dimensions\",\n",
    "        \"output_channels\",\n",
    "        \"sig_depth\",\n",
    "        \"num_heads\",\n",
    "        \"num_layers\",\n",
    "        \"ffn_hidden_dim\",\n",
    "        \"dropout_rate\",\n",
    "        \"learning_rate\",\n",
    "    ]\n",
    "]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f51bb8d5-097b-4b30-affa-77e32293d6b0",
   "metadata": {},
   "outputs": [],
   "source": [
    "best_seqsignet_attention_umap_80[\"f1\"].mean()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c2e9dcf2-8a1e-4046-acaf-1766f2dfae04",
   "metadata": {},
   "outputs": [],
   "source": [
    "best_seqsignet_attention_umap_80[\"precision\"].mean()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f1dac213-232a-4089-8870-a5ecd329e57e",
   "metadata": {},
   "outputs": [],
   "source": [
    "best_seqsignet_attention_umap_80[\"recall\"].mean()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6aec6058-559e-4e6d-b8dc-71ed42fd8aff",
   "metadata": {},
   "outputs": [],
   "source": [
    "np.stack(best_seqsignet_attention_umap_80[\"f1_scores\"]).mean(axis=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b968437b-271e-4226-98f0-84aa0b05e12a",
   "metadata": {},
   "outputs": [],
   "source": [
    "np.stack(best_seqsignet_attention_umap_80[\"precision_scores\"]).mean(axis=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "06390249-340e-4653-a9bd-475fa34fd8be",
   "metadata": {},
   "outputs": [],
   "source": [
    "np.stack(best_seqsignet_attention_umap_80[\"recall_scores\"]).mean(axis=0)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "aebd5695-92e3-4190-a534-e63ecef6dfdf",
   "metadata": {},
   "source": [
    "## Random Projections"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4e98bb45-e549-47d5-86b1-c172f37927a3",
   "metadata": {},
   "outputs": [],
   "source": [
    "(\n",
    "    seqsignet_attention_grp_80,\n",
    "    best_seqsignet_attention_grp_80,\n",
    "    _,\n",
    "    __,\n",
    ") = seqsignet_attention_hyperparameter_search(\n",
    "    num_epochs=num_epochs,\n",
    "    df=df_rumours,\n",
    "    id_column=\"timeline_id\",\n",
    "    label_column=\"label\",\n",
    "    embeddings=sbert_embeddings,\n",
    "    y_data=y_data,\n",
    "    output_dim=output_dim,\n",
    "    shift=shift,\n",
    "    window_size=window_size,\n",
    "    n=n,\n",
    "    dim_reduce_methods=[\"gaussian_random_projection\"],\n",
    "    dimensions=dimensions,\n",
    "    log_signature=True,\n",
    "    swmhau_parameters=swmhau_parameters,\n",
    "    num_layers=num_layers,\n",
    "    lstm_hidden_dim_sizes=lstm_hidden_dim_sizes,\n",
    "    ffn_hidden_dim_sizes=ffn_hidden_dim_sizes,\n",
    "    dropout_rates=dropout_rates,\n",
    "    learning_rates=learning_rates,\n",
    "    seeds=seeds,\n",
    "    loss=loss,\n",
    "    gamma=gamma,\n",
    "    device=device,\n",
    "    split_ids=split_ids,\n",
    "    k_fold=True,\n",
    "    features=features,\n",
    "    standardise_method=standardise_method,\n",
    "    include_features_in_path=include_features_in_path,\n",
    "    patience=patience,\n",
    "    validation_metric=validation_metric,\n",
    "    results_output=f\"{output_dir}/seqsignet_attention_grp_focal_{gamma}_{shift}_{window_size}_{n}_kfold.csv\",\n",
    "    verbose=False,\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7a0108b3-42a8-4d43-bfb7-b7ee494cdecb",
   "metadata": {},
   "outputs": [],
   "source": [
    "seqsignet_attention_grp_80.groupby(\n",
    "    [\n",
    "        \"dimensions\",\n",
    "        \"output_channels\",\n",
    "        \"sig_depth\",\n",
    "        \"num_heads\",\n",
    "        \"num_layers\",\n",
    "        \"ffn_hidden_dim\",\n",
    "        \"dropout_rate\",\n",
    "        \"learning_rate\",\n",
    "    ]\n",
    ").mean()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c06eeff4-d239-4e57-a982-afebea14314e",
   "metadata": {},
   "outputs": [],
   "source": [
    "best_seqsignet_attention_grp_80"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e89c5d1b-e53e-4195-8e29-76213c4c5be3",
   "metadata": {},
   "outputs": [],
   "source": [
    "best_seqsignet_attention_grp_80.columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "37ed0e9c-fe51-4700-8e85-716a79c1c636",
   "metadata": {},
   "outputs": [],
   "source": [
    "best_seqsignet_attention_grp_80[\n",
    "    [\n",
    "        \"dimensions\",\n",
    "        \"output_channels\",\n",
    "        \"sig_depth\",\n",
    "        \"num_heads\",\n",
    "        \"num_layers\",\n",
    "        \"ffn_hidden_dim\",\n",
    "        \"dropout_rate\",\n",
    "        \"learning_rate\",\n",
    "    ]\n",
    "]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cd7097c2-68fe-40f4-9b91-852eb4bc8a83",
   "metadata": {},
   "outputs": [],
   "source": [
    "best_seqsignet_attention_grp_80[\"f1\"].mean()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "eb95f40f-9543-4655-ba3b-f8e4ce921a60",
   "metadata": {},
   "outputs": [],
   "source": [
    "best_seqsignet_attention_grp_80[\"precision\"].mean()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "807e9a8c-8156-4650-89ed-21138c37f414",
   "metadata": {},
   "outputs": [],
   "source": [
    "best_seqsignet_attention_grp_80[\"recall\"].mean()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "aef44d1b-e95b-4dea-97d6-f6ee5c0e9a37",
   "metadata": {},
   "outputs": [],
   "source": [
    "np.stack(best_seqsignet_attention_grp_80[\"f1_scores\"]).mean(axis=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d0e0195e-90b6-4318-a879-78f420ca2a54",
   "metadata": {},
   "outputs": [],
   "source": [
    "np.stack(best_seqsignet_attention_grp_80[\"precision_scores\"]).mean(axis=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d2594667-041e-4961-a2b8-96fb0d205b95",
   "metadata": {},
   "outputs": [],
   "source": [
    "np.stack(best_seqsignet_attention_grp_80[\"recall_scores\"]).mean(axis=0)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "nlpsig-networks (Conda)",
   "language": "python",
   "name": "sys_nlpsig-networks"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.17"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
